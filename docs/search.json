[{"path":"index.html","id":"ders-hakkında","chapter":"Ders Hakkında","heading":"Ders Hakkında","text":"Bu dersin amacı, R yazılımını kullanarak veri üzerinde istenilen çok değişkenli istatistiksel ve psikometrik işlemlerin yapılabilmesini sağlamaktır.Tez ve makale çalışmalarında öğrencilerimizin analizlerini R yazılımı ile hiçbir paket programa ihtiyaç duymadan kendi başlarına yapmalarını sağlamaktır.Ders İçeriği:Çok değişkenli İstatistik VarsayımlarıÇoklu RegresyonYol AnaliziAçımlayıcı Faktör AnaliziDoğrulayıcı Faktör AnaliziProgralamaya GirişKlasik Test KuramıMadde Tepki KuramıVeri Üretimi","code":""},{"path":"index.html","id":"eğitmen","chapter":"Ders Hakkında","heading":"Eğitmen","text":"Dr. Kübra Atalay Kabasakalkkatalay@gmail.comkatalay@hacettepe.edu.tr","code":""},{"path":"index.html","id":"kitaplar","chapter":"Ders Hakkında","heading":"Kitaplar","text":"Atar, B., Atalay Kabasakal, K, Unsal Ozberk, E. B., Ozberk, E. H. & Kibrislioglu Uysal, N. (2020). R ile Veri Analizi ve Psikometri Uygulamaları, Pegem Akademi, Ankara.🔗 📖Atar, B., Atalay Kabasakal, K, Unsal Ozberk, E. B., Ozberk, E. H. & Kibrislioglu Uysal, N. (2020). R ile Veri Analizi ve Psikometri Uygulamaları, Pegem Akademi, Ankara.🔗 📖Desjardins, C. D., & Bulut, O. (2018). Handbook educational measurement psychometrics using R. Boca Raton, FL: CRC Press. 🔗📖Desjardins, C. D., & Bulut, O. (2018). Handbook educational measurement psychometrics using R. Boca Raton, FL: CRC Press. 🔗📖Demir, E. R Diliyle İstatistik Uygulamaları. Pegem Akademi, Ankara.(2021). 🔗📖Demir, E. R Diliyle İstatistik Uygulamaları. Pegem Akademi, Ankara.(2021). 🔗📖Kline,R. B. (2019). Yapısal Eşitlik Modellemesinin İlkeleri ve Uygulaması(4. Baskı). (S. Şen, Çev.) Ankara: Nobel Yayınevi.Kline,R. B. (2019). Yapısal Eşitlik Modellemesinin İlkeleri ve Uygulaması(4. Baskı). (S. Şen, Çev.) Ankara: Nobel Yayınevi.Şen, S. (2020). Mplus ile Yapısal Eşitlik Modellemesi Uygulamaları (2020).Nobel Yayınevi.Şen, S. (2020). Mplus ile Yapısal Eşitlik Modellemesi Uygulamaları (2020).Nobel Yayınevi.Tabachnick, B. G., & Fidell, L. S. (2012). Using Multivariate Statistics (4rd ed.). New York: Harper Collins.Tabachnick, B. G., & Fidell, L. S. (2012). Using Multivariate Statistics (4rd ed.). New York: Harper Collins.Wolf, E. J., Harrington, K. M., Clark, S. L., & Miller, M. W. (2013). Sample Size Requirements Structural Equation Models: Evaluation Power, Bias, Solution Propriety. Educational Psychological Measurement, 73(6), 913–934. https://doi.org/10.1177/0013164413495237Wolf, E. J., Harrington, K. M., Clark, S. L., & Miller, M. W. (2013). Sample Size Requirements Structural Equation Models: Evaluation Power, Bias, Solution Propriety. Educational Psychological Measurement, 73(6), 913–934. https://doi.org/10.1177/0013164413495237","code":""},{"path":"varsayımlar-i.html","id":"varsayımlar-i","chapter":"Bölüm 1 Varsayımlar I","heading":"Bölüm 1 Varsayımlar I","text":"Veri Dosyasındaki Verinin DoğruluğuVeri Dosyasındaki Verinin DoğruluğuKayıp Verinin Miktarı ve DağılımıKayıp Verinin Miktarı ve DağılımıTek Değişkenli ve Çok Değişkenli Uç Değerler (Outliers)Tek Değişkenli ve Çok Değişkenli Uç Değerler (Outliers)SayıltılarSayıltılarÇoklu Bağlantı (Multicollinearity) ve Tekillik (Singularity)Çoklu Bağlantı (Multicollinearity) ve Tekillik (Singularity)","code":""},{"path":"varsayımlar-i.html","id":"veri-inceleme","chapter":"Bölüm 1 Varsayımlar I","heading":"1.1 Veri İnceleme","text":"Varsayımlar incelenirken ilk olarak yanlış girilmiş bir değer olup\nolmadığına bakılmalıdır.Varsayımlar incelenirken ilk olarak yanlış girilmiş bir değer olup\nolmadığına bakılmalıdır.Bu bölümde 🔗 SCREEN.SAV adlı\nveri seti kullanılmıştır. Bu veri setinde 20-59 yaşları arasında 465\nkadının 6 değişkene ilişkin bilgileri bulunmaktadır. Değişkenlerden\ntimedrs, attdrug, atthouse ve income değişkenleri sürekli, mstatus\nve race değişkenleriyse iki kategorili değişkenlerdir. Bu veri seti\nTabachnick, B. G., & Fidell, L. S. (2012). Using Multivariate\nStatistics (4rd ed.). New York: Harper Collins. kitabının 4.\nbölümünde kullanılmaktadır.Bu bölümde 🔗 SCREEN.SAV adlı\nveri seti kullanılmıştır. Bu veri setinde 20-59 yaşları arasında 465\nkadının 6 değişkene ilişkin bilgileri bulunmaktadır. Değişkenlerden\ntimedrs, attdrug, atthouse ve income değişkenleri sürekli, mstatus\nve race değişkenleriyse iki kategorili değişkenlerdir. Bu veri seti\nTabachnick, B. G., & Fidell, L. S. (2012). Using Multivariate\nStatistics (4rd ed.). New York: Harper Collins. kitabının 4.\nbölümünde kullanılmaktadır.Veri incelemede birden fazla paket kullanılabilir. En temel\nfonksiyon base paketin summary() fonksiyonudur. psych\npaketinde describe() fonksiyonu da aynı amaçla kullanılabilir.Veri incelemede birden fazla paket kullanılabilir. En temel\nfonksiyon base paketin summary() fonksiyonudur. psych\npaketinde describe() fonksiyonu da aynı amaçla kullanılabilir.Veri setindeki maksimum ve minumum değerleri belirlenmiştir.Elde edilen değerlerin makul olduğu söylenebilir. Ancak bunu elde\netmek için başka yollar da bulunmaktadır. psych paketi ile\ninceleme daha ayrıntılı yapılabilir.🔗 personality-project\nsayfasını daha fazla örnek\niçin inceleyebilirsiniz.gtsummary paketi ile inceleme🔗[Presentation-Ready Summary Tables] \ngtsummary(https://education.rstudio.com/blog/2020/07/gtsummary)🔗[Presentation-Ready Summary Tables] \ngtsummary(https://education.rstudio.com/blog/2020/07/gtsummary)vtable paketi ile incelemevtable paketi ile inceleme\nTablo 1.1: Summary Statistics\n🔗 vtable paketi için\nörnekler🔗 vtable paketi için\nörneklersütun isimleri aşağıdaki gibi değiştirilebilir.sütun isimleri aşağıdaki gibi değiştirilebilir.\nTablo 1.2: Summary Statistics\nkable paketi ile psych paketi çıktılarını düzenlemeTablo 1.3: Betimsel İstatistikler🔗\nrmarkdown-cookbook","code":"\nlibrary(haven)\nscreen <- read_sav(\"import/SCREEN.sav\")\nhead(screen)\nsummary(screen)##      subno          timedrs          attdrug          atthouse    \n##  Min.   :  1.0   Min.   : 0.000   Min.   : 5.000   Min.   : 2.00  \n##  1st Qu.:137.0   1st Qu.: 2.000   1st Qu.: 7.000   1st Qu.:21.00  \n##  Median :314.0   Median : 4.000   Median : 8.000   Median :24.00  \n##  Mean   :317.4   Mean   : 7.901   Mean   : 7.686   Mean   :23.54  \n##  3rd Qu.:483.0   3rd Qu.:10.000   3rd Qu.: 9.000   3rd Qu.:27.00  \n##  Max.   :758.0   Max.   :81.000   Max.   :10.000   Max.   :35.00  \n##                                                    NA's   :1      \n##      income         mstatus           race      \n##  Min.   : 1.00   Min.   :1.000   Min.   :1.000  \n##  1st Qu.: 2.50   1st Qu.:2.000   1st Qu.:1.000  \n##  Median : 4.00   Median :2.000   Median :1.000  \n##  Mean   : 4.21   Mean   :1.778   Mean   :1.088  \n##  3rd Qu.: 6.00   3rd Qu.:2.000   3rd Qu.:1.000  \n##  Max.   :10.00   Max.   :2.000   Max.   :2.000  \n##  NA's   :26\nlibrary(psych)## Warning: package 'psych' was built under R version 4.3.3## \n## Attaching package: 'psych'## The following objects are masked from 'package:ggplot2':\n## \n##     %+%, alpha\nround(describe(screen[,-1]),2)\nlibrary(gtsummary)\nscreen %>% select(2:6) %>%tbl_summary(statistic = all_continuous() ~ c(\n\"{min}, {max}\"),missing =\"always\")\nlibrary(vtable)\nsumtable(screen, summ=c('notNA(x)','min(x)','max(x)'))\nsumtable(screen, summ = c('notNA(x)','min(x)','max(x)'),\n         summ.names = c('Frekans'\n,'Minimum','Maksimum'))\nozet <- describe(screen[,-1])\nkable(ozet,format='markdown',\n      caption=\"Betimsel İstatistikler\",digits=2)"},{"path":"varsayımlar-i.html","id":"kayıp-değerler","chapter":"Bölüm 1 Varsayımlar I","heading":"1.2 Kayıp Değerler","text":"Kayıp veri, veri analizindeki en yaygın problemlerden biridir.Kayıp veri, veri analizindeki en yaygın problemlerden biridir.Kayıp verinin önemi kayıp verinin miktarına, örüntüsüne ve neden\neksik olduğuna bağlıdır.Kayıp verinin önemi kayıp verinin miktarına, örüntüsüne ve neden\neksik olduğuna bağlıdır.Bir değişkene ait beklenmeyen miktarda kayıp veri varsa, ilk olarak\nbunun nedeni araştırılmalıdır. Daha sonra kayıp verinin örüntüsüne\nbakılarak, rastlantısal mı yoksa sistematik bir örüntü mü gösterdiği\nbelirlenmelidir.\nÖrneğin, 30 yaşın üstündeki birçok kadın yaş ile ilgili soruyu\ncevaplamak istemezler.\nBir değişkene ait beklenmeyen miktarda kayıp veri varsa, ilk olarak\nbunun nedeni araştırılmalıdır. Daha sonra kayıp verinin örüntüsüne\nbakılarak, rastlantısal mı yoksa sistematik bir örüntü mü gösterdiği\nbelirlenmelidir.Örneğin, 30 yaşın üstündeki birçok kadın yaş ile ilgili soruyu\ncevaplamak istemezler.Genellikle kayıp verinin örüntüsü miktarından daha önemlidir.\nRastlantısal dağılmayan kayıp veriler sonuçların\ngenellenebilirliğini etkileyeceğinden miktarları az da olsa,\nrastlantısal dağılan kayıp verilere oranla daha ciddi problemlere\nyol açarlar.Genellikle kayıp verinin örüntüsü miktarından daha önemlidir.\nRastlantısal dağılmayan kayıp veriler sonuçların\ngenellenebilirliğini etkileyeceğinden miktarları az da olsa,\nrastlantısal dağılan kayıp verilere oranla daha ciddi problemlere\nyol açarlar.","code":""},{"path":"varsayımlar-i.html","id":"kayıp-veri-türleri","chapter":"Bölüm 1 Varsayımlar I","heading":"1.3 Kayıp Veri Türleri","text":"Kayıp veri türleri arasındaki ayrım 1976 yılında Rubin tarafından\nyapılmıştır. Rubin (1976) kayıp veriyi aşağıdaki şekilde\nsınıflandırmıştır.\nTamamen Rastgele Olarak Kayıp (TRK) - Missing Completely \nRandom MCAR\nRastgele Kayıp (RK) - Missing Random (MAR)\nRastgele Olmayan Kayıp / İhmal Edilemez Kayıp (ROK) - \nMissing Random (NMAR)\nKayıp veri türleri arasındaki ayrım 1976 yılında Rubin tarafından\nyapılmıştır. Rubin (1976) kayıp veriyi aşağıdaki şekilde\nsınıflandırmıştır.Tamamen Rastgele Olarak Kayıp (TRK) - Missing Completely \nRandom MCARTamamen Rastgele Olarak Kayıp (TRK) - Missing Completely \nRandom MCARRastgele Kayıp (RK) - Missing Random (MAR)Rastgele Kayıp (RK) - Missing Random (MAR)Rastgele Olmayan Kayıp / İhmal Edilemez Kayıp (ROK) - \nMissing Random (NMAR)Rastgele Olmayan Kayıp / İhmal Edilemez Kayıp (ROK) - \nMissing Random (NMAR)Kayıp veri en azından MAR türünde değilse, kayıp verinin ihmal\nedilemeyeceği söylenir. Bu türdeki kayıp veri rastlantısal olamyan\nkayıp veya ihmal edilemez kayıp olarak adlandırılır.Kayıp veri en azından MAR türünde değilse, kayıp verinin ihmal\nedilemeyeceği söylenir. Bu türdeki kayıp veri rastlantısal olamyan\nkayıp veya ihmal edilemez kayıp olarak adlandırılır.Büyük bir veri setinde, verinin %5’veya daha azı rastlantısal\nolarak kayıpsa çok ciddi problemlerle karşılaşılmaz ve kayıp veri\nile ilgili problemleri çözmek için kullanılan herhangi bir yöntem\nbenzer sonuçlar verir. Halbuki küçük veya orta büyüklükteki bir veri\nsetinde çok sayıda veri kaybı varsa ciddi problemler ortaya\nçıkabilir.Büyük bir veri setinde, verinin %5’veya daha azı rastlantısal\nolarak kayıpsa çok ciddi problemlerle karşılaşılmaz ve kayıp veri\nile ilgili problemleri çözmek için kullanılan herhangi bir yöntem\nbenzer sonuçlar verir. Halbuki küçük veya orta büyüklükteki bir veri\nsetinde çok sayıda veri kaybı varsa ciddi problemler ortaya\nçıkabilir.Eldeki bilgiden yararlanarak kayıp verideki örüntüler test\nedilebilir.Eldeki bilgiden yararlanarak kayıp verideki örüntüler test\nedilebilir.","code":""},{"path":"varsayımlar-i.html","id":"trk","chapter":"Bölüm 1 Varsayımlar I","heading":"1.3.1 TRK","text":"Bir Y değişkeninde kayıp veri bulunma olasılığının, Y değişkeninin\nkendi değerleriyle ve veri setindeki diğer değişkenlerin\ndeğerleriyle ilişkisiz olması durumunda Y değişkenindeki verinin\ntamamen rastgele kayıp (TRK) olduğu söylenir (Allison, 2002).Bir Y değişkeninde kayıp veri bulunma olasılığının, Y değişkeninin\nkendi değerleriyle ve veri setindeki diğer değişkenlerin\ndeğerleriyle ilişkisiz olması durumunda Y değişkenindeki verinin\ntamamen rastgele kayıp (TRK) olduğu söylenir (Allison, 2002).Örneğin; bir ilkokulda okuma başarısı üzerine yürütülen bir\nboylamsal araştırmada çocuklar hastalık ya da ailede ölüm gibi\ntesadüfi bir sebepten değerlendirmeye katılmadığında veri TRK olarak\nadlandırılır. Ayrıca bu faktörlerin sosyoekonomik düzey gibi ölçülen\ndiğer değişkenle ilişkisi olmadığı varsayıldığında, araştırmacı\ntarafından elde edilen veriler hipotetik bir tam veri setinin\nrastgele bir örneklemini temsil eder (Peugh ve Enders, 2004).Örneğin; bir ilkokulda okuma başarısı üzerine yürütülen bir\nboylamsal araştırmada çocuklar hastalık ya da ailede ölüm gibi\ntesadüfi bir sebepten değerlendirmeye katılmadığında veri TRK olarak\nadlandırılır. Ayrıca bu faktörlerin sosyoekonomik düzey gibi ölçülen\ndiğer değişkenle ilişkisi olmadığı varsayıldığında, araştırmacı\ntarafından elde edilen veriler hipotetik bir tam veri setinin\nrastgele bir örneklemini temsil eder (Peugh ve Enders, 2004).","code":""},{"path":"varsayımlar-i.html","id":"rastgele-kayıp-rk","chapter":"Bölüm 1 Varsayımlar I","heading":"1.3.2 Rastgele kayıp (RK)","text":"Bir Y değişkenindeki kayıp veri bulunma olasılığının, analiz\nmodelindeki diğer değişkenlerin bazılarıyla ilişkili olduğunu ancak\nY değişkeninin kendi değerleriyle ilişkili olmadığını ifade eder.Bir Y değişkenindeki kayıp veri bulunma olasılığının, analiz\nmodelindeki diğer değişkenlerin bazılarıyla ilişkili olduğunu ancak\nY değişkeninin kendi değerleriyle ilişkili olmadığını ifade eder.Örneğin, kanser hastalarıyla yaşam kalitesi üzerine çalışma yapan\nbir psikologun yaşlı ve eğitim düzeyi düşük hastaların yaşam\nkalitesi anketini reddetme eğiliminin daha yüksek olduğu sonucuna\nulaştığını düşünelim. Bu durumda kayıp veriye eğilimin, kayıp veri\nbulunan değişkenle arasında artık ilişki yoksa verinin RK olduğu\nsöylenir. Başka bir ifadeyle, RK yaş ve eğitim kontrol edildiğinde\nkayıp veri olasılığının yaşam kalitesiyle arasında ilişki olmaması\ndurumudur (Enders, 2010). Kayıp veri olasılığı yalnızca diğer\ngözlenen değişkenlerin değerlerine bağlı olduğunda veri RK’dır\n(Robitzsch ve Rupp, 2009).Örneğin, kanser hastalarıyla yaşam kalitesi üzerine çalışma yapan\nbir psikologun yaşlı ve eğitim düzeyi düşük hastaların yaşam\nkalitesi anketini reddetme eğiliminin daha yüksek olduğu sonucuna\nulaştığını düşünelim. Bu durumda kayıp veriye eğilimin, kayıp veri\nbulunan değişkenle arasında artık ilişki yoksa verinin RK olduğu\nsöylenir. Başka bir ifadeyle, RK yaş ve eğitim kontrol edildiğinde\nkayıp veri olasılığının yaşam kalitesiyle arasında ilişki olmaması\ndurumudur (Enders, 2010). Kayıp veri olasılığı yalnızca diğer\ngözlenen değişkenlerin değerlerine bağlı olduğunda veri RK’dır\n(Robitzsch ve Rupp, 2009).RK türünde veri gerçekte rastlantısal olarak kayıp değildir, veri\nkaybı veri setindeki değişkenlerden bazılarına bağlıdır.\nRastlantısal olarak kayıp değerler ve gözlenen değerler arasında\nsistematik farklılıkların olabileceği ancak bu farklılıkların diğer\ngözlenen değişkenlerle tamamen açıklanabileceği anlamındadır.RK türünde veri gerçekte rastlantısal olarak kayıp değildir, veri\nkaybı veri setindeki değişkenlerden bazılarına bağlıdır.\nRastlantısal olarak kayıp değerler ve gözlenen değerler arasında\nsistematik farklılıkların olabileceği ancak bu farklılıkların diğer\ngözlenen değişkenlerle tamamen açıklanabileceği anlamındadır.Bir değişkenin gözlemleri rastlantısal olarak kayıpsa, şartlı\ndeğişkenler kontrol edilebilirse , rastlantısal küme elde\nedilebilir; kayıp ve gözlenen değerler kontrol altına alınan\ngruplarda benzer dağılımlara sahip olacaklardır.Bir değişkenin gözlemleri rastlantısal olarak kayıpsa, şartlı\ndeğişkenler kontrol edilebilirse , rastlantısal küme elde\nedilebilir; kayıp ve gözlenen değerler kontrol altına alınan\ngruplarda benzer dağılımlara sahip olacaklardır.Örneğin, kayıp verinin bulunduğu değişkene göre eksik değerlere\nsahip bireyler ve tam değerlere sahip bireylerden iki grup\noluşturulabilir. Sonra analizde bu değişkenle ilgili olabilecek\ndiğer değişkenlerde t testi ile iki grup arasındaki ortalama\nfarklara bakılabilir.Örneğin, kayıp verinin bulunduğu değişkene göre eksik değerlere\nsahip bireyler ve tam değerlere sahip bireylerden iki grup\noluşturulabilir. Sonra analizde bu değişkenle ilgili olabilecek\ndiğer değişkenlerde t testi ile iki grup arasındaki ortalama\nfarklara bakılabilir.","code":""},{"path":"varsayımlar-i.html","id":"rastgele-olmayan-kayıp","chapter":"Bölüm 1 Varsayımlar I","heading":"1.3.3 Rastgele Olmayan Kayıp","text":"Rastgele olmayan kayıp (ROK), bir Y değişkenindeki kayıp veri\nbulunma olasılığının diğer değişkenler kontrol edildiğinde bile Y\ndeğişkeninin değerleriyle ilişkili olması durumunda meydana gelir.\nÖrneğin, okuma becerileri zayıf olan öğrencilerin okuma testinde\nanlama güçlüğü çekerek soruları atlaması kaçınılmaz olacaktır. Bu\ndurumda okuma değerlendirmesi okuma başarısıyla doğrudan ilişkilidir\n(Enders, 2010; Peugh ve Enders, 2004).","code":""},{"path":"varsayımlar-i.html","id":"kayıp-veri-atama-yöntemleri","chapter":"Bölüm 1 Varsayımlar I","heading":"1.4 Kayıp Veri Atama Yöntemleri","text":"Kayıp veriyle baş etme yöntemleri\nveri silmeye dayalı yöntemler (liste bazında - çiftler bazında)\nVeri atamaya dayalı yöntemler\nModel tabanlı yöntemler\nKayıp veriyle baş etme yöntemleriveri silmeye dayalı yöntemler (liste bazında - çiftler bazında)veri silmeye dayalı yöntemler (liste bazında - çiftler bazında)Veri atamaya dayalı yöntemlerVeri atamaya dayalı yöntemlerModel tabanlı yöntemlerModel tabanlı yöntemlerVeri silmeye dayalı yöntemler TRK veri mekanizmasını\ngerektirmektedir ve bu varsayım sağlanmadığında yanlış parametre\nkestirimleri verebilir. MCAR varsayımı sağlandığında bile verinin\nsilinmesi analizin gücünün düşmesine neden olabilmektedir (Enders,\n2010).Veri silmeye dayalı yöntemler TRK veri mekanizmasını\ngerektirmektedir ve bu varsayım sağlanmadığında yanlış parametre\nkestirimleri verebilir. MCAR varsayımı sağlandığında bile verinin\nsilinmesi analizin gücünün düşmesine neden olabilmektedir (Enders,\n2010).","code":""},{"path":"varsayımlar-i.html","id":"veri-silmeye-dayalı-yöntemler","chapter":"Bölüm 1 Varsayımlar I","heading":"1.4.1 Veri Silmeye Dayalı Yöntemler","text":"Liste bazında veri silme yöntemi uygulandığında veri kümesinde\nsadece birinci,\nikinci ve beşinci gözlemler üzerinden istatistiksel çözümlemeler\nyapılacaktır.\nÜçüncü, dördüncü, altıncı ve yedinci gözlemler kayıp veri\nbulundurduklarından\nçözümleme dışında bırakılmıştır.Liste bazında veri silme yöntemi uygulandığında veri kümesinde\nsadece birinci,\nikinci ve beşinci gözlemler üzerinden istatistiksel çözümlemeler\nyapılacaktır.\nÜçüncü, dördüncü, altıncı ve yedinci gözlemler kayıp veri\nbulundurduklarından\nçözümleme dışında bırakılmıştır.çiftler bazında veri silme ile ele alındığında birinci ve ikinci\ndeğişken için birinci, ikinci, dördüncü ve beşinci gözlemler\nüzerinden işlem yapılacaktır. Birinci ve üçüncü değişken için yapılacak\nkestirimler,\nbirinci, ikinci, üçüncü ve beşinci gözlemler üzerinden yapılacaktır.\nİkinci ve üçüncü değişkenler baz alındığında ise üçüncü ve dördüncü gözlem hariç diğer gözlemler üzerinden çözümlemeler yapılacaktır. Yapılan işlemler dikkate\nalındığında ilk altküme için dört gözlem çifti, ikinci altküme için\ndört gözlem çifti ve üçüncü altküme için beş gözlem çifti üzerinden\nçözümlemeler yapılarak birleştirilecektir.\nGörüldüğü gibi altkümelerin gözlem sayıları birbirlerinden farklı\nolabilmektedir. Liste bazında veri silme yönteminde gözlenmesine\nrağmen çözümleme dışında kalan değerlerden oluşan bilgi kaybı, çiftler\nbazında veri silme yöntemi ile azaltılmıştır. değişkenin farklı\nörneklem sayısı bulundurmasının ANOVA ve regresyon çözümlemesi gibi yöntemlerin kullanılacağı durumlarda problemli olduğunu belirtilmiştir.çiftler bazında veri silme ile ele alındığında birinci ve ikinci\ndeğişken için birinci, ikinci, dördüncü ve beşinci gözlemler\nüzerinden işlem yapılacaktır. Birinci ve üçüncü değişken için yapılacak\nkestirimler,\nbirinci, ikinci, üçüncü ve beşinci gözlemler üzerinden yapılacaktır.\nİkinci ve üçüncü değişkenler baz alındığında ise üçüncü ve dördüncü gözlem hariç diğer gözlemler üzerinden çözümlemeler yapılacaktır. Yapılan işlemler dikkate\nalındığında ilk altküme için dört gözlem çifti, ikinci altküme için\ndört gözlem çifti ve üçüncü altküme için beş gözlem çifti üzerinden\nçözümlemeler yapılarak birleştirilecektir.\nGörüldüğü gibi altkümelerin gözlem sayıları birbirlerinden farklı\nolabilmektedir. Liste bazında veri silme yönteminde gözlenmesine\nrağmen çözümleme dışında kalan değerlerden oluşan bilgi kaybı, çiftler\nbazında veri silme yöntemi ile azaltılmıştır. değişkenin farklı\nörneklem sayısı bulundurmasının ANOVA ve regresyon çözümlemesi gibi yöntemlerin kullanılacağı durumlarda problemli olduğunu belirtilmiştir.","code":""},{"path":"varsayımlar-i.html","id":"veri-atamaya-dayalı-yöntemler","chapter":"Bölüm 1 Varsayımlar I","heading":"1.4.2 Veri atamaya dayalı yöntemler","text":"Ortalama veri atamaRegresyon İle veri atamaDeck/Deste ile Veri YüklemeEn Yakın Komşu YöntemiSon Gözlemi İleri Taşıma","code":""},{"path":"varsayımlar-i.html","id":"ortalama-veri-atama","chapter":"Bölüm 1 Varsayımlar I","heading":"1.4.2.1 Ortalama veri atama","text":"Bu yöntemde mevcut veriden ilgili\ndegiskenlere ait ortalamalar hesaplanır ve analize baslamadan\nönce kayıp deger yerine ortalama deger koyulur.Bu yöntemde mevcut veriden ilgili\ndegiskenlere ait ortalamalar hesaplanır ve analize baslamadan\nönce kayıp deger yerine ortalama deger koyulur.Örnegin, income degiskeni için ortalama deger 4 ise, gelirini\nbelirtmeyen birey için gelir 4 olarak kabul edilir.Örnegin, income degiskeni için ortalama deger 4 ise, gelirini\nbelirtmeyen birey için gelir 4 olarak kabul edilir.Diger bütün bilgilerin eksikliginde, ortalama, bir degiskenin degeri\nhakkındaki en iyi tahmindir. Ancak ortalama deger ortalamaya\nkayıp degerden daha yakın olacagından degiskenin varyansı\ndaralır, degiskenin diger degiskenlerle korelasyonu da daralır.\nVaryans daralmasının derecesi kayıp verinin miktarına ve kayıp\nolan gerçek degere baglıdır.Diger bütün bilgilerin eksikliginde, ortalama, bir degiskenin degeri\nhakkındaki en iyi tahmindir. Ancak ortalama deger ortalamaya\nkayıp degerden daha yakın olacagından degiskenin varyansı\ndaralır, degiskenin diger degiskenlerle korelasyonu da daralır.\nVaryans daralmasının derecesi kayıp verinin miktarına ve kayıp\nolan gerçek degere baglıdır.Bir alternatif kayıp deger yerine grup ortalaması yerlestirmektir.\nBu yaklasım, yerine ortalama yerlestirme yönteminden daha iyi\nsonuç saglar. Kayıp degerler için atıflar daha yerindedir ve\nvaryans çok fazla daralmamıs olur. Ancak grupiçi varyansın\ndaralması gruplar arasında çok büyük farklılıklara neden olabilir.Bir alternatif kayıp deger yerine grup ortalaması yerlestirmektir.\nBu yaklasım, yerine ortalama yerlestirme yönteminden daha iyi\nsonuç saglar. Kayıp degerler için atıflar daha yerindedir ve\nvaryans çok fazla daralmamıs olur. Ancak grupiçi varyansın\ndaralması gruplar arasında çok büyük farklılıklara neden olabilir.","code":""},{"path":"varsayımlar-i.html","id":"regresyon-kullanılması","chapter":"Bölüm 1 Varsayımlar I","heading":"1.4.2.2 Regresyon Kullanılması","text":"Bu yöntemde kayıp veriye sahip\ndegisken bagımlı degisken, diger degiskenlerse bagımsız\ndegiskenler olarak ele alınarak bir regresyon esitligi yazılır. Tam\nveriye sahip bireyler regresyon esitliginin üretilmesinde kullanılır.\nDaha sonra esitlik kayıp degerleri tahmin etmek için kullanılır.Bu yöntemde kayıp veriye sahip\ndegisken bagımlı degisken, diger degiskenlerse bagımsız\ndegiskenler olarak ele alınarak bir regresyon esitligi yazılır. Tam\nveriye sahip bireyler regresyon esitliginin üretilmesinde kullanılır.\nDaha sonra esitlik kayıp degerleri tahmin etmek için kullanılır.Bu yöntemle tahmin edilen deger olasılıkla ortalama degere daha\nyakın olacagından varyans daralması olabilir.Bu yöntemle tahmin edilen deger olasılıkla ortalama degere daha\nyakın olacagından varyans daralması olabilir.Veri setinde iyi bagımsız degiskenlerin bulunması gerekir. Eger\nveri setindeki degiskenler kayıp veriye sahip degiskenin iyi birer\nyordayıcısı degillerse regresyon tahminini yerlestirmek\nortalamayı yerlestirmek gibidir.Veri setinde iyi bagımsız degiskenlerin bulunması gerekir. Eger\nveri setindeki degiskenler kayıp veriye sahip degiskenin iyi birer\nyordayıcısı degillerse regresyon tahminini yerlestirmek\nortalamayı yerlestirmek gibidir.Bu yöntemle tahmin edilen deger degiskenin alabilecegi olası\ndeger aralıgındaysa kullanılır, aksi halde kullanılmamalıdır.Bu yöntemle tahmin edilen deger degiskenin alabilecegi olası\ndeger aralıgındaysa kullanılır, aksi halde kullanılmamalıdır.","code":""},{"path":"varsayımlar-i.html","id":"model-tabanlı-yöntemler","chapter":"Bölüm 1 Varsayımlar I","heading":"1.4.3 Model tabanlı yöntemler","text":"Gözlenmiş değerler üzerinden kurulan bir modelde olabilirlik ve sonsal dağılımlara\nbağlı olarak parametrelerin kestirilmesine dayanan kayıp veri yöntemleridir. Bu\nyöntemlerin en önemli getirisi esneklikleridir. Geçici yöntemlerden kaçınarak model\nvarsayımları altında çözümleme yaparlar. Ayrıca veri matrisinde gözlenememiş\ndeğerleri de hesaba katarak varyans kestirimleri verirler.Gözlenmiş değerler üzerinden kurulan bir modelde olabilirlik ve sonsal dağılımlara\nbağlı olarak parametrelerin kestirilmesine dayanan kayıp veri yöntemleridir. Bu\nyöntemlerin en önemli getirisi esneklikleridir. Geçici yöntemlerden kaçınarak model\nvarsayımları altında çözümleme yaparlar. Ayrıca veri matrisinde gözlenememiş\ndeğerleri de hesaba katarak varyans kestirimleri verirler.ML YöntemiML YöntemiEM AlgoritmasıEM AlgoritmasıÇoklu Veri AtamaÇoklu Veri Atama","code":""},{"path":"varsayımlar-i.html","id":"beklenti-maksimizasyonu","chapter":"Bölüm 1 Varsayımlar I","heading":"1.4.3.1 Beklenti Maksimizasyonu:","text":"Bu yöntem iki adımdan olusan\niteratif bir yöntemdir – beklenti (expectation (E) ve\nmaksimizasyon (maximization (M)).Bu yöntem iki adımdan olusan\niteratif bir yöntemdir – beklenti (expectation (E) ve\nmaksimizasyon (maximization (M)).Ilk olarak, E adımında gözlenen degerlerden ve korelasyon gibi\ntahmin edilen parametrelerden kayıp verinin beklentisi bulunur.\nBu beklentiler kayıp veri yerine yerlestirilir.Ilk olarak, E adımında gözlenen degerlerden ve korelasyon gibi\ntahmin edilen parametrelerden kayıp verinin beklentisi bulunur.\nBu beklentiler kayıp veri yerine yerlestirilir.Sonra, M adımında kayıp veri doldurulmus gibi maksimum\nolabilirlik tahmini gerçeklestirilir.Sonra, M adımında kayıp veri doldurulmus gibi maksimum\nolabilirlik tahmini gerçeklestirilir.Daha sonra,eger yakınsanma basarılırsa, EM varyans/kovaryans\nmatrisi elde edilebilir veya doldurulan veri, veri setinde\nkaydedilebilir.Daha sonra,eger yakınsanma basarılırsa, EM varyans/kovaryans\nmatrisi elde edilebilir veya doldurulan veri, veri setinde\nkaydedilebilir.Bu yöntemde EM veri seti veri setine hata eklenmedigi için\nyanlıdır. Böylece bu veri setine dayalı analizlerde hipotez testleri\niçin uygun olmayan standart hatalar elde edilebilir.Bu yöntemde EM veri seti veri setine hata eklenmedigi için\nyanlıdır. Böylece bu veri setine dayalı analizlerde hipotez testleri\niçin uygun olmayan standart hatalar elde edilebilir.","code":""},{"path":"varsayımlar-i.html","id":"çoklu-atıf","chapter":"Bölüm 1 Varsayımlar I","heading":"1.4.3.2 Çoklu Atıf","text":"Bu yöntemde ilk olarak lojistik regresyon kullanılır;\nbelli bir degiskende kayıp veriye sahip ve sahip olmayan\ngözlemler iki kategorili bagımlı degiskeni olusturur, bagımsız\ndegiskenler olarak ele alınacak diger degiskenler belirlenir ve bir\nregresyon esitligi yazılır.Bu yöntemde ilk olarak lojistik regresyon kullanılır;\nbelli bir degiskende kayıp veriye sahip ve sahip olmayan\ngözlemler iki kategorili bagımlı degiskeni olusturur, bagımsız\ndegiskenler olarak ele alınacak diger degiskenler belirlenir ve bir\nregresyon esitligi yazılır.Sonra tam veriye sahip gözlemlerden rastlantısal bir örneklem\nseçilir ve bu örneklem kayıp veriye sahip degiskenin dagılımının\nbelirlenmesinde kullanılır.Sonra tam veriye sahip gözlemlerden rastlantısal bir örneklem\nseçilir ve bu örneklem kayıp veriye sahip degiskenin dagılımının\nbelirlenmesinde kullanılır.Daha sonra kayıp veriye sahip degiskenin dagılımından m tane\nrastlantısal örneklem seçilir ve m tane veri seti için degiskene ait\nkestirimlerde bulunulur. Çogu durumda bes hatta üç örneklem\nyeterli olacaktır.Daha sonra kayıp veriye sahip degiskenin dagılımından m tane\nrastlantısal örneklem seçilir ve m tane veri seti için degiskene ait\nkestirimlerde bulunulur. Çogu durumda bes hatta üç örneklem\nyeterli olacaktır.Istatistiksel analiz m veri seti için ayrı ayrı uygulanır ve ortalama\nparametre kestirimi rapor edilir.Istatistiksel analiz m veri seti için ayrı ayrı uygulanır ve ortalama\nparametre kestirimi rapor edilir.Bu yöntemin bir avantajı kayıp verinin rastlantısal olduguyla ilgili\nbir varsayımda bulunmamasıdır.Bu yöntemin bir avantajı kayıp verinin rastlantısal olduguyla ilgili\nbir varsayımda bulunmamasıdır.","code":""},{"path":"varsayımlar-i.html","id":"kayıp-veri-analizinde-kullanılan-paketler","chapter":"Bölüm 1 Varsayımlar I","heading":"1.4.4 Kayıp Veri Analizinde Kullanılan Paketler","text":"Kayıp veriyi incelemek ve kayıp veri ile baş etmek konusunda birden\nfazla paket mevcuttur. Bu paketler arasında\nVIM\nmissMethods\nAmelia\nnaniar paketi sayılabilir.\nVIMmissMethodsAmeliananiar paketi sayılabilir.İlk örnekler naniar üzerinden gösterilmektedir.herhangi bir eksik veri olup olmadığının kontrolütoplam kaç eksik veri vareksik veri oranı ne?eksik veriler hangi sütunlardaeksik veri tablosu, frekans ve orandeğişkenlere göre eksik veri tablosuHangi bireylerde/satırlarda eksik veri vartam ve eksik veri tablosuEksik verinin görselleştirilmesiEksik verinin görselleştirilmesi","code":"\nlibrary(naniar)\n\nany_na(screen)## [1] TRUE\nn_miss(screen)## [1] 27\nprop_miss(screen)## [1] 0.008294931\nscreen %>% is.na() %>% colSums()##    subno  timedrs  attdrug atthouse   income  mstatus     race \n##        0        0        0        1       26        0        0\nmiss_var_summary(screen)\nmiss_var_table(screen)\nhead(miss_case_summary(screen))\nmiss_case_table(screen)\ngg_miss_var(screen)\nlibrary(ggplot2)\nvis_miss(screen) + theme(axis.text.x = element_text(angle=80))\ngg_miss_upset(screen)## `geom_line()`: Each group consists of only one observation.\n## ℹ Do you need to adjust the group aesthetic?"},{"path":"varsayımlar-i.html","id":"kayıp-veri-testi","chapter":"Bölüm 1 Varsayımlar I","heading":"1.4.5 Kayıp Veri Testi","text":"Veri kaybının diğer değişkenlerle ilişkili olup olmadığının incelenmesi\nfinalfit paketi ile gerçekleştirilebilir.income değişleninde eksik veriler diğer değişkenlerle ilişkili mi?Tablo 1.4: Eksik veriye sahip olan ve olmayan değişkenlerin ortalama karşılaştırması","code":"\n# değişkeni kopyala\nscreen2 <- screen\nscreen2$income_m <- screen2$income\n\nlibrary(finalfit)\n\nexplanatory = c(\"timedrs\", \"attdrug\", \"atthouse\")\ndependent = \"income_m\"\nscreen2 %>% \n  missing_compare(dependent, explanatory) %>% \n    knitr::kable(row.names=FALSE, align = c(\"l\", \"l\", \"r\", \"r\", \"r\"), \n        caption = \"Eksik veriye sahip olan ve olmayan değişkenlerin ortalama karşılaştırması\") "},{"path":"varsayımlar-i.html","id":"bir-değişkenin-kategorilerinde-inceleme","chapter":"Bölüm 1 Varsayımlar I","heading":"1.4.5.1 Bir değişkenin kategorilerinde inceleme","text":"","code":"\nlibrary(tidyverse)\nmiss_test <- screen2 %>%mutate(miss_income = is.na(income))\n  \n# evli olmayanlar için\nnotmarried <- miss_test %>% filter(mstatus == 1) %>%\n   pull(miss_income)\n  \n# Evliler için\nmarried <- miss_test %>% filter(mstatus == 2) %>% pull(miss_income)\n  \n#c Oran\nt.test(notmarried, married)## \n##  Welch Two Sample t-test\n## \n## data:  notmarried and married\n## t = -0.95833, df = 198.7, p-value = 0.3391\n## alternative hypothesis: true difference in means is not equal to 0\n## 95 percent confidence interval:\n##  -0.06708191  0.02320485\n## sample estimates:\n##  mean of x  mean of y \n## 0.03883495 0.06077348\ngg_miss_fct(screen, fct = mstatus)"},{"path":"varsayımlar-i.html","id":"mcar-test","chapter":"Bölüm 1 Varsayımlar I","heading":"1.4.6 MCAR test","text":"Littleın MCAR testine ilişkin p değerinin . 773 olduğu\ngörülmektedir. Böylece kayıp verinin MCAR olduğu sonucuna\nvarılabilir.","code":"\nlibrary(naniar)\nmcar_test(data=screen[,2:5])"},{"path":"varsayımlar-i.html","id":"kayıp-veri-ile-başetme","chapter":"Bölüm 1 Varsayımlar I","heading":"1.4.7 Kayıp veri ile başetme","text":"Liste bazında silme işlemi na.omit ve complete.cases\nfonkisyonları ile sağlanabilir.Ortalama atama işlemi yapılabir. Tek bir değişkene ortalama atamaif_else() ile ortalama atama işlemi yapılabir.mutate() ile ortalama atama işlemi yapılabilir","code":"\nna.omit(screen) \nscreen[!complete.cases(screen),]\nscreen[complete.cases(screen),]\ndf = data.frame(x = 1:20, y = c(1:10,rep(NA,10)))\ndf$y[is.na(df$y)] = mean(df$y, na.rm=TRUE)\nscreen2 <- screen\nscreen2$income[is.na(screen2$income)]<- mean(screen2$income, na.rm=TRUE)\nscreen3 <- screen\n\nscreen3 = transform(screen3, income = ifelse(is.na(income), \n                                        mean(income, na.rm=TRUE), income))\nsummary(screen3$income)##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##    1.00    3.00    4.00    4.21    6.00   10.00\nscreen %>%  \nmutate(income = ifelse(is.na(income), mean(income, na.rm =TRUE), income))"},{"path":"varsayımlar-i.html","id":"veri-setindeki-kayıp-veriler","chapter":"Bölüm 1 Varsayımlar I","heading":"1.4.8 Veri setindeki kayıp veriler","text":"atthouse değişkeninde bir kayıp değer bulunmaktadır ve liste\nbazında silme yöntemi ile veri setinden çıkarılmıştır.atthouse değişkeninde bir kayıp değer bulunmaktadır ve liste\nbazında silme yöntemi ile veri setinden çıkarılmıştır.Veri setinde income değişkeni 26 kayıp değere sahiptir ve bu\nsayı örneklemin %5’inden fazladır. Eğer bu değişken araştırma\naçısından öneme sahip değilse, veri setinden çıkarılabilir, aksi\nhalde kayıp verinin tahmin edilmesi yöntemlerinden biri\nkullanılabilir.Veri setinde income değişkeni 26 kayıp değere sahiptir ve bu\nsayı örneklemin %5’inden fazladır. Eğer bu değişken araştırma\naçısından öneme sahip değilse, veri setinden çıkarılabilir, aksi\nhalde kayıp verinin tahmin edilmesi yöntemlerinden biri\nkullanılabilir.income değişkenindeki kayıp değerler için kayıp verinin tahmin\nedilmesi yöntemlerinden ortalamanın yerleştirilmesi kullanılarak\nkayıp değer yerine değişkenin ortalama değeri (4.21 değeri)\nyerleştirilmiştir.income değişkenindeki kayıp değerler için kayıp verinin tahmin\nedilmesi yöntemlerinden ortalamanın yerleştirilmesi kullanılarak\nkayıp değer yerine değişkenin ortalama değeri (4.21 değeri)\nyerleştirilmiştir.","code":"\nscreen <- screen %>% \nmutate(income = ifelse(is.na(income), mean(income, na.rm =TRUE),\n                       income)) %>% na.omit()\nsummary(screen)##      subno          timedrs          attdrug         atthouse    \n##  Min.   :  1.0   Min.   : 0.000   Min.   : 5.00   Min.   : 2.00  \n##  1st Qu.:136.8   1st Qu.: 2.000   1st Qu.: 7.00   1st Qu.:21.00  \n##  Median :313.5   Median : 4.000   Median : 8.00   Median :24.00  \n##  Mean   :317.3   Mean   : 7.914   Mean   : 7.69   Mean   :23.54  \n##  3rd Qu.:483.2   3rd Qu.:10.000   3rd Qu.: 9.00   3rd Qu.:27.00  \n##  Max.   :758.0   Max.   :81.000   Max.   :10.00   Max.   :35.00  \n##      income          mstatus          race      \n##  Min.   : 1.000   Min.   :1.00   Min.   :1.000  \n##  1st Qu.: 3.000   1st Qu.:2.00   1st Qu.:1.000  \n##  Median : 4.000   Median :2.00   Median :1.000  \n##  Mean   : 4.208   Mean   :1.78   Mean   :1.086  \n##  3rd Qu.: 6.000   3rd Qu.:2.00   3rd Qu.:1.000  \n##  Max.   :10.000   Max.   :2.00   Max.   :2.000"},{"path":"varsayımlar-i.html","id":"daha-fazlası-için","chapter":"Bölüm 1 Varsayımlar I","heading":"1.5 Daha Fazlası için","text":"🔗Heymans, MW Eekhout, . (2019). Applied missing data analysis SPSS\n(R) Studio. Heymans Eekhout: Amsterdam, Netherlands🔗Heymans, MW Eekhout, . (2019). Applied missing data analysis SPSS\n(R) Studio. Heymans Eekhout: Amsterdam, Netherlands🔗naniar paketi vigneti🔗naniar paketi vigneti🔗 Van Buuren, S. (2018). Flexible imputation missing data. CRC press.🔗 Van Buuren, S. (2018). Flexible imputation missing data. CRC press.","code":""},{"path":"varsayımlar-i.html","id":"odev","chapter":"Bölüm 1 Varsayımlar I","heading":"1.6 ODEV","text":"Dealing Missing Data R ilk üç bölümüHandling Missing Data Imputations R ilk bölümüIntroduction Statistics R ilk bölümü","code":""},{"path":"varsayımlar-i.html","id":"kaynaklar","chapter":"Bölüm 1 Varsayımlar I","heading":"1.7 Kaynaklar","text":"Allison, P. D. (2003). Missing Data Techniques Structural Equation Modeling.\nJournal Abnormal Psychology. 112(4), 545-557.Allison, P. D. (2003). Missing Data Techniques Structural Equation Modeling.\nJournal Abnormal Psychology. 112(4), 545-557.Peugh, J.L. & Enders, J.K. (2004). Missing Data Educational Research: Review \nReporting Practices Suggestions İmprovement. Review \nEducationalResearch, 74(4), 525-556, DOI: 10.3102/00346543074004525\nPeugh ve Enders, 2004Peugh, J.L. & Enders, J.K. (2004). Missing Data Educational Research: Review \nReporting Practices Suggestions İmprovement. Review \nEducationalResearch, 74(4), 525-556, DOI: 10.3102/00346543074004525\nPeugh ve Enders, 2004Rubin, D. B. (1976). Inference missing data. Biometrika , 63, 581Rubin, D. B. (1976). Inference missing data. Biometrika , 63, 581Robitzsch ve Rupp, 2009","code":""},{"path":"varsayımlar-ii.html","id":"varsayımlar-ii","chapter":"Bölüm 2 Varsayımlar II","heading":"Bölüm 2 Varsayımlar II","text":"","code":""},{"path":"varsayımlar-ii.html","id":"uç-değerler","chapter":"Bölüm 2 Varsayımlar II","heading":"2.1 Uç değerler","text":"Uç değerler hem . tip hem de II. tip hatalara neden olurlar ve\nsonuçların genellenebilirliğini düşürürler.Uç değerler hem . tip hem de II. tip hatalara neden olurlar ve\nsonuçların genellenebilirliğini düşürürler.Veri setinde uç değer bulunmasının 4 nedeni olabilir\nVerinin veri dosyasına yanlış girilmesi\nKayıp veri kodlamasında hata yapılması\nUç değerin örneklemin alındığı evrenin üyesi olmaması\nUç değerin örneklemin alındığı evrenin üyesi olması ancak\ndeğişkenin evrendeki dağılımının normal dağılıma göre aşırı\ndeğerlere sahip olması\nVeri setinde uç değer bulunmasının 4 nedeni olabilirVerinin veri dosyasına yanlış girilmesiKayıp veri kodlamasında hata yapılmasıUç değerin örneklemin alındığı evrenin üyesi olmamasıUç değerin örneklemin alındığı evrenin üyesi olması ancak\ndeğişkenin evrendeki dağılımının normal dağılıma göre aşırı\ndeğerlere sahip olmasıHatalı veri girişi ve kayıp değer kodlaması kolaylıkla\nbulunup düzeltilebilir ancak 3. ve 4. durumlar arasında\nayrım yapıp uç değerin veri setinden silinip\nsilinmemesine karar vermek oldukça güçtür.Hatalı veri girişi ve kayıp değer kodlaması kolaylıkla\nbulunup düzeltilebilir ancak 3. ve 4. durumlar arasında\nayrım yapıp uç değerin veri setinden silinip\nsilinmemesine karar vermek oldukça güçtür.Tek değişkenli uç değerlerin belirlenmesi çok değişkenli\nuç değerlerin belirlenmesine göre daha kolaydır.Tek değişkenli uç değerlerin belirlenmesi çok değişkenli\nuç değerlerin belirlenmesine göre daha kolaydır.İki kategorili değişkenler için, eşit büyüklükte olmayan\nkategorilerde yanlış kategoride gözlenen bir değer olasılıkla uç\ndeğerdir. Rummel (1970) iki kategorili bir değişken için kategorilerden biri\nörneklemdeki bireylerin %90’ını diğeri ise %10’unu içeriyorsa,\ndeğişkenin analiz dışı bırakılmasını önermektedir.İki kategorili değişkenler için, eşit büyüklükte olmayan\nkategorilerde yanlış kategoride gözlenen bir değer olasılıkla uç\ndeğerdir. Rummel (1970) iki kategorili bir değişken için kategorilerden biri\nörneklemdeki bireylerin %90’ını diğeri ise %10’unu içeriyorsa,\ndeğişkenin analiz dışı bırakılmasını önermektedir.","code":""},{"path":"varsayımlar-ii.html","id":"iki-kategorili-değişkenlerde-uç-değerlerin-belirlenmesi","chapter":"Bölüm 2 Varsayımlar II","heading":"2.1.1 İki kategorili değişkenlerde uç değerlerin belirlenmesi","text":"summarytools paketinde freq() fonksiyonu ile frekans tabloları oluşturulabilir.summarytools paketinde freq() fonksiyonu ile frekans tabloları oluşturulabilir.Veri setinde yer alan mstatus ve race değişkenlerinin frekans tabloları incelenmiştir.Veri setinde yer alan mstatus ve race değişkenlerinin frekans tabloları incelenmiştir.İlk olarak eksik veri düzenlenmesi yapılmıştır.İlk olarak eksik veri düzenlenmesi yapılmıştır.race değişkenin frekans tablosuİki kategorili değişkenlerden race değişkeninin kategorilere dağılımları incelendiğinde kategoriler arasında yaklaşık 10.1:1 (91/9) oranı olduğu görülmektedir. Bu oran oldukça yüksektir. Değişken araştırma için önemli değilse çıkarılabilir, aksi halde değişkenle ilgili sonuçlar\nyorumlanırken bu durum göz önüne alınmalıdır.İki kategorili değişkenlerden race değişkeninin kategorilere dağılımları incelendiğinde kategoriler arasında yaklaşık 10.1:1 (91/9) oranı olduğu görülmektedir. Bu oran oldukça yüksektir. Değişken araştırma için önemli değilse çıkarılabilir, aksi halde değişkenle ilgili sonuçlar\nyorumlanırken bu durum göz önüne alınmalıdır.mstatus değişkenin frekans tablosu oluşturulurup kable() fonksiyonu ile tablolaştırılmıştır.mstatus değişkenin frekans tablosu oluşturulurup kable() fonksiyonu ile tablolaştırılmıştır.Tablo 2.1: Frekans Tablosuİki kategorili değişkenlerden mstatus değişkeninin kategorilere\ndağılımları incelendiğinde kategoriler arasında yaklaşık 3.5:1 (78/22)\noranı olduğu görülmektedir. Bu oran kabul edilebilir bir orandır.İki kategorili değişkenlerden mstatus değişkeninin kategorilere\ndağılımları incelendiğinde kategoriler arasında yaklaşık 3.5:1 (78/22)\noranı olduğu görülmektedir. Bu oran kabul edilebilir bir orandır.🔗 summarytools paketinin vignettei için🔗 summarytools paketinin vignettei için","code":"\nlibrary(haven)\nlibrary(dplyr)\nscreen <- read_sav(\"import/SCREEN.sav\")\nscreen <- screen %>% \nmutate(income = ifelse(is.na(income), mean(income, na.rm =TRUE),\n                       income)) %>% na.omit()\nlibrary(summarytools)\nfreq(screen$race, \n     round.digits=2,report.nas = FALSE,\n style = \"rmarkdown\") ## ### Frequencies  \n## #### screen$race  \n## **Label:** Ethnic group membership  \n## **Type:** Numeric  \n## \n## |    &nbsp; | Freq |      % | % Cum. |\n## |----------:|-----:|-------:|-------:|\n## |     **1** |  424 |  91.38 |  91.38 |\n## |     **2** |   40 |   8.62 | 100.00 |\n## | **Total** |  464 | 100.00 | 100.00 |\nlibrary(knitr)\nfreq(screen$mstatus,report.nas = FALSE) %>%\n  kable(format='markdown', \n      caption=\"Frekans Tablosu\",digits = 2)"},{"path":"varsayımlar-ii.html","id":"sürekli-değişkenlerde-uç-değerlerin-belirlenmesi","chapter":"Bölüm 2 Varsayımlar II","heading":"2.1.2 Sürekli değişkenlerde uç değerlerin belirlenmesi","text":"Sürekli değişkenler için tek değişkenli uç değerleri belirlemenin bir\nyolu, değişkene ait bütün değerlerin ortalama 0, standart sapma 1\nolacak şekilde standart değerlere (z puanlarına) dönüştürülmesidir.\nTek değişkenli uç değerler çok büyük z puanlarına sahiptirler.Sürekli değişkenler için tek değişkenli uç değerleri belirlemenin bir\nyolu, değişkene ait bütün değerlerin ortalama 0, standart sapma 1\nolacak şekilde standart değerlere (z puanlarına) dönüştürülmesidir.\nTek değişkenli uç değerler çok büyük z puanlarına sahiptirler.Örneklem büyüklüğü 100 veya daha az olduğunda, eğer herhangi\nbir gözlemin z puanı ±3.0 veya daha fazlaysa, gözlem uç değerdir.Örneklem büyüklüğü 100 veya daha az olduğunda, eğer herhangi\nbir gözlemin z puanı ±3.0 veya daha fazlaysa, gözlem uç değerdir.Örneklem büyüklüğü 100’den fazla olduğunda, eğer herhangi bir\ngözlemin z puanı ±4.0 veya daha fazlaysa, gözlem uç değerdir.Örneklem büyüklüğü 100’den fazla olduğunda, eğer herhangi bir\ngözlemin z puanı ±4.0 veya daha fazlaysa, gözlem uç değerdir.Bu yöntem eşit aralık veya eşit oran düzeyinde ölçülen değişkenler\niçin veya sürekli değişken olarak ele alınan sıralama ölçeğinde\nölçülen değişkenler için geçerli olup sınıflama düzeyinde ölçülen\ndeğişkenler için geçerli değildir.Bu yöntem eşit aralık veya eşit oran düzeyinde ölçülen değişkenler\niçin veya sürekli değişken olarak ele alınan sıralama ölçeğinde\nölçülen değişkenler için geçerli olup sınıflama düzeyinde ölçülen\ndeğişkenler için geçerli değildir.outliers paketinde select() fonksiyonu ile z değerleri hesaplanabilir.outliers paketinde select() fonksiyonu ile z değerleri hesaplanabilir.summarytools paketinde descr() fonksiyonu ile z değerlerinin minumum ve maksimum değerleri incelenebilir.timedrs değişkeni için z puanlarının maksimum değerin 4.0’ten büyük olduğu, atthouse değişkeni z puanlarının içinse minimum değerin 4.0’ten küçük olduğu görülmektedir. Diğer değişkenler için değerler beklenen sınırlar içerisindedir.Tek değişkenli uç değerleri saptamak için grafiksel yöntemlerden de\nyararlanılabilir (Örneğin, histogramlar, kutu grafikleri, normal olasılık\ngrafikleri gibi).Tek değişkenli uç değerleri saptamak için grafiksel yöntemlerden de\nyararlanılabilir (Örneğin, histogramlar, kutu grafikleri, normal olasılık\ngrafikleri gibi).Histogramlar kolay anlaşılan ve yorumlanan grafiklerdir ve uç\ndeğerlerin belirlenmesine yardımcı olabilirler. Genellikle ortalamanın\nyakınındaki çoğu gözlemle birlikte ortalamanın iki yönüne doğru\nuzanan gözlemler vardır. Uç değer dağılımın geri kalanıyla\nbağlantısı bulunmayan gözlemdir.Histogramlar kolay anlaşılan ve yorumlanan grafiklerdir ve uç\ndeğerlerin belirlenmesine yardımcı olabilirler. Genellikle ortalamanın\nyakınındaki çoğu gözlemle birlikte ortalamanın iki yönüne doğru\nuzanan gözlemler vardır. Uç değer dağılımın geri kalanıyla\nbağlantısı bulunmayan gözlemdir.Kutu grafikleri de basittir. Medyan etrafındaki gözlemler kutu içine\nalınır. Kutudan çok uzağa düşen gözlemler uç değerdir.Kutu grafikleri de basittir. Medyan etrafındaki gözlemler kutu içine\nalınır. Kutudan çok uzağa düşen gözlemler uç değerdir.Normal olasılık grafikleri değişkenlerin dağılımlarının normalliğinin\ndeğerlendirilmesinde oldukça kullanışlıdır. Uç değerler de bu\ngrafiklerde gözlenebilir; diğerlerinden önemli derecede uzakta\nbulunan nokta uçdeğerdir.Normal olasılık grafikleri değişkenlerin dağılımlarının normalliğinin\ndeğerlendirilmesinde oldukça kullanışlıdır. Uç değerler de bu\ngrafiklerde gözlenebilir; diğerlerinden önemli derecede uzakta\nbulunan nokta uçdeğerdir.","code":"\nlibrary(outliers)\nz.scores <- screen %>%  \n select(2:5) %>% \n scores(type = \"z\") %>%\n round(2)\nhead(z.scores)\nsummarytools::descr(z.scores,\n stats     = c(\"min\", \"max\"),\n transpose = TRUE,\n headings  = FALSE) %>%   \n kable()\nlibrary(DT)\n\nDT::datatable(z.scores)"},{"path":"varsayımlar-ii.html","id":"timedrs-değişkenin-incelenmesi","chapter":"Bölüm 2 Varsayımlar II","heading":"2.1.3 timedrs değişkenin incelenmesi","text":"","code":""},{"path":"varsayımlar-ii.html","id":"histogram","chapter":"Bölüm 2 Varsayımlar II","heading":"2.1.3.1 histogram","text":"grafik üzerinde ortalamanın gösterilmesi","code":"\nlibrary(ggplot2)\nggplot(screen, aes(x = timedrs)) +\n  geom_histogram(bins = 30L, fill = \"#0c4c8a\") +\n  theme_minimal()\nlibrary(ggpmisc)\nggplot(screen, aes(x = timedrs)) + geom_histogram() + \ngeom_vline(xintercept =7.914, color = \"red\", \nlinetype = \"dashed\") + \nannotate(\"text\", label = \"Ort = 7.913\", x = 10, y = 100,  color =\"black\")"},{"path":"varsayımlar-ii.html","id":"yoğunluk-grafiği","chapter":"Bölüm 2 Varsayımlar II","heading":"2.1.3.2 yoğunluk grafiği","text":"","code":"\nggplot(screen, aes(x = timedrs)) +\n geom_histogram(aes(y=..density..))+\n geom_density(alpha=.5, fill=\"#0c4c8a\") +\n  theme_minimal()"},{"path":"varsayımlar-ii.html","id":"interaktif-grafik","chapter":"Bölüm 2 Varsayımlar II","heading":"2.1.3.3 interaktif grafik","text":"","code":"\nlibrary(plotly)\nplot_ly(x = screen$timedrs,  type = \"histogram\", \nhistnorm = \"probability\")"},{"path":"varsayımlar-ii.html","id":"kutu-grafik","chapter":"Bölüm 2 Varsayımlar II","heading":"2.1.3.4 kutu grafik","text":"boxplot.stats fonksiyonun bileşini uç değerleri vermektedir.Bu uç değerlerin timedrs değişkeninde hangi gözlemlerde olduğu ise aşağıdaki kodlarla belirlenebilir.interaktif kutu grafiğiinteraktif kutu grafiği üzerine uç değerlerin idlerinin işaretlenmesi ise aşağıdaki kodla yapılabilir.","code":"\nggplot(screen, aes(y = timedrs)) + \n  geom_boxplot()  \nout <- boxplot.stats(screen$timedrs)$out\nout##  [1] 60 23 39 33 38 34 27 30 25 49 60 27 27 52 24 57 52 58 57 43 37 75 29 30 25\n## [26] 37 56 29 37 81 27 23\nout_ind <- which(screen$timedrs %in% c(out))\nout_ind##  [1]  40  64  67  76  79  96 102 117 150 163 168 170 178 193 203 206 213 249 274\n## [20] 278 285 289 309 342 344 362 367 374 388 404 408 443\nplot_ly(y = screen$timedrs, type = 'box') \nplot_ly(y = screen$timedrs, type = 'box')  %>% \n  layout(title = 'Box Plot',\nannotations = list( x = -0.01,  y = boxplot.stats(screen$timedrs)$out, \ntext = paste(out_ind), showarrow = FALSE,\nxanchor = \"right\"))"},{"path":"varsayımlar-ii.html","id":"timedrs-değişkenin-mstatus-değişkenine-göre-incelenmesi","chapter":"Bölüm 2 Varsayımlar II","heading":"2.1.3.5 timedrs değişkenin mstatus değişkenine göre incelenmesi","text":"","code":"\nggplot(screen, aes(x = factor(mstatus), \ny = timedrs, fill = factor(mstatus))) +\n  geom_boxplot()"},{"path":"varsayımlar-ii.html","id":"attdrug-değişkenin-incelenmesi","chapter":"Bölüm 2 Varsayımlar II","heading":"2.1.4 attdrug değişkenin incelenmesi","text":"","code":"\nggplot(screen) + aes(x =  attdrug) +\n  geom_histogram( bins = 6, fill = \"#0c4c8a\")+\ntheme_minimal()"},{"path":"varsayımlar-ii.html","id":"atthouse-değişkenin-incelenmesi","chapter":"Bölüm 2 Varsayımlar II","heading":"2.1.5 atthouse değişkenin incelenmesi","text":"","code":""},{"path":"varsayımlar-ii.html","id":"histogram-1","chapter":"Bölüm 2 Varsayımlar II","heading":"2.1.5.1 histogram","text":"","code":"\nggplot(screen) +\naes(x =  atthouse) +\ngeom_histogram( bins = 10, fill = \"darkgreen\") +\ntheme_minimal()"},{"path":"varsayımlar-ii.html","id":"kutu-grafiği","chapter":"Bölüm 2 Varsayımlar II","heading":"2.1.5.2 kutu grafiği","text":"🔗Color codesVeri setinde potansiyel tek değişkenli uç değerler tespit\nedildiğinde, önce uç değerin nedeni araştırılmalıdır. Eğer\nveri girişinde hata varsa veya kayıp veri kodlanırken hata\nyapıldıysa düzeltilmelidir.Veri setinde potansiyel tek değişkenli uç değerler tespit\nedildiğinde, önce uç değerin nedeni araştırılmalıdır. Eğer\nveri girişinde hata varsa veya kayıp veri kodlanırken hata\nyapıldıysa düzeltilmelidir.Bunun dışındaki nedenlerde değişkenin\ndönüştürülmesinin uygun olup olmayacağına karar\nverilmelidir.Bunun dışındaki nedenlerde değişkenin\ndönüştürülmesinin uygun olup olmayacağına karar\nverilmelidir.Dönüşümler hem dağılımların normalliğini geliştirir hem de tek\ndeğişkenli uç değerleri dağılımın merkezine çekerler ve etkisini\nazaltırlar.Dönüşümler hem dağılımların normalliğini geliştirir hem de tek\ndeğişkenli uç değerleri dağılımın merkezine çekerler ve etkisini\nazaltırlar.Dönüşüme karar verilirse çok değişkenli uç değerler\nincelenmeden dönüşüm yapılmalıdır. Çünkü çok değişkenli uç\ndeğerlerin belirlenmesinde kullanılan istatistikler normal dağılımı\ngerektirir.Dönüşüme karar verilirse çok değişkenli uç değerler\nincelenmeden dönüşüm yapılmalıdır. Çünkü çok değişkenli uç\ndeğerlerin belirlenmesinde kullanılan istatistikler normal dağılımı\ngerektirir.","code":"\nggplot(screen) +\naes(x = \"\", y = atthouse) +\ngeom_boxplot(fill = \"#3357FF\") +\ntheme_minimal()"},{"path":"varsayımlar-ii.html","id":"uç-değerlerin-belirlenmesi","chapter":"Bölüm 2 Varsayımlar II","heading":"2.1.6 Uç değerlerin Belirlenmesi","text":"Veri setinde iki değişken – timedrs ve atthouse uç\ndeğerlere sahiptir.Veri setinde iki değişken – timedrs ve atthouse uç\ndeğerlere sahiptir.timedrs değişkeni için uç değer olarak belirlenen değerlerin\nbeklenen değerlerin üstünde olduğu ancak veri girişinde hata\nbulunmadığı rapor edilmiş, bu değerlere sahip bireylerin veri\nsetinde kalmasına karar verilmiştir.timedrs değişkeni için uç değer olarak belirlenen değerlerin\nbeklenen değerlerin üstünde olduğu ancak veri girişinde hata\nbulunmadığı rapor edilmiş, bu değerlere sahip bireylerin veri\nsetinde kalmasına karar verilmiştir.atthouse değişkeni için uç değerler olarak belirlenen değerler\ndiğer değerlerden kopuktur. Bu değerlerin evren için beklenen\ndeğerler mi olduğuna veya veri girişinde hata yapılıp\nyapılmadığına karar verilmelidir.atthouse değişkeni için uç değerler olarak belirlenen değerler\ndiğer değerlerden kopuktur. Bu değerlerin evren için beklenen\ndeğerler mi olduğuna veya veri girişinde hata yapılıp\nyapılmadığına karar verilmelidir.iki durumda da veri setinde 260. ve 296. satırda yer alan 2 birey (346 ve 407 subno.lu bireyler) veri setinden çıkarılabilir. 2 bireyin veri setinden çıkarılması sonucu örneklem büyüklüğü 462’ye eşit olacaktır.iki durumda da veri setinde 260. ve 296. satırda yer alan 2 birey (346 ve 407 subno.lu bireyler) veri setinden çıkarılabilir. 2 bireyin veri setinden çıkarılması sonucu örneklem büyüklüğü 462’ye eşit olacaktır.","code":"\nscreen[c(260,298),]\nscreen <- screen[-c(260,298),]"},{"path":"varsayımlar-ii.html","id":"mahalanobis-uzaklığı","chapter":"Bölüm 2 Varsayımlar II","heading":"2.1.7 Mahalanobis Uzaklığı","text":"Çok değişkenli uç değerleri belirlemenin bir yolu\nMahalanobis uzaklığını hesaplamaktır. Mahalanobis uzaklığı z puanının çok boyutlu versiyonudur. Bir gözlemin, dağılımın kovaryansı (çok\nboyutlu varyansı) verildiğinde, dağılımın ağırlık merkezinden (çok\nboyutlu ortalamasından) uzaklığını ölçer.Çok değişkenli uç değerleri belirlemenin bir yolu\nMahalanobis uzaklığını hesaplamaktır. Mahalanobis uzaklığı z puanının çok boyutlu versiyonudur. Bir gözlemin, dağılımın kovaryansı (çok\nboyutlu varyansı) verildiğinde, dağılımın ağırlık merkezinden (çok\nboyutlu ortalamasından) uzaklığını ölçer.Mahalonobis uzaklığı ki-kare dağılımı gösterir (serbestlik derecesi\nhesaplamada kullanılan değişken sayısına eşittir) ve ki-kare dağılımı\nkullanılarak değerlendirilebilir. Eğer hesaplanan Mahalonobis\nuzaklığının gözlenme olasılığı 0.001 veya daha küçükse gözlem\nuçdeğerdir.Mahalonobis uzaklığı ki-kare dağılımı gösterir (serbestlik derecesi\nhesaplamada kullanılan değişken sayısına eşittir) ve ki-kare dağılımı\nkullanılarak değerlendirilebilir. Eğer hesaplanan Mahalonobis\nuzaklığının gözlenme olasılığı 0.001 veya daha küçükse gözlem\nuçdeğerdir.Bu yöntem eşit aralık veya eşit oran düzeyinde ölçülen değişkenler\niçin veya sürekli değişken olarak ele alınan sıralama ölçeğinde\nölçülen değişkenler için geçerli olup sınıflama düzeyinde ölçülen\ndeğişkenler için geçerli değildir.Bu yöntem eşit aralık veya eşit oran düzeyinde ölçülen değişkenler\niçin veya sürekli değişken olarak ele alınan sıralama ölçeğinde\nölçülen değişkenler için geçerli olup sınıflama düzeyinde ölçülen\ndeğişkenler için geçerli değildir.Mahalanobis uzaklığı hesaplamaMahalanobis uzaklığı hesaplamaMahalanobis uzaklığı kritik değer belirlemeMahalonobis uzaklığı değerleri ki-kare ile değerlendirilir (serbestlik\nderecesi bağımsız değişken sayısına eşittir). Buna göre 20.51501 kritik\ndeğerinden büyük olan değerler 0.001 alfa düzeyinde istatistiksel olarak\nanlamlı olarak değerlendirilir.548, 398, 48, 235, 330, 502, 276, 291 ve 370 subno.lu bireyler için\nMahalonobis uzaklık değerleri kritik değerden büyüktür. Bu gözlemler\nçok değişkenli uç değerler olarak değerlendirilir.","code":"\nlibrary(psych)\nveri <- screen[,1:5]\nmd <- mahalanobis(veri, center = colMeans(veri), cov = cov(veri))\nhead(md,20)##  [1]  3.785517  4.541493  3.501077  7.281365  5.457240  2.896550  5.807898\n##  [8]  3.879478  4.751166  7.415405 10.602100  5.249121  6.073732  3.271885\n## [15] 12.316463  4.440749  4.836160  6.362806  4.126524 10.797545\nlibrary(psych)\nalpha <- .001\ncutoff <- (qchisq(p = 1 - alpha, df = ncol(veri)))\ncutoff## [1] 20.51501\nucdegerler <- which(md > cutoff)\nveri[ucdegerler, ]\n\ndata_temiz <- veri[-ucdegerler, ]\nveri[ucdegerler, ]"},{"path":"varsayımlar-ii.html","id":"çok-değişkenli-normallik-sayıltısı","chapter":"Bölüm 2 Varsayımlar II","heading":"2.2 Çok Değişkenli Normallik Sayıltısı","text":"Çok degiskenli normallik sayıltısını test etmek için\ndoğrudan bir test bulunmadığından, genellikle bir\ndeğişken ayrı ayrı test edilir ve eğer bir değişken\nnormal dağılım gösteriyorsa çok değişkenli normal\noldukları varsayılır.\n: bir değişkenin normal olarak dağılım çok değişkenli\nnormallik için gereklidir ancak yeterli degildir.\nÇok degiskenli normallik sayıltısını test etmek için\ndoğrudan bir test bulunmadığından, genellikle bir\ndeğişken ayrı ayrı test edilir ve eğer bir değişken\nnormal dağılım gösteriyorsa çok değişkenli normal\noldukları varsayılır.: bir değişkenin normal olarak dağılım çok değişkenli\nnormallik için gereklidir ancak yeterli degildir.Normalliğin değerlendirilmesi için hem istatistiksel hem\nde grafiksel yöntemler vardır.Normalliğin değerlendirilmesi için hem istatistiksel hem\nde grafiksel yöntemler vardır.Istatistiksel yöntemler normallik için hipotez testlerini içerir.Istatistiksel yöntemler normallik için hipotez testlerini içerir.Grafiksel yöntemler histogram ve normallik grafiklerinin\nincelenmelerini içerir.Grafiksel yöntemler histogram ve normallik grafiklerinin\nincelenmelerini içerir.Çok değişkenli normallik bir değişkenin ve degiskenlerin bütün doğrusal kombinasyonlarının normal dağıldığı sayıltısıdır.Çok değişkenli normallik bir değişkenin ve degiskenlerin bütün doğrusal kombinasyonlarının normal dağıldığı sayıltısıdır.Sayıltının karşılanması durumunda analizin artıkları (hataları) da normal dağılır.Sayıltının karşılanması durumunda analizin artıkları (hataları) da normal dağılır.Çok değişkenli normallik sayıltısı farklı çok değişkenli istatistikler için farklı ele alınır.Çok değişkenli normallik sayıltısı farklı çok değişkenli istatistikler için farklı ele alınır.","code":""},{"path":"varsayımlar-ii.html","id":"normallik-sayıltısı","chapter":"Bölüm 2 Varsayımlar II","heading":"2.2.0.1 Normallik Sayıltısı","text":"Normalliğin iki bileşeni vardır: Çarpıklık ve basıklıkBir değişkene ait dağılım normal olduğunda, değişkenin çarpıklık ve basıklık\ndeğerleri sıfıra eşittir.Bir değişkene ait dağılım normal olduğunda, değişkenin çarpıklık ve basıklık\ndeğerleri sıfıra eşittir.Kural olarak eğer değişkenin çarpıklık ve basıklık değerleri -1.0 ile +1.0\narasındaysa, değişkenin normale oldukça yakın olduğu söylenebilir.Kural olarak eğer değişkenin çarpıklık ve basıklık değerleri -1.0 ile +1.0\narasındaysa, değişkenin normale oldukça yakın olduğu söylenebilir.Hem çarpıklık hem de basıklık için istatistiksel anlamlılık testleri vardır. Bu testlerde z dağılımı kullanılarak elde edilen çarpıklık veya basıklık değeri sıfır ile karşılaştırılır:Hem çarpıklık hem de basıklık için istatistiksel anlamlılık testleri vardır. Bu testlerde z dağılımı kullanılarak elde edilen çarpıklık veya basıklık değeri sıfır ile karşılaştırılır:jarque.test fonksiyonu veri normal dağılımdan farklılaşmamaktır yokluk hipotezini test etmektedir.","code":"\nlibrary(sur)\nattach(screen)\n\nskew(timedrs)## [1] 3.226868\nse.skew(timedrs)## [1] 0.1135929\nskew.ratio(timedrs)## [1] 28.4073\nskew(timedrs)/se.skew(timedrs)## [1] 28.4073\nlibrary(moments)\nlibrary(labelled)\njarque.test(remove_labels(timedrs))## \n##  Jarque-Bera Normality Test\n## \n## data:  remove_labels(timedrs)\n## JB = 3984.7, p-value < 2.2e-16\n## alternative hypothesis: greater\njarque.test(remove_labels(attdrug))## \n##  Jarque-Bera Normality Test\n## \n## data:  remove_labels(attdrug)\n## JB = 5.1381, p-value = 0.07661\n## alternative hypothesis: greater\njarque.test(remove_labels(atthouse))## \n##  Jarque-Bera Normality Test\n## \n## data:  remove_labels(atthouse)\n## JB = 1.5155, p-value = 0.4687\n## alternative hypothesis: greater\nset.seed(0)\nnormal <- rnorm(200)\nnon_normal<- rexp(200, rate=3)\npar(mfrow=c(1,2)) \nhist(normal, col='steelblue', main='Normal')\nhist(non_normal, col='steelblue', main='Non-normal')\npar(mfrow=c(1,2)) \nqqnorm(normal, main='Normal')\nqqline(normal)\nqqnorm(non_normal, main='Non-normal')\nqqline(non_normal)\nggplot(data = screen, aes(sample = atthouse )) + \n  geom_qq()+\n  geom_qq_line( ) "},{"path":"varsayımlar-ii.html","id":"doğrusallık","chapter":"Bölüm 2 Varsayımlar II","heading":"2.3 Doğrusallık","text":"Doğrusallık iki değişken arasında doğrusal bir iliskinin oldugu sayıltısıdır.Doğrusallık iki değişken arasında doğrusal bir iliskinin oldugu sayıltısıdır.İki değişken arasındaki doğrusallık iki değişkenli saçılım grafik incelenerek değerlendirilebilir.İki değişken arasındaki doğrusallık iki değişkenli saçılım grafik incelenerek değerlendirilebilir.Gruplanmamış veride bütün bireyler analize katılırken, gruplanmamış veride analiz bir grup içinde ayrı ayrı yapılır.Gruplanmamış veride bütün bireyler analize katılırken, gruplanmamış veride analiz bir grup içinde ayrı ayrı yapılır.Eğer iki değişken de normal dağılıyorsa ve doğrusal olarak ilişkiliyse, saçılım grafiği oval şeklindedir.Eğer iki değişken de normal dağılıyorsa ve doğrusal olarak ilişkiliyse, saçılım grafiği oval şeklindedir.Eğer değişkenlerden bir normal dağılmıyorsa, saçılım grafik oval şeklinde olmayacaktır.Eğer değişkenlerden bir normal dağılmıyorsa, saçılım grafik oval şeklinde olmayacaktır.Eğer veri setinde çok sayıda değişken varsa, olası bütün değişken çiftlerini incelemek yerine doğrusallıktan uzaklaşabilecek değişken çiftleri incelenebilirEğer veri setinde çok sayıda değişken varsa, olası bütün değişken çiftlerini incelemek yerine doğrusallıktan uzaklaşabilecek değişken çiftleri incelenebilir","code":""},{"path":"varsayımlar-ii.html","id":"varyansların-homojenliği","chapter":"Bölüm 2 Varsayımlar II","heading":"2.4 Varyansların homojenliği","text":"Varyansların homojenliği (homoscedasticity), bağımlı\ndeğişken(ler)bağımsız değişken(ler)aralığı boyunca\naynı düzeyde varyansa sahip olduğu sayıltısıdır.Varyansların homojenliği (homoscedasticity), bağımlı\ndeğişken(ler)bağımsız değişken(ler)aralığı boyunca\naynı düzeyde varyansa sahip olduğu sayıltısıdır.Çoğu durumda, bağımsız değişkenin bir değerinde bağımlı\ndeğişkenin çok farklı değerleri bulunur. Bu ilişkinin ele\nalınabilmesi için bağımlı değişkenin değerlerinin varyansı,\nbağımsız değişkenin değerinde oldukça eşit olmalıdır.Çoğu durumda, bağımsız değişkenin bir değerinde bağımlı\ndeğişkenin çok farklı değerleri bulunur. Bu ilişkinin ele\nalınabilmesi için bağımlı değişkenin değerlerinin varyansı,\nbağımsız değişkenin değerinde oldukça eşit olmalıdır.Varyansların homojenliği normallik sayıltısı ile ilişkilidir.\nÇok değişkenli normallik sayıltısı karşılandığında,\ndeğişkenler arasındaki ilişkiler homojendir.Varyansların homojenliği normallik sayıltısı ile ilişkilidir.\nÇok değişkenli normallik sayıltısı karşılandığında,\ndeğişkenler arasındaki ilişkiler homojendir.Varyansların heterojenliği, gruplanmış veri için çok\nönemli degildir. İki değişkenli saçılım grafik incelenerek\ndegerlendirilebilir. Değişkenler arasındaki varyans\nfarklılıkları tahmin edilebiliyorsa saçılım grafikte bu\nfarklılıklar gözlenebilir. Grafikte açıklanamayan farklılıklar\nvarsa analizi zayıflar ve geçerliği düşer.Varyansların heterojenliği, gruplanmış veri için çok\nönemli degildir. İki değişkenli saçılım grafik incelenerek\ndegerlendirilebilir. Değişkenler arasındaki varyans\nfarklılıkları tahmin edilebiliyorsa saçılım grafikte bu\nfarklılıklar gözlenebilir. Grafikte açıklanamayan farklılıklar\nvarsa analizi zayıflar ve geçerliği düşer.Varyansların heterojenligi gruplanmış veride daha\nönemlidir. Varyans homojenligini test etmek için Box’s M\ntest kullanılabilir.Varyansların heterojenligi gruplanmış veride daha\nönemlidir. Varyans homojenligini test etmek için Box’s M\ntest kullanılabilir.Varyansların heterojenliği değişkenlerden birinin normal\ndağılım göstermemesinden veya bağımsız değişkendeki\nhatalı ölçümlerden kaynaklanabilir.Varyansların heterojenliği değişkenlerden birinin normal\ndağılım göstermemesinden veya bağımsız değişkendeki\nhatalı ölçümlerden kaynaklanabilir.","code":"\npairs(screen[,2:5])"},{"path":"varsayımlar-ii.html","id":"veri-dönüştürme","chapter":"Bölüm 2 Varsayımlar II","heading":"2.4.1 Veri Dönüştürme","text":"Normallik ve varyansların homojenliği sayıltıları ihlal\nedildiği zaman veri dönüştürme düşünülebilir. Ancak veri\ndönüştürüldüğü zaman yorumlanmasının da\ngüçleşebileceği göz önünde bulundurulmalıdır.Normallik ve varyansların homojenliği sayıltıları ihlal\nedildiği zaman veri dönüştürme düşünülebilir. Ancak veri\ndönüştürüldüğü zaman yorumlanmasının da\ngüçleşebileceği göz önünde bulundurulmalıdır.Veri dönüştürmede değişkenlerin normallikten ne kadar\nuzaklaştıkları önemlidir.Veri dönüştürmede değişkenlerin normallikten ne kadar\nuzaklaştıkları önemlidir.Eğer dağılım normalden orta derecede farklılık gösteriyorsa, ilk\nolarak karekök dönüştürme denenir.Eğer dağılım normalden orta derecede farklılık gösteriyorsa, ilk\nolarak karekök dönüştürme denenir.Eğer dağılım normalden önemli derecede farklılık gösteriyorsa,\nlog dönüştürme denenir.Eğer dağılım normalden önemli derecede farklılık gösteriyorsa,\nlog dönüştürme denenir.Eğer dağılım normalden ciddi derecede farklılık gösteriyorsa, ters\ndönüştürme denenir.Eğer dağılım normalden ciddi derecede farklılık gösteriyorsa, ters\ndönüştürme denenir.Veri dönüştürmede değişkenlerin normallikten ne yönde\nuzaklaştıkları önemlidir.Veri dönüştürmede değişkenlerin normallikten ne yönde\nuzaklaştıkları önemlidir.Eğer sola çarpıklık varsa, değişkenin yansıtılması ve yansıtılma\nsonucu sağa çarpık şekle dönüşen dağılım üzerinden\ndönüştürme işlemlerinin yapılması önerilir.Eğer sola çarpıklık varsa, değişkenin yansıtılması ve yansıtılma\nsonucu sağa çarpık şekle dönüşen dağılım üzerinden\ndönüştürme işlemlerinin yapılması önerilir.Değişkeni yansıtmak için önce dağılımdaki en yüksek değer bulunur\nve bu değere 1 eklenerek sabit bir değer elde edilir. Sonra\ndağılımdaki bir değer sabit değerden çıkarılarak yeni bir değişken\nelde edilir. Böylece dönüştürme işleminden önce sola çarpık dağılım\nsağa çarpık dağılıma dönüştürülmüş olur.Değişkeni yansıtmak için önce dağılımdaki en yüksek değer bulunur\nve bu değere 1 eklenerek sabit bir değer elde edilir. Sonra\ndağılımdaki bir değer sabit değerden çıkarılarak yeni bir değişken\nelde edilir. Böylece dönüştürme işleminden önce sola çarpık dağılım\nsağa çarpık dağılıma dönüştürülmüş olur.Veri dönüştürme işlemlerinden sonra sayıltılar tekrar\nkontrol edilmelidir.Veri dönüştürme işlemlerinden sonra sayıltılar tekrar\nkontrol edilmelidir.timedrs değişkeni üzerinde yapılan dönüşüm","code":"\nltimedrs <- log(timedrs+1)\ndescribe(timedrs)\n\ndescribe(ltimedrs)"},{"path":"varsayımlar-ii.html","id":"çoklu-bağlantı-ve-tekillik","chapter":"Bölüm 2 Varsayımlar II","heading":"2.5 Çoklu Bağlantı ve Tekillik","text":"(Çoklu) bağlantı ve tekillik bağımsız değişkenler\narasındaki korelasyon çok yüksek olduğunda ortaya\nçıkan problemlerdir.(Çoklu) bağlantı ve tekillik bağımsız değişkenler\narasındaki korelasyon çok yüksek olduğunda ortaya\nçıkan problemlerdir.(Çoklu) bağlantıda değişkenler arasındaki korelasyon çok\nyüksektir.(Çoklu) bağlantıda değişkenler arasındaki korelasyon çok\nyüksektir.Tekillikte değişkenler fazlalıktır; değişkenlerden biri analizdeki iki\nveya daha fazla değişkenin bileşimidir.Tekillikte değişkenler fazlalıktır; değişkenlerden biri analizdeki iki\nveya daha fazla değişkenin bileşimidir.Değişkenler (çoklu) bağlantılıysa veya tekilse, gereksiz\nbilgi içerirler ve analizde bu değişkenlerin hepsine ihtiyaç\nyoktur. Bu değişkenlerin hepsinin modele yer alması\nmodeldeki hataları artırır ve analizi zayıflatır.Değişkenler (çoklu) bağlantılıysa veya tekilse, gereksiz\nbilgi içerirler ve analizde bu değişkenlerin hepsine ihtiyaç\nyoktur. Bu değişkenlerin hepsinin modele yer alması\nmodeldeki hataları artırır ve analizi zayıflatır.Bağlantı problemini belirlemek için bağımsız değişkenler\narasındaki iki değişkenli korelasyon katsayılarını içeren\nkorelasyon matrisi incelenebilir.Bağlantı problemini belirlemek için bağımsız değişkenler\narasındaki iki değişkenli korelasyon katsayılarını içeren\nkorelasyon matrisi incelenebilir.Örneğin, iki değişken arasındaki korelasyon katsayısının 0.90\nveya 0.90’dan daha yüksek olması bağlantı problemine işarettir.Örneğin, iki değişken arasındaki korelasyon katsayısının 0.90\nveya 0.90’dan daha yüksek olması bağlantı problemine işarettir.: Yüksek korelasyon değerlerinin bulunmaması, bağlantı\nprobleminin olmadığı anlamına gelmez. Bağlantı ilgili bağımsız\ndeğişken dışındaki diğer bağımsız değişkenlerden iki veya daha\nfazlasının bir aradaki etkisinden kaynaklanabilir ki bu durumda\nçoklu bağlantı söz konusudur.: Yüksek korelasyon değerlerinin bulunmaması, bağlantı\nprobleminin olmadığı anlamına gelmez. Bağlantı ilgili bağımsız\ndeğişken dışındaki diğer bağımsız değişkenlerden iki veya daha\nfazlasının bir aradaki etkisinden kaynaklanabilir ki bu durumda\nçoklu bağlantı söz konusudur.Çoklu bağlantının değerlendirilmesi için bir bağımsız\ndeğişkenin diğer bağımsız değişkenler tarafından ne\nölçüde açıklandığının tespit edilmesi gerekir.Çoklu bağlantının değerlendirilmesi için bir bağımsız\ndeğişkenin diğer bağımsız değişkenler tarafından ne\nölçüde açıklandığının tespit edilmesi gerekir.Çoklu bağlantının belirlenmesinde bir değişken için\nSMC (squared multiple correlation, \\(R^2\\)) değeri\nincelenebilir. \\(R^2\\) değeri regresyon modelinde belli bir\nbağımsız değişkenin gözlenen varyansının diğer bütün\nbağımsız değişkenler tarafından açıklanan miktarıdır.Çoklu bağlantının belirlenmesinde bir değişken için\nSMC (squared multiple correlation, \\(R^2\\)) değeri\nincelenebilir. \\(R^2\\) değeri regresyon modelinde belli bir\nbağımsız değişkenin gözlenen varyansının diğer bütün\nbağımsız değişkenler tarafından açıklanan miktarıdır.\\(R^2\\) değeri bağımsız değişkenlerden birinin (Örneğin, X1) bağımlı\ndeğişken, diğer bağımsız değişkenlerinse bağımsız değişken\n(Örneğin, X2, X3 gibi) olarak ele alındığı bir regresyon modeli\nkurularak hesaplanır.\\(R^2\\) değeri bağımsız değişkenlerden birinin (Örneğin, X1) bağımlı\ndeğişken, diğer bağımsız değişkenlerinse bağımsız değişken\n(Örneğin, X2, X3 gibi) olarak ele alındığı bir regresyon modeli\nkurularak hesaplanır.\\(R^2\\) değeri yüksekse, değişken diğer değişkenlerle oldukça\nilişkilidir ve yüksek değerler çoklu bağlantıya işarettir.\\(R^2\\) değeri yüksekse, değişken diğer değişkenlerle oldukça\nilişkilidir ve yüksek değerler çoklu bağlantıya işarettir.\\(R^2\\) değeri 1’e eşitse, değişken diğer değişkenlerle mükemmel\nderecede ilişkilidir ve bu değer tekilliğe işarettir.\\(R^2\\) değeri 1’e eşitse, değişken diğer değişkenlerle mükemmel\nderecede ilişkilidir ve bu değer tekilliğe işarettir.Çoklu bağlantının belirlenmesinde bir değişken için\ntolerans (tolerance) ( \\(1- R^2\\)) değeri incelenebilir. Bu değer\nbelli bir bağımsız değişkenin gözlenen varyansının\nmodeldeki diğer bağımsız değişkenler tarafından\naçıklanmayan miktarıdır.Çoklu bağlantının belirlenmesinde bir değişken için\ntolerans (tolerance) ( \\(1- R^2\\)) değeri incelenebilir. Bu değer\nbelli bir bağımsız değişkenin gözlenen varyansının\nmodeldeki diğer bağımsız değişkenler tarafından\naçıklanmayan miktarıdır.Örneğin, X1 değişkeninin gözlenen varyansının yaklaşık %25’\nmodeldeki diğer bağımsız değişkenler tarafından açıklanırsa ( \\(R^2\\)\n= 0.25), X1 değişkeninin tolerans değeri yaklaşık 0.75’tir ( \\(1- R^2\\)=\n1-0.25 = 0.75).Örneğin, X1 değişkeninin gözlenen varyansının yaklaşık %25’\nmodeldeki diğer bağımsız değişkenler tarafından açıklanırsa ( \\(R^2\\)\n= 0.25), X1 değişkeninin tolerans değeri yaklaşık 0.75’tir ( \\(1- R^2\\)=\n1-0.25 = 0.75).Tolerans değerinin yüksek olması gerekir. Daha düşük tolerans\ndeğerleri, daha yüksek derecede çoklu bağlantı anlamına gelir.\nTolerans değeri için önerilen kesme değeri 0.10’dur. Bu değer bir\nbağımsız değişken ve diğer bağımsız değişkenler arasında 0.95\ndeğerinde bir çoklu korelasyona karşılık gelmektedir.Tolerans değerinin yüksek olması gerekir. Daha düşük tolerans\ndeğerleri, daha yüksek derecede çoklu bağlantı anlamına gelir.\nTolerans değeri için önerilen kesme değeri 0.10’dur. Bu değer bir\nbağımsız değişken ve diğer bağımsız değişkenler arasında 0.95\ndeğerinde bir çoklu korelasyona karşılık gelmektedir.Çoklu bağlantının belirlenmesinde bir değişken için\nVIF değeri incelenebilir. VIF değeri tolerance değerinin tersi alınarak hesaplanır.( \\(1/(1- R^2)\\))Çoklu bağlantının belirlenmesinde bir değişken için\nVIF değeri incelenebilir. VIF değeri tolerance değerinin tersi alınarak hesaplanır.( \\(1/(1- R^2)\\))Örneğin X1 değişkenin tolerans değeri yaklaşık 0.75 ise VIF değeri 1.33 olacaktır. VIF değerinin karekoku çoklu bağlantıdan kaynaklı standart hatanın artma derecesini yansıtır.Örneğin X1 değişkenin tolerans değeri yaklaşık 0.75 ise VIF değeri 1.33 olacaktır. VIF değerinin karekoku çoklu bağlantıdan kaynaklı standart hatanın artma derecesini yansıtır.VIF değerinin kesme değeri 10'dur. Dolayısla standart hatalar hiç çoklu bağlantı bulunmayan duruma oranla üç kattan daha fazla artacaktır.VIF değerinin kesme değeri 10'dur. Dolayısla standart hatalar hiç çoklu bağlantı bulunmayan duruma oranla üç kattan daha fazla artacaktır.Çoklu bağlantı problemi belirlenirse,Çoklu bağlantı problemi belirlenirse,Birinci seçenek çoklu bağlantıya neden olan değişkenlerden en\naz birisinin analizden çıkarılmasıdır.Birinci seçenek çoklu bağlantıya neden olan değişkenlerden en\naz birisinin analizden çıkarılmasıdır.İkinci seçenek çoklu bağlantıya neden olan değişkenlere ait\ndeğerlerin toplanması veya ortalamasının alınmasıdır.İkinci seçenek çoklu bağlantıya neden olan değişkenlere ait\ndeğerlerin toplanması veya ortalamasının alınmasıdır.Üçüncü seçenek temel bileşenlerin hesaplanıp analizlerde temel\nbileşenlerin kullanılmasıdır.Üçüncü seçenek temel bileşenlerin hesaplanıp analizlerde temel\nbileşenlerin kullanılmasıdır.","code":"\ncor(screen[,2:5]) %>% kable(digit=2)\nlibrary(corrplot)\n\ncorrplot(cor(screen[,2:5]))\nmodel <- lm(subno ~ timedrs  +   attdrug  +  atthouse  +income + race+ mstatus ,\ndata = screen)\nlibrary(olsrr)\nols_vif_tol(model) %>% kable(digit=2)"},{"path":"varsayımlar-ii.html","id":"kaynaklar-1","chapter":"Bölüm 2 Varsayımlar II","heading":"2.6 Kaynaklar","text":"Rummel, R. J. (1970). Applied Factor Analyis. Evanston,IL: Northwestern University\nPress.","code":""},{"path":"regresyon.html","id":"regresyon","chapter":"Bölüm 3 Regresyon","heading":"Bölüm 3 Regresyon","text":"Bilindiği üzere, t-testi, varyans analizi gibi ortalama farkları ile ilgili hipotez testleri değişkenler arasındaki ilişkiye dair herhangi bir bilgi vermemektedir.Bilindiği üzere, t-testi, varyans analizi gibi ortalama farkları ile ilgili hipotez testleri değişkenler arasındaki ilişkiye dair herhangi bir bilgi vermemektedir.Oysa serpilme diyagramlarına bakıldığında değişkenler arasında bir ilişki olabileceği hissedilebilmekte fakat bu tür analizlerle bu ilişkiler ortaya koyulamamaktadır.Oysa serpilme diyagramlarına bakıldığında değişkenler arasında bir ilişki olabileceği hissedilebilmekte fakat bu tür analizlerle bu ilişkiler ortaya koyulamamaktadır.Dolayısıyla değişkenler arasındaki ilişkinin şeklini, yönünü ve kuvvetini belirleyebilmemiz için yeni metotlara ihtiyaç vardır. Bu metotlar ise genel olarak regresyon (eğri uydurma) ve korelasyon analizi olarak adlandırılır.Dolayısıyla değişkenler arasındaki ilişkinin şeklini, yönünü ve kuvvetini belirleyebilmemiz için yeni metotlara ihtiyaç vardır. Bu metotlar ise genel olarak regresyon (eğri uydurma) ve korelasyon analizi olarak adlandırılır.","code":""},{"path":"regresyon.html","id":"regresyon-kullanım-alanları","chapter":"Bölüm 3 Regresyon","heading":"3.1 Regresyon Kullanım Alanları","text":"Tarımda belli ürünlerin verimi etkileyen toprak türü, tohum, sulama v.b. faktörlerin saptanması ve bunlar yardımıyla belli şartlarda alınacak ürün miktarının kestirilmesi tarımın önemli konusudur.Tarımda belli ürünlerin verimi etkileyen toprak türü, tohum, sulama v.b. faktörlerin saptanması ve bunlar yardımıyla belli şartlarda alınacak ürün miktarının kestirilmesi tarımın önemli konusudur.Bir değişkenin değerlerinin ilgili başka değişkenler yardımıyla kestirilmesi, günlük yaşamımızın, ticaretin ekonominin, doğa ve sosyal bilimlerin önemli konularını içendedir.Bir değişkenin değerlerinin ilgili başka değişkenler yardımıyla kestirilmesi, günlük yaşamımızın, ticaretin ekonominin, doğa ve sosyal bilimlerin önemli konularını içendedir.günlük yaşamımızın, ticaretin ekonominin, doğa ve sosyal bilimlerin pek çok alanındaki çalışmalarda iki ya da daha çok değişken arasında fonksiyonel ilişkiler vardır. Bu ilişkiler matematiksel bir denklem yazılabilir.günlük yaşamımızın, ticaretin ekonominin, doğa ve sosyal bilimlerin pek çok alanındaki çalışmalarda iki ya da daha çok değişken arasında fonksiyonel ilişkiler vardır. Bu ilişkiler matematiksel bir denklem yazılabilir.Örneğin taksi hizmeti ödenen \\(ücret = + bx\\)\n\n: sabit (taksimetre açılış ücreti)\n\nb: kilometrede artan ücret","code":""},{"path":"regresyon.html","id":"regresyon-kullanım-alanları-1","chapter":"Bölüm 3 Regresyon","heading":"3.2 Regresyon Kullanım Alanları","text":"Regresyon çözümlemenin temel amacı; bağımlı değişken ile bağımsız değişken(ler) arasındaki ilişkiyi matematiksel modelle açıklayarak bağlantılar bulmak ve bağımsız değişken(ler) yardımıyla bağımlı değişkenli kestirmek şeklinde özetlenebilir.Regresyon çözümlemenin temel amacı; bağımlı değişken ile bağımsız değişken(ler) arasındaki ilişkiyi matematiksel modelle açıklayarak bağlantılar bulmak ve bağımsız değişken(ler) yardımıyla bağımlı değişkenli kestirmek şeklinde özetlenebilir.Sosyal bilimlerde değişkenler arasındaki ilişkiler bir dereceye kadar fonksiyoneldir. (taksimetre örneği kadar net değildir!) Bu ilişkiye probabilisitik ilişki denir.Sosyal bilimlerde değişkenler arasındaki ilişkiler bir dereceye kadar fonksiyoneldir. (taksimetre örneği kadar net değildir!) Bu ilişkiye probabilisitik ilişki denir.Sosyal bilimlerde değişkenler arasındaki ilişkilerin matematiksel olarak kesin ifadelerle yazılamaması, bu değişkenlere ait önceki bilgiler yardımıyla elde edilmesi ve matematiksel ifadelerin bu bilgilere dayanılarak yazılması yolunu açmıştır.Sosyal bilimlerde değişkenler arasındaki ilişkilerin matematiksel olarak kesin ifadelerle yazılamaması, bu değişkenlere ait önceki bilgiler yardımıyla elde edilmesi ve matematiksel ifadelerin bu bilgilere dayanılarak yazılması yolunu açmıştır.Regresyon terimi 19. yüzyılda İngiliz istatistikçisi Francis Galton tarafından bir biyolojik inceleme için ortaya atılmıştır. Bu incelemenin ana konusu kalıtım olup, aile içinde baba ve annenin boyu ile çocukların boyu arasındaki bağlantıyı araştırmakta ve çocukların boylarının bir nesil içinde eski ata nesillerinin ortalamasına geri döndüklerini yani bir nesil içinde ortalamaya geri dönüş olduğu inceleme konusudur.Regresyon terimi 19. yüzyılda İngiliz istatistikçisi Francis Galton tarafından bir biyolojik inceleme için ortaya atılmıştır. Bu incelemenin ana konusu kalıtım olup, aile içinde baba ve annenin boyu ile çocukların boyu arasındaki bağlantıyı araştırmakta ve çocukların boylarının bir nesil içinde eski ata nesillerinin ortalamasına geri döndüklerini yani bir nesil içinde ortalamaya geri dönüş olduğu inceleme konusudur.","code":""},{"path":"regresyon.html","id":"basit-doğrusal-regresyon","chapter":"Bölüm 3 Regresyon","heading":"3.3 Basit Doğrusal Regresyon","text":"Bir bağımsız \\(X\\) değişkeninin değerlerinden ona bağlı değişkeninin değerlerinin kestirilmesini sağlayan denkleme \\(Y\\)’\\(X\\)’e göre regresyonu denir.\\[Y= bx + \\]\n- Regresyon denkleminde \\(b\\) doğrunun eğimidir – \\(X\\)’1 puanlık değişimine karşılık Y’nin ne kadar değişeceğini belirtir. (buna regresyon katsayısı denir)\\(\\) ise \\(Y\\)-kesişim noktasıdır – \\(X\\) sıfıra eşit olduğunda \\(Y\\)’nin alacağı değerdir (buna regresyon sabiti denir)\\(\\) ise \\(Y\\)-kesişim noktasıdır – \\(X\\) sıfıra eşit olduğunda \\(Y\\)’nin alacağı değerdir (buna regresyon sabiti denir)Lise matematik puanlarından yararlanarak üniversite genel matematik puanlarını kestirme amacıyla üniversite genel matematik dersini alan öğrencilerden uygun bir örneklem alınmıştır.Lise matematik puanlarından yararlanarak üniversite genel matematik puanlarını kestirme amacıyla üniversite genel matematik dersini alan öğrencilerden uygun bir örneklem alınmıştır.Regresyon analizi yapmadan önce saçılım diagramı incelenmelidir. Puanlar saçılım grafiğinde tek bir doğru oluşturmamaktadır. Ancak doğru oluşturma eğilimleri vardır.Noktalardan olabildiğince yakın geçecek bir doğru çizilebilirse bu doğrudan yararlanarak \\(X\\) puanı bilinen öğrencilerin \\(Y\\) puanları kestirilebilir.","code":"\nlise_not <- c(18,35,53,24,64,58,32,39,64,82,32,49,48,70,57)\nuni_not  <- c(33,46,47,21,73,55,74,32,56,68,43,46,68,84,61)\nveri <- data.frame(lise_not, uni_not)\nggplot2::ggplot(veri, aes(x = lise_not, y = uni_not)) + \n  geom_point() +   \n  geom_smooth(method = \"lm\", se = F)\nbasitreg <- lm(uni_not ~ lise_not , veri)\nsummary(basitreg)## \n## Call:\n## lm(formula = uni_not ~ lise_not, data = veri)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -16.475  -8.349  -0.449   5.037  31.158 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(>|t|)   \n## (Intercept)   21.373     10.196    2.10   0.0562 . \n## lise_not       0.671      0.198    3.38   0.0049 **\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 13.4 on 13 degrees of freedom\n## Multiple R-squared:  0.468,  Adjusted R-squared:  0.427 \n## F-statistic: 11.4 on 1 and 13 DF,  p-value: 0.0049"},{"path":"regresyon.html","id":"en-küçük-kareler-yöntemi","chapter":"Bölüm 3 Regresyon","heading":"3.4 En küçük kareler yöntemi","text":"Bu yönteme göre ve b öyle bir belirlenmelidir ki dağılımdaki noktaların, doğrunun etrafındaki değişkenliği en aza indirgenmiş olmalıdır.Bu yönteme göre ve b öyle bir belirlenmelidir ki dağılımdaki noktaların, doğrunun etrafındaki değişkenliği en aza indirgenmiş olmalıdır.Regresyon doğrusu, noktalar ile regresyon doğrusu arasındaki sapmaların kareler toplamı en az olacak şekilde, saçılım grafiğindeki noktalar kümesine en uygun yere çizildiğinden bu ölçüte en küçük kareler ölçütü adı verilir.Regresyon doğrusu, noktalar ile regresyon doğrusu arasındaki sapmaların kareler toplamı en az olacak şekilde, saçılım grafiğindeki noktalar kümesine en uygun yere çizildiğinden bu ölçüte en küçük kareler ölçütü adı verilir.\\(Y\\) değeri ve regresyon doğrusundaki \\(Y′\\) arasındaki farkın en küçük olacak şekilde yerleştirilir.\\(Y\\) değeri ve regresyon doğrusundaki \\(Y′\\) arasındaki farkın en küçük olacak şekilde yerleştirilir.\\(\\sum(Y-Y′)^2\\) en küçük olacak şekilde yerleştirir.\\(\\sum(Y-Y′)^2\\) en küçük olacak şekilde yerleştirir.\\(b_{yx}=\\frac{n\\sum{XY}-\\sum{X}\\sum{Y}}{n\\sum{X^2}-(\\sum{X})^2}\\)\\(b_{yx}=\\frac{n\\sum{XY}-\\sum{X}\\sum{Y}}{n\\sum{X^2}-(\\sum{X})^2}\\)\\(a_{yx}=\\frac{n\\sum{Y}-b_{YX}\\sum{X}}{n}\\)\\(a_{yx}=\\frac{n\\sum{Y}-b_{YX}\\sum{X}}{n}\\)\\(b_{yx}\\) hesaplama\\(b_{yx}\\) hesaplama\\(b_{YX}=\\frac{n\\sum{XY}-\\sum{X}\\sum{Y}}{n\\sum{X^2}-(\\sum{X})^2}\\)\\(b_{YX}=\\frac{n\\sum{XY}-\\sum{X}\\sum{Y}}{n\\sum{X^2}-(\\sum{X})^2}\\)Regresyon doğrusunun eğimi, değişkenlerin standart sapmalarının oranlarıyla bunlar arasındaki korelasyonun çarpımına eşittir.\\(a_{yx}\\) hesaplama\\(a_{yx}\\) hesaplama\\(a_{yx}=\\frac{n\\sum{Y}-b_{yx}\\sum{X}}{n}\\)\\(a_{yx}=\\frac{n\\sum{Y}-b_{yx}\\sum{X}}{n}\\)","code":"\nn <- length(lise_not)\nbyx = (n*sum(lise_not*uni_not)-sum(lise_not)*sum(uni_not))/\n  (n*sum(lise_not^2) - sum(lise_not)^2)\nbyx## [1] 0.671\n(sd(uni_not)/sd(lise_not))*cor(lise_not,uni_not)## [1] 0.671\nattach(veri)\nayx = (sum(uni_not) - byx*sum(lise_not))/15\nayx## [1] 21.4"},{"path":"regresyon.html","id":"kestirimin-standart-hatası","chapter":"Bölüm 3 Regresyon","heading":"3.5 Kestirimin Standart Hatası","text":"Kestirim sonunda \\(Y\\) değişkeninin gözlenen değerleri ile regresyon değerleri \\(Y'\\) arasında fark olmaması veya bu farkın olabildiği kadar küçük olması istenir.Kestirim sonunda \\(Y\\) değişkeninin gözlenen değerleri ile regresyon değerleri \\(Y'\\) arasında fark olmaması veya bu farkın olabildiği kadar küçük olması istenir.Gözlenen \\(Y\\) ve kestirilen \\(Y'\\) değerleri arasındaki farklar kestirimdeki hatalardır. Bu farkların karelerinin ortalamasının kare köküne kestirimin standart hatası adı verilir.Gözlenen \\(Y\\) ve kestirilen \\(Y'\\) değerleri arasındaki farklar kestirimdeki hatalardır. Bu farkların karelerinin ortalamasının kare köküne kestirimin standart hatası adı verilir.\\[S_{yx}=\\sqrt{\\sum{\\frac{(Y-Y')^2}{n-2}}}\\]\\[S_{yx}=\\sqrt{\\sum{\\frac{(Y-Y')^2}{n-2}}}\\]\\[S_{yx}=\\sqrt{\\frac{\\sum{Y^2}-\\sum{Y}-b\\sum{XY}}{n-2}}\\]\\[S_{yx}=\\sqrt{\\frac{\\sum{Y^2}-\\sum{Y}-b\\sum{XY}}{n-2}}\\]Ortak dağılımın için kestirimin standart hatası tek değişkenli dağılımın standart sapmasına benzer.Ortak dağılımın için kestirimin standart hatası tek değişkenli dağılımın standart sapmasına benzer.Standart sapma tek değişkenli dağılımın ortalamadan farkının standart bir ölçüsü olduğu gibi, kestirimin standart hatası da noktaların standart regresyon çizgisinden farkının ölçüsüdür.Standart sapma tek değişkenli dağılımın ortalamadan farkının standart bir ölçüsü olduğu gibi, kestirimin standart hatası da noktaların standart regresyon çizgisinden farkının ölçüsüdür.Bu nedenle kestirimin standart hatası verilen X değeri için kestirilen Y değerinin standart sapması şeklinde okunabilen \\(S_{yx}\\) sembolü ile gösterilir.Bu nedenle kestirimin standart hatası verilen X değeri için kestirilen Y değerinin standart sapması şeklinde okunabilen \\(S_{yx}\\) sembolü ile gösterilir.\\(X\\) değerlerinden kestirilen \\(Y'\\) ’lerin standart hatası","code":"\nsqrt((sum(uni_not^2)-ayx*sum(uni_not)-\n       byx*(sum(uni_not*lise_not)))/13)\n\n\nres <- basitreg$residuals## [1] 13.4\nsqrt(sum((res - mean(res)) ^ 2 / (length(res)-2)))## [1] 13.4"},{"path":"regresyon.html","id":"basit-doğrusal-regresyon-uygulama","chapter":"Bölüm 3 Regresyon","heading":"3.5.1 Basit Doğrusal Regresyon Uygulama","text":"\\(R\\) İki değişken arasında pearson korelasyon katsayısı\\(R\\) İki değişken arasında pearson korelasyon katsayısı\\(R-Square:\\) Determinasyon katsayısı/bağımsız değişkenin bağımlı değişken üzerindeki açıklama oranı\\(R-Square:\\) Determinasyon katsayısı/bağımsız değişkenin bağımlı değişken üzerindeki açıklama oranı\\(\\text{Adjusted R Square:}\\) Düzeltmiş determinasyon katsayısı, şans eseri açıklanan değişimin neden olduğu hatanın arındırılmış hali.\\(\\text{Adjusted R Square:}\\) Düzeltmiş determinasyon katsayısı, şans eseri açıklanan değişimin neden olduğu hatanın arındırılmış hali.\\(\\text{Standart Kestirimin Hatası:}\\) Hata teriminin standart sapmasıdır.\\(\\text{Standart Kestirimin Hatası:}\\) Hata teriminin standart sapmasıdır.Tablodaki \\(p\\) değeri regresyon modelindeki yordanan ve yordayan değişkenler arasındaki ilişki için hesaplanan değerin anlamlı olup olmadığını göstermektedir.Tablodaki \\(p\\) değeri regresyon modelindeki yordanan ve yordayan değişkenler arasındaki ilişki için hesaplanan değerin anlamlı olup olmadığını göstermektedir.Yani regresyon modelinde lise matematik puanları ile genel matematik puanları arasında doğrusal ilişki anlamlı düzeydedir. Regresyon modelindeki \\(\\text{df}\\) 1 olması nedeni, regresyon modelindeki sabit ve eğimi katsayı olarak almasıdır. 2-1Yani regresyon modelinde lise matematik puanları ile genel matematik puanları arasında doğrusal ilişki anlamlı düzeydedir. Regresyon modelindeki \\(\\text{df}\\) 1 olması nedeni, regresyon modelindeki sabit ve eğimi katsayı olarak almasıdır. 2-1\\(p\\) değerleri sabitin ve yordayıcı değişkenin katsayısının anlamlılık testi sonuçları\\(p\\) değerleri sabitin ve yordayıcı değişkenin katsayısının anlamlılık testi sonuçları","code":"\nbasitreg <- lm(uni_not ~ lise_not , veri)\nlibrary(broom)\nglance(basitreg) %>% kable()\nglance(basitreg)[,c(1,2,4,6,5)]\ntidy(basitreg)"},{"path":"çoklu-regresyon.html","id":"çoklu-regresyon","chapter":"Bölüm 4 Çoklu Regresyon","heading":"Bölüm 4 Çoklu Regresyon","text":"Çok değişkenli analiz, bir çalışmadaki bireylerden veya\nnesnelerden elde edilen çoklu ölçümlerin aynı anda\nanalizidir. Dolayısıyla ikiden fazla değişkenin aynı anda\nanalizi çok değişkenli analiz olarak düşünülebilir.Çok değişkenli analiz, bir çalışmadaki bireylerden veya\nnesnelerden elde edilen çoklu ölçümlerin aynı anda\nanalizidir. Dolayısıyla ikiden fazla değişkenin aynı anda\nanalizi çok değişkenli analiz olarak düşünülebilir.Çoklu regresyon, basit regresyonun tek bir bağımlı değişkenin\niki veya daha fazla yordayıcısına izin veren uzantısıdır. Diğer bir\nifadeyle, çoklu regresyon tek bir bağımlı değişken ile iki veya daha\nfazla bağımsız (yordayıcı) değişken arasındaki ilişkinin analiz\nedilmesi için kullanılan istatistiksel bir yöntemdir.Çoklu regresyon, basit regresyonun tek bir bağımlı değişkenin\niki veya daha fazla yordayıcısına izin veren uzantısıdır. Diğer bir\nifadeyle, çoklu regresyon tek bir bağımlı değişken ile iki veya daha\nfazla bağımsız (yordayıcı) değişken arasındaki ilişkinin analiz\nedilmesi için kullanılan istatistiksel bir yöntemdir.Çoklu regresyonun amacı değerleri bilinen bağımsız değişkenleri\nkullanarak bağımlı değişkenin değerini yordamaktır.Çoklu regresyonun amacı değerleri bilinen bağımsız değişkenleri\nkullanarak bağımlı değişkenin değerini yordamaktır.Regresyon yöntemiyle bağımsız değişkenlerden en fazla yordamayı\nsağlamak üzere bağımsız değişken ağırlıklandırılır.Regresyon yöntemiyle bağımsız değişkenlerden en fazla yordamayı\nsağlamak üzere bağımsız değişken ağırlıklandırılır.Ağırlıklar bağımsız değişkenin yordamaya bağıl katkısını ifade eder\nve bir değişkenin yordamadaki etkisine ilişkin yorumlamayı kolaylaştırır.Ağırlıklar bağımsız değişkenin yordamaya bağıl katkısını ifade eder\nve bir değişkenin yordamadaki etkisine ilişkin yorumlamayı kolaylaştırır.Çoklu regresyon, hem bağımlı değişken hem de bağımsız\ndeğişkenler en az eşit aralıklı ölçek düzeyinde ölçüldüğünde\nkullanılmalıdır.Çoklu regresyon, hem bağımlı değişken hem de bağımsız\ndeğişkenler en az eşit aralıklı ölçek düzeyinde ölçüldüğünde\nkullanılmalıdır.Ancak bağımsız değişkenler sınıflama veya sıralama ölçeğinde ölçüldüğünde ilgili değişkenler belli koşullar\naltında analize dahil edilebilir.Ancak bağımsız değişkenler sınıflama veya sıralama ölçeğinde ölçüldüğünde ilgili değişkenler belli koşullar\naltında analize dahil edilebilir.Çoklu regresyon bir bağımsız değişkendeki değişikliklerin\nbağımlı değişkendeki değişikliklerle ne ölçüde ilişkili olduğunu\nkestirir.Çoklu regresyon bir bağımsız değişkendeki değişikliklerin\nbağımlı değişkendeki değişikliklerle ne ölçüde ilişkili olduğunu\nkestirir.Ancak bağımsız değişkenler arasındaki korelasyon\nyordama sürecini zorlaştırır.Ancak bağımsız değişkenler arasındaki korelasyon\nyordama sürecini zorlaştırır.","code":""},{"path":"çoklu-regresyon.html","id":"bağımsız-değişkenler-arasındaki-ilişki","chapter":"Bölüm 4 Çoklu Regresyon","heading":"4.1 Bağımsız değişkenler arasındaki ilişki","text":"ceteris paribusÖrneğin, \\(X_1\\) ve \\(Y\\) arasındaki korelasyon katsayısı 0.40, \\(X_2\\) ve \\(Y\\)\narasındaki korelasyon katsayısı 0.60, \\(X_1\\) ve \\(X_2\\) arasındaki korelasyon\nkatsayısı sıfır ise, \\(Y\\)’nin varyansının iki değişken tarafından\naçıklanan toplam oranı iki değişkenin \\(Y\\) ile korelasyonlarının\nkareleri toplamından elde edilebilir:\\(0.40^2 + 0.50^2 = 0.16 + 0.25 = 0.41\\)Ancak, uygulamada çoğunlukla \\(X_1\\) ve \\(X_2\\) birlikte değişim gösterirler\nve iki değişkenin \\(Y\\) ile korelasyonlarının kareleri toplamı\nçok yüksek bir oran verir.Ancak, uygulamada çoğunlukla \\(X_1\\) ve \\(X_2\\) birlikte değişim gösterirler\nve iki değişkenin \\(Y\\) ile korelasyonlarının kareleri toplamı\nçok yüksek bir oran verir.Bunun nedeni, iki bağımsız değişkenin aralarındaki korelasyondan dolayı\nbir bağımsız değişken tarafından açıklanan \\(Y\\) varyansının bir kısmının üst üste gelmesidir.Bunun nedeni, iki bağımsız değişkenin aralarındaki korelasyondan dolayı\nbir bağımsız değişken tarafından açıklanan \\(Y\\) varyansının bir kısmının üst üste gelmesidir.Çoklu regresyonun en önemli özelliği modele eklenen bağımsız\ndeğişkenler arasındaki ilişkileri kontrol altına almasıdır.Çoklu regresyonun en önemli özelliği modele eklenen bağımsız\ndeğişkenler arasındaki ilişkileri kontrol altına almasıdır.Modeldeki bağımsız değişkenler arasındaki ilişkilerin kontrol altına alınması, modeldeki bir değişkenin bağımlı değişken üzerindeki etkisini incelerken, modeldeki diğer bütün değişkenlerin sabit tutulmasıdır.ceteris paribus\nÖrneğin, bir çalışmada kahve tüketiminin ölüm oranını nasıl etkilediği çalışılmıştır. Başta, sonuçlar daha yüksek kahve tüketiminin daha yüksek ölüm riskiyle ilişkili olduğunu göstermiştir. Ancak kahve içen çoğu kişi sigara da içmektedir. Araştırmacılar modellerine sigara içme alışkanlıkları için bir değişken eklediklerinde, sigara içmenin ölüm riskini artırırken, kahve tüketiminin ölüm riskini azalttığını bulmuşlardır.\nModeldeki bağımsız değişkenler arasındaki ilişkilerin kontrol altına alınması, modeldeki bir değişkenin bağımlı değişken üzerindeki etkisini incelerken, modeldeki diğer bütün değişkenlerin sabit tutulmasıdır.ceteris paribusÖrneğin, bir çalışmada kahve tüketiminin ölüm oranını nasıl etkilediği çalışılmıştır. Başta, sonuçlar daha yüksek kahve tüketiminin daha yüksek ölüm riskiyle ilişkili olduğunu göstermiştir. Ancak kahve içen çoğu kişi sigara da içmektedir. Araştırmacılar modellerine sigara içme alışkanlıkları için bir değişken eklediklerinde, sigara içmenin ölüm riskini artırırken, kahve tüketiminin ölüm riskini azalttığını bulmuşlardır.Bu durumda modele bütün önemli değişkenlerin eklenmesi gerekmektedir. Önemli değişkenlerin modelin dışında bırakılması, katsayılara ilişkin kestirimlerin yanlı olmasına neden olabilmektedir.Bu durumda modele bütün önemli değişkenlerin eklenmesi gerekmektedir. Önemli değişkenlerin modelin dışında bırakılması, katsayılara ilişkin kestirimlerin yanlı olmasına neden olabilmektedir.","code":""},{"path":"çoklu-regresyon.html","id":"çoklu-regresyon-uygulama","chapter":"Bölüm 4 Çoklu Regresyon","heading":"4.2 Çoklu Regresyon Uygulama","text":"Öğrencilerin matematikteki performans düzeylerini, motivasyon ve\nkaygı düzeylerinden yordamak ile ilgilendiğimizi düşünelim.Öğrencilerin matematikteki performans düzeylerini, motivasyon ve\nkaygı düzeylerinden yordamak ile ilgilendiğimizi düşünelim.Bu araştırma sorusuna cevap vermek için çoklu regresyon uygun bir\nistatistiksel analiz yöntemdir.Bu araştırma sorusuna cevap vermek için çoklu regresyon uygun bir\nistatistiksel analiz yöntemdir.\\[Y_{\\text{performans}_i} = b_0 + b_1 X_{\\text{motivasyon}_i}  +  b_2 X_{\\text{kaygi}_i}  + e_i\\]Burada, \\(b_1\\) ve \\(b_2\\) motivasyon ve kaygı yordayıcıları için ağırlıklardır. Diğer bir ifadeyle regresyon katsayılarıdır veya eğimlerdir. \\(b_0\\) ise kesişimdir.Burada, \\(b_1\\) ve \\(b_2\\) motivasyon ve kaygı yordayıcıları için ağırlıklardır. Diğer bir ifadeyle regresyon katsayılarıdır veya eğimlerdir. \\(b_0\\) ise kesişimdir.veri seti 🔗 Performans.savveri seti 🔗 Performans.savPerformans: Öğrencilerin matematik performans düzeyleri olup eşit aralık\nölçeğinde ölçülen sürekli bir değişkendir.Performans: Öğrencilerin matematik performans düzeyleri olup eşit aralık\nölçeğinde ölçülen sürekli bir değişkendir.Motivasyon: Öğrencilerin motivasyon\ndüzeyleri olup eşit aralık ölçeğinde\nölçülen sürekli bir değişkendir.Motivasyon: Öğrencilerin motivasyon\ndüzeyleri olup eşit aralık ölçeğinde\nölçülen sürekli bir değişkendir.Kaygı: Öğrencilerin kaygı düzeyleri olup\neşit aralık ölçeğinde ölçülen sürekli bir\ndeğişkendir.Kaygı: Öğrencilerin kaygı düzeyleri olup\neşit aralık ölçeğinde ölçülen sürekli bir\ndeğişkendir.Güven: Öğrencilerin matematiğe karşı\ngüven düzeyleri olup eşit aralık ölçeğinde\nölçülen sürekli bir değişkendir.Güven: Öğrencilerin matematiğe karşı\ngüven düzeyleri olup eşit aralık ölçeğinde\nölçülen sürekli bir değişkendir.Analize başlamadan önce değişkenlerin betimsel istatistikleri ve değişkenler arası korelasyonlar incelenmelidir.Analize başlamadan önce değişkenlerin betimsel istatistikleri ve değişkenler arası korelasyonlar incelenmelidir.Betimsel İstatistiklerKorelasyon değerleri ve anlamlılığıİlişki Grafiği3D grafik3D grafik\nRegresyonda amaç hata puanlarının (artıkların) kareleri toplamının küçüleceği,\ndiğer bir ifade ile \\(Y\\) ve yordanan \\(Y'\\) arasındaki korelasyonun\nbüyüyeceği, \\(b_0\\), \\(b_1\\) ve \\(b_2\\) değerleri için tek bir çözüm kümesi\nbulmaktır.Regresyonda amaç hata puanlarının (artıkların) kareleri toplamının küçüleceği,\ndiğer bir ifade ile \\(Y\\) ve yordanan \\(Y'\\) arasındaki korelasyonun\nbüyüyeceği, \\(b_0\\), \\(b_1\\) ve \\(b_2\\) değerleri için tek bir çözüm kümesi\nbulmaktır.Grafiğin sadeleştirilmesi için bir bağımsız değişken kullanılmıştır. Tek bir çözüm bulmak için kullanılan yöntem Sıradan En\nKüçük Kareler Yöntemi (Ordinary Least Squares Procedure) olarak adlandırılır.Grafiğin sadeleştirilmesi için bir bağımsız değişken kullanılmıştır. Tek bir çözüm bulmak için kullanılan yöntem Sıradan En\nKüçük Kareler Yöntemi (Ordinary Least Squares Procedure) olarak adlandırılır.\\(R^2\\) değeri çoklu korelasyon katsayısı (multiple correlation\ncoefficient) olup bağımlı değişkenin gözlenen değerleri ile bağımsız\ndeğişkenlerin en iyi doğrusal kombinasyonu arasındaki\nkorelasyondur.\\(R^2\\) değeri çoklu korelasyon katsayısı (multiple correlation\ncoefficient) olup bağımlı değişkenin gözlenen değerleri ile bağımsız\ndeğişkenlerin en iyi doğrusal kombinasyonu arasındaki\nkorelasyondur.En iyi doğrusal kombinasyon, bağımlı değişkenin\nbağımsız değişkenlerden yordanmasında, daha iyi bir iş yapacak\nregresyon katsayıları kümesi olmadığı anlamına gelir.En iyi doğrusal kombinasyon, bağımlı değişkenin\nbağımsız değişkenlerden yordanmasında, daha iyi bir iş yapacak\nregresyon katsayıları kümesi olmadığı anlamına gelir.Çoklu KorelasyonR değeri bağımlı değişkenin gözlenen ve yordanan değerleri arasındaki korelasyondur.R değeri bağımlı değişkenin gözlenen ve yordanan değerleri arasındaki korelasyondur.Bağımlı değişkenin yordanan değerinin bağımlı değişkenin\ngözlenen değerine mümkün olduğunca yakın olmasını\ngerektiren en küçük kareler kriterinden dolayı bağımlı\ndeğişkenin gözlenen ve yordanan değerleri arasındaki korelasyon eksi\ndeğerler alamaz. Dolayısıyla çoklu korelasyon katsayısı 0 ile 1\narasında değişirBağımlı değişkenin yordanan değerinin bağımlı değişkenin\ngözlenen değerine mümkün olduğunca yakın olmasını\ngerektiren en küçük kareler kriterinden dolayı bağımlı\ndeğişkenin gözlenen ve yordanan değerleri arasındaki korelasyon eksi\ndeğerler alamaz. Dolayısıyla çoklu korelasyon katsayısı 0 ile 1\narasında değişirÇoklu Korelasyon Formulu \n\\[R_{Y_{12}}= \\sqrt{\\frac{r^2_{Y_1}+r^2_{Y_2}-2r^2_{Y_1}r^2_{Y_2}r_{12}}{1-r_{12}}}\\]\n\\[R_{Y_{12}}=\\sqrt{\\frac{(0.824)^2+(-0.241)^2-2*(0.824)(-0.241)(0.147)}{1-(0.147)^2}}) = 0.902\\]öğrencilerin gözlenen performans puanları ve yoradan performans puanları arasındaki korelasyon katsayısı nokta 0.902 eşittirÇoklu korelasyon katsayısının kestirimi hem örneklem büyüklüğüne\n\\((n)\\) hem de bağımsız değişkenlerin sayısına \\((k)\\) bağlıdır.Çoklu korelasyon katsayısının kestirimi hem örneklem büyüklüğüne\n\\((n)\\) hem de bağımsız değişkenlerin sayısına \\((k)\\) bağlıdır.Bağımlı değişken ile bağımsız değişkenler arasında hiç ilişki yoksa,\n\\(R\\) değerinin sıfıra yakın olması beklenir ancak \\(R\\)’nin beklenen değeri\nrastgele bir veri için \\(k/(n-1)\\)’dir.\nÖrneğin, örneklem büyüklüğünün 50, bağımsız değişken sayısının 2 olduğu bir durumda, bağımlı değişken ile bağımsız değişkenler arasında hiç ilişki yoksa, R değeri 0.04 olacaktır, 0 değil.\nBağımlı değişken ile bağımsız değişkenler arasında hiç ilişki yoksa,\n\\(R\\) değerinin sıfıra yakın olması beklenir ancak \\(R\\)’nin beklenen değeri\nrastgele bir veri için \\(k/(n-1)\\)’dir.Örneğin, örneklem büyüklüğünün 50, bağımsız değişken sayısının 2 olduğu bir durumda, bağımlı değişken ile bağımsız değişkenler arasında hiç ilişki yoksa, R değeri 0.04 olacaktır, 0 değil.Bu nedenle büyük örnekleme sahip olmak önemlidir. bağımsız\ndeğişken için en az 10 gözlem önerilmektedir. Bir başka öneri de\nörneklem büyüklüğünün bağımsız değişken sayısından en az 50\nfazla olması yönündedir.Bu nedenle büyük örnekleme sahip olmak önemlidir. bağımsız\ndeğişken için en az 10 gözlem önerilmektedir. Bir başka öneri de\nörneklem büyüklüğünün bağımsız değişken sayısından en az 50\nfazla olması yönündedir.Bir çalışmada, tek bir bağımsız değişken bulunduğunda, 0.80 güce sahip olmak için 0.30 evren korelasyonunun 124 birey gerektireceği belirtilmiştir. Beş bağımsız değişken bulunduğundaysa, örneklem büyüklüğünün 187 olması gerekmektedir.Bir çalışmada, tek bir bağımsız değişken bulunduğunda, 0.80 güce sahip olmak için 0.30 evren korelasyonunun 124 birey gerektireceği belirtilmiştir. Beş bağımsız değişken bulunduğundaysa, örneklem büyüklüğünün 187 olması gerekmektedir.","code":"\nlibrary(haven)\nlibrary(dplyr)\nlibrary(knitr)## Warning: package 'knitr' was built under R version 4.3.3\nperformans <- read_sav(\"import/Performans.sav\")\npsych::describe(performans) %>% kable(digit=3)\nlibrary(broom)\ncor_1 <- cor.test(~ Performans + Motivasyon , data = performans)\ntidy(cor_1)  %>% kable(digit=3)\ncor_2 <- cor.test(~ Performans + Kaygi , data = performans)\ntidy(cor_2)[,c(1,3)]  %>% kable(digit=3)\ncor_3 <- cor.test(~ Motivasyon + Kaygi , data = performans)\ntidy(cor_3)[,c(1,3)] %>% kable(digit=3)\nlibrary(GGally)\nggpairs(performans[,1:3])\nlibrary(scatterplot3d)\nscatterplot3d(performans[,1:3],\n              pch = 16,\n              color=\"steelblue\", \n              angle=75)\nscatterplot3d(performans[,1:3],\n              pch = 16, color=\"steelblue\",\n              angle=75,\n              box = FALSE,type = \"h\")## Warning: Unknown or uninitialised column: `color`.\nlibrary(rgl)\nplot3d(performans$Performans, performans$Motivasyon, performans$Kaygi,\nxlab = \"Performans\", ylab = \"Motivasyon\", \nzlab = \"Kaygi\", \ntype = \"s\",size = 1.5,col = \"red\")\nrglwidget() \nmodel <- lm(Performans ~ Motivasyon + Kaygi,data=performans)\nsqrt(glance(model)[,1]) #r.squared değerinin karekoku alınır\nmodel_s <- augment(model,data=performans)\ncor(model_s[,1], model_s[,5]) # Y ve Y' arası korelasyon##              .fitted\n## Performans 0.9019952"},{"path":"çoklu-regresyon.html","id":"belirlilik-katsayısı","chapter":"Bölüm 4 Çoklu Regresyon","heading":"4.3 Belirlilik Katsayısı","text":"\\(R^2\\) değeri belirlilik katsayısı (coefficient determination) olup\nbağımlı değişkenin gözlenen ve yordanan değerleri arasındaki\nkorelasyonun karesi alınarak hesaplanır. Bu değer bağımlı\ndeğişkendeki varyansın model tarafından açıklanan oranını ifade\neder. Diğer bir ifadeyle bağımlı değişkenin varyansının bağımsız\ndeğişkenlerin en iyi doğrusal kombinasyonu ile paylaşılan oranını\nifade eder.\nPerformans puanlarındaki varyansın yaklaşık %81’öğrencilerin motivasyon ve kaygı puanları tarafından açıklanabilir.Modele yeni bir bağımsız değişken eklendiğinde, \\(R^2\\) değeri artar,\nsadece şans eseri olsa bile. Böylece daha fazla bağımsız değişken\niçeren model sadece daha fazla bağımsız değişken içerdiği için\nveriye daha iyi uyum sağlıyor gibi gözükebilir.Modele yeni bir bağımsız değişken eklendiğinde, \\(R^2\\) değeri artar,\nsadece şans eseri olsa bile. Böylece daha fazla bağımsız değişken\niçeren model sadece daha fazla bağımsız değişken içerdiği için\nveriye daha iyi uyum sağlıyor gibi gözükebilir.Bu etkiyi gidermek için \\(adj R^2\\) değeri hesaplanabilir.Bu etkiyi gidermek için \\(adj R^2\\) değeri hesaplanabilir.\\(\\text{adj}{R^2}\\) değeri, \\(R^2\\) değerinin modeldeki bağımsız değişken sayısı için modifiye edilmiş versiyonudur. \\(\\text{adj}{R^2}\\) değeri, yeni eklenen bağımsız\ndeğişken modeli şans eseri beklenenden daha fazla geliştirirse artar,\ndaha az geliştirirse azalır.\\(\\text{adj}{R^2}\\) değeri, \\(R^2\\) değerinin modeldeki bağımsız değişken sayısı için modifiye edilmiş versiyonudur. \\(\\text{adj}{R^2}\\) değeri, yeni eklenen bağımsız\ndeğişken modeli şans eseri beklenenden daha fazla geliştirirse artar,\ndaha az geliştirirse azalır.\\(\\text{adj}{R^2}\\) değeri, eksi değerler alabilir ancak genellikle artı değerler alır. zaman \\(R^2\\) değerinden daha düşüktür.\\(\\text{adj}{R^2}\\) değeri, eksi değerler alabilir ancak genellikle artı değerler alır. zaman \\(R^2\\) değerinden daha düşüktür.\\(R^2\\) değeri, \\(n\\) gözlemlerin sayısı, \\(k\\) bağımsız değişkenlerin sayısı olmak üzere, aşağıdaki eşitlikle hesaplanabilir.\n\\[R^2_{adj}= R^2 - \\frac{k-(1-R^2)}{n-k-1}\\]\n\\[R^2_{adj}= 0.814 - \\frac{2-(1-0.814)}{15-2-1} =0.783\\]\\(R^2\\) değeri, \\(n\\) gözlemlerin sayısı, \\(k\\) bağımsız değişkenlerin sayısı olmak üzere, aşağıdaki eşitlikle hesaplanabilir.\n\\[R^2_{adj}= R^2 - \\frac{k-(1-R^2)}{n-k-1}\\]\n\\[R^2_{adj}= 0.814 - \\frac{2-(1-0.814)}{15-2-1} =0.783\\]\\(adj R^2\\) evrende gerçek korelasyonun karesinin daha az yanlı kestirimi olsa da, çoğunlukla \\(R^2\\) değeri rapor edilir.","code":"\nmodel <- lm(Performans ~ Motivasyon + Kaygi,data=performans)\nglance(model)[,1]\nglance(model)[,2]"},{"path":"çoklu-regresyon.html","id":"kestirimin-standart-hatası-1","chapter":"Bölüm 4 Çoklu Regresyon","heading":"4.4 Kestirimin standart hatası","text":"Kestirimin standart hatası (standard error estimation), modeldeki artıkların karelerinin toplamının, \\(n-p\\) ( \\(n\\) örneklem büyüklüğü ve \\(p\\) modeldeki parametrelerin sayısı) ile bölünmesiyle elde edilen bölümün kareköküdür.","code":"\nres <- model$residuals\n\n\nsqrt(sum((res - mean(res)) ^ 2 / (length(res)-3)))## [1] 3.650458\nglance(model)[,3]"},{"path":"çoklu-regresyon.html","id":"model-veri-uyumu","chapter":"Bölüm 4 Çoklu Regresyon","heading":"4.5 Model veri uyumu","text":"Modelin veriye iyi uyup uymadığının test edilmesinde kullanılacak F değeri varyans analizi sonucunda elde edilir.Modelin veriye iyi uyup uymadığının test edilmesinde kullanılacak F değeri varyans analizi sonucunda elde edilir.Regresyonun anlamlılığının test edildiği varyans analizinde, birlikte ele alınan bir grup bağımsız değişkenin (motivasyon ve kaygı gibi) en iyi doğrusal kombinasyonu ile bağımlı değişken (performans gibi) arasında korelasyon yoktur sıfır hipotezi test edilir. İstatistiksel olarak anlamlı etki, evrende çoklu korelasyon katsayısının sıfırdan farklı olduğu anlamına gelir.Regresyonun anlamlılığının test edildiği varyans analizinde, birlikte ele alınan bir grup bağımsız değişkenin (motivasyon ve kaygı gibi) en iyi doğrusal kombinasyonu ile bağımlı değişken (performans gibi) arasında korelasyon yoktur sıfır hipotezi test edilir. İstatistiksel olarak anlamlı etki, evrende çoklu korelasyon katsayısının sıfırdan farklı olduğu anlamına gelir.F istatistiği 26.2 değerine eşittir ve istatistiğe ilişkin p < 0.001. Bu olasılık 0.05’ten küçük olduğundan, sıfır hipotezi reddedilir.F istatistiği 26.2 değerine eşittir ve istatistiğe ilişkin p < 0.001. Bu olasılık 0.05’ten küçük olduğundan, sıfır hipotezi reddedilir.Bu sonuç motivasyon ve kaygı değişkenlerinin ikisi birlikte kullanıldığında, çoklu korelasyon katsayısının anlamlı olarak sıfırdan büyük olduğunu ifade etmektedir. Diğer bir ifadeyle, motivasyon ve kaygı değişkenleri performansı istatistiksel olarak anlamlı bir şekilde yordamaktadır.Bu sonuç motivasyon ve kaygı değişkenlerinin ikisi birlikte kullanıldığında, çoklu korelasyon katsayısının anlamlı olarak sıfırdan büyük olduğunu ifade etmektedir. Diğer bir ifadeyle, motivasyon ve kaygı değişkenleri performansı istatistiksel olarak anlamlı bir şekilde yordamaktadır.Regresyon modeli veriye iyi uyum sağlamaktadır.Regresyon modeli veriye iyi uyum sağlamaktadır.Model sonuçlarıModel sonuçlarıPerformans puanlarındaki farklılıkların bir kısmı motivasyon puanlarındaki farklılıklardan, bir kısmı ise kaygı puanlarındaki farklılıklardan kaynaklanmaktadır","code":"\nglance(model)[,4:6] %>% kable(digit=3)\ntidy(model) %>% kable(digit=3)"},{"path":"çoklu-regresyon.html","id":"kaygının-sabit-tutulması","chapter":"Bölüm 4 Çoklu Regresyon","heading":"4.6 Kaygının sabit tutulması","text":"Performansın sadece kaygıdan yordandığı basit regresyon analizi gerçekleştirilirse, yordanan puanlar ve gözlenen puanlar arasındaki fark (artıkPER1), performansın kaygıdan yordanamayan kısmı olacaktır.Motivasyonun sadece kaygıdan yordandığı basit regresyon analizi gerçekleştirilirse, yordanan puanlar ve gözlenen puanlar arasındaki fark (artıkMOT), motivasyonun kaygıdan yordanamayan kısmı olacaktır.Böylece artıkPER1 ve artıkMOT olarak adlandırılan artık puanlar kaygıdan bağımsız olacaktır.Böylece artıkPER1 ve artıkMOT olarak adlandırılan artık puanlar kaygıdan bağımsız olacaktır.Diğer bir ifadeyle, kaygı ilişkilerinde herhangi bir rol oynamayacaktır. artıkPER1 puanları artıkMOT puanlarından yordanırsa, artıkMOT puanlarına ilişkin eğim katsayısı 0.686 olarak kestirilecektir. Bu değer, öğrencilerin kaygı düzeyleri kontrol altına alındıktan sonra, motivasyon düzeylerindeki bir birimlik artışın matematikteki performans düzeylerini 0.686 birim artırmaya eğilimli olduğunu önermektedirDiğer bir ifadeyle, kaygı ilişkilerinde herhangi bir rol oynamayacaktır. artıkPER1 puanları artıkMOT puanlarından yordanırsa, artıkMOT puanlarına ilişkin eğim katsayısı 0.686 olarak kestirilecektir. Bu değer, öğrencilerin kaygı düzeyleri kontrol altına alındıktan sonra, motivasyon düzeylerindeki bir birimlik artışın matematikteki performans düzeylerini 0.686 birim artırmaya eğilimli olduğunu önermektedir\\[B_{Y_{12}} = \\frac{r_{Y1}-r_{Y2}r_{12}}{1-r^2_{12}}\\frac{sd_Y}{sd_1}\\]\\[B_{Y_{12}} = \\frac{r_{Y1}-r_{Y2}r_{12}}{1-r^2_{12}}\\frac{sd_Y}{sd_1}\\]\\[B_{Y_{12}} = \\frac{(0.824)-(-0.241)(0.147)}{1-(0.022)}\\frac{7.827}{10.025} = 0.879 * 0.780 =0.686\\]\\[B_{Y_{12}} = \\frac{(0.824)-(-0.241)(0.147)}{1-(0.022)}\\frac{7.827}{10.025} = 0.879 * 0.780 =0.686\\]Bu değer, kaygı puanı kontrol altına alındıktan sonra, motivasyon puanlarındaki\nbir birimlik artışın öğrencilerin matematik performansından 0.686 birim artmaya eğilimi olduğunu önermektedir.Bu değer, kaygı puanı kontrol altına alındıktan sonra, motivasyon puanlarındaki\nbir birimlik artışın öğrencilerin matematik performansından 0.686 birim artmaya eğilimi olduğunu önermektedir.","code":"\nartıkPER1 <- lm(Performans ~  Kaygi,data=performans)$residuals\nartıkMOT <- lm(Motivasyon  ~  Kaygi,data=performans)$residuals\nlm(artıkPER1  ~  artıkMOT,\n   data=data.frame(artıkPER1,artıkMOT))$coefficients %>% kable(digit=3)\n((cor(performans)[2,1] - cor(performans)[3,1]*cor(performans)[2,3])/\n   (1-cor(performans)[2,3]^2))*(sd(performans$Performans)/sd(performans$Motivasyon))## [1] 0.6862988"},{"path":"çoklu-regresyon.html","id":"motivasyonun-sabit-tutulması","chapter":"Bölüm 4 Çoklu Regresyon","heading":"4.7 Motivasyonun sabit tutulması","text":"Performansın sadece motivasyondan yordandığı basit regresyon analizi\ngerçekleştirilirse, yordanan puanlar ve gözlenen puanlar arasındaki fark\n(artıkPER2), performansın motivasyondan yordanamayan kısmı olacaktır.Kaygının sadece motivasyondan yordandığı basit regresyon analizi\ngerçekleştirilirse, yordanan puanlar ve gözlenen puanlar arasındaki\nfark (artıkKAY), kaygının motivasyondan yordanamayan kısmı olacaktır.Böylece artıkPER2 ve artıkKAY olarak adlandırılan artık puanlar motivasyondan bağımsız olacaktır. Diğer bir ifadeyle, motivasyon ilişkilerinde herhangi bir rol oynamayacaktır.Böylece artıkPER2 ve artıkKAY olarak adlandırılan artık puanlar motivasyondan bağımsız olacaktır. Diğer bir ifadeyle, motivasyon ilişkilerinde herhangi bir rol oynamayacaktır.artıkPER2 puanları artıkKAY puanlarından yordanırsa, artıkKAY\npuanlarına ilişkin eğim katsayısı -0.607 olarak kestirilecektir. Bu değer,\nöğrencilerin motivasyon düzeyleri kontrol altına alındıktan sonra, kaygı\ndüzeylerindeki bir birimlik artışın matematikteki performans düzeylerini 0.607 birim azaltmaya eğilimli olduğunu önermektedirartıkPER2 puanları artıkKAY puanlarından yordanırsa, artıkKAY\npuanlarına ilişkin eğim katsayısı -0.607 olarak kestirilecektir. Bu değer,\nöğrencilerin motivasyon düzeyleri kontrol altına alındıktan sonra, kaygı\ndüzeylerindeki bir birimlik artışın matematikteki performans düzeylerini 0.607 birim azaltmaya eğilimli olduğunu önermektedir\\[B_{Y_{21}} = \\frac{r_{Y2}-r_{Y1}r_{12}}{1-r^2_{12}}\\frac{sd_Y}{sd_2}\\]\\[B_{Y_{12}} = \\frac{(-0.241)-(0.824)(0.147)}{1-(0.022)}\\frac{7.827}{4.769}=(-0.370)*(1.641) =-0.607\\]Bu değer, motivasyon puanı kontrol altına alındıktan sonra, kaygı puanlarındaki bir birimlik artışın öğrencilerin matematik performansından 0.607 birim azaltmaya eğilimli olduğunu önermektedir.","code":"\nartıkPER2 <- lm(Performans ~  Motivasyon ,data=performans)$residuals\nartıkKAY <- lm(Kaygi ~  Motivasyon ,data=performans)$residuals\nlm(artıkPER2  ~  artıkKAY,\n   data=data.frame(artıkPER2,artıkKAY))$coefficients %>% kable(digit=3)\n((cor(performans)[3,1] - cor(performans)[2,1]*cor(performans)[2,3])/\n   (1-cor(performans)[2,3]^2))*(sd(performans$Performans)/sd(performans$Kaygi))## [1] -0.6072857"},{"path":"çoklu-regresyon.html","id":"regresyon-sabiti","chapter":"Bölüm 4 Çoklu Regresyon","heading":"4.8 Regresyon Sabiti","text":"\\[B_0 = M_Y - B_{Y12}*M_1 -B_{Y21}*M_2\\]\n\\[B_0 = 18.176  - (0.686)*(39.933) -(-0.607)*(18.701) = 1.744\\]Bu değer hem motivasyon puanı hem de kaygı puanı 0'eşit olduğunda yordanan performans puanıdır.Böylece yordanan performans puanı\\[Y_{\\text{performans}_i} = 1.744 + 0.686 X_{\\text{motivasyon}_i} -  0.607 X_{\\text{kaygi}_i}\\]","code":"\nmean(performans$Performans)-\n  model$coefficients[2]*mean(performans$Motivasyon)-\n  model$coefficients[3]*mean(performans$Kaygi)## Motivasyon \n##   1.744129"},{"path":"çoklu-regresyon.html","id":"standart-puanlar-ile-regresyon","chapter":"Bölüm 4 Çoklu Regresyon","heading":"4.9 Standart puanlar ile regresyon","text":"Çoklu regresyon eşitliğini elde etmeden önce değişkenlerin biri\nstandartlaştırılırsa (değişkenlerin birinin ortalaması 0, standart sapması 1 olacak şekilde ayarlanırsa), sonuçlar standart sapma birimlerince ifade edilir.Böylece örnekte standartlaştırılmış değişkenler kullanıldığında, yordanan\nstandartlaştırılmış performans düzeyleri aşağıdaki eşitlikle hesaplanabilir:\\[Y_\\text{Zperformans_i} = 0.879 X_\\text{Zmotivasyon_i} + -0.370 X_\\text{Zkaygi_i}\\]\n- Değişkenler standartlaştırıldığında, kesişim katsayısı 0 olacaktır ve eşitlikte gösterilmeyecektir.Motivasyon için standartlaştırılmış eğim katsayısı \\(\\beta_\\text{motivasyon}\\) 0.879 değerine eşittir. Bu değer, kaygı puanı kontrol altına alındıktan sonra, motivasyon\npuanındaki bir standart sapmalık artışın öğrencilerin matematikteki\nperformans puanlarını 0.879 standart sapma artırmaya eğilimli olduğunu\nönermektedir.Motivasyon için standartlaştırılmış eğim katsayısı \\(\\beta_\\text{motivasyon}\\) 0.879 değerine eşittir. Bu değer, kaygı puanı kontrol altına alındıktan sonra, motivasyon\npuanındaki bir standart sapmalık artışın öğrencilerin matematikteki\nperformans puanlarını 0.879 standart sapma artırmaya eğilimli olduğunu\nönermektedir.Benzer şekilde, kaygı için standartlaştırılmamış eğim katsayısı \\(\\beta_{motivasyon}\\) -0.370 değerine eşittir. Bu değer, motivasyon puanı kontrol altına alındıktan sonra, kaygı puanındaki bir standart sapmalık artışın öğrencilerin matematikteki performans puanlarını 0.370 standart sapma azaltmaya eğilimli olduğunu\nönermektedir.Benzer şekilde, kaygı için standartlaştırılmamış eğim katsayısı \\(\\beta_{motivasyon}\\) -0.370 değerine eşittir. Bu değer, motivasyon puanı kontrol altına alındıktan sonra, kaygı puanındaki bir standart sapmalık artışın öğrencilerin matematikteki performans puanlarını 0.370 standart sapma azaltmaya eğilimli olduğunu\nönermektedir.Motivasyonun standartlaştırılmış eğim katsayısının mutlak değeri,\nkaygının standartlaştırılmış eğim katsayının mutlak değerinden daha büyük olduğundan,\nmotivasyonun öğrencilerin matematikteki performanslarını yordamada kaygıya\ngöre daha önemli bir yordayıcı olduğu söylenebilir.Motivasyonun standartlaştırılmış eğim katsayısının mutlak değeri,\nkaygının standartlaştırılmış eğim katsayının mutlak değerinden daha büyük olduğundan,\nmotivasyonun öğrencilerin matematikteki performanslarını yordamada kaygıya\ngöre daha önemli bir yordayıcı olduğu söylenebilir.|0.879| > |-0.307|Standartlaştırılmış eğim katsayılarının bağıl büyüklükleri \"önemin\" en iyi\ngöstergeleri olmasa da, yorumlanmaları kolaydır ve regresyon analizlerinin\nyürütülmesinde yararlanılan bilgisayar programlarının çoğu tarafından yazdırılır.\nAncak bağımsız değişkenlerin standartlaştırılmamış eğim katsayılarını karşılaştırmak uygun değildir.\n: Bağımsız değişkenler arasında korelasyon olduğunda, standartlaştırılmış eğim katsayısı bağımlı değişken ile bağımsız değişken arasındaki korelasyon katsayısı değildir.\nStandartlaştırılmış eğim katsayılarının bağıl büyüklükleri \"önemin\" en iyi\ngöstergeleri olmasa da, yorumlanmaları kolaydır ve regresyon analizlerinin\nyürütülmesinde yararlanılan bilgisayar programlarının çoğu tarafından yazdırılır.Ancak bağımsız değişkenlerin standartlaştırılmamış eğim katsayılarını karşılaştırmak uygun değildir.Ancak bağımsız değişkenlerin standartlaştırılmamış eğim katsayılarını karşılaştırmak uygun değildir.: Bağımsız değişkenler arasında korelasyon olduğunda, standartlaştırılmış eğim katsayısı bağımlı değişken ile bağımsız değişken arasındaki korelasyon katsayısı değildir.: Bağımsız değişkenler arasında korelasyon olduğunda, standartlaştırılmış eğim katsayısı bağımlı değişken ile bağımsız değişken arasındaki korelasyon katsayısı değildir.","code":"\nlibrary(QuantPsyc)\nlm.beta(model) %>% kable(digit=3)"},{"path":"çoklu-regresyon.html","id":"yordanan-ve-artık-değerler","chapter":"Bölüm 4 Çoklu Regresyon","heading":"4.10 Yordanan ve Artık Değerler","text":"Öğrencilerin standratlaştırılmamış yordanan matematik performans düzeyleri ve standartlaştırılmamış artıkları modelden çekilebilir.Örneğin, ilk öğrenci için standratlaştırılmamış yordanan değer yaklaşık 7.46, artık ise yaklaşık 4.910’tir.","code":"\ndata.frame(\n  gercek = performans$Performans,\n  yordanan = model$fitted.values,\n  artik = model$residuals) %>% kable(digit=3)"},{"path":"çoklu-regresyon.html","id":"yordanan-ve-artık-değerlerin-standart-puanları","chapter":"Bölüm 4 Çoklu Regresyon","heading":"4.10.1 Yordanan ve Artık Değerlerin Standart Puanları","text":"Öğrencilerin standratlaştırılmış yordanan matematik performans düzeyleri ve standartlaştırılmış artıkları modelden çekilebilir.","code":"\nlibrary(outliers)\nyordanan_s <- model$fitted.values %>% scores(type = \"z\")\nartik_s <- model$residuals %>% scores(type = \"z\")\ndata.frame(yordanan_s,artik_s)  %>% kable(digit=3)"},{"path":"çoklu-regresyon.html","id":"model-grafikleri","chapter":"Bölüm 4 Çoklu Regresyon","heading":"4.11 Model Grafikleri","text":"Model grafikleri dört farklı şekilde göstermektedir:Artıklar ve Yordanan Değerler: Doğrusal ilişki varsayımlarını kontrol etmek için kullanılır. Belirgin desenleri olmayan yatay bir çizgi, doğrusal bir ilişkinin göstergesidir.Normal Q-Q. Artıkların normal dağılıp dağılmadığını incelemek için kullanılır. Artık noktalarının düz kesikli çizgiyi takip etmesi beklenir.Ölçek-Konum (veya Yayılma-Konum). Artıkların varyansının homojenliğini (homoscedasticity) kontrol etmek için kullanılır. Eşit yayılmış noktalara sahip yatay çizgi, homoscedasticity'nin iyi bir göstergesidir.Artıklar ve Kaldıraç/Leverage Etkili gözlemleri, yani analize dahil edildiğinde veya analizden çıkarıldığında regresyon sonuçlarını etkileyebilecek uç değerleri belirlemek için kullanılır.Model grafiklerini daha düzgün elde etmek için ggfortify pakeini de kullanabilirsiniz.","code":"\nopar <- par(mfrow = c(2,2), oma = c(0, 0, 1.1, 0))\nplot(model, las = 1)      # Residuals, Fitted, ...\npar(opar)\nlibrary(ggfortify)## Warning: package 'ggfortify' was built under R version 4.3.3\nautoplot(model)"},{"path":"çoklu-regresyon.html","id":"çoklu-regresyon-1","chapter":"Bölüm 4 Çoklu Regresyon","heading":"4.12 Çoklu Regresyon","text":"Regresyon katsayılarından birinin istatistiksel olarak sıfırdan\nfarklı olup olmadığı test edilebilir. Bu durumda regresyon\nkatsayılarına ilişkin test edilecek sıfır hipotezleri aşağıdaki gibidir:\\(H_0: \\beta_1 = 0\\)\n- Kaygı düzeyleri eşit olan öğrenciler için\nmotivasyon düzeylerindeki farklılıklar\nperformans düzeylerinde farklılığa yol açmaz.\\(H_0: \\beta_2 = 0\\)\n- Motivasyon düzeyleri eşit olan öğrenciler için\nkaygı düzeylerindeki farklılıklar performans\ndüzeylerinde farklılığa yol açmaz.Hipotez testlerine ilişkin t istatistiği, standartlaştırılmamış regresyon\nkatsayılarının standart hatalarına bölünmesi ile hesaplanır.Motivasyona ilişkin eğim için testin, olasılık değeri (p ˂ 0.001)\n0.05’ten daha küçük olduğundan, anlamlı olarak sıfırdan farklı\nolduğu görülmektedir.Motivasyona ilişkin eğim için testin, olasılık değeri (p ˂ 0.001)\n0.05’ten daha küçük olduğundan, anlamlı olarak sıfırdan farklı\nolduğu görülmektedir.Hipotez testlerine ilişkin t istatistiği standartlaştırılmamış regresyon\nkatsayılarının standart hatalarına bölünmesi ile hesaplanır.Hipotez testlerine ilişkin t istatistiği standartlaştırılmamış regresyon\nkatsayılarının standart hatalarına bölünmesi ile hesaplanır.Kaygıya ilişkin eğim de anlamlıdır (t = -2.936, p = 0.012), öğrencilerin\nmotivasyon düzeylerindeki farklılıklar kontrol altına alınsa bile, öğrencilerin\nkaygı düzeyleri performans düzeylerinde fark yapmaktadır ve kaygı düzeyi negatif bir etkiye\nsahiptir.Kaygıya ilişkin eğim de anlamlıdır (t = -2.936, p = 0.012), öğrencilerin\nmotivasyon düzeylerindeki farklılıklar kontrol altına alınsa bile, öğrencilerin\nkaygı düzeyleri performans düzeylerinde fark yapmaktadır ve kaygı düzeyi negatif bir etkiye\nsahiptir.Hipotez testlerine ilişkin t istatistiği standartlaştırılmamış regresyon\nkatsayılarının standart hatalarına bölünmesi ile hesaplanır.Hipotez testlerine ilişkin t istatistiği standartlaştırılmamış regresyon\nkatsayılarının standart hatalarına bölünmesi ile hesaplanır.Regresyon katsayısının standart hatası tekrarlanan örneklemlerde\nistatistiğin değişkenliğini belirtir.Regresyon katsayısının standart hatası tekrarlanan örneklemlerde\nistatistiğin değişkenliğini belirtir.İki regresyon katsayısı ile ilgili p değerleri 0.05 alfa düzeyinden daha\nküçüktür, bu nedenle iki bağımsız değişken de öğrencilerin matematikteki\nperformanslarını yordamada istatistiksel olarak anlamlıdır.İki regresyon katsayısı ile ilgili p değerleri 0.05 alfa düzeyinden daha\nküçüktür, bu nedenle iki bağımsız değişken de öğrencilerin matematikteki\nperformanslarını yordamada istatistiksel olarak anlamlıdır.","code":"\ntidy(model) %>% kable(digit=3)\n0.686 /0.0984## [1] 6.971545"},{"path":"çoklu-regresyon.html","id":"yol-şeması","chapter":"Bölüm 4 Çoklu Regresyon","heading":"4.13 Yol Şeması","text":"Çoklu regresyon modelini bir yol şeması ile sunmak oldukça kullanışlıdır.Standart çözümStandart olmayan çözüm:: Araştırmacılar özellikle ortalamaların yapısı ile ilgilenmedikleri sürece yol şemasında \\(b_0\\) gösterilmez.Yol şemeasını istediğiniz formata getirebilirsiniz.Anlamlılık düzeylerini ekleyebilirsiniz.Öğrencilerin matematik performanslarının düzeyini motivasyon\nve kaygı düzeylerinden yordamak için çoklu regresyon analizi\ngerçekleştirilmiştir. Genel regresyon istatistiksel olarak anlamlıdır\n\\(F_{[2, 12]} = 26.188, p < .001\\) ve \\(R^2 = 0.814\\) Öğrencilerin hem\nmotivasyonlarının düzeyi ( \\(b_1 = 0.686\\)) hem kaygılarının düzeyi ( \\(b_2 = -0.607\\)) matematik performanslarının düzeyinin istatistiksel olarak anlamlı yordayıcılarıdır,\n\\(t = 6.975; p < .001, t = -2.936; p = .012\\)","code":"\n# path model\nlibrary(lavaan)## This is lavaan 0.6-17\n## lavaan is FREE software! Please report any bugs.\nlibrary(lavaanPlot)\nmodel_1 <- 'Performans ~  Motivasyon + Kaygi'\nfit1 <- sem(model_1, data = performans)\nlavaanPlot(model = fit1, coefs = TRUE, stand = TRUE, sig = 0.05) \nlavaanPlot(model = fit1, coefs = TRUE, stand = FALSE, sig = 0.05) \nlibrary(semptools)\nlibrary(semPlot)\nm <- matrix(c(\"Motivasyon\", NA, \"NA\",  NA,   NA,\n                NA, NA, NA,  NA, \"Performans\",\n              \"Kaygi\",    NA, NA,  NA,   NA), byrow = TRUE, 3, 5)\n\n\nyol<- semPaths( fit1,  whatLabels = \"std\",\n           sizeMan = 10,\n           edge.label.cex = 1.15,\n           style = \"ram\",\n           nCharNodes = 0, nCharEdges = 0,\n           layout = m)\nyol <- mark_sig(yol, fit1)\n\nplot(yol)"},{"path":"çoklu-regresyon.html","id":"aşamalı-stepwise-regresyon","chapter":"Bölüm 4 Çoklu Regresyon","heading":"4.14 Aşamalı (Stepwise) Regresyon","text":"Bir regresyon modeline dahil edilebilecek çok sayıda değişken\nbulunduğunda, bu değişkenlerden en uygun regresyon eşitliğinin\noluşturulması için değişken seçiminde çeşitli yöntemler vardır. Bu\nyöntemlerden birisi aşamalı stepwise regresyondur.Bir regresyon modeline dahil edilebilecek çok sayıda değişken\nbulunduğunda, bu değişkenlerden en uygun regresyon eşitliğinin\noluşturulması için değişken seçiminde çeşitli yöntemler vardır. Bu\nyöntemlerden birisi aşamalı stepwise regresyondur.Aşamalı regresyon yöntemi bağımsız değişkenin regresyon\nmodeline katkısının incelenmesini sağlar.Aşamalı regresyon yöntemi bağımsız değişkenin regresyon\nmodeline katkısının incelenmesini sağlar.Bu yönteme göre önce bağımlı değişkenle en yüksek korelasyona\nsahip bağımsız değişken seçilerek basit regresyon modeli kurulur.Bu yönteme göre önce bağımlı değişkenle en yüksek korelasyona\nsahip bağımsız değişken seçilerek basit regresyon modeli kurulur.Birinci regresyon eşitliğinden kalan hata varyansının istatistiksel olarak anlamlı kısmını en çok açıklayan bağımsız değişkeni bulmak\niçin kısmi korelasyon katsayıları incelenir ve en yüksek kısmi korelasyon katsayısına sahip bağımsız değişken modele eklenir.Birinci regresyon eşitliğinden kalan hata varyansının istatistiksel olarak anlamlı kısmını en çok açıklayan bağımsız değişkeni bulmak\niçin kısmi korelasyon katsayıları incelenir ve en yüksek kısmi korelasyon katsayısına sahip bağımsız değişken modele eklenir.İki bağımsız değişken ile regresyon eşitliği yeniden hesaplanır ve\neklenen değişkenin modele anlamlı katkısı olup olmadığı test edilir.\nBu işlem modele anlamlı katkı sağlayacak değişken kalmayana\nkadar devam eder.İki bağımsız değişken ile regresyon eşitliği yeniden hesaplanır ve\neklenen değişkenin modele anlamlı katkısı olup olmadığı test edilir.\nBu işlem modele anlamlı katkı sağlayacak değişken kalmayana\nkadar devam eder.Birinci modelde motivasyon tek yordayıcıdır ve performans ile korelasyonu 0.824’tür \\(R = 0.824\\) . Motivasyon tek başına performans puanlarındaki\nvaryansın yaklaşık %68’ini \\(R^2 = 0.680\\) açıklamaktadır.Birinci modelde motivasyon tek yordayıcıdır ve performans ile korelasyonu 0.824’tür \\(R = 0.824\\) . Motivasyon tek başına performans puanlarındaki\nvaryansın yaklaşık %68’ini \\(R^2 = 0.680\\) açıklamaktadır.Modele kaygının yordayıcı olarak eklenmesiyle korelasyon 0.902’ye \\(R = 0.902\\) yükselmiştir. Motivasyon ve kaygı birlikte performans puanlarındaki\nvaryansın yaklaşık %81’ini \\(R^2 = 0.814\\) açıklamaktadır.Modele kaygının yordayıcı olarak eklenmesiyle korelasyon 0.902’ye \\(R = 0.902\\) yükselmiştir. Motivasyon ve kaygı birlikte performans puanlarındaki\nvaryansın yaklaşık %81’ini \\(R^2 = 0.814\\) açıklamaktadır.Modele kaygının eklenmesiyle \\(R^2\\) değişimi (R Square Change) 0.134’tür. \\(R^2\\) değerindeki bu değişim kaygının eklenmesiyle açıklanan varyans oranında\n%13’lük bir artış olduğu anlamındadır. \\(R^2\\) değişimi F testi (F Change) ile test edilmiştir ve F değerindeki değişim istatistiksel olarak anlamlıdır \\(p = 0.012\\) Dolayısıyla modele eklenen kaygı değişkeni yordamayı anlamlı olarak\ngeliştirmiştir.Modele kaygının eklenmesiyle \\(R^2\\) değişimi (R Square Change) 0.134’tür. \\(R^2\\) değerindeki bu değişim kaygının eklenmesiyle açıklanan varyans oranında\n%13’lük bir artış olduğu anlamındadır. \\(R^2\\) değişimi F testi (F Change) ile test edilmiştir ve F değerindeki değişim istatistiksel olarak anlamlıdır \\(p = 0.012\\) Dolayısıyla modele eklenen kaygı değişkeni yordamayı anlamlı olarak\ngeliştirmiştir.Modelde tek bir yordayıcı (motivasyon) varken, korelasyon 0.824’tür ve sıfır hipotezi doğruysa bu kadar yüksek bir korelasyon elde etme olasılığı p < 0.001.\nBu olasılık 0.05’ten küçük olduğundan, korelasyonun anlamlı olarak sıfırdan\nbüyük olduğu söylenebilir.Modelde tek bir yordayıcı (motivasyon) varken, korelasyon 0.824’tür ve sıfır hipotezi doğruysa bu kadar yüksek bir korelasyon elde etme olasılığı p < 0.001.\nBu olasılık 0.05’ten küçük olduğundan, korelasyonun anlamlı olarak sıfırdan\nbüyük olduğu söylenebilir.Modele motivasyon değişkeninin yanı sıra kaygı değişkeni de yordayıcı olarak\neklendiğinde, çoklu korelasyon 0.902’dir ve sıfır hipotezi doğruysa bu kadar yüksek bir korelasyon elde etme olasılığı p < 0.001. Bu olasılık 0.05’ten küçük olduğundan, çoklu korelasyonun anlamlı olarak sıfırdan büyük olduğu söylenebilir.Modele motivasyon değişkeninin yanı sıra kaygı değişkeni de yordayıcı olarak\neklendiğinde, çoklu korelasyon 0.902’dir ve sıfır hipotezi doğruysa bu kadar yüksek bir korelasyon elde etme olasılığı p < 0.001. Bu olasılık 0.05’ten küçük olduğundan, çoklu korelasyonun anlamlı olarak sıfırdan büyük olduğu söylenebilir.Birinci modelde motivasyon tek yordayıcıdır. Bu modelde motivasyona ilişkin\nstandartlaştırılmamış eğim katsayısı 0.644 olarak kestirilmiş olup kestirimin standart hatası 0.123’tür. Bu katsayı p ˂ .05’te anlamlıdır. Standartlaştırılmış eğim katsayısı 0.824 olarak kestirilmiştir ve bu değer motivasyon ile performansarasındaki korelasyondur.Birinci modelde motivasyon tek yordayıcıdır. Bu modelde motivasyona ilişkin\nstandartlaştırılmamış eğim katsayısı 0.644 olarak kestirilmiş olup kestirimin standart hatası 0.123’tür. Bu katsayı p ˂ .05’te anlamlıdır. Standartlaştırılmış eğim katsayısı 0.824 olarak kestirilmiştir ve bu değer motivasyon ile performansarasındaki korelasyondur.İkinci modelde motivasyon ve kaygı yordayıcılardır. Bu modelde motivasyona ilişkin standartlaştırılmamış eğim katsayısı 0.686 olarak kestirilmiş olup kestirimin standart hatası 0.098’dir.İkinci modelde motivasyon ve kaygı yordayıcılardır. Bu modelde motivasyona ilişkin standartlaştırılmamış eğim katsayısı 0.686 olarak kestirilmiş olup kestirimin standart hatası 0.098’dir.Öğrencilerin kaygı düzeyi kontrol altına alındığında,\nartan motivasyon düzeyi daha yüksek performans puanları ile ilişkilidir. Bu katsayı p ˂ .05’te anlamlıdır. Standartlaştırılmış eğim katsayısı 0.879 olarak kestirilmiştir. Kaygıya ilişkin standartlaştırılmamış eğim katsayısı -0.607 olarak kestirilmiş olup kestirimin standart hatası 0.207’dir. Öğrencilerin motivasyon düzeyi kontrol altına alındığında, artan kaygı düzeyi daha düşük performans puanları ile ilişkilidir.Öğrencilerin kaygı düzeyi kontrol altına alındığında,\nartan motivasyon düzeyi daha yüksek performans puanları ile ilişkilidir. Bu katsayı p ˂ .05’te anlamlıdır. Standartlaştırılmış eğim katsayısı 0.879 olarak kestirilmiştir. Kaygıya ilişkin standartlaştırılmamış eğim katsayısı -0.607 olarak kestirilmiş olup kestirimin standart hatası 0.207’dir. Öğrencilerin motivasyon düzeyi kontrol altına alındığında, artan kaygı düzeyi daha düşük performans puanları ile ilişkilidir.Kaygının modele eklenmesi korelasyonu çok fazla artırmasa da istatistiksel olarak anlamlı bir yordayıcıdır. Standartlaştırılmış eğim katsayısı -0.370 olarak kestirilmiştir.Kaygının modele eklenmesi korelasyonu çok fazla artırmasa da istatistiksel olarak anlamlı bir yordayıcıdır. Standartlaştırılmış eğim katsayısı -0.370 olarak kestirilmiştir.","code":"\ntekdegisken <- lm(Performans ~ Motivasyon, data=performans)\nglance(tekdegisken) %>%  kable(digit=3)\ntum  <- lm(Performans ~  Motivasyon + Kaygi, data=performans)\nglance(tum) %>%  kable(digit=3)\ntidy(anova(tum,tekdegisken))"},{"path":"çoklu-regresyon.html","id":"etkili-gözlemlerin-belirlenmesi","chapter":"Bölüm 4 Çoklu Regresyon","heading":"4.15 Etkili Gözlemlerin Belirlenmesi","text":"Etkili gözlemler (influential observations) regresyon sonuçları\nüzerinde orantısız etkisi olan bütün gözlemleri içerir.Etkili gözlemler (influential observations) regresyon sonuçları\nüzerinde orantısız etkisi olan bütün gözlemleri içerir.Bu aşırı değerler regresyon doğrusunu kendilerine doğru çekerek modelin\nkatsayıları üzerinde anlamlı etkileri olan değerlerdir.Bu aşırı değerler regresyon doğrusunu kendilerine doğru çekerek modelin\nkatsayıları üzerinde anlamlı etkileri olan değerlerdir.Regresyon analizinin sonuçları ve sonuçların genellenebilirliği\nbirkaç gözlemle değişebilir. Dolayısıyla bu gözlemlerin etkilerinin\ndeğerlendirilmesi için belirlenmesi gerekir.Regresyon analizinin sonuçları ve sonuçların genellenebilirliği\nbirkaç gözlemle değişebilir. Dolayısıyla bu gözlemlerin etkilerinin\ndeğerlendirilmesi için belirlenmesi gerekir.Etkili gözlem, gözlemlerdeki veya veri girişindeki bir hatadan\nkaynaklanabilir. Bu durumda birey analizden çıkarılabilir veya veri\ndüzeltilebilir.Etkili gözlem, gözlemlerdeki veya veri girişindeki bir hatadan\nkaynaklanabilir. Bu durumda birey analizden çıkarılabilir veya veri\ndüzeltilebilir.Sıradışı bir durumla açıklanabilen, ender karşılaşılan geçerli bir\ngözlem analizden çıkarılabilir. Halbuki olası bir açıklaması olmayan,\nender karşılaşılan bir gözlemi bir neden olmadan çıkarmak\nproblemlidir ancak gözlemin analize dahil edilmesi de\nsavunulamayabilir. Bu durumda analizlerin gözlem dahil edilerek ve\ndahil edilmeyerek tekrarlanması önerilir.Sıradışı bir durumla açıklanabilen, ender karşılaşılan geçerli bir\ngözlem analizden çıkarılabilir. Halbuki olası bir açıklaması olmayan,\nender karşılaşılan bir gözlemi bir neden olmadan çıkarmak\nproblemlidir ancak gözlemin analize dahil edilmesi de\nsavunulamayabilir. Bu durumda analizlerin gözlem dahil edilerek ve\ndahil edilmeyerek tekrarlanması önerilir.Cook’s D\nEtkinin en yaygın ölçümü Cook’s D olarak bilinir.\nBağımlı değişkenlerdeki potansiyel uç değerlerin belirlenmesinde kullanışlı bir istatistiktir. Uzaklık için en yaygın ölçüm artıktır.\nArtık herhangi bir nokta ve regresyon eğrisi arasındaki dikey uzaklığı ölçer. Bu noktalar rastgele hatayı temsil edebilir, veri yanlış kodlanmış olabilir veya veri setine ait olmayan olağan dışı durumları yansıtabilir.\nCook’s D gözlemi veriden çıkarılıp analiz yeniden gerçekleştirilirse, \\(b_j\\) katsayısındaki değişikliğin karesinin toplamının bir fonksiyonudur.\ngözlem için hesaplanabilir. gözlem için bu değer, N gözlemlerin sayısı olmak üzere 4/N ile karşılaştırılabilir. 4/N üzerindeki değerler problem olabilecek gözlemlere işaret eder.\nCook’s DEtkinin en yaygın ölçümü Cook’s D olarak bilinir.Etkinin en yaygın ölçümü Cook’s D olarak bilinir.Bağımlı değişkenlerdeki potansiyel uç değerlerin belirlenmesinde kullanışlı bir istatistiktir. Uzaklık için en yaygın ölçüm artıktır.Bağımlı değişkenlerdeki potansiyel uç değerlerin belirlenmesinde kullanışlı bir istatistiktir. Uzaklık için en yaygın ölçüm artıktır.Artık herhangi bir nokta ve regresyon eğrisi arasındaki dikey uzaklığı ölçer. Bu noktalar rastgele hatayı temsil edebilir, veri yanlış kodlanmış olabilir veya veri setine ait olmayan olağan dışı durumları yansıtabilir.Artık herhangi bir nokta ve regresyon eğrisi arasındaki dikey uzaklığı ölçer. Bu noktalar rastgele hatayı temsil edebilir, veri yanlış kodlanmış olabilir veya veri setine ait olmayan olağan dışı durumları yansıtabilir.Cook’s D gözlemi veriden çıkarılıp analiz yeniden gerçekleştirilirse, \\(b_j\\) katsayısındaki değişikliğin karesinin toplamının bir fonksiyonudur.Cook’s D gözlemi veriden çıkarılıp analiz yeniden gerçekleştirilirse, \\(b_j\\) katsayısındaki değişikliğin karesinin toplamının bir fonksiyonudur.gözlem için hesaplanabilir. gözlem için bu değer, N gözlemlerin sayısı olmak üzere 4/N ile karşılaştırılabilir. 4/N üzerindeki değerler problem olabilecek gözlemlere işaret eder.gözlem için hesaplanabilir. gözlem için bu değer, N gözlemlerin sayısı olmak üzere 4/N ile karşılaştırılabilir. 4/N üzerindeki değerler problem olabilecek gözlemlere işaret eder.Cook's D için kesme noktası \\(4/15= 0.267\\), 1., 8. ve 11. gözlemler bu sınırı asıyorCook's D için kesme noktası \\(4/15= 0.267\\), 1., 8. ve 11. gözlemler bu sınırı asıyorCook’s DDFBETACook’s D etkinin genel bir ölçümü olarak düşünülebilir. Gözlemin\neklenmesiyle katsayının nasıl değiştiğini ölçen daha spesifik bir\nölçüm ele alınabilir. Bu ölçüm DFBETA olarak adlandırılır ve \ngözlem için hesaplanabilir. (kritik değer \\(2/\\sqrt{n}\\)DFBETA için kesme noktası ise \\(2/\\sqrt{15} = 0.516\\)\nhat değerleri ise levarge karşılık geliyor.DFBETALeverage (hi)\nBağımsız değişkenlerdeki potansiyel uç değerlerin belirlenmesinde \nkullanışlı bir istatistiktir.\nLevarage bir gözlemin bir bağımsız değişkene, \\(X_j\\), göre olağan dışı olma derecesini ölçer.\nLeverage için olası değerler, N gözlemlerin sayısı olmak üzere, 1/N ile 1.0 arasında değişir.\nOrtalama leverage puanı, p bağımsız değişken sayısı ve N gözlem sayısı olmak üzere, (p +1)/N eşitliği ile hesaplanabilir. Yüksek leverage değerine sahip gözlemler ortalama değerden 2 veya 3 kat daha yüksek leverage puanlarına sahip olacaktır.\nLeverage (hi)Bağımsız değişkenlerdeki potansiyel uç değerlerin belirlenmesinde \nkullanışlı bir istatistiktir.Bağımsız değişkenlerdeki potansiyel uç değerlerin belirlenmesinde \nkullanışlı bir istatistiktir.Levarage bir gözlemin bir bağımsız değişkene, \\(X_j\\), göre olağan dışı olma derecesini ölçer.Levarage bir gözlemin bir bağımsız değişkene, \\(X_j\\), göre olağan dışı olma derecesini ölçer.Leverage için olası değerler, N gözlemlerin sayısı olmak üzere, 1/N ile 1.0 arasında değişir.Leverage için olası değerler, N gözlemlerin sayısı olmak üzere, 1/N ile 1.0 arasında değişir.Ortalama leverage puanı, p bağımsız değişken sayısı ve N gözlem sayısı olmak üzere, (p +1)/N eşitliği ile hesaplanabilir. Yüksek leverage değerine sahip gözlemler ortalama değerden 2 veya 3 kat daha yüksek leverage puanlarına sahip olacaktır.Ortalama leverage puanı, p bağımsız değişken sayısı ve N gözlem sayısı olmak üzere, (p +1)/N eşitliği ile hesaplanabilir. Yüksek leverage değerine sahip gözlemler ortalama değerden 2 veya 3 kat daha yüksek leverage puanlarına sahip olacaktır.Influence (Etki)\nEtkili bir gözlem uzaklık ve/veya leverage için yüksek değere\nsahip olan ve modelin kesişim ve eğim katsayılarını anlamlı olarak etkileyen bir\ngözlemdir.\nBu gözlemin varlığı veya yokluğu regresyon yüzeyinin yerini önemli\nölçüde değiştirecektir.\nUzaklık ve/veya leverage için yüksek değere sahip gözlemlerin regresyon\nüzerinde önemli bir etkisi olmayabilir. Bir gözlemin etkide yüksek olması için\nhem uzaklık hem de leverage için yüksek değerlere sahip olması gerekir.\nInfluence (Etki)Etkili bir gözlem uzaklık ve/veya leverage için yüksek değere\nsahip olan ve modelin kesişim ve eğim katsayılarını anlamlı olarak etkileyen bir\ngözlemdir.Etkili bir gözlem uzaklık ve/veya leverage için yüksek değere\nsahip olan ve modelin kesişim ve eğim katsayılarını anlamlı olarak etkileyen bir\ngözlemdir.Bu gözlemin varlığı veya yokluğu regresyon yüzeyinin yerini önemli\nölçüde değiştirecektir.Bu gözlemin varlığı veya yokluğu regresyon yüzeyinin yerini önemli\nölçüde değiştirecektir.Uzaklık ve/veya leverage için yüksek değere sahip gözlemlerin regresyon\nüzerinde önemli bir etkisi olmayabilir. Bir gözlemin etkide yüksek olması için\nhem uzaklık hem de leverage için yüksek değerlere sahip olması gerekir.Uzaklık ve/veya leverage için yüksek değere sahip gözlemlerin regresyon\nüzerinde önemli bir etkisi olmayabilir. Bir gözlemin etkide yüksek olması için\nhem uzaklık hem de leverage için yüksek değerlere sahip olması gerekir.","code":"\nlibrary(olsrr)\nols_plot_cooksd_bar(model)\nols_plot_dfbetas(model)\ninfluence.measures(model, infl = influence(model))## Influence measures of\n##   lm(formula = Performans ~ Motivasyon + Kaygi, data = performans) :\n## \n##      dfb.1_  dfb.Mtvs dfb.Kayg   dffit cov.r   cook.d    hat inf\n## 1   0.95795 -0.960377 -0.16108  1.1422 0.896 0.372039 0.3012    \n## 2  -0.25252  0.415588 -0.15745 -0.4984 1.422 0.084595 0.2501    \n## 3   0.14949 -0.263213  0.00861 -0.3676 1.209 0.045656 0.1388    \n## 4  -0.04850  0.110703 -0.01220  0.1872 1.332 0.012398 0.1026    \n## 5  -0.05212 -0.059328  0.11625 -0.1413 1.796 0.007232 0.2869   *\n## 6  -0.50564 -0.103904  0.68481 -0.8203 0.924 0.201071 0.2200    \n## 7  -0.09262  0.115511 -0.02600 -0.1686 1.409 0.010150 0.1264    \n## 8   1.12071 -0.626060 -0.99660 -1.3623 1.570 0.574244 0.4905   *\n## 9   0.07075 -0.094818  0.07387  0.3019 1.061 0.030173 0.0774    \n## 10 -0.00254  0.000079 -0.00142 -0.0191 1.390 0.000132 0.0670    \n## 11 -0.76153  1.357765 -0.15466  1.6459 0.228 0.510106 0.2092   *\n## 12 -0.07535  0.006834  0.07308 -0.1166 1.424 0.004897 0.1142    \n## 13 -0.06170 -0.043739  0.14852  0.1670 1.965 0.010089 0.3487   *\n## 14 -0.00051 -0.015642  0.01231 -0.0267 1.490 0.000260 0.1297    \n## 15 -0.07231  0.081208 -0.00672 -0.1135 1.472 0.004648 0.1373\nlibrary(olsrr)\nols_plot_resid_lev(model)\nols_plot_dffits(model)"},{"path":"çoklu-regresyon.html","id":"kategorik-bağımsız-bir-değişken-ile-çoklu-regresyon","chapter":"Bölüm 4 Çoklu Regresyon","heading":"4.16 Kategorik Bağımsız bir Değişken ile Çoklu Regresyon","text":"Regresyon modellerinde bağımsız bir değişken sürekli\nveya kategorik olabilir.Regresyon modellerinde bağımsız bir değişken sürekli\nveya kategorik olabilir.Bir regresyon analizine kategorik bir değişkeni dahil\nederken, regresyon modelinin değişkenin düzeylerindeki\nfarklılıkları doğru olarak kestirmesini saglamak için,\ndeğişkenin düzeylerinin yeniden kodlanması\ngerekmektedir.Bir regresyon analizine kategorik bir değişkeni dahil\nederken, regresyon modelinin değişkenin düzeylerindeki\nfarklılıkları doğru olarak kestirmesini saglamak için,\ndeğişkenin düzeylerinin yeniden kodlanması\ngerekmektedir.Kategorik değişkenleri kodlamanın en basit yöntemi dummy\n(yapay) kodlamadır.Kategorik değişkenleri kodlamanın en basit yöntemi dummy\n(yapay) kodlamadır.Dummy kodlama ile kategorik değişkenin\ndüzeylerine sayısal değerler atanarak dummy değişken(ler)\noluşturulur.Dummy kodlama ile kategorik değişkenin\ndüzeylerine sayısal değerler atanarak dummy değişken(ler)\noluşturulur.Dummy değişken kategorik bir değişkenin düzeylerinin sayısal\ngösterimidir.Bir bireyin k tane düzeye sahip kategorik bağımsız bir değişkenin\nbelli bir düzeyine ilişkin üyeliğini temsil eden k-1 tane dummy\ndeğişken oluşturulur.Bir bireyin k tane düzeye sahip kategorik bağımsız bir değişkenin\nbelli bir düzeyine ilişkin üyeliğini temsil eden k-1 tane dummy\ndeğişken oluşturulur.Eğer bir birey kategorik değişkenin birinci düzeyindeyse birinci dummy\ndeğişkene 1 değeri verilir, birey değişkenin başka bir düzeyindeyse\nbirinci dummy değişkene 0 değeri verilir.Eğer bir birey kategorik değişkenin birinci düzeyindeyse birinci dummy\ndeğişkene 1 değeri verilir, birey değişkenin başka bir düzeyindeyse\nbirinci dummy değişkene 0 değeri verilir.Eğer aynı birey kategorik değişkenin ikinci düzeyindeyse ikinci dummy\ndeğişkene 1 değeri verilir, birey değişkenin başka bir düzeyindeyse ikinci\ndummy değişkene 0 değeri verilir.Eğer aynı birey kategorik değişkenin ikinci düzeyindeyse ikinci dummy\ndeğişkene 1 değeri verilir, birey değişkenin başka bir düzeyindeyse ikinci\ndummy değişkene 0 değeri verilir.Eğer aynı birey kategorik değişkenin (k-1). düzeyindeyse (k-1). dummy\ndeğişkene 1 değeri verilir, birey değişkenin başka bir düzeyindeyse (k-1). dummy değişkene 0 değeri verilir.Eğer aynı birey kategorik değişkenin (k-1). düzeyindeyse (k-1). dummy\ndeğişkene 1 değeri verilir, birey değişkenin başka bir düzeyindeyse (k-1). dummy değişkene 0 değeri verilir.Böyle bir kodlama ile oluşturulan bir dummy değişken iki düzeye\nsahiptir: 1 ve 0Böyle bir kodlama ile oluşturulan bir dummy değişken iki düzeye\nsahiptir: 1 ve 0Bir kategorik değişken için oluşturulan dummy değişkenlerle\ngerçekleştirilen bir regresyon analizinde regresyon katsayılarının yorumlanması aşağıdaki gibidir:Bir kategorik değişken için oluşturulan dummy değişkenlerle\ngerçekleştirilen bir regresyon analizinde regresyon katsayılarının yorumlanması aşağıdaki gibidir:Birinci dummy değişkene ilişkin katsayı, diğer bütün değişkenler kontrol\naltına alındığında, kategorik değişkenin birinci düzeyi ve kategorik değişkenin son düzeyi arasındaki bağımlı değişkenin yordanan değerinin\nfarkıdır.Birinci dummy değişkene ilişkin katsayı, diğer bütün değişkenler kontrol\naltına alındığında, kategorik değişkenin birinci düzeyi ve kategorik değişkenin son düzeyi arasındaki bağımlı değişkenin yordanan değerinin\nfarkıdır.İkinci dummy değişkene ilişkin katsayı, diğer bütün değişkenler kontrol\naltına alındığında, kategorik değişkenin ikinci düzeyi ve kategorik değişkenin son düzeyi arasındaki bağımlı değişkenin yordanan değerinin\nfarkıdır.İkinci dummy değişkene ilişkin katsayı, diğer bütün değişkenler kontrol\naltına alındığında, kategorik değişkenin ikinci düzeyi ve kategorik değişkenin son düzeyi arasındaki bağımlı değişkenin yordanan değerinin\nfarkıdır.j. dummy değişkene ilişkin katsayı, diğer bütün değişkenler kontrol altına alındığında, kategorik değişkenin j. düzeyi ve kategorik değişkenin son düzeyi arasındaki bağımlı değişkenin yordanan değerinin farkıdır.j. dummy değişkene ilişkin katsayı, diğer bütün değişkenler kontrol altına alındığında, kategorik değişkenin j. düzeyi ve kategorik değişkenin son düzeyi arasındaki bağımlı değişkenin yordanan değerinin farkıdır.","code":""},{"path":"çoklu-regresyon.html","id":"dummy-değişkenlerin-oluşturulması-örnek-performansın-yordanması","chapter":"Bölüm 4 Çoklu Regresyon","heading":"4.16.1 Dummy Değişkenlerin Oluşturulması Örnek: Performansın Yordanması","text":"Üç düzeyi (evil, bekar ve diger) bulunan medeni durum değişkeni\niçin biri “Evli”, digeri “Bekar” olarak adlandırılan iki dummy değişken\n(ornegin, D1 ve D2) oluşturulabilir.Referans Grup: DiğerReferans Grup: DiğerKategorik değişkenin üç düzeyini göstermek için üç gösterge değişkenine ihtiyaç yoktur. değişkenin düzeyleri sadece iki göstergeyle tanımlanmıştır.Kategorik değişkenin üç düzeyini göstermek için üç gösterge değişkenine ihtiyaç yoktur. değişkenin düzeyleri sadece iki göstergeyle tanımlanmıştır.D1 değişkeni için 0 değerine, D2 değişkeni için 0 değerine sahip bir birey diğer kategorisine aittir.D1 değişkeni için 0 değerine, D2 değişkeni için 0 değerine sahip bir birey diğer kategorisine aittir.D1 ve D2 bağımsız değişkenleri ile gerçekleştirilen bir regresyon\nanalizinde kestirilen \\(b_1\\) eğim katsayısı evliler ve diğerleri arasındaki\nyordanan matematik performansı farkını, \\(b_2\\) eğim katsayısı ise\nbekarlar ve diğerleri arasındaki yordanan matematik performansı\nfarkını belirtir.D1 ve D2 bağımsız değişkenleri ile gerçekleştirilen bir regresyon\nanalizinde kestirilen \\(b_1\\) eğim katsayısı evliler ve diğerleri arasındaki\nyordanan matematik performansı farkını, \\(b_2\\) eğim katsayısı ise\nbekarlar ve diğerleri arasındaki yordanan matematik performansı\nfarkını belirtir.Evliler ve bekarlar arasındaki yordanan matematik performansi farkı,\nbirinci ve ikinci medeni durum katsayıları arasındaki farktır: \\(b_1 - b_2\\)Evliler ve bekarlar arasındaki yordanan matematik performansi farkı,\nbirinci ve ikinci medeni durum katsayıları arasındaki farktır: \\(b_1 - b_2\\)veri seti 🔗Performansd1.savveri seti 🔗Performansd1.savKesişim katsayısı \\(b_0\\) 19.644 matematik değerine eşittir. Bu değer, medeni\ndurumu diğer olan öğrencilerin yordanan performans puanıdır.Kesişim katsayısı \\(b_0\\) 19.644 matematik değerine eşittir. Bu değer, medeni\ndurumu diğer olan öğrencilerin yordanan performans puanıdır.Evli için standartlaştırılmamış eğim katsayısı \\(b_1\\) -6.623 değerine eşittir. Bu değer, evliler ve diğerleri arasındaki yordanan matematik performans\npuanları farkının -6.623 birim olduğunu önerir.Evli için standartlaştırılmamış eğim katsayısı \\(b_1\\) -6.623 değerine eşittir. Bu değer, evliler ve diğerleri arasındaki yordanan matematik performans\npuanları farkının -6.623 birim olduğunu önerir.\\(19.644 – 6.623 = 13.021\\) medeni durumu evli olan öğrencilerin yordanan matematik performans puanıdır.\\(19.644 – 6.623 = 13.021\\) medeni durumu evli olan öğrencilerin yordanan matematik performans puanıdır.benzer şekilde, bekar için standartlaştırılmamış eğim katsayısı \\(b_21\\) 0.639\ndeğerine eşittir. Bu değer, bekarlar ve diğerleri arasındaki yordanan\nmatematik performans puanları farkının 0.639 birim olduğunu önerir.benzer şekilde, bekar için standartlaştırılmamış eğim katsayısı \\(b_21\\) 0.639\ndeğerine eşittir. Bu değer, bekarlar ve diğerleri arasındaki yordanan\nmatematik performans puanları farkının 0.639 birim olduğunu önerir.\\(19.644 + 0.639 = 20.283\\) medeni durumu bekar olan öğrencilerin yordanan matematik\nperformans puanıdır.\\(19.644 + 0.639 = 20.283\\) medeni durumu bekar olan öğrencilerin yordanan matematik\nperformans puanıdır.lm() fonksiyonu ise aşağıdaki şekilde\nMedeni değişkenini kategorik hale getirmeketdir.lm() fonksiyonu ise aşağıdaki şekilde\nMedeni değişkenini kategorik hale getirmeketdir.","code":"\nlibrary(haven)\nPerformansd1 <- read_sav(\"import/Performansd1.sav\")\nsummary(Performansd1)##    Performans       Motivasyon        Kaygi           Guven      \n##  Min.   : 4.112   Min.   :22.00   Min.   :10.72   Min.   : 8.75  \n##  1st Qu.:11.864   1st Qu.:34.00   1st Qu.:15.54   1st Qu.:17.12  \n##  Median :18.041   Median :40.00   Median :18.30   Median :22.00  \n##  Mean   :18.176   Mean   :39.93   Mean   :18.07   Mean   :21.63  \n##  3rd Qu.:22.941   3rd Qu.:47.00   3rd Qu.:18.84   3rd Qu.:25.60  \n##  Max.   :35.501   Max.   :55.00   Max.   :28.17   Max.   :38.70  \n##     Medeni         \n##  Length:15         \n##  Class :character  \n##  Mode  :character  \n##                    \n##                    \n## \nlibrary(fastDummies)## Thank you for using fastDummies!## To acknowledge our work, please cite the package:## Kaplan, J. & Schlegel, B. (2023). fastDummies: Fast Creation of Dummy (Binary) Columns and Rows from Categorical Variables. Version 1.7.1. URL: https://github.com/jacobkap/fastDummies, https://jacobkap.github.io/fastDummies/.\n# Performansd1$D1 <- ifelse(Performansd1$Medeni  == \"Evli\", 1, 0)\n# Performansd1$D2<- ifelse(Performansd1$Medeni  == \"Bekar\", 1, 0)\ndataf <- dummy_cols(Performansd1, select_columns = 'Medeni')\nsummary(dataf)##    Performans       Motivasyon        Kaygi           Guven      \n##  Min.   : 4.112   Min.   :22.00   Min.   :10.72   Min.   : 8.75  \n##  1st Qu.:11.864   1st Qu.:34.00   1st Qu.:15.54   1st Qu.:17.12  \n##  Median :18.041   Median :40.00   Median :18.30   Median :22.00  \n##  Mean   :18.176   Mean   :39.93   Mean   :18.07   Mean   :21.63  \n##  3rd Qu.:22.941   3rd Qu.:47.00   3rd Qu.:18.84   3rd Qu.:25.60  \n##  Max.   :35.501   Max.   :55.00   Max.   :28.17   Max.   :38.70  \n##     Medeni             Medeni_1         Medeni_2         Medeni_3     \n##  Length:15          Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n##  Class :character   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000  \n##  Mode  :character   Median :0.0000   Median :0.0000   Median :0.0000  \n##                     Mean   :0.2667   Mean   :0.4667   Mean   :0.2667  \n##                     3rd Qu.:0.5000   3rd Qu.:1.0000   3rd Qu.:0.5000  \n##                     Max.   :1.0000   Max.   :1.0000   Max.   :1.0000\nmodel_dummy <- lm(Performans ~ Medeni_1 + Medeni_2 , \n                  data=dataf)\nmodel_dummy## \n## Call:\n## lm(formula = Performans ~ Medeni_1 + Medeni_2, data = dataf)\n## \n## Coefficients:\n## (Intercept)     Medeni_1     Medeni_2  \n##     19.6442      -6.6234       0.6386\ntidy(model_dummy)\nmodel_2 <- lm(Performans ~ Medeni , \n                  data=Performansd1)\nlibrary(broom)\ntidy(model_2)"},{"path":"çoklu-regresyon.html","id":"çoklu-regresyonda-iki-yönlü-etkileşim-etkisi","chapter":"Bölüm 4 Çoklu Regresyon","heading":"4.17 Çoklu Regresyonda İki-Yönlü Etkileşim Etkisi","text":"Eğer bir çoklu regresyon modelinde bir bağımsız değişken ile\nbağımlı değişken arasındaki ilişkinin büyüklüğü diğer bir bağımsız\ndeğişkenin düzeyine göre değişirse, etkileşim gözlenir.Eğer bir çoklu regresyon modelinde bir bağımsız değişken ile\nbağımlı değişken arasındaki ilişkinin büyüklüğü diğer bir bağımsız\ndeğişkenin düzeyine göre değişirse, etkileşim gözlenir.Etkileşim etkisi, düzenleyici (moderator) etki olarak da bilinmektedir.Etkileşim etkisi, düzenleyici (moderator) etki olarak da bilinmektedir.Etkileşim terimi \\(X_1\\) değişkeninin değerlerinin aracı \\(X_2\\) değişkeninin\ndeğerleriyle çarpılmasıyla oluşan bileşik bir değişkendir. Regresyon eşitliği aşağıdaki gibidir:\\[Y= + b_1x_{1i} +  b_2x_{2i} + b_3x_{1i}x_{2i}\\]Burada, \\(b_3\\) katsayısı aracı etki olup \\(X_2\\) değişkenin değeri değişirken \\(X_1\\)\ndeğişkeninin etkisindeki birim değişimi belirtir.\\[Y= + b_1x_{1i} +  b_2x_{2i} + b_3x_{1i}x_{2i}\\]\\(b_1\\) katsayısı \\(X_2\\) değişkenine ilişkin değer sıfırken \\(X_1\\) değişkeninin etkisini,\\(b_1\\) katsayısı \\(X_2\\) değişkenine ilişkin değer sıfırken \\(X_1\\) değişkeninin etkisini,\\(b_2\\) katsayısı \\(X_1\\) değişkenine ilişkin değer sıfırken \\(X_2\\) değişkeninin etkisini belirtir (Etkileşim etkisinin bulunmadığı modelde, \\(b_1\\) katsayısı \\(X_2\\) değişkeninin bütün düzeylerinde \\(X_1\\) değişkeninin etkisini, \\(b_2\\) katsayısı \\(X_1\\) değişkeninin bütün düzeylerinde \\(X_2\\) değişkeninin etkisini temsil eder).\\(b_2\\) katsayısı \\(X_1\\) değişkenine ilişkin değer sıfırken \\(X_2\\) değişkeninin etkisini belirtir (Etkileşim etkisinin bulunmadığı modelde, \\(b_1\\) katsayısı \\(X_2\\) değişkeninin bütün düzeylerinde \\(X_1\\) değişkeninin etkisini, \\(b_2\\) katsayısı \\(X_1\\) değişkeninin bütün düzeylerinde \\(X_2\\) değişkeninin etkisini temsil eder).Bağımsız değişkenin toplam etkisini belirlemek için değişkenin ayrı ve aracı etkisi bir araya getirilmelidir. \\(X_1\\) değişkeninin \\(X_2\\) değişkeninin herhangi bir değerindeki toplam etkisi aşağıdaki eşitlikle hesaplanabilir:Bağımsız değişkenin toplam etkisini belirlemek için değişkenin ayrı ve aracı etkisi bir araya getirilmelidir. \\(X_1\\) değişkeninin \\(X_2\\) değişkeninin herhangi bir değerindeki toplam etkisi aşağıdaki eşitlikle hesaplanabilir:\\[ b_{toplam} = b_1+b_3X_2\\]Sunumdaki örnek Wagner, Compas ve Howell’(1988) çalışmasından\ngelmektedir.Sunumdaki örnek Wagner, Compas ve Howell’(1988) çalışmasından\ngelmektedir.Wagner ve diğerleri çalışmalarında daha fazla strese maruz kalan bireylerin psikolojik belirtileri daha yüksek düzeyde göstereceğini\nönermiştir. Ancak bir birey stresiyle basa çıkmasına yardımcı olacak yüksek\ndüzeyde sosyal desteğe sahipse, belirtilerin stres arttıkça daha yavaş\nartmasının bekleneceğini, daha az sosyal desteğe sahip bireyler için ise, semptomların stres arttıkça daha hızlı artmasının bekleneceğini belirttiler. veri seti 🔗 Hassles.savWagner ve diğerleri çalışmalarında daha fazla strese maruz kalan bireylerin psikolojik belirtileri daha yüksek düzeyde göstereceğini\nönermiştir. Ancak bir birey stresiyle basa çıkmasına yardımcı olacak yüksek\ndüzeyde sosyal desteğe sahipse, belirtilerin stres arttıkça daha yavaş\nartmasının bekleneceğini, daha az sosyal desteğe sahip bireyler için ise, semptomların stres arttıkça daha hızlı artmasının bekleneceğini belirttiler. veri seti 🔗 Hassles.sav“Hassles.sav” SPSS veri dosyası bir ID değişkeni ve ID değişkeni dışında dört değişken ve 56 üniversite birinci sınıf öğrencisini içermektedir.“Hassles.sav” SPSS veri dosyası bir ID değişkeni ve ID değişkeni dışında dört değişken ve 56 üniversite birinci sınıf öğrencisini içermektedir.İlk olarak değişkenler arasındaki ilişkilere bakılır.Destek, sorun veya belirtiler ile ilişkili olmamasına rağmen, beklendiği\ngibi, sorun ve belirtiler arasında istatistiksel olarak bir ilişki vardır (r = 0,\n577).Destek, sorun veya belirtiler ile ilişkili olmamasına rağmen, beklendiği\ngibi, sorun ve belirtiler arasında istatistiksel olarak bir ilişki vardır (r = 0,\n577).Ancak bu bulgular sorun ve belirtiler arasındaki ilişkinin destek\ndüzeyine bağlı olup olmadığı sorusuna cevap vermemektedir. Sorun ve destek etkileşimini test etmek için sorun değerleri ile\ndestek değerlerinin çarpımıyla yeni bir değişken olusturulur.Ancak bu bulgular sorun ve belirtiler arasındaki ilişkinin destek\ndüzeyine bağlı olup olmadığı sorusuna cevap vermemektedir. Sorun ve destek etkileşimini test etmek için sorun değerleri ile\ndestek değerlerinin çarpımıyla yeni bir değişken olusturulur.Ancak bu iki değişkene ilişkin değerlerin çarpılmasıyla oluşan değişkenin\nanalize dahil edilmesinde iki problem ortaya çıkacaktır.Ancak bu iki değişkene ilişkin değerlerin çarpılmasıyla oluşan değişkenin\nanalize dahil edilmesinde iki problem ortaya çıkacaktır.Sorun veya Destek değişkenlerinden biri veya ikisi, çarpımlarıyla oluşan değişken ile yüksek düzeyde korelasyona sahip olacaktır ki bu da veride çoklu bağlantı problemine neden olacaktir.Sorun veya Destek değişkenlerinden biri veya ikisi, çarpımlarıyla oluşan değişken ile yüksek düzeyde korelasyona sahip olacaktır ki bu da veride çoklu bağlantı problemine neden olacaktir.Regresyon analizinde sorun veya destek değişkeninin herhangi bir etkisi diğer değişkenin değerinin 0 olduğu durumda değerlendirilecektir. diğer bir ifadeyle, sorun üzerindeki test hiç sosyal desteği olmayan bir katılımcı için Sorunların belirtilerle ilişkili olup olmadığı testi olacaktır.Regresyon analizinde sorun veya destek değişkeninin herhangi bir etkisi diğer değişkenin değerinin 0 olduğu durumda değerlendirilecektir. diğer bir ifadeyle, sorun üzerindeki test hiç sosyal desteği olmayan bir katılımcı için Sorunların belirtilerle ilişkili olup olmadığı testi olacaktır.Benzer şekilde, destek üzerindeki test hiç sorunları olmayan katılımcılar için değerlendirilecektir.Benzer şekilde, destek üzerindeki test hiç sorunları olmayan katılımcılar için değerlendirilecektir.Hem çoklu bağlantı problemi, hem de ana etkilerden birinin diğer ana etkinin uç değerinde değerlendirilmesi problemi istenmeyen durumlardır.Hem çoklu bağlantı problemi, hem de ana etkilerden birinin diğer ana etkinin uç değerinde değerlendirilmesi problemi istenmeyen durumlardır.Bahsedilen problemlerle başa çıkmak için sorun değişkeni ve destek değişkeni merkezlenebilir.Bahsedilen problemlerle başa çıkmak için sorun değişkeni ve destek değişkeni merkezlenebilir.Bunun için bir değişkene ilişkin bireysel gözlemlerden ilgili\ndeğişkenin ortalaması çıkarılarak sapma puanları hesaplanacaktır.Bunun için bir değişkene ilişkin bireysel gözlemlerden ilgili\ndeğişkenin ortalaması çıkarılarak sapma puanları hesaplanacaktır.değişkenler merkezlendikten sonra merkezlenen sorun\ndeğişkeni için 0 değeri sorun değişkeninin ortalama düzeyindeki\nkatılımcıları temsil ederken, merkezlenen destek değişkeni için 0 değeri\ndestek değişkeninin ortalama düzeyindeki katılımcıları\ntemsil eder.değişkenler merkezlendikten sonra merkezlenen sorun\ndeğişkeni için 0 değeri sorun değişkeninin ortalama düzeyindeki\nkatılımcıları temsil ederken, merkezlenen destek değişkeni için 0 değeri\ndestek değişkeninin ortalama düzeyindeki katılımcıları\ntemsil eder.Böylece ana etkiler diğer değişkenin uygun düzeyinde değerlendirilir.Böylece ana etkiler diğer değişkenin uygun düzeyinde değerlendirilir.Değişkenlerin merkezlenmesiyle sorun ve destek değişkenleri\narasındaki çoklu bağlantı da önemli ölçüde düşecektir.Değişkenlerin merkezlenmesiyle sorun ve destek değişkenleri\narasındaki çoklu bağlantı da önemli ölçüde düşecektir.Merkezlenen sorun, Merkezlenen destek, Merkezlenen sorun\ndeğişkeninin değerleri ile Merkezlenen Destek değişkeninin değerlerinin\nçarpılmasıyla elde edilen etkileşim terimi ve Belirtiler arasındaki\nkorelasyon matrisi incelenir.Merkezlenen sorun, Merkezlenen destek, Merkezlenen sorun\ndeğişkeninin değerleri ile Merkezlenen Destek değişkeninin değerlerinin\nçarpılmasıyla elde edilen etkileşim terimi ve Belirtiler arasındaki\nkorelasyon matrisi incelenir.Belirtilerin bağımlı degişken, merkezlenen sorunların ve merkezlenen\ndesteğin bağımsız değişken olarak modellendiğ regresyonda, iki\nbağımsız değişkenin etkileşimini incelemek üzere etkileşim terimi de\nregresyon modeline eklenir.etkileşim teriminin açıklanan varyansı ne kadar değiştirdiğine bakalım.Etkileşimli modelin daha yüksek bir \\(R^2\\) değerine sahip olduğu açıktır. Bununla birlikte birden fazla açıklayıcı değişkene sahip modellerde model seçimi için \\(R^2\\) iyi bir fikir değildir, çünkü herhangi bir değişken moda eklendiğinde \\(R^2\\) artar.Etkileşimli modelin daha yüksek bir \\(R^2\\) değerine sahip olduğu açıktır. Bununla birlikte birden fazla açıklayıcı değişkene sahip modellerde model seçimi için \\(R^2\\) iyi bir fikir değildir, çünkü herhangi bir değişken moda eklendiğinde \\(R^2\\) artar.model seçimi için (daha) objektif bir ölçü düzeltilmiş \\(R^2\\) dir, modele dahil edilen değişken sayısı için bir düzeltme uyguladığından, yeni değişken herhangi bir yeni bilgi sağlamıyorsa veya tamamen ilgisizse düzeltilmiş \\(R^2\\) artmaz. Bu da düzeltilmiş \\(R^2\\) çoklu regresyon modellerinde model seçimi için tercih edilebilir bir metriktir.model seçimi için (daha) objektif bir ölçü düzeltilmiş \\(R^2\\) dir, modele dahil edilen değişken sayısı için bir düzeltme uyguladığından, yeni değişken herhangi bir yeni bilgi sağlamıyorsa veya tamamen ilgisizse düzeltilmiş \\(R^2\\) artmaz. Bu da düzeltilmiş \\(R^2\\) çoklu regresyon modellerinde model seçimi için tercih edilebilir bir metriktir.etkileşim teriminin düzeltilmiş \\(R^2\\) yi ne kadar değiştirdiğine bakalım.etkileşim teriminin düzeltilmiş \\(R^2\\) yi ne kadar değiştirdiğine bakalım.\\(R^2\\) değeri yaklaşık 0.39 olup belirtilerdeki varyansın yaklaşık\n%39’unun doğrusal regresyon modeli tarafından açıklandığı\nanlamına gelmektedir.Hem merkezlenen sorun hem de etkileşim terimi istatistiksel olarak\nanlamlıdır (sırasıyla p ˂ 0.001 ve p = 0.037). Ancak merkezlenen destek\nistatistiksel olarak anlamlı değildir (p = 0.634). Destek değişkeni\netkileşim teriminin hesaplanmasında yer aldığından, regresyon\nmodelinde kalabilir.Hem merkezlenen sorun hem de etkileşim terimi istatistiksel olarak\nanlamlıdır (sırasıyla p ˂ 0.001 ve p = 0.037). Ancak merkezlenen destek\nistatistiksel olarak anlamlı değildir (p = 0.634). Destek değişkeni\netkileşim teriminin hesaplanmasında yer aldığından, regresyon\nmodelinde kalabilir.Etkileşim etkisinin anlamını yorumlamak için değişkenler arasındaki\nilişkilerin grafik ile gösterimi yardımcı olabilir. En basit çözüm sosyal\ndesteğin sabit düzeyleri için zorluklar ve psikolojik belirtiler\narasındaki ilişkiye bakmaktır.Etkileşim etkisinin anlamını yorumlamak için değişkenler arasındaki\nilişkilerin grafik ile gösterimi yardımcı olabilir. En basit çözüm sosyal\ndesteğin sabit düzeyleri için zorluklar ve psikolojik belirtiler\narasındaki ilişkiye bakmaktır.Merkezlenen sosyal destek değişkeninin değerileri -21 ile +19 arasında\ndeğişmektedir. Bu değişken için düşük, orta ve yüksek değerleri temsil etmek\nüzere sırasıyla -15, 0 ve +15 değerleri seçilebilir.Merkezlenen sosyal destek değişkeninin değerileri -21 ile +19 arasında\ndeğişmektedir. Bu değişken için düşük, orta ve yüksek değerleri temsil etmek\nüzere sırasıyla -15, 0 ve +15 değerleri seçilebilir.yüksek düzeyde sosyal destek ile sorunlardaki artışlar psikolojik belirtilerde küçük artışlarla ilişkilendirilirler. Orta düzeyde sosyal destek ile sorunlardaki artışlar psikolojik belirtilerde\ndaha büyük artışlarla ilişkilendirilir. Düşük düzeyde sosyal destek ile sorunlardakı artışlar psikolojik belirtilerde\ndramatik artışlarla ilişkilendirilir.","code":"\nlibrary(haven)\nzorluklar <- read_sav(\"import/Hassles.sav\")[,c(1,2,4,5)]\ncolnames(zorluklar)  <- c(\"id\",\"sorun\",\"destek\",\"belirtiler\")\nggpairs(zorluklar[,-1])\nzorluklar$csorun <- zorluklar$sorun -mean(zorluklar$sorun)\nzorluklar$cdestek <- zorluklar$destek -mean(zorluklar$destek)\nzorluklar$cross  <- zorluklar$sorun*zorluklar$destek\nzorluklar$cross_m  <- zorluklar$csorun*zorluklar$cdestek\nggpairs(zorluklar[,c(2:4,7)])\nggpairs(zorluklar[,c(5,6,4,8)])\nn_model <- lm(belirtiler  ~ csorun  + cdestek  ,data=zorluklar)\ncross_model <- lm(belirtiler  ~ csorun  + cdestek + cross_m ,data=zorluklar)\nglance(n_model)$r.squared## [1] 0.3344622\nglance(cross_model)$r.squared## [1] 0.3884955\nglance(n_model)$adj.r.squared## [1] 0.3093475\nglance(cross_model)$adj.r.squared## [1] 0.3532164\ntidy(cross_model)\nlibrary(dplyr)\nzorluklar <- zorluklar %>% mutate(\n  cdestek_kat = case_when(\n  cdestek <= -15 ~ \"dusuk\",\n  cdestek >-15 &    cdestek <15~ \"orta\",\n  cdestek >=15 ~ \"yuksek\",\n  )\n)\nzorluklar <- zorluklar %>%  arrange(csorun)"},{"path":"çoklu-regresyon.html","id":"anscombeun-dörtlüsü","chapter":"Bölüm 4 Çoklu Regresyon","heading":"4.18 Anscombe'un Dörtlüsü","text":"anscombe_quartet veri setinin amacı, verilerinizi görselleştirmenin önemli olduğu noktasını vurgulamaya yardımcı olmaktır. Francis Anscombe bu dört veri setini, istatistiksel özet ölçümlerin tek başına iki değişken (burada x ve y) arasındaki tam ilişkiyi yakalayamayacağını göstermek için oluşturmuştur. Anscombe, özet istatistikleri hesaplamadan önce verileri görselleştirmenin önemini vurgulamıştır.Veri seti 1, x ve y arasında doğrusal bir ilişkiye sahiptirVeri Seti 2, x ve y arasında doğrusal olmayan bir ilişki olduğunu göstermektedirVeri seti 3, x ve y arasında tek bir aykırı değer ile doğrusal bir ilişkiye sahiptirVeri seti 4, etkili değer olarak işlev gören tek bir aykırı değer ile x ve y arasında hiçbir ilişki göstermemektedir.değişkenlerin ortalamalarıdeğişkenlerin standart sapmalarıdeğişkenler arası korelasyonlarregresyon denklemleriÖzetle\\(\\overline{X}\\): 9\\(sd_{\\overline{X}}\\): 3.32\\(\\overline{Y}\\): 7.5\\(sd_{\\overline{Y}}\\): 4.125\\(cor_{XY}\\): 0.816Regresyon denklemleri: \\(y = 3 + 0.5x\\)Açıklanan varyans \\(R^2\\) : 0.67bu sayfayı da 🔗inceleyebilirsiniz.bu sayfayı da 🔗inceleyebilirsiniz.Bunun gibi diğer örnekler için 🔗bağlantıyı\ninceleyebilirsiniz.Bunun gibi diğer örnekler için 🔗bağlantıyı\ninceleyebilirsiniz.","code":"\nlibrary(datasets)\ndatasets::anscombe\nlibrary(dplyr)\ncolMeans(anscombe) %>% kable(digits=2)\napply(anscombe,2,sd) %>% kable(digits=2)\ncor(anscombe[,1:4],anscombe[,5:8]) %>% kable(digits=2)\nff <- y ~ x\nmods <- setNames(as.list(1:4), paste0(\"lm\", 1:4))\nfor(i in 1:4) {\n  ff[2:3] <- lapply(paste0(c(\"y\",\"x\"), i), as.name)\n  mods[[i]] <- lmi <- lm(ff, data = anscombe)\n  print(anova(lmi))\n}## Analysis of Variance Table\n## \n## Response: y1\n##           Df Sum Sq Mean Sq F value  Pr(>F)   \n## x1         1 27.510 27.5100   17.99 0.00217 **\n## Residuals  9 13.763  1.5292                   \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## Analysis of Variance Table\n## \n## Response: y2\n##           Df Sum Sq Mean Sq F value   Pr(>F)   \n## x2         1 27.500 27.5000  17.966 0.002179 **\n## Residuals  9 13.776  1.5307                    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## Analysis of Variance Table\n## \n## Response: y3\n##           Df Sum Sq Mean Sq F value   Pr(>F)   \n## x3         1 27.470 27.4700  17.972 0.002176 **\n## Residuals  9 13.756  1.5285                    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## Analysis of Variance Table\n## \n## Response: y4\n##           Df Sum Sq Mean Sq F value   Pr(>F)   \n## x4         1 27.490 27.4900  18.003 0.002165 **\n## Residuals  9 13.742  1.5269                    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nsapply(mods, coef)##                   lm1      lm2       lm3       lm4\n## (Intercept) 3.0000909 3.000909 3.0024545 3.0017273\n## x1          0.5000909 0.500000 0.4997273 0.4999091\nlibrary(tidyverse)\nlibrary(quartets)\n\nggplot(anscombe_quartet, aes(x = x, y = y)) +\n  geom_point() + \n  geom_smooth(method = \"lm\", formula = \"y ~ x\") +\n  facet_wrap(~dataset)\nanscombe_quartet |>\n  group_by(dataset) |>\n  summarise(mean_x = mean(x),\n            sd_x = sd(x),\n            mean_y = mean(y),\n            sd_y = sd(y),\n            cor = cor(x, y)) |>\n  knitr::kable(digits = 2)"},{"path":"çoklu-regresyon.html","id":"simpson-paradoxu","chapter":"Bölüm 4 Çoklu Regresyon","heading":"4.19 Simpson Paradoxu","text":"Simpson Paradoksu, bir gruptaki iki değişken arasındaki ilişkinin, alt gruplara bölündüğünde ortaya çıktığı, kaybolduğu veya tersine döndüğü istatistiksel bir olgudur.Simpson Paradoksu, bir gruptaki iki değişken arasındaki ilişkinin, alt gruplara bölündüğünde ortaya çıktığı, kaybolduğu veya tersine döndüğü istatistiksel bir olgudur.Örneğin, iki değişken bir grupta pozitif ilişkili olabilir, ancak tüm alt gruplarda bağımsız veya hatta negatif ilişkili olabilir.Örneğin, iki değişken bir grupta pozitif ilişkili olabilir, ancak tüm alt gruplarda bağımsız veya hatta negatif ilişkili olabilir.Paradoksu sergileyen vakalar matematik ve olasılık teorisi açısından problemsizdir, ancak yine de birçok insanı şaşırtmaktadır.Paradoksu sergileyen vakalar matematik ve olasılık teorisi açısından problemsizdir, ancak yine de birçok insanı şaşırtmaktadır.","code":""},{"path":"çoklu-regresyon.html","id":"berkeleydeki-cinsiyete-dayalı-kabul-oranları","chapter":"Bölüm 4 Çoklu Regresyon","heading":"4.19.1 Berkeley'deki cinsiyete dayalı kabul oranları:","text":"\"Berkeley'deki California Üniversitesi'ne 1973 sonbaharında yapılan lisansüstü kabullere ilişkin toplu veriler incelendiğinde, kadın başvuru sahiplerine karşı açık ama yanıltıcı bir önyargı örüntüsü görülmektedir.\"Berkeley'deki California Üniversitesi'ne 1973 sonbaharında yapılan lisansüstü kabullere ilişkin toplu veriler incelendiğinde, kadın başvuru sahiplerine karşı açık ama yanıltıcı bir önyargı örüntüsü görülmektedir.Veriler altı bölümden gelmektedir. Gizlilik için bunlara -F olarak kodlanmıştır.Veriler altı bölümden gelmektedir. Gizlilik için bunlara -F olarak kodlanmıştır.Elimizde başvuru sahibinin kadın mı erkek mi olduğu ve kabul edilip edilmediğine dair bilgiler var.Elimizde başvuru sahibinin kadın mı erkek mi olduğu ve kabul edilip edilmediğine dair bilgiler var.İlk olarak, kabul edilen erkeklerin yüzdesinin genel olarak kadınlardan gerçekten daha yüksek olup olmadığını değerlendireceğiz. Daha sonra, bölüm için aynı yüzdeyi hesaplayacağız.İlk olarak, kabul edilen erkeklerin yüzdesinin genel olarak kadınlardan gerçekten daha yüksek olup olmadığını değerlendireceğiz. Daha sonra, bölüm için aynı yüzdeyi hesaplayacağız.Genel cinsiyet dağılımı hakkında ne söyleyebilirsiniz? İpucu: Aşağıdaki olasılıkları hesaplayın: \\(P(Kabul | Erkek)\\) ve \\(P(Kabul | Kadın)\\).\\(P(Kabul | Kadın)\\) = 0.304\\(P(Kabul | Erkek)\\) = 0.445Departmanlara göre cinsiyet dağılımı hakkında ne söyleyebilirsiniz?Tabloya bakıldığında kadın öğrenciler, üniversitenin en büyük 6 bölümünün 4’ünde erkek öğrencilere göre daha fazla kabul almıştır. Yani , B, D ve F bölümlerine kabul gören erkek sayısı kadın sayısına göre daha azdır. Şöyle ki erkekler en fazla öğrenci kabul edilen bölüme başvuruyu daha fazla yaparken kız öğrenciler ise en az öğrenci kabul edilen bölüme daha fazla başvuru yapmıştır. Bu sebeple grup yüzdeleri ile toplam yüzdeleri birbirinden farklılık göstermektedir. Konuyu pekiştirmek için başka bir örnekle devam edelim.","code":"\nlibrary(dsbox)\nucbadmit %>%\n  count(gender)\nucbadmit %>%\n  count(dept)\nucbadmit %>%\n  count(admit)\nucbadmit %>%\n  count(gender, admit)\nucbadmit %>%\n  count(gender, admit) %>%\n  group_by(gender) %>%\n  mutate(prop_admit = n / sum(n))\nggplot(ucbadmit, aes(y = gender, fill = admit)) +\n  geom_bar(position = \"fill\") + \n  labs(title = \"Admit by gender\",\n       y = NULL, x = NULL)\nucbadmit %>%\n  count(dept, gender, admit)\nucbadmit %>%\n  count(dept, gender, admit) %>%\n  pivot_wider(names_from = dept, values_from = n)\nggplot(ucbadmit, aes(y = gender, fill = admit)) +\n  geom_bar(position = \"fill\") +\n  facet_wrap(. ~ dept) +\n  scale_x_continuous(labels = scales::label_percent()) +\n  labs(title = \"Admissions by gender and department\",\n       x = NULL, y = NULL, fill = NULL) +\n  theme(legend.position = \"bottom\")\nucbadmit %>%\n  count(dept, gender, admit) %>%\n  group_by(dept, gender) %>%\n  mutate(\n    n_applied  = sum(n),\n    prop_admit = n / n_applied\n    ) %>%\n  filter(admit == \"Admitted\") %>%\n  rename(n_admitted = n) %>%\n  dplyr::select(-admit) %>%\n  print(n = 12)## # A tibble: 12 × 5\n## # Groups:   dept, gender [12]\n##    dept  gender n_admitted n_applied prop_admit\n##    <ord> <fct>       <int>     <int>      <dbl>\n##  1 A     Female         89       108     0.824 \n##  2 A     Male          512       825     0.621 \n##  3 B     Female         17        25     0.68  \n##  4 B     Male          353       560     0.630 \n##  5 C     Female        202       593     0.341 \n##  6 C     Male          120       325     0.369 \n##  7 D     Female        131       375     0.349 \n##  8 D     Male          138       417     0.331 \n##  9 E     Female         94       393     0.239 \n## 10 E     Male           53       191     0.277 \n## 11 F     Female         24       341     0.0704\n## 12 F     Male           22       373     0.0590"},{"path":"çoklu-regresyon.html","id":"iki-değişken-arasındaki-ilişki","chapter":"Bölüm 4 Çoklu Regresyon","heading":"4.19.2 İki değişken arasındaki ilişki","text":"","code":"## `geom_smooth()` using method = 'loess' and formula = 'y ~ x'"},{"path":"çoklu-regresyon.html","id":"üç-değişken-arasındaki-ilişki","chapter":"Bölüm 4 Çoklu Regresyon","heading":"4.19.3 Üç değişken arasındaki ilişki","text":"Simpson's paradoxSimpson's paradoxBir ilişkiyi incelerken önemli bir değişkeni dikkate almamak Simpson paradoksu ile sonuçlanabilir.Bir ilişkiyi incelerken önemli bir değişkeni dikkate almamak Simpson paradoksu ile sonuçlanabilir.Simpson paradoksu, açıklayıcı bir değişkenin ihmal edilmesinin, başka bir açıklayıcı değişken ile yanıt değişkeni arasındaki ilişkinin ölçüsü üzerinde yaratabileceği etkiyi göstermektedir.Simpson paradoksu, açıklayıcı bir değişkenin ihmal edilmesinin, başka bir açıklayıcı değişken ile yanıt değişkeni arasındaki ilişkinin ölçüsü üzerinde yaratabileceği etkiyi göstermektedir.Üçüncü bir değişkenin analize dahil edilmesi, diğer iki değişken arasındaki görünür ilişkiyi değiştirebilirÜçüncü bir değişkenin analize dahil edilmesi, diğer iki değişken arasındaki görünür ilişkiyi değiştirebilir","code":"## `geom_smooth()` using formula = 'y ~ x'## `geom_smooth()` using formula = 'y ~ x'\n## `geom_smooth()` using formula = 'y ~ x'"},{"path":"çoklu-regresyon.html","id":"kaynaklar-2","chapter":"Bölüm 4 Çoklu Regresyon","heading":"4.20 Kaynaklar","text":"Wagner, B. M., Compas, B. E., & Howell, D. C. (1988). Daily major life events: test integrative model psychosocial stress. American Journal Community Psychology, 16 (2), 189-205.","code":""},{"path":"lavaan-ve-sem.html","id":"lavaan-ve-sem","chapter":"Bölüm 5 lavaan ve sem","heading":"Bölüm 5 lavaan ve sem","text":"Bundan sonraki bölümlerde kullanılacak olan lavaan paketinin cfa ve sem\nve semPlot paketinin semPathsfonksiyonlarının argümanları açıklanmıştır.","code":""},{"path":"lavaan-ve-sem.html","id":"sem-fonksiyonu","chapter":"Bölüm 5 lavaan ve sem","heading":"5.1 sem fonksiyonu","text":"cfa() fonksiyonunun kullanımı aşağıdaki gibidir:","code":"\ncfa(model = NULL,\n    data = NULL, \n    ordered = NULL, sampling.weights = NULL, \n    sample.cov = NULL, sample.mean = NULL, sample.th = NULL, \n    sample.nobs = NULL, group = NULL, cluster = NULL, \n    constraints = \"\", WLS.V = NULL, NACOV = NULL, ...)"},{"path":"lavaan-ve-sem.html","id":"sempaths","chapter":"Bölüm 5 lavaan ve sem","heading":"5.2 semPaths","text":"","code":""},{"path":"lavaan-ve-sem.html","id":"semplot-paketi","chapter":"Bölüm 5 lavaan ve sem","heading":"5.3 semPlot Paketi","text":"semPlot paketi YEM analizlerine ilişkin diyagramların çizilmesine olanak sağlayan fonksiyonları içerir.semPlot paketi YEM analizlerine ilişkin diyagramların çizilmesine olanak sağlayan fonksiyonları içerir.Paket içinde yer alan semPaths() fonksiyonu lavaan fonksiyonlarının çıktılarıyla doğrudan çalıştırılabildiğinden, YEM analizlerine ilişkin diyagramların çizilmesinde oldukça kullanışlıdır.Paket içinde yer alan semPaths() fonksiyonu lavaan fonksiyonlarının çıktılarıyla doğrudan çalıştırılabildiğinden, YEM analizlerine ilişkin diyagramların çizilmesinde oldukça kullanışlıdır.semPaths() fonksiyonunun diyagramların özelleştirilmesine ilişkin çok sayıda argümanı bulunmaktadır.semPaths() fonksiyonunun diyagramların özelleştirilmesine ilişkin çok sayıda argümanı bulunmaktadır.","code":""},{"path":"yol-analizi.html","id":"yol-analizi","chapter":"Bölüm 6 Yol Analizi","heading":"Bölüm 6 Yol Analizi","text":"Yol analizi modeli YEM ailesinin en eski üyelerinden\nbiridir ve halen yaygın olarak kullanılmaktadır.Yol analizi modeli YEM ailesinin en eski üyelerinden\nbiridir ve halen yaygın olarak kullanılmaktadır.Herbir yapının sadece tek bir gözlenen ölçümün\n(göstergesinin) olduğu durumlar bulunabilir ve bu\ndurumlarda da tek-gösterge tekniği olan yol analizi\nkullanılabilir. Bu analizde ele alınan ölçülen değişkenlerin\nmükemmel derecede güvenilir olduğu varsayılır.Herbir yapının sadece tek bir gözlenen ölçümün\n(göstergesinin) olduğu durumlar bulunabilir ve bu\ndurumlarda da tek-gösterge tekniği olan yol analizi\nkullanılabilir. Bu analizde ele alınan ölçülen değişkenlerin\nmükemmel derecede güvenilir olduğu varsayılır.Yol analizinde sadece gözlenen değişkenler modellenir.\nBu model gözlenen değişkenler için bir yapısal eşitlik\nmodelidir.Yol analizinde sadece gözlenen değişkenler modellenir.\nBu model gözlenen değişkenler için bir yapısal eşitlik\nmodelidir.YEM bir grup değişken arasındaki ilişkilerin modellenmesine ve öngörülen modellerin test edilmesine imkan verir.YEM bir grup değişken arasındaki ilişkilerin modellenmesine ve öngörülen modellerin test edilmesine imkan verir.Temelde gözlenenen değişkenlerin varyanslarına ve gözlenen değişkenler arasındaki kovaryanslara dayalı olan YEM analizlerinin amacı bir grup gözlenen değişken arasındaki kovaryans örüntüsünü anlamak ve araştırma modeli ile gözlenen değişkenlerin varyanslarını açıklamaktır.Temelde gözlenenen değişkenlerin varyanslarına ve gözlenen değişkenler arasındaki kovaryanslara dayalı olan YEM analizlerinin amacı bir grup gözlenen değişken arasındaki kovaryans örüntüsünü anlamak ve araştırma modeli ile gözlenen değişkenlerin varyanslarını açıklamaktır.","code":""},{"path":"yol-analizi.html","id":"yol-analizi-modelleri","chapter":"Bölüm 6 Yol Analizi","heading":"6.1 Yol Analizi Modelleri","text":"Yol analizinde amaç ölçülen değişkenler arasındaki ilişkileri  açıklamaktır.Yol analizinde amaç ölçülen değişkenler arasındaki ilişkileri  açıklamaktır.Yol analizi gözlenen değişkenler arasındakı doğrudan ve\ndoğrudan olmayan etkileri gösteren yapısal modellerin\ntanımlanmasına ve test edilmesine izin verirYol analizi gözlenen değişkenler arasındakı doğrudan ve\ndoğrudan olmayan etkileri gösteren yapısal modellerin\ntanımlanmasına ve test edilmesine izin verir","code":""},{"path":"yol-analizi.html","id":"bir-araştırma-senaryosu-hastalık-faktörleri","chapter":"Bölüm 6 Yol Analizi","heading":"6.2 Bir Araştırma Senaryosu: Hastalık Faktörleri","text":"Sunumdaki örnek Roth, Wiebe, Fillingim ve Shay’(1989) çalışmasından gelmektedir. Çalışmalarında\nüniversite öğrencilerinde egzersiz, dayanıklılık, form ve stresin hastalık üzerindeki etkilerini incelemişlerdir.Sunumdaki örnek Roth, Wiebe, Fillingim ve Shay’(1989) çalışmasından gelmektedir. Çalışmalarında\nüniversite öğrencilerinde egzersiz, dayanıklılık, form ve stresin hastalık üzerindeki etkilerini incelemişlerdir.🔗illness.dat adlı veri setinde 5 değişken, 400 birey vardır. Değişkenler egzersiz, dayanıklılık, form, stres ve hastalık değişkenleri olup sürekli değişkenlerdir.🔗illness.dat adlı veri setinde 5 değişken, 400 birey vardır. Değişkenler egzersiz, dayanıklılık, form, stres ve hastalık değişkenleri olup sürekli değişkenlerdir.Araştırma hipotezleri:egzersiz ve dayanıklılık formu etkiler.egzersiz ve dayanıklılık formu etkiler.egzersiz ve dayanıklılık stresi etkiler.egzersiz ve dayanıklılık stresi etkiler.egzersiz, dayanıklılık, form ve stres hastalığı (illness) etkiler.egzersiz, dayanıklılık, form ve stres hastalığı (illness) etkiler.Bu üç hipotezin biri çoklu regresyon modelidir:\\(\\text{form}_i = \\beta_0  + \\beta_{\\text{eegzersiz}_i} + \\beta_{\\text{dayanıklılık}_i} + e_{fi}\\)\\(\\text{stres}_i = \\beta_0  + \\beta_{\\text{eegzersiz}_i} + \\beta_{\\text{dayanıklılık}_i} + e_{fi}\\)\\(\\text{hastalık}_i = \\beta_0  + \\beta_{\\text{eegzersiz}_i} + \\beta_{\\text{dayanıklılık}_i} + \\beta_{\\text{form}_i} + \\beta_{\\text{stres}_i} + e_{fi}\\)Bu modeller R'da lavaan paketi ile model denklemi oluşturularak kullanılmalıdır.Veri setini okumaYol modelini kurma","code":"\nyol_model <-  'stres     ~ egzersiz + dayaniklilik\n               hastalik  ~ egzersiz + dayaniklilik + form + stres\n               form      ~ egzersiz + dayaniklilik'\nlibrary(readr)\nveri <- read_table(\"import/illness.dat\", col_names = FALSE)\ncolnames(veri) <- c(\"form\", \"stres\", \"hastalik\", \"egzersiz\", \"dayaniklilik\")\nlibrary(lavaan)\nyol_model <-  'stres     ~ egzersiz + dayaniklilik\n               hastalik  ~ egzersiz + dayaniklilik + form + stres\n               form      ~ egzersiz + dayaniklilik\negzersiz ~~ dayaniklilik'\nyol_fit <- sem(yol_model, veri)"},{"path":"yol-analizi.html","id":"hastalık-faktörleri-yol-modeli","chapter":"Bölüm 6 Yol Analizi","heading":"6.2.1 Hastalık Faktörleri Yol Modeli","text":"","code":""},{"path":"yol-analizi.html","id":"yol-şemasının-öğeleri","chapter":"Bölüm 6 Yol Analizi","heading":"6.3 Yol Şemasının Öğeleri","text":"Gözlenen DeğişkenDışsal (Exogenous) Değişken: Nedenleri bilinmeyen ve\nmodelde gösterilmeyen değişkendir. Dışsal değişken\ndeğişkenlik göstermekte serbesttir.Örneğin, egzersiz ve dayaniklilikİçsel (Endogenous) Değişken: Varsayılan nedenleri modelde açıkça gösterilen değişkendir. İçsel değişken değişkenlik göstermekte serbest değildir.Örneğin, form, stres ve hastalıkÖrneğin, form, stres ve hastalıkHer içsel değişkenin bozukluğu (disturbance) vardır ve bozukluk\n(disturbance) modelde D sembolü ile gösterilir.içsel değişkenin bozukluğu (disturbance) vardır ve bozukluk\n(disturbance) modelde D sembolü ile gösterilir.Bozukluk model için hata (artık) terimidir ve içsel değişkende\ngözlenen varyansın açıklanmayan kısmını temsil eder.Bozukluk model için hata (artık) terimidir ve içsel değişkende\ngözlenen varyansın açıklanmayan kısmını temsil eder.Bozukluk ilgili içsel değişkenin ölçülemeyen bütün nedenlerini temsil eden\nbileşik bir değişkendir.Bozukluk ilgili içsel değişkenin ölçülemeyen bütün nedenlerini temsil eden\nbileşik bir değişkendir.Model ele alındığında bu nedenlerin doğası\nve sayısı bilinmediğinden bozukluklar gizil değişkenler olarak\ndüşünülebilir ve çember sembolü ile temsil edilirler.Model ele alındığında bu nedenlerin doğası\nve sayısı bilinmediğinden bozukluklar gizil değişkenler olarak\ndüşünülebilir ve çember sembolü ile temsil edilirler.Gizil Değişkenlerdoğrudan ölçülmezler.doğrudan ölçülmezler.bir değer alamayabilirler.bir değer alamayabilirler.daha doğrudan ölçülebilen değişkenleri etkilediklerine inanılır.daha doğrudan ölçülebilen değişkenleri etkilediklerine inanılır.Yapısal eşitlik modelinde iki tür gizil değişken vardır:faktör veya yapıartık veya bozuklukBir değişkenin diğer bir değişken üzerindeki doğrudan etkisi (direct effect) olup okun kuyruğundaki değişkenin okun başındaki değişkeni etkilediği varsayılır. Doğrudan etki yol olarak da\nadlandırılır.\nÖrneğin, egzersiz’ın form üzerindeki doğrudan etkisi\nÖrneğin, Dfi’nin form üzerindeki doğrudan etkisi (ölçülmeyen bütün\nnedenlerin form üzerindeki doğrudan etkisi)\nBir değişkenin diğer bir değişken üzerindeki doğrudan etkisi (direct effect) olup okun kuyruğundaki değişkenin okun başındaki değişkeni etkilediği varsayılır. Doğrudan etki yol olarak da\nadlandırılır.Örneğin, egzersiz’ın form üzerindeki doğrudan etkisiÖrneğin, egzersiz’ın form üzerindeki doğrudan etkisiÖrneğin, Dfi’nin form üzerindeki doğrudan etkisi (ölçülmeyen bütün\nnedenlerin form üzerindeki doğrudan etkisi)Örneğin, Dfi’nin form üzerindeki doğrudan etkisi (ölçülmeyen bütün\nnedenlerin form üzerindeki doğrudan etkisi)Doğrudan etkilerin istatistiksel kestirimi yol katsayıları (path\ncoefficients) olup çoklu regresyondaki regresyon katsayıları gibi\nyorumlanır.Doğrudan etkilerin istatistiksel kestirimi yol katsayıları (path\ncoefficients) olup çoklu regresyondaki regresyon katsayıları gibi\nyorumlanır.bozukluk ve \\(y_1\\) yolunda gözüken 1 sayısı ölçekleme sabitidir (scaling constant), standartlaştırılmamış artık yol katsayısı (unstandardized\nresidual path coefficient) olarak da adlandırılır ve bozukluğa bir ölçek atandığını gösterir.bozukluk ve \\(y_1\\) yolunda gözüken 1 sayısı ölçekleme sabitidir (scaling constant), standartlaştırılmamış artık yol katsayısı (unstandardized\nresidual path coefficient) olarak da adlandırılır ve bozukluğa bir ölçek atandığını gösterir.Bozukluklar gizil olduğu ve gizil değişkenler de\nprogram onlarla ilgili herhangi bir kestirimde bulunmadan önce ölçeğe ihtiyaç duyduklarından böyle bir sabit atanır.İki dışsal değişken arasındaki analiz edilmeyen ilişki\nÖrneğin, egsersiz degişkeni ve dayanıklılık değişkeni arasındaki\nkovaryans\nÖrneğin, egsersiz degişkeni ve dayanıklılık değişkeni arasındaki\nkovaryansBir dışsal değişkenin varyansı\nÖrneğin, dayanıklılık değişkeninin varyansı\nÖrneğin, dayanıklılık değişkeninin varyansıBir bozuklugun varyansı\nÖrneğin, D’nin varyansı\nÖrneğin, D’nin varyansı","code":""},{"path":"yol-analizi.html","id":"doğrudan-etki","chapter":"Bölüm 6 Yol Analizi","heading":"6.4 Doğrudan Etki","text":"Bir dışsal veya içsel bir değişken diğer bir içsel değişkenin\ndoğrudan nedeni olabilir.egzersiz → formdayaniklilik → formegzersiz → stresdayaniklilik → stresform → hastalikstres → hastalikegzersiz → hastalikdayaniklilik → hastalik","code":""},{"path":"yol-analizi.html","id":"yol-şemasının-öğeleri-1","chapter":"Bölüm 6 Yol Analizi","heading":"6.5 Yol Şemasının Öğeleri","text":"Dolaylı veya Arabulucu EtkiBazı içsel değişkenlerin yol modelinde hem bağımsız hem de\nbağımlı değişken olarak ikili rolü vardır. Bu değişkenlere\narabulucu değişkenler adı verilir.Bazı içsel değişkenlerin yol modelinde hem bağımsız hem de\nbağımlı değişken olarak ikili rolü vardır. Bu değişkenlere\narabulucu değişkenler adı verilir.formformstresstresArabulucu değişkenler kendilerinden önceki değişkenlerin\nnedensel etkilerinin bir kısmını kendilerinden sonraki\ndeğişkenlere iletirler, böyle etkilere dolaylı etkiler adı verilir.\negzersiz → form → hastalik\ndayaniklilik→ form → hastalik\negzersiz → stres → hastalik\ndayaniklilik → stres → hastalik\nArabulucu değişkenler kendilerinden önceki değişkenlerin\nnedensel etkilerinin bir kısmını kendilerinden sonraki\ndeğişkenlere iletirler, böyle etkilere dolaylı etkiler adı verilir.egzersiz → form → hastalikdayaniklilik→ form → hastalikegzersiz → stres → hastalikdayaniklilik → stres → hastalik","code":""},{"path":"yol-analizi.html","id":"yol-analizi-modeli","chapter":"Bölüm 6 Yol Analizi","heading":"6.6 Yol Analizi Modeli","text":"Veri modellemedeki düşünce gözlenen kovaryans matrisinin bir\ngrup değişken arasındaki varsayılan ilişki tarafından üretilip\nüretilemeyeceğini test etmektir.Veri modellemedeki düşünce gözlenen kovaryans matrisinin bir\ngrup değişken arasındaki varsayılan ilişki tarafından üretilip\nüretilemeyeceğini test etmektir.Varsayılan model belli bir varyans ve kovaryans deseni gerektirir ki\nbu varyans ve kovaryans deseni üretilmiş varyans ve kovaryans\nmatrisi (reproduced variance covariance matrix) olarak\nadlandırılır.Varsayılan model belli bir varyans ve kovaryans deseni gerektirir ki\nbu varyans ve kovaryans deseni üretilmiş varyans ve kovaryans\nmatrisi (reproduced variance covariance matrix) olarak\nadlandırılır.Bu matris çoğunlukla üretilmiş kovaryans matrisi\n(reproduced covariance matrix) olarak kısaltılır.Bu matris çoğunlukla üretilmiş kovaryans matrisi\n(reproduced covariance matrix) olarak kısaltılır.Gözlenen kovaryans matrisi ve üretilmiş kovaryans matrisi\narasındaki fark artık kovaryans matrisini (residual covariance\nmatrix) oluşturur.Gözlenen kovaryans matrisi ve üretilmiş kovaryans matrisi\narasındaki fark artık kovaryans matrisini (residual covariance\nmatrix) oluşturur.Eğer artık kovaryans matrisinin bütün elemanları sıfırsa, varsayılan\nmodel veriyle tamamen eşleşmiş demektir (mükemmel model-veri\nuyumu)Eğer artık kovaryans matrisinin bütün elemanları sıfırsa, varsayılan\nmodel veriyle tamamen eşleşmiş demektir (mükemmel model-veri\nuyumu)Eğer artık kovaryans matrisinin bütün elemanları sıfır değilse,\nvarsayılan model ve veri arasında bir takım uyuşmazlıklar vardır.Eğer artık kovaryans matrisinin bütün elemanları sıfır değilse,\nvarsayılan model ve veri arasında bir takım uyuşmazlıklar vardır.Yol analizi modelinde sıfır hipotezi, model tarafından\nüretilen kovaryans matrisinin gerçek veriyle (örneğin,\ngözlenen kovaryans matrisiyle) tamamen eşleştiğidir.Yol analizi modelinde sıfır hipotezi, model tarafından\nüretilen kovaryans matrisinin gerçek veriyle (örneğin,\ngözlenen kovaryans matrisiyle) tamamen eşleştiğidir.\\(\\sum = \\hat{\\sum}\\)Burada\\(\\sum\\) (sigma): gözlenen değişkenlerin evren kovaryans matrisi\\(\\sum\\) (sigma): gözlenen değişkenlerin evren kovaryans matrisi\\(\\hat{\\sum}\\): model tarafından üretilen kovaryans matrisi\\(\\hat{\\sum}\\): model tarafından üretilen kovaryans matrisiYol analizi modelinde, sıfır hipotezinin reddedilmesi istenmez!\nBu nedenle, genel model uyumunu test etmek için kullanılan\nolabilirlik oranı (ki-kare) testinin p-değerinin yüksek olması istenir.Yol analizi modelinde, sıfır hipotezinin reddedilmesi istenmez!\nBu nedenle, genel model uyumunu test etmek için kullanılan\nolabilirlik oranı (ki-kare) testinin p-değerinin yüksek olması istenir.Artık kovaryans matrisi model tarafından açıklanmayan\nvaryans ve kovaryansları içeren matristir. Aşağıdaki\neşitlikle hesaplanır:Artık kovaryans matrisi model tarafından açıklanmayan\nvaryans ve kovaryansları içeren matristir. Aşağıdaki\neşitlikle hesaplanır:\\(\\sum - \\hat{\\sum}\\)S örneklemden elde edilen gözlenen kovaryans matrisidir.Gözlenen değişkenler arasındaki bütün varyans ve\nkovaryanslar model tarafından açıklandığı zaman artık\nkovaryans matrisinin bütün öğeleri sıfır olacaktır. Gözlenen değişkenler arasındaki bütün varyans ve\nkovaryanslar model tarafından açıklandığı zaman artık\nkovaryans matrisinin bütün öğeleri sıfır olacaktır. Aksi halde, artık kovaryans matrisinin sıfırdan farklı\nolacaktır.Aksi halde, artık kovaryans matrisinin sıfırdan farklı\nolacaktır.","code":""},{"path":"yol-analizi.html","id":"hastalık-faktörleri-yol-şeması","chapter":"Bölüm 6 Yol Analizi","heading":"6.6.1 Hastalık Faktörleri (Yol Şeması)","text":"","code":"\nlibrary(lavaan)\nyol_model <-  'stres     ~ egzersiz + dayaniklilik\n               hastalik  ~ egzersiz + dayaniklilik + form + stres\n               form      ~ egzersiz + dayaniklilik\negzersiz ~~ dayaniklilik'\nyol_fit <- sem(yol_model, veri)\n\nsemPaths(yol_fit,rotation=2, curvePivot = TRUE,\n           sizeMan = 12, sizeInt = 1, \n            sizeLat = 4,\n           edge.label.cex = 1.8,\n           pastel=TRUE,\n           nCharNodes = 0, nCharEdges = 0)"},{"path":"yol-analizi.html","id":"evren-kovaryans-matrisi","chapter":"Bölüm 6 Yol Analizi","heading":"6.7 Evren Kovaryans Matrisi","text":"hastalık faktörleri örneği için gözlenen değişkenlerin evren\nkovaryans matrisi \\(\\sum\\) aşağıdaki gibidir:\\[\\begin{bmatrix}{}\nVAR_{y_1}\\\\\nCOV_{y_2,y_1} & VAR_{y_2}\\\\\nCOV_{y_3,y_1} & COV_{y_3,y_2} & VAR_{y_3}\\\\\nCOV_{x_1,y_1} & COV_{x_1,y_2} & COV_{x_1,y_3} & VAR_{x_1}\\\\\nCOV_{x_2,y_1} & COV_{x_2,y_2} & COV_{x_2,y_3} & COV_{x_2,x_1} & VAR_{x_2}\\\\\n\\end{bmatrix}{}\\]\\(\\sum\\) kare ve simetrik bir matristir ve matriste\nçoğunlukla alt üçgen ve köşegen öğeleri yazılır.\\(\\sum\\) kare ve simetrik bir matristir ve matriste\nçoğunlukla alt üçgen ve köşegen öğeleri yazılır.bir yol modelindeki gözlenen değişkenler arasındaki varyans ve\nkovaryanslardır.bir yol modelindeki gözlenen değişkenler arasındaki varyans ve\nkovaryanslardır.Model gözlemlerinin sayısı \\(v\\) gözlenen değişkenlerin sayısı olmak\nüzere \\(v(v + 1) / 2\\)’ye eşittir.Model gözlemlerinin sayısı \\(v\\) gözlenen değişkenlerin sayısı olmak\nüzere \\(v(v + 1) / 2\\)’ye eşittir.hastalık faktörleri örneğine göre, \\(v = 5\\) ve \\(v(v + 1) / 2 = 15\\)hastalık faktörleri örneğine göre, \\(v = 5\\) ve \\(v(v + 1) / 2 = 15\\)\\[\\begin{bmatrix}{}\nVAR_{y_1}\\\\\nCOV_{y_2,y_1} & VAR_{y_2}\\\\\nCOV_{y_3,y_1} & COV_{y_3,y_2} & VAR_{y_3}\\\\\nCOV_{x_1,y_1} & COV_{x_1,y_2} & COV_{x_1,y_3} & VAR_{x_1}\\\\\nCOV_{x_2,y_1} & COV_{x_2,y_2} & COV_{x_2,y_3} & COV_{x_2,x_1} & VAR_{x_2}\\\\\n\\end{bmatrix}{}\\]Modelden kestirilen parametre sayısıya gözlenen ya da gözlenmeyen dışsal değişkenlerin varyanslarının ve\nkovaryanslarının sayısı\nveya gözlenen ya da gözlenmeyen dışsal değişkenlerin varyanslarının ve\nkovaryanslarının sayısı\nvegözlenen değişkenlerden içsel değişkenlere olan doğrudan etkilerin\nsayısı toplamıdır.gözlenen değişkenlerden içsel değişkenlere olan doğrudan etkilerin\nsayısı toplamıdır.Hastalık faktörleri örneğinde, kestirilecek model parametreleri:Hastalık faktörleri örneğinde, kestirilecek model parametreleri:Dışsal değişkenlerin varyansları: 2Dışsal değişkenlerin varyansları: 2Dışsal değişkenlerin kovaryansı: 1Dışsal değişkenlerin kovaryansı: 1Bozuklukların varyansları: 3Bozuklukların varyansları: 3Doğrudan etkiler: 8Doğrudan etkiler: 8\\(2 + 1 + 3 + 8 = 14\\)İçsel değişkenlerin varyansları ve kovaryansları model parametreleri olarak ele alınmaz.Bozukluk, modelde nedeni bilinmediğinden, gözlenmeyen dışsal\ndeğişken olarak ele alınır.Model parametresi araştırmacının tanımlamasına bağlı olarak\nserbest (free), sabit (fixed) veya sınırlandırılmış (constrained)\nolabilir.Model parametresi araştırmacının tanımlamasına bağlı olarak\nserbest (free), sabit (fixed) veya sınırlandırılmış (constrained)\nolabilir.Serbest parametre (free parameter) örneklem verisinden bilgisayar\nyazılımı tarafından kestirilen parametredir.Serbest parametre (free parameter) örneklem verisinden bilgisayar\nyazılımı tarafından kestirilen parametredir.Sabit parametre (fixed parameter) bir sabite eşit olarak belirlenen\nparametredir; yazılım bu sabiti veriye bağlı olmaksızın parametrenin\nkestirimi olarak kabul eder.Sabit parametre (fixed parameter) bir sabite eşit olarak belirlenen\nparametredir; yazılım bu sabiti veriye bağlı olmaksızın parametrenin\nkestirimi olarak kabul eder.Sınırlandırılmış parametre (constrained parameter) yazılım tarafından\nbelli sınırlılıklar içerisinde kestirilir ancak bir sabite eşit olmak üzere\nsabitlenmez.Sınırlandırılmış parametre (constrained parameter) yazılım tarafından\nbelli sınırlılıklar içerisinde kestirilir ancak bir sabite eşit olmak üzere\nsabitlenmez.","code":""},{"path":"yol-analizi.html","id":"serbestlik-derecesi","chapter":"Bölüm 6 Yol Analizi","heading":"6.7.1 Serbestlik Derecesi:","text":"Model serbestlik derecesi (sd) model gözlemlerinin sayısı ve\nmodelden kestirilecek parametre sayısı arasındaki farka eşittir:Model serbestlik derecesi (sd) model gözlemlerinin sayısı ve\nmodelden kestirilecek parametre sayısı arasındaki farka eşittir:Hastalık faktörleri örneğinde,Hastalık faktörleri örneğinde,\\[sd = 15 – 14 = 1\\]sd<0 model tanımlanamaz.sd=0 model ancak tanımlanır (just identification) ve kuramsal olarak parametrenin tek bir çözümü vardır. Model veriye mükemmel uyum gösterir.sd>0 model aşırı tanımlanmış (identification) olur. Aşırı tanımlanan modellerde kuramsal olarak bir parametrenin birden fazla çözümü vardır.","code":""},{"path":"yol-analizi.html","id":"model-tanımlanması","chapter":"Bölüm 6 Yol Analizi","heading":"6.8 Model Tanımlanması","text":"(Model Identification) İlkeleriBir yol modelinin değerlendirilmesi sırasında karşılaşılacak olası\nproblemlerden biri modelin tanımlanmasıdır.Bir yol modelinin değerlendirilmesi sırasında karşılaşılacak olası\nproblemlerden biri modelin tanımlanmasıdır.Modeldeki bir parametre için kuramsal olarak tek bir kestirim üretilebiliyorsa, model tanımlanır denir. Aksi halde, model\ntanımlanamaz.Modeldeki bir parametre için kuramsal olarak tek bir kestirim üretilebiliyorsa, model tanımlanır denir. Aksi halde, model\ntanımlanamaz.Kuramsal olarak ifadesi tanımlanmanın verinin değil, modelin bir\nözelliği olduğunu vurgulamak için kullanılmıştır.Kuramsal olarak ifadesi tanımlanmanın verinin değil, modelin bir\nözelliği olduğunu vurgulamak için kullanılmıştır.Örneğin, eğer bir model tanımlanmazsa, örneklem büyüklüğüne (100, 1000,\nvb.) bağlı olmaksızın tanımlanamaz olarak kalır.Örneğin, eğer bir model tanımlanmazsa, örneklem büyüklüğüne (100, 1000,\nvb.) bağlı olmaksızın tanımlanamaz olarak kalır.Bu nedenle, tanımlanmayan modellerin yeniden tanımlanması gerekir. Aksi halde, analizler çözüm üretmez.Bu nedenle, tanımlanmayan modellerin yeniden tanımlanması gerekir. Aksi halde, analizler çözüm üretmez.Herhangi bir yapısal eşitlik modeli için tanımlanmanın gerektirdiği iki\nkoşul vardır:\ngözlenmeyen (gizil) değişken bir ölçeğe atanmalıdır, bozukluk yol\nanalizindeki tek gizil değişkendir.\nEn az serbest model parametreleri kadar gözlem olmalıdır (sd ≥ 0)\nHerhangi bir yapısal eşitlik modeli için tanımlanmanın gerektirdiği iki\nkoşul vardır:gözlenmeyen (gizil) değişken bir ölçeğe atanmalıdır, bozukluk yol\nanalizindeki tek gizil değişkendir.gözlenmeyen (gizil) değişken bir ölçeğe atanmalıdır, bozukluk yol\nanalizindeki tek gizil değişkendir.En az serbest model parametreleri kadar gözlem olmalıdır (sd ≥ 0)En az serbest model parametreleri kadar gözlem olmalıdır (sd ≥ 0)Gizil Değişkenlere Ölçek AtanmasıGizil değişkenler yapay bir ölçektedirler. Yazılımın gizil\ndeğişkenleri içeren etkilerin kestirimlerini\nhesaplayabilmesi için gizil değişkenlere bir ölçek atanması\ngerekir. Gizil değişkenler yapay bir ölçektedirler. Yazılımın gizil\ndeğişkenleri içeren etkilerin kestirimlerini\nhesaplayabilmesi için gizil değişkenlere bir ölçek atanması\ngerekir. Unit Loading Identification (ULI) constraint: Artık yol katsayısı\n(bozukluğun doğrudan etkisini ifade eden yol katsayısı) 1.0’e\nsabitlenir, böylece bozukluk ilgili içsel değişkenin açıklanmayan\nvaryansıyla ilişkili bir ölçeğe atanmış olur.\nRegresyon ve yol analizi modellerinde, ölçekler bozukluklara\ngenellikle ULI aracılığıyla atanırlar.\nUnit Loading Identification (ULI) constraint: Artık yol katsayısı\n(bozukluğun doğrudan etkisini ifade eden yol katsayısı) 1.0’e\nsabitlenir, böylece bozukluk ilgili içsel değişkenin açıklanmayan\nvaryansıyla ilişkili bir ölçeğe atanmış olur.Regresyon ve yol analizi modellerinde, ölçekler bozukluklara\ngenellikle ULI aracılığıyla atanırlar.Unit Variance Identification (UVI) constraint: Gizil içsel\ndeğişkenlerin (yol modelinde bozuklukların) varyansı 1.0’e\neşitlenir böylece gizil değişkenin varyansı standartlaştırılmış\nölçekte olur.Unit Variance Identification (UVI) constraint: Gizil içsel\ndeğişkenlerin (yol modelinde bozuklukların) varyansı 1.0’e\neşitlenir böylece gizil değişkenin varyansı standartlaştırılmış\nölçekte olur.","code":""},{"path":"yol-analizi.html","id":"yetersiz-tanımlanma-underidentification","chapter":"Bölüm 6 Yol Analizi","heading":"6.8.1 Yetersiz Tanımlanma (Underidentification)","text":"Yetersiz tanımlanan bir modelde serbest model parametrelerinin\nsayısı gözlem sayısından büyüktür, diğer bir ifadeyle modelin\nserbestlik derecesi sıfırdan küçüktür (sd < 0).Yetersiz tanımlanan bir modelde serbest model parametrelerinin\nsayısı gözlem sayısından büyüktür, diğer bir ifadeyle modelin\nserbestlik derecesi sıfırdan küçüktür (sd < 0).Yetersiz tanımlanan bir model test edilemez ve yeniden\ntanımlanması gerekir. Bu durumda en az bir parametrenin çözümü yoktur.Yetersiz tanımlanan bir model test edilemez ve yeniden\ntanımlanması gerekir. Bu durumda en az bir parametrenin çözümü yoktur.Örnek:Örnek:Gözlem eksikliğinin tanımlanmamaya nasıl yol açtığının\nbir örneği\n\\(+ b = 6\\)\nGözlem eksikliğinin tanımlanmamaya nasıl yol açtığının\nbir örneği\\(+ b = 6\\)Verilen eşitlik bir model olarak ele alınırsa, 6 gözlem, \nve b de parametrelerdir. Verilen eşitlik bir model olarak ele alınırsa, 6 gözlem, \nve b de parametrelerdir. Eşitlikte parametre sayısı (2), gözlem sayısından (1)\ndaha fazla olduğundan,bir parametre için tek bir\nçözüm bulmak imkansızdır.Eşitlikte parametre sayısı (2), gözlem sayısından (1)\ndaha fazla olduğundan,bir parametre için tek bir\nçözüm bulmak imkansızdır.ve b parametreleri için eşitliği sağlayacak sonsuz sayıda çözüm\nvardır:ve b parametreleri için eşitliği sağlayacak sonsuz sayıda çözüm\nvardır:Örneğin, (= 4, b = 2), (= 8, b = -2) vb.Örneğin, (= 4, b = 2), (= 8, b = -2) vb.Yetersiz tanımlanan bir yol modeli için program bir\nparametreye ait tek bir kestirim üretmeye çalışırken de\nbenzer bir durum söz konusudur.Yetersiz tanımlanan bir yol modeli için program bir\nparametreye ait tek bir kestirim üretmeye çalışırken de\nbenzer bir durum söz konusudur.","code":""},{"path":"yol-analizi.html","id":"ancak-tanımlanma-just-identification","chapter":"Bölüm 6 Yol Analizi","heading":"6.8.2 Ancak Tanımlanma (Just Identification)","text":"Ancak tanımlanan bir modelde parametre sayısı ve gözlem sayısı\nbirbirine eşittir, diğer bir ifadeyle modelin serbestlik derecesi sıfıra\neşittir (sd = 0) ve model tanımlanır; kuramsal olarak \nparametrenin tek bir çözümü vardır.Örnek:Ancak tanımlanmanın bir örneği aşağıda verilmiştir:\n- \\(+ b = 6\\)\n- \\(2a + b =10\\)\n- Verilen eşitlikler bir model olarak ele alınırsa, 6 ve 10\ngözlemler, ve b de parametrelerdir.\n- Eşitlikte parametre sayısı (2), gözlem sayısına (2) eşit\nolduğundan,bir parametre için tek bir çözümü\nbulunmaktadır.(= 4, b = 2)(= 4, b = 2)Parametre kestirimleri verildiğinde gözlemler mükemmel bir şekilde\nüretilir.Parametre kestirimleri verildiğinde gözlemler mükemmel bir şekilde\nüretilir.Ancak tanımlanan bir yol modeli için program bir\nparametreye ait tek bir kestirim üretmekle kalmayıp\nmodel veriye mükemmel uyum sağlayacaktır.Ancak tanımlanan bir yol modeli için program bir\nparametreye ait tek bir kestirim üretmekle kalmayıp\nmodel veriye mükemmel uyum sağlayacaktır.","code":""},{"path":"yol-analizi.html","id":"aşırı-tanımlanma-overidentification","chapter":"Bölüm 6 Yol Analizi","heading":"6.8.3 Aşırı Tanımlanma (Overidentification)","text":"Aşırı tanımlanan bir modelde parametre sayısı, gözlem sayısından\nküçüktür, diğer bir ifadeyle modelin serbestlik derecesi sıfırdan\nbüyüktür sd > 0, kuramsal olarak parametrenin olası bir çok\nçözümü vardır.\nAşırı tanımlanan bir model için, üretilen kovaryans matrisi örneklem\nkovaryans matrisini mükemmel bir şekilde üretmeyecektir.Aşırı tanımlanmanın bir örneği aşağıda verilmiştir:\n- \\(+ b = 6\\)\n- \\(2a + b =10\\)\n- \\(3a + b = 12\\)\n- Verilen eşitlikler bir model olarak ele alınırsa, 6, 10 ve\n12 gözlemler, ve b de parametrelerdir. \n- Üç eşitliği sağlayacak ve b değerleri bulunmayabilir.Örneğin, (= 4, b = 2) değerleri sadece ilk iki eşitliği sağlar.Örneğin, (= 4, b = 2) değerleri sadece ilk iki eşitliği sağlar.Aşırı tanımlama durumda, bir parametre için tek bir çözüm\naşağıdaki şekilde üretilir:\nGözlemler ve üretilen gözlemler arasındaki farkın karesinin\ntoplamının mümkün olduğunca küçük olacağı pozitif parametre\ndeğerleri bulunur.\nÖrneğin, (= 3, b = 3,3) sadece en küçük toplam kareler farkını\nsağlamakla kalmaz tek bir çözüm üretir.\nAşırı tanımlama durumda, bir parametre için tek bir çözüm\naşağıdaki şekilde üretilir:Gözlemler ve üretilen gözlemler arasındaki farkın karesinin\ntoplamının mümkün olduğunca küçük olacağı pozitif parametre\ndeğerleri bulunur.Gözlemler ve üretilen gözlemler arasındaki farkın karesinin\ntoplamının mümkün olduğunca küçük olacağı pozitif parametre\ndeğerleri bulunur.Örneğin, (= 3, b = 3,3) sadece en küçük toplam kareler farkını\nsağlamakla kalmaz tek bir çözüm üretir.Örneğin, (= 3, b = 3,3) sadece en küçük toplam kareler farkını\nsağlamakla kalmaz tek bir çözüm üretir.","code":""},{"path":"yol-analizi.html","id":"model-veri-uyumunun-değerlendirilmesi","chapter":"Bölüm 6 Yol Analizi","heading":"6.9 Model-Veri Uyumunun Değerlendirilmesi","text":"Kestirilen parametre sayısından daha fazla sayıda\ngözleme sahip olan aşırı tanımlanan (overidentified)\nmodeller genellikle veriye mükemmel uyum sağlamaz. \nBu durumda böyle modellerin veriyle ne derece uyumlu\nolduğunu ölçmeye ihtiyaç vardır.Kestirilen parametre sayısından daha fazla sayıda\ngözleme sahip olan aşırı tanımlanan (overidentified)\nmodeller genellikle veriye mükemmel uyum sağlamaz. \nBu durumda böyle modellerin veriyle ne derece uyumlu\nolduğunu ölçmeye ihtiyaç vardır.YEM literatüründe tanımlanan çok sayıda model uyum\nindeksi vardır ve sürekli olarak yeni indeksler\ngeliştirilmektedir.YEM literatüründe tanımlanan çok sayıda model uyum\nindeksi vardır ve sürekli olarak yeni indeksler\ngeliştirilmektedir.Çok sayıda farklı uyum indeksinin olması bazı\nproblemleri de beraberinde getirir:\nFarklı makalelerde farklı uyum indeksleri rapor edilir.\nAynı makale için farklı hakemler kendi bildikleri veya tercih\nettikleri farklı indekslerin rapor edilmesini isteyebilirler.\nUyum indekslerinin değerlerini rapor ederken seçici davranma\nolasılığı vardır (örneğin, sadece iyi uyum öneren uyum\nindekslerinin rapor edilmesi gibi).\nÇok sayıda farklı uyum indeksinin olması bazı\nproblemleri de beraberinde getirir:Farklı makalelerde farklı uyum indeksleri rapor edilir.Farklı makalelerde farklı uyum indeksleri rapor edilir.Aynı makale için farklı hakemler kendi bildikleri veya tercih\nettikleri farklı indekslerin rapor edilmesini isteyebilirler.Aynı makale için farklı hakemler kendi bildikleri veya tercih\nettikleri farklı indekslerin rapor edilmesini isteyebilirler.Uyum indekslerinin değerlerini rapor ederken seçici davranma\nolasılığı vardır (örneğin, sadece iyi uyum öneren uyum\nindekslerinin rapor edilmesi gibi).Uyum indekslerinin değerlerini rapor ederken seçici davranma\nolasılığı vardır (örneğin, sadece iyi uyum öneren uyum\nindekslerinin rapor edilmesi gibi).YEM uygulamalarına ve simülasyon çalışmalarına göre\nYEM analizinin sonuçlarını rapor ederken sunulacak ve\nyorumlanacak uyum indeksleri aşağıdaki gibidir:\nModel Ki-Kare Değeri\nSteiger-Lind Root Mean Square Error Approximation RMSEA\n(Steiger, 1990) (%90 güven aralığı ile birlikte)\nBentler Comparative Fit Index CFI (Bentler, 1990)\nStandardized Root Mean Square Residual SRMR\nYEM uygulamalarına ve simülasyon çalışmalarına göre\nYEM analizinin sonuçlarını rapor ederken sunulacak ve\nyorumlanacak uyum indeksleri aşağıdaki gibidir:Model Ki-Kare DeğeriModel Ki-Kare DeğeriSteiger-Lind Root Mean Square Error Approximation RMSEA\n(Steiger, 1990) (%90 güven aralığı ile birlikte)Steiger-Lind Root Mean Square Error Approximation RMSEA\n(Steiger, 1990) (%90 güven aralığı ile birlikte)Bentler Comparative Fit Index CFI (Bentler, 1990)Bentler Comparative Fit Index CFI (Bentler, 1990)Standardized Root Mean Square Residual SRMRStandardized Root Mean Square Residual SRMRUyum indekslerinin değerleri bir modelin sadece ortalama\nveya genel uyumunu belirtir. Bu nedenle belli bir indeksin\ndeğeri uygun bile görünse, modelin belli kısımları veriye\nzayıf uyum sağlayabilir. Uyum indekslerinin değerleri bir modelin sadece ortalama\nveya genel uyumunu belirtir. Bu nedenle belli bir indeksin\ndeğeri uygun bile görünse, modelin belli kısımları veriye\nzayıf uyum sağlayabilir. Uyum indeksleri sonuçların kuramsal olarak anlamlı olup\nolmadığını belirtmezler.Uyum indeksleri sonuçların kuramsal olarak anlamlı olup\nolmadığını belirtmezler.Örneğin, bazı yol katsayılarının işaretleri beklenenin aksi yönde\nolabilir. Uyum indekslerinin değerleri uygun bile görünse\nbeklenmeyen sonuçlar açıklama gerektirir. Örneğin, bazı yol katsayılarının işaretleri beklenenin aksi yönde\nolabilir. Uyum indekslerinin değerleri uygun bile görünse\nbeklenmeyen sonuçlar açıklama gerektirir. Yeterli uyumu öneren uyum indekslerinin değerleri\nyordayıcıların yordama güçlerinin de yüksek olduğunu\nbelirtmezler.Yeterli uyumu öneren uyum indekslerinin değerleri\nyordayıcıların yordama güçlerinin de yüksek olduğunu\nbelirtmezler.Örneğin, veriye mükemmel uyum sağlayan modellerin\nbozukluklarının varyansı halen yüksek olabilir.Örneğin, veriye mükemmel uyum sağlayan modellerin\nbozukluklarının varyansı halen yüksek olabilir.Tek bir indeks modelin sadece belli bir yönünü\nyansıttığından,modelin iyi uyum sağladığını belirtmek\niçin tek başına yeterli olmaz. Bu nedenle, model uyumu\nbirden fazla indeksin değerine dayanarak değerlendirilir.Tek bir indeks modelin sadece belli bir yönünü\nyansıttığından,modelin iyi uyum sağladığını belirtmek\niçin tek başına yeterli olmaz. Bu nedenle, model uyumu\nbirden fazla indeksin değerine dayanarak değerlendirilir.Uyum hem modelin belli kısımlarında bölgesel olarak\nhem de genel model ve veri uyuşmasının ne kadar iyi\nolduğu yönünde global olarak değerlendirilmelidir.Uyum hem modelin belli kısımlarında bölgesel olarak\nhem de genel model ve veri uyuşmasının ne kadar iyi\nolduğu yönünde global olarak değerlendirilmelidir.Genel olarak YEM analizinde model uyumu\ndeğerlendirilirken, odak tek bir istatistiksel anlamlılık\ntestinde değildir. Çeşitli indeksleri incelerken bütüncül bir\nyaklaşım kullanılmalıdır. Genel olarak YEM analizinde model uyumu\ndeğerlendirilirken, odak tek bir istatistiksel anlamlılık\ntestinde değildir. Çeşitli indeksleri incelerken bütüncül bir\nyaklaşım kullanılmalıdır. Çoklu indekslerin kullanılması bir modelin uyumu ile ilgili\nen doğru yaklaşımı verecektir. Çoklu indekslerin kullanılması bir modelin uyumu ile ilgili\nen doğru yaklaşımı verecektir. ","code":""},{"path":"yol-analizi.html","id":"ki-kare-testi-chi-square-test","chapter":"Bölüm 6 Yol Analizi","heading":"6.9.1 Ki-Kare Testi (Chi-Square Test)","text":"Ki-kare testi gözlenen kovaryans matrisinin tanımlanan modelle\ntutarlı olup olmadığını değerlendirir.MLE yöntemi için sıfır hipotezini değerlendirmek üzere T-istatistiği\n(model chi-square, likelihood ratio chi-square veya generalized\nlikelihood ratio olarak da adlandırılır) hesaplanır:\n\\(T=(n-1)F_{ML}\\)MLE yöntemi için sıfır hipotezini değerlendirmek üzere T-istatistiği\n(model chi-square, likelihood ratio chi-square veya generalized\nlikelihood ratio olarak da adlandırılır) hesaplanır:\n\\(T=(n-1)F_{ML}\\)Burada n örneklem büyüklüğüdür.\nn büyük ise ve ölçülen değişkenler evrende çok değişkenli normal\ndağılımlara sahipse ve doğru model tanımlanmışsa; T-istatistiği yaklaşık\nolarak tanımlanan modelin serbestlik derecesi ile ki-kare dağılımı\ngösterir.\nBurada n örneklem büyüklüğüdür.n büyük ise ve ölçülen değişkenler evrende çok değişkenli normal\ndağılımlara sahipse ve doğru model tanımlanmışsa; T-istatistiği yaklaşık\nolarak tanımlanan modelin serbestlik derecesi ile ki-kare dağılımı\ngösterir.Ancak tanımlanan (just identified) bir model için ki-kare değeri\ngenellikle sıfıra eşittir ve serbestlik derecesi yoktur sd = 0. Eğer\nmodel ki-kare değeri sıfıra eşitse model veriye mükemmel bir şekilde\nuyar (kestirilen korelasyon ve kovaryans değerleri gözlenenlere\neşittir).Ancak tanımlanan (just identified) bir model için ki-kare değeri\ngenellikle sıfıra eşittir ve serbestlik derecesi yoktur sd = 0. Eğer\nmodel ki-kare değeri sıfıra eşitse model veriye mükemmel bir şekilde\nuyar (kestirilen korelasyon ve kovaryans değerleri gözlenenlere\neşittir).Model ki-kare değeri arttıkça, aşırı tanımlanan (overidentified) bir\nmodelin uyumu giderek kötüleşir.Model ki-kare değeri arttıkça, aşırı tanımlanan (overidentified) bir\nmodelin uyumu giderek kötüleşir.Örneğin, sd = 1 ile 12.30’eşit model ki-kare değeri.Örneğin, sd = 1 ile 12.30’eşit model ki-kare değeri.Model ki-kare değeri arttıkça, modelin veriye uyumu kötüleştiği için\nmodel ki-kare aslında bir kötülük uyum indeksidir.Model ki-kare değeri arttıkça, modelin veriye uyumu kötüleştiği için\nmodel ki-kare aslında bir kötülük uyum indeksidir.Geleneksel hipotez testinin aksine, ki-kare testinin sıfır hipotezinin\nreddedilmemesi tercih edilir. Sıfır hipotezinin reddedilmemesi modelin veriye uyduğunu önerir.Geleneksel hipotez testinin aksine, ki-kare testinin sıfır hipotezinin\nreddedilmemesi tercih edilir. Sıfır hipotezinin reddedilmemesi modelin veriye uyduğunu önerir.Diğer yandan sıfır hipotezinin reddedilmesi model-veri uyumunun iyi olmadığını önerir. Diğer yandan sıfır hipotezinin reddedilmesi model-veri uyumunun iyi olmadığını önerir. sd = 1 için ki-karenin 0.05 alfa düzeyindeki kritik değeri 3.84’tür.\n12.3 değeri 3.84 değerinden büyük olduğundan gözlenen kikare değeri (12,302)sd = 1 için ki-karenin 0.05 alfa düzeyindeki kritik değeri 3.84’tür.\n12.3 değeri 3.84 değerinden büyük olduğundan gözlenen kikare değeri (12,302)0,05 alfa düzeyinde istatistiksel olarak\nanlamlıdır.0,05 alfa düzeyinde istatistiksel olarak\nanlamlıdır.12.3 değerini elde etme olasılığını da verir.\nÖrnekte bu olasılık 0.0005’tir. Bu değer 0.05 alfa düzeyinden\nküçüktür.12.3 değerini elde etme olasılığını da verir.\nÖrnekte bu olasılık 0.0005’tir. Bu değer 0.05 alfa düzeyinden\nküçüktür.Ki-kare testi örneklem büyüklüğünden doğrudan etkilenir. Eğer *n büyükse ki bu durum YEM için genellikle istenen bir durumdur, ki-kare testine dayanarak modeli zayıf uyumlu gerekçesiyle reddetmek daha olasıdır (gözlenen\nve kestirilen kovaryans değerleri arasındaki fark çok\nminimal düzeyde olsa bile).Ki-kare testi örneklem büyüklüğünden doğrudan etkilenir. Eğer *n büyükse ki bu durum YEM için genellikle istenen bir durumdur, ki-kare testine dayanarak modeli zayıf uyumlu gerekçesiyle reddetmek daha olasıdır (gözlenen\nve kestirilen kovaryans değerleri arasındaki fark çok\nminimal düzeyde olsa bile).Eğer ki-kare testine dayalı sıfır hipotezi reddedilirse, modelin\nyeterliğini incelemek için diğer indeksler düşünülmelidir.Eğer ki-kare testine dayalı sıfır hipotezi reddedilirse, modelin\nyeterliğini incelemek için diğer indeksler düşünülmelidir.Eğer n küçükse ve güç eksikliğinden dolayı sıfır hipotezi reddedilmediyse, diğer uyum indeksleri modelin desteklenip desteklenmemesinde yardımcı olacaktır.Eğer n küçükse ve güç eksikliğinden dolayı sıfır hipotezi reddedilmediyse, diğer uyum indeksleri modelin desteklenip desteklenmemesinde yardımcı olacaktır.Ki-kare testi örneklem büyüklüğüne bağlılığından dolayı iyilik uyumunun değerlendirilmesi için çok ideal değildir. Ancak geleneksel olarak rapor edilir ve diğer uyum indeksleriyle desteklenir.Ki-kare testi örneklem büyüklüğüne bağlılığından dolayı iyilik uyumunun değerlendirilmesi için çok ideal değildir. Ancak geleneksel olarak rapor edilir ve diğer uyum indeksleriyle desteklenir.Model ki-kare değerinin örneklem büyüklüğüne hassasiyetini azaltmak için bazı araştırmacılar bu değeri ilgili serbestlik derecesine bölerler. Elde edilen değer normed chi-square (NC) değeri olarak adlandırılır.Model ki-kare değerinin örneklem büyüklüğüne hassasiyetini azaltmak için bazı araştırmacılar bu değeri ilgili serbestlik derecesine bölerler. Elde edilen değer normed chi-square (NC) değeri olarak adlandırılır.Ancak bu değerin yorumlanması için minimum kabul edilebilirlik düzeyini temsil edecek net bir kesim değeri yoktur.\nNC <= 2 ve ya 3 ve ya 5 (Kabul edilir.)\nAncak bu değerin yorumlanması için minimum kabul edilebilirlik düzeyini temsil edecek net bir kesim değeri yoktur.NC <= 2 ve ya 3 ve ya 5 (Kabul edilir.)Ayrıca NC örneklem büyüklüğünün etkisini tamamen düzeltmez. Ayrıca NC örneklem büyüklüğünün etkisini tamamen düzeltmez. ","code":"\nfitmeasures(yol_fit,fit.measures = c(\"chisq\" ,\"df\" , \"pvalue\"))##  chisq     df pvalue \n##   12.3    1.0    0.0"},{"path":"yol-analizi.html","id":"rmsea","chapter":"Bölüm 6 Yol Analizi","heading":"6.9.2 RMSEA","text":"Root Mean Square Error Approximation (RMSEA)\nserbestlik derecesinin bir fonksiyonu olarak uyumu\ndeğerlendiren bir indekstir:\\(RMSEA = \\sqrt{\\frac{\\hat{\\delta}}{df(n-1)}}\\)\\(\\delta\\) parametresi araştırmacının modelinin\nhatalı tanımlanma derecesini yansıtır.\nBurada \\(\\hat{\\delta} = max(\\chi^2 - df,0)\\) parantez içindeki iki ifadeden birinin maksimum değerini kapsar.RMSEA indeksi de kötülük uyum indeksidir.RMSEA indeksi de kötülük uyum indeksidir.RMSEA indeksinin daha yüksek değerleri daha kötü uyumu belirtir. RMSEA indeksinin daha yüksek değerleri daha kötü uyumu belirtir. RMSEA = 0 değeri en iyi uyumu belirtir. Ancak RMSEA = 0 değeri mükemmel bir uyumu ifade etmez.RMSEA = 0 değeri en iyi uyumu belirtir. Ancak RMSEA = 0 değeri mükemmel bir uyumu ifade etmez.RMSEA uyumu doğrudan serbestlik derecesinin bir\nfonksiyonu olarak ele alır; modelin tutumunu hesaba katar\n(ölçülen değişkenlerin sayısına karşılık kestirilen model\nparametrelerinin sayısı).RMSEA uyumu doğrudan serbestlik derecesinin bir\nfonksiyonu olarak ele alır; modelin tutumunu hesaba katar\n(ölçülen değişkenlerin sayısına karşılık kestirilen model\nparametrelerinin sayısı).RMSEA için önerilen kesme noktaları (Hu & Bentler,\n1999):\nRMSEA ≤ 0.05 iyi uyumu belirtir.\n0.05 < RMSEA < 0.08 kabul edilebilir uyumu belirtir.\nRMSEA ≥ 0.08 zayıf uyumu belirtir.\nRMSEA için önerilen kesme noktaları (Hu & Bentler,\n1999):RMSEA ≤ 0.05 iyi uyumu belirtir.RMSEA ≤ 0.05 iyi uyumu belirtir.0.05 < RMSEA < 0.08 kabul edilebilir uyumu belirtir.0.05 < RMSEA < 0.08 kabul edilebilir uyumu belirtir.RMSEA ≥ 0.08 zayıf uyumu belirtir.RMSEA ≥ 0.08 zayıf uyumu belirtir.RMSEA tarafından kestirilen evren parametresi \\(\\epsilon\\) için\n%90 güven aralığı genellikle YEM yazılımlarının\nçıktısında verilir.RMSEA tarafından kestirilen evren parametresi \\(\\epsilon\\) için\n%90 güven aralığı genellikle YEM yazılımlarının\nçıktısında verilir.\\(\\epsilon\\) için güven aralığı kestirilen merkezi olmayan \\(\\delta\\) parametresine\ndayanır ve RMSEA örneklem değeri etrafında simetrik olmayabilir.\\(\\epsilon\\) için güven aralığı kestirilen merkezi olmayan \\(\\delta\\) parametresine\ndayanır ve RMSEA örneklem değeri etrafında simetrik olmayabilir.Bu güven aralığı nokta kestirimi olarak RMSEA değeri ile ilişkili\nbelirsizlik derecesini yansıtır.Bu güven aralığı nokta kestirimi olarak RMSEA değeri ile ilişkili\nbelirsizlik derecesini yansıtır.Eğer \\(\\epsilon\\) için %90 güven aralığının alt sınırının değeri 0,05’ten\nküçükse, modelinin evrende tahmini yaklaşık uyuma sahip olduğu\nhipotezi \\(H_{0}:\\epsilon_{0} ≤ 0.05\\) reddedilmeyecektir.Eğer \\(\\epsilon\\) için %90 güven aralığının alt sınırının değeri 0,05’ten\nküçükse, modelinin evrende tahmini yaklaşık uyuma sahip olduğu\nhipotezi \\(H_{0}:\\epsilon_{0} ≤ 0.05\\) reddedilmeyecektir.Çıktıda kestirilen RMSEA değeri ve\nilgili %90 güven aralığı (90% C. .) verilir.Çıktıda kestirilen RMSEA değeri ve\nilgili %90 güven aralığı (90% C. .) verilir.Kestirilen RMSEA değeri 0.168’dir. 0.168 değeri 0.08 değerinden\nbüyük olduğundan RMSEA indeksi model için zayıf uyum belirtir.Kestirilen RMSEA değeri 0.168’dir. 0.168 değeri 0.08 değerinden\nbüyük olduğundan RMSEA indeksi model için zayıf uyum belirtir.%90 güven aralığının alt sınırı 0.05 değerinden büyük olduğundan\naraştırmacının modelinin evrende tahmini yaklaşık uyuma sahip\nolduğu hipotezi reddedilir.%90 güven aralığının alt sınırı 0.05 değerinden büyük olduğundan\naraştırmacının modelinin evrende tahmini yaklaşık uyuma sahip\nolduğu hipotezi reddedilir.","code":"\n  # summary(yol_fit, fit.measures = TRUE)\nfitMeasures(yol_fit, c(\"rmsea\",\"rmsea.ci.lower\",\n                       \"rmsea.ci.upper\",\"rmsea.pvalue\"))##          rmsea rmsea.ci.lower rmsea.ci.upper   rmsea.pvalue \n##          0.168          0.093          0.258          0.006"},{"path":"yol-analizi.html","id":"srmr","chapter":"Bölüm 6 Yol Analizi","heading":"6.9.3 SRMR","text":"Standardized Root Mean Square Residual (SRMR) Bu indeks RMR\nindeksinin hesaplandığı şekilde hesaplanır ancak standartlaştırılmış\nartıklar kullanılır.0.08’den küçük değerler uygun olarak düşünülür (Hu & Bentler, 1999).Kestirilen SRMR değeri 0.043’dir. 0.043 değeri 0.08 değerinden küçük\nolduğundan SRMR indeksi model için kabul edilebilir uyum belirtir.Root Mean Square Residual (RMR) Bu indeksi hesaplamak için \nbir artık öğenin karesi alınır, karelerin toplanmasıyla elde edilen\ntoplam artık sayısına bölünür ve bu ortalama kare artıkların kare kökü\nalınır.Sıfır değeri mükemmel bir uyum belirtir ancak sıfırdan büyük değerlerin yorumlanması zordur.","code":"\nfitMeasures(yol_fit, \"srmr\")##  srmr \n## 0.043"},{"path":"yol-analizi.html","id":"karşılaştırmalı-uyum-indeksleri","chapter":"Bölüm 6 Yol Analizi","heading":"6.9.4 Karşılaştırmalı Uyum İndeksleri","text":"(Comparative Fit Indices)Bir çok indeks araştırmacının modelinin veriye nasıl\nuyduğunu, modelin uyumunu daha sınırlandırılmış bir\nmodelle karşılaştırarak değerlendirir.\nAraştırmacının modeli ile karşılaştırılan model taban modeli\n(baseline model) olarak adlandırılır. Bu model tipik olarak bağımsız\nmodeldir (independence model) ve sıfır modeli (null model) olarak\nda adlandırılır.\nBir çok indeks araştırmacının modelinin veriye nasıl\nuyduğunu, modelin uyumunu daha sınırlandırılmış bir\nmodelle karşılaştırarak değerlendirir.Araştırmacının modeli ile karşılaştırılan model taban modeli\n(baseline model) olarak adlandırılır. Bu model tipik olarak bağımsız\nmodeldir (independence model) ve sıfır modeli (null model) olarak\nda adlandırılır.Sıfır yol modeli gözlenen değişkenler\narasındaki evren kovaryanslarının (dışsal gözlenen\ndeğişkenler arasındaki kovaryanslar ve bütün gözlenen\ndeğişkenlerin varyansları hariç) sıfır olduğunu varsayar.Sıfır yol modeli gözlenen değişkenler\narasındaki evren kovaryanslarının (dışsal gözlenen\ndeğişkenler arasındaki kovaryanslar ve bütün gözlenen\ndeğişkenlerin varyansları hariç) sıfır olduğunu varsayar.Sıfır modeli değişkenlerin ilişkili olmadığını varsaydığından\ngenellikle araştırmacının modelinden daha yüksek ki-kare\ndeğerine sahiptir.\nBu nedenle karşılaştırmalı uyum indeksleri artımlı uyum indeksleri\n(incremental fit indices) olarak da bilinir: daha sınırlandırılmış\nmodel (örneğin, sıfır modeli) uyumundan daha esnek model\n(örneğin, araştırmacının modeli) uyumuna artırım.\nSıfır modeli değişkenlerin ilişkili olmadığını varsaydığından\ngenellikle araştırmacının modelinden daha yüksek ki-kare\ndeğerine sahiptir.Bu nedenle karşılaştırmalı uyum indeksleri artımlı uyum indeksleri\n(incremental fit indices) olarak da bilinir: daha sınırlandırılmış\nmodel (örneğin, sıfır modeli) uyumundan daha esnek model\n(örneğin, araştırmacının modeli) uyumuna artırım.Karşılaştırmalı uyum indekslerinden YEM analizlerinde sık\nkullanılan iki tanesi CFI ve NNFI (TLI) indeksleridir. Ancak\niki indeks de örneklem dayanaklı indekslerdir.Karşılaştırmalı uyum indekslerinden YEM analizlerinde sık\nkullanılan iki tanesi CFI ve NNFI (TLI) indeksleridir. Ancak\niki indeks de örneklem dayanaklı indekslerdir.CFI indeksi Bentler (1990) tarafından geliştirilmiştir ve\naşağıdaki şekilde hesaplanır:\n\\(CFI = \\frac{\\hat{\\delta_{null} - \\delta_{researcher}}}{\\delta_{null}}\\)CFI indeksi Bentler (1990) tarafından geliştirilmiştir ve\naşağıdaki şekilde hesaplanır:\n\\(CFI = \\frac{\\hat{\\delta_{null} - \\delta_{researcher}}}{\\delta_{null}}\\)Araştırmacının modeli sıfır modelinden daha iyi uyum\nsağlarsa, araştırmacının modelinin ki-kare değeri sıfır\nmodelinin ki-kare değerinden daha küçük olacaktır.Araştırmacının modeli sıfır modelinden daha iyi uyum\nsağlarsa, araştırmacının modelinin ki-kare değeri sıfır\nmodelinin ki-kare değerinden daha küçük olacaktır.İki model arasındaki fark arttıkça, CFI değeri 1’e daha çok\nyaklaşacaktır.\nCFI = 0 değeri araştırmacının modelinin sıfır modeline göre\ngelişmediğini belirtir.\nCFI değerinin 0.90 veya 0.95’ten daha büyük olması kabul edilebilir\nuyum için önerilir (Hu & Bentler, 1999).\nCFI = 1 değeri mükemmel uyumu belirtmez.\nİki model arasındaki fark arttıkça, CFI değeri 1’e daha çok\nyaklaşacaktır.CFI = 0 değeri araştırmacının modelinin sıfır modeline göre\ngelişmediğini belirtir.CFI değerinin 0.90 veya 0.95’ten daha büyük olması kabul edilebilir\nuyum için önerilir (Hu & Bentler, 1999).CFI = 1 değeri mükemmel uyumu belirtmez.Non-Normed Fit Index (NNFI veya Tucker-Lewis Index,\nTLI) sıfır modeli ve araştırmacının modelinin serbestlik\nderecesini hesaba katarak negatif yanlılığı düzeltmeye\nçalışır:Non-Normed Fit Index (NNFI veya Tucker-Lewis Index,\nTLI) sıfır modeli ve araştırmacının modelinin serbestlik\nderecesini hesaba katarak negatif yanlılığı düzeltmeye\nçalışır:\\[NNFI= \\frac{\\frac{T_{null}}{df_{null}} - \\frac{T_{researcher}}{df_{researcher}}}{\\frac{T_{null}}{df_{null}}-1}\\]NNFI değerleri 0 ile 1 aralığında değer alır ancak bu\naralığın dışında bir değer de alabilir.\nNNFI değerinin 0.90 veya 0,95’ten daha büyük olması kabul\nedilebilir uyum için önerilir (Hu & Bentler, 1999).\nNNFI değerleri 0 ile 1 aralığında değer alır ancak bu\naralığın dışında bir değer de alabilir.NNFI değerinin 0.90 veya 0,95’ten daha büyük olması kabul\nedilebilir uyum için önerilir (Hu & Bentler, 1999).NNFI örneklemlerin aynı evrenden alındığı küçük ve orta\nbüyüklükteki verilerin kullanıldığı çalışmalarda kararlı\ndeğildir.NNFI örneklemlerin aynı evrenden alındığı küçük ve orta\nbüyüklükteki verilerin kullanıldığı çalışmalarda kararlı\ndeğildir.sıfır modeli için ki-kare testine ait değerleri ve CFI ve TLI değerlerini verir:sıfır modeli için ki-kare testine ait değerleri ve CFI ve TLI değerlerini verir:Kestirilen CFI değeri 0.949’dur. 0.949 değeri 0.90 değerinden\nbüyük olduğundan CFI indeksi model için iyi uyum belirtir.Kestirilen CFI değeri 0.949’dur. 0.949 değeri 0.90 değerinden\nbüyük olduğundan CFI indeksi model için iyi uyum belirtir.Kestirilen TLI değeri 0.485’dur. 0.485 değeri 0.90 değerinden küçük\nolduğundan TLI indeksi model için zayıf uyum belirtirKestirilen TLI değeri 0.485’dur. 0.485 değeri 0.90 değerinden küçük\nolduğundan TLI indeksi model için zayıf uyum belirtir","code":"\nfitmeasures(yol_fit,fit.measures = c(\"cfi\",\"tli\",\"nnfi\"))##   cfi   tli  nnfi \n## 0.948 0.485 0.485"},{"path":"yol-analizi.html","id":"uyum-indekslerini-raporlarken-öneriler","chapter":"Bölüm 6 Yol Analizi","heading":"6.10 Uyum İndekslerini Raporlarken Öneriler","text":"Tek bir indeks model uyumunun sadece belli bir yönünü\nyansıtır. Araştırmacılar aşağıdakilerin rapor edilmesini\nönerir:Model ki-kare değeri: anlamlı olmayan sonuçNot: Bu kesme değerlerin kullanılmasıyla ilgili çok sayıda\ntartışma vardır.Önerilen uyum indeksleri göz önüne alınınca model-veri\nuyumu ile ilgili ne söylenebilir?","code":"\nfitmeasures(yol_fit,fit.measures = c(\"chisq\" ,\"df\" ,\"pvalue\",\n                                     \"cfi\",\"tli\",\"rmsea\",    \n                                     \"rmsea.ci.lower\",\"rmsea.ci.upper\"\n                                     ,\"srmr\"))##          chisq             df         pvalue            cfi            tli \n##         12.307          1.000          0.000          0.948          0.485 \n##          rmsea rmsea.ci.lower rmsea.ci.upper           srmr \n##          0.168          0.093          0.258          0.043"},{"path":"yol-analizi.html","id":"bireysel-istatistiksel-testler","chapter":"Bölüm 6 Yol Analizi","heading":"6.11 Bireysel İstatistiksel testler:","text":"t-değeriBireysel istatistiksel test belli parametre kestirimlerine\ndayalı hesaplanır. Hatalı tanımlamanın\ndeğerlendirilmesinde kullanışlıdır.t-değeri = parametre kestirimi / standart hataNormal olarak dağılır.Normal olarak dağılır.z-istatistiği gibi kullanılır.z-istatistiği gibi kullanılır.Parametrelerin beklenen yönde olup olmadığını ve istatistiksel\nolarak sıfırdan farklı olup olmadığını değerlendirir.Parametrelerin beklenen yönde olup olmadığını ve istatistiksel\nolarak sıfırdan farklı olup olmadığını değerlendirir.Anlamlı olmayan parametreler 0’sabitlenebilir ancak test n ile\nilişkilidir.Anlamlı olmayan parametreler 0’sabitlenebilir ancak test n ile\nilişkilidir.Ancak bir parametrenin sabitlenmesi diğer bütün kestirimleri\ndeğiştirecektir. Bu da hatalı tanımlamadan dolayı hatalara sebep\nolabilirAncak bir parametrenin sabitlenmesi diğer bütün kestirimleri\ndeğiştirecektir. Bu da hatalı tanımlamadan dolayı hatalara sebep\nolabilirStandartlaştırılmış Artıkİdeal olarak artık değerleri küçük ve tek biçimli olmalıdır.Artık kovaryans matrisini yorumlamak standartlaştırılmış\nartık kovaryans matrisinden daha zordur.Standartlaştırılmış artık:\nz-puanları gibidir.\nHangi değerin büyük olduğunu belirlemek kolaydır (0.05 alfa\ndüzeyinde 1.96 istatistiksel anlamlılık)\nKöşegen dışındaki standartlaştırılmış artıkların mutlak değerlerinin\nortalaması tipik bir artığı temsil eden bir indeks sağlar.\nz-puanları gibidir.Hangi değerin büyük olduğunu belirlemek kolaydır (0.05 alfa\ndüzeyinde 1.96 istatistiksel anlamlılık)Köşegen dışındaki standartlaştırılmış artıkların mutlak değerlerinin\nortalaması tipik bir artığı temsil eden bir indeks sağlar.Standarlaştırılmış hata kovaryans matrisinde yer alan diyagonal dışındaki bir değerin mutlak değerinin 1.96’dan küçük olması beklenir.","code":"\n# lavResiduals(yol_fit)\n# resid(yol_fit)\nresid(yol_fit, type='normalized')## $type\n## [1] \"normalized\"\n## \n## $cov\n##               stres hastlk   form egzrsz dynkll\n## stres         0.002                            \n## hastalik      0.718  0.392                     \n## form         -2.950 -1.031  0.006              \n## egzersiz     -0.021 -0.011  0.010  0.000       \n## dayaniklilik -0.005 -0.005  0.025  0.067  0.000"},{"path":"yol-analizi.html","id":"modifikasyon-indeksleri","chapter":"Bölüm 6 Yol Analizi","heading":"6.12 Modifikasyon İndeksleri","text":"modindices fonksiyonu ile modifikasyon indeksleri istenebilir.modindices fonksiyonu ile modifikasyon indeksleri istenebilir.mi sütunu yapılacak modifikasyon sonucunda ki-karedeki düşüsü göstermektedir.mi sütunu yapılacak modifikasyon sonucunda ki-karedeki düşüsü göstermektedir.Bu tablo dört parametreden herhangi birinin (aynı anda, eş zamanlı\nDEĞİL) model ki-kare değerini 12.1 değerinde düşüreceğini\nönermektedir.Bu tablo dört parametreden herhangi birinin (aynı anda, eş zamanlı\nDEĞİL) model ki-kare değerini 12.1 değerinde düşüreceğini\nönermektedir.Artık kovaryans matrisinden gelen kanıt da\nbirleştirildiğinde, modele form değişkeninin stres\ndeğişkenine doğrudan etkisini gösteren bir parametre\neklenebilirArtık kovaryans matrisinden gelen kanıt da\nbirleştirildiğinde, modele form değişkeninin stres\ndeğişkenine doğrudan etkisini gösteren bir parametre\neklenebilirBu model ancak tanımlanan modeldir (sd = 0), bu nedenle\nveriye mükemmel uyum sağlayacaktırBu model ancak tanımlanan modeldir (sd = 0), bu nedenle\nveriye mükemmel uyum sağlayacaktır","code":"\nmodindices(yol_fit, sort = TRUE)\n## modindices(yol_fit, sort = TRUE, maximum.number = 5)"},{"path":"yol-analizi.html","id":"modelin-yeniden-tanımlanması","chapter":"Bölüm 6 Yol Analizi","heading":"6.13 Modelin Yeniden Tanımlanması","text":"Revised Model 1stres ~ form\nyolu eklenir.Yeni tanımlanan model için verilen uyum indeksleri\nbeklendiği gibidir.Yeni tanımlanan model için verilen uyum indeksleri\nbeklendiği gibidir.Kikare = 0 ve sd = 0 olduğunda, p değerini 0,0000 olarak\nyazdırır. Ancak bu değer ki kare testinin reddedildiği anlamına gelmez.Kikare = 0 ve sd = 0 olduğunda, p değerini 0,0000 olarak\nyazdırır. Ancak bu değer ki kare testinin reddedildiği anlamına gelmez.good fit vs parsinomy parsinomy principle","code":"\nyol_model_v1 <- \n'stres     ~ egzersiz + dayaniklilik\nhastalik  ~ egzersiz + dayaniklilik + form + stres\nform      ~ egzersiz + dayaniklilik\nstres     ~ form\negzersiz ~~ dayaniklilik' \nyol_fit_v1 <- sem(yol_model_v1, veri)\nsemPaths(yol_fit_v1,rotation=2, curvePivot = TRUE,\nsizeMan = 12, sizeInt = 1, \nsizeLat = 4,\nedge.label.cex = 1.8,\npastel=TRUE,\nnCharNodes = 0, nCharEdges = 0)\nfitmeasures(yol_fit_v1,fit.measures=c(\"chisq\",\"p\",\"df\"))## chisq    df \n##     0     0\np_pa <- \nsemPaths(yol_fit_v1, whatLabels = \"est\",\nsizeMan = 10,\nedge.label.cex = 1.15,\nstyle = \"ram\",layout = \"spring\" ,\nnCharNodes = 0, nCharEdges = 0)\np_pa_2 <- semptools::mark_sig(p_pa, yol_fit_v1)\nplot(p_pa_2)"},{"path":"yol-analizi.html","id":"modelin-yeniden-tanımlanması-1","chapter":"Bölüm 6 Yol Analizi","heading":"6.14 Modelin Yeniden Tanımlanması","text":"Revised Model 2anlamlı olmayan yol katsayıları kaldırıldıranlamlı olmayan yol katsayıları kaldırıldırsd = 3 için ki-karenin 0.05 alfa düzeyindeki kritik değeri 7.82’dir.\n1.354 değeri 7.82 değerinden küçük olduğundan gözlenen ki-kare\ndeğeri (1,354) 0.05 alfa düzeyinde istatistiksel olarak anlamlı\ndeğildir.sd = 3 için ki-karenin 0.05 alfa düzeyindeki kritik değeri 7.82’dir.\n1.354 değeri 7.82 değerinden küçük olduğundan gözlenen ki-kare\ndeğeri (1,354) 0.05 alfa düzeyinde istatistiksel olarak anlamlı\ndeğildir.RMSEA, CFI ve SRMR indekslerinin değerleri istenilen değerdedirRMSEA, CFI ve SRMR indekslerinin değerleri istenilen değerdedir","code":"\nyol_model_v1 <- \n'stres     ~ egzersiz + dayaniklilik\nhastalik  ~ egzersiz + dayaniklilik + form + stres\nform      ~ egzersiz + dayaniklilik\nstres     ~ form\negzersiz ~~ dayaniklilik' \n\n\nyol_model_v2 <- \n'stres     ~  dayaniklilik\nhastalik  ~ form + stres\nform      ~ egzersiz + dayaniklilik\nstres     ~ form\negzersiz ~~ dayaniklilik' \nyol_fit_v2 <- sem(yol_model_v2, veri)\nfitmeasures(yol_fit_v2,c(\"rmsea\",\"cfi\",\"srmr\"))## rmsea   cfi  srmr \n## 0.000 1.000 0.011\nm <- matrix(c(NA, NA, \"form\",  NA,   NA,\n              \"egzersiz\", NA, NA,  NA,   NA,\n                NA, NA, NA,  NA, \"hastalik\",\n              \"dayaniklilik\",    NA, NA,  NA,   NA,\n                NA, NA, \"stres\",  NA, NA\n              \n              ), byrow = TRUE, 5, 5)\n\np_pa <- semPaths(yol_fit_v2, whatLabels = \"est\",\n           sizeMan = 10,\n           edge.label.cex = 1.15,\n           style = \"ram\",\n           nCharNodes = 0, nCharEdges = 0,\n           layout=m)\np_pa_2 <- semptools::mark_sig(p_pa, yol_fit_v2)\nplot(p_pa_2)\nfitmeasures(yol_fit_v2,fit.measures = c(\"chisq\" ,\"df\" , \"pvalue\",\n                                        \"cfi\",\"tli\",\"rmsea\",\n                                        \"rmsea.ci.lower\",   \"rmsea.ci.upper\"\n                                        ,\"srmr\"))##          chisq             df         pvalue            cfi            tli \n##          1.354          3.000          0.716          1.000          1.025 \n##          rmsea rmsea.ci.lower rmsea.ci.upper           srmr \n##          0.000          0.000          0.061          0.011"},{"path":"yol-analizi.html","id":"ki-kare-fark-testi","chapter":"Bölüm 6 Yol Analizi","heading":"6.14.1 Ki-Kare Fark Testi","text":"Hem revised model 1 hem de revised model 2 veriye iyi\nuyum sağlamaktadır.\nBu durumda hangi model seçilmelidir?\nMükemmel uyum sağlayan ancak daha karmaşık model mi?\nİyi uyum sağlayan ancak daha basit model mi?\n\nHem revised model 1 hem de revised model 2 veriye iyi\nuyum sağlamaktadır.Bu durumda hangi model seçilmelidir?\nMükemmel uyum sağlayan ancak daha karmaşık model mi?\nİyi uyum sağlayan ancak daha basit model mi?\nBu durumda hangi model seçilmelidir?Mükemmel uyum sağlayan ancak daha karmaşık model mi?Mükemmel uyum sağlayan ancak daha karmaşık model mi?İyi uyum sağlayan ancak daha basit model mi?İyi uyum sağlayan ancak daha basit model mi?Ki-kare fark testi hiyerarşik olarak kümelenmiş iki modelin\nkarşılaştırılmasında oldukça kullanışlıdır.\nEğer modellerden birisi diğerinin alt kümesiyse iki model\nkümelenmiştir (daha basit model daha karmaşık modelin içinde\nkümelenmiştir).\nBu durumda revised model 2 (daha basit model) revised model 1\n(daha karmaşık model) içinde kümelenmiştir.\n\nKi-kare fark testi hiyerarşik olarak kümelenmiş iki modelin\nkarşılaştırılmasında oldukça kullanışlıdır.Eğer modellerden birisi diğerinin alt kümesiyse iki model\nkümelenmiştir (daha basit model daha karmaşık modelin içinde\nkümelenmiştir).\nBu durumda revised model 2 (daha basit model) revised model 1\n(daha karmaşık model) içinde kümelenmiştir.\nEğer modellerden birisi diğerinin alt kümesiyse iki model\nkümelenmiştir (daha basit model daha karmaşık modelin içinde\nkümelenmiştir).Bu durumda revised model 2 (daha basit model) revised model 1\n(daha karmaşık model) içinde kümelenmiştir.Ki-kare fark testi modellerin bağıl uyumlarını\ndeğerlendirmek için kullanılabilir.Ki-kare fark testi modellerin bağıl uyumlarını\ndeğerlendirmek için kullanılabilir.İki model de veriye iyi uyum sağladığında, ki-kare\ndeğerleri arasındaki fark serbestlik derecesi iki model\narasındaki parametre sayısındaki farka eşit olan ki-kare\ndağılımı gösterir:\n\\(\\chi^2_{dif} = \\chi^2_{simple} -\\chi^2_{complex}\\)\n\\(df_{dif} = df_{simple} - df_{complex}\\)\nİki model de veriye iyi uyum sağladığında, ki-kare\ndeğerleri arasındaki fark serbestlik derecesi iki model\narasındaki parametre sayısındaki farka eşit olan ki-kare\ndağılımı gösterir:\\(\\chi^2_{dif} = \\chi^2_{simple} -\\chi^2_{complex}\\)\\(\\chi^2_{dif} = \\chi^2_{simple} -\\chi^2_{complex}\\)\\(df_{dif} = df_{simple} - df_{complex}\\)\\(df_{dif} = df_{simple} - df_{complex}\\)Anlamlı olmayan ki-kare farkı daha basit modelin daha\nkarmaşık modelden istatistiksel olarak veriye daha kötü\nuymadığını önerir.Anlamlı olmayan ki-kare farkı daha basit modelin daha\nkarmaşık modelden istatistiksel olarak veriye daha kötü\nuymadığını önerir.Bu nedenle, daha basit model daha tutumlu olduğundan dolayı\nseçilmelidir. Aksi halde karmaşık model seçilmelidir.Bu nedenle, daha basit model daha tutumlu olduğundan dolayı\nseçilmelidir. Aksi halde karmaşık model seçilmelidir.Örnekte revised model 2 (12 model parametresine sahip\nolup sd = 3) revised model 1’den (15 model parametresine\nsahip olup sd = 0) daha basittir.\n\\(\\chi^2_{dif} = \\chi^2_{simple} -\\chi^2_{complex}\\)\n\\(df_{dif} = df_{simple} - df_{complex}\\)\nÖrnekte revised model 2 (12 model parametresine sahip\nolup sd = 3) revised model 1’den (15 model parametresine\nsahip olup sd = 0) daha basittir.\\(\\chi^2_{dif} = \\chi^2_{simple} -\\chi^2_{complex}\\)\\(\\chi^2_{dif} = \\chi^2_{simple} -\\chi^2_{complex}\\)\\(df_{dif} = df_{simple} - df_{complex}\\)\\(df_{dif} = df_{simple} - df_{complex}\\)1.354 ki-kare değeri sd = 3 olduğunda, 0,05 alfa\ndüzeyinde (kritik ki-kare değeri = 7.82) istatistiksel olarak\nanlamlı değildir. \nBu nedenle revised model 2 (daha basit\nolan) revised model 1’e (daha karmaşık olan) tercih edilir\nşeklinde sonuca varılabilir\n1.354 ki-kare değeri sd = 3 olduğunda, 0,05 alfa\ndüzeyinde (kritik ki-kare değeri = 7.82) istatistiksel olarak\nanlamlı değildir. Bu nedenle revised model 2 (daha basit\nolan) revised model 1’e (daha karmaşık olan) tercih edilir\nşeklinde sonuca varılabilir","code":""},{"path":"yol-analizi.html","id":"aic-ve-bic","chapter":"Bölüm 6 Yol Analizi","heading":"6.14.2 AIC ve BIC","text":"Akaike Information Criterion (AIC) ve Bayesian\nInformation Criterion (BIC) evren dayanaklı yordayıcı\nuyum indeksleri olarak bilinir.Akaike Information Criterion (AIC) ve Bayesian\nInformation Criterion (BIC) evren dayanaklı yordayıcı\nuyum indeksleri olarak bilinir.Farklı YEM yazılımları AIC ve BIC değerlerini farklı şekilde\nhesaplayabilir.\n\\(AIC = - 2LogL + 2r\\) , r modeldeki parametre sayısı\n\\(BIC = - 2LogL + r ln n\\), n örneklem büyüklüğü\n\\(adjusted BIC = - 2LogL + r ln n*\\) , n* = (n+2) /24\nFarklı YEM yazılımları AIC ve BIC değerlerini farklı şekilde\nhesaplayabilir.\\(AIC = - 2LogL + 2r\\) , r modeldeki parametre sayısı\\(BIC = - 2LogL + r ln n\\), n örneklem büyüklüğü\\(adjusted BIC = - 2LogL + r ln n*\\) , n* = (n+2) /24AIC ve BIC değerleri çoğunlukla aynı veriden kestirilen\nhiyerarşik olmayan modellerin arasından seçim yapmak\niçin kullanılır. Bağıl olarak daha küçük değerler uygundurAIC ve BIC değerleri çoğunlukla aynı veriden kestirilen\nhiyerarşik olmayan modellerin arasından seçim yapmak\niçin kullanılır. Bağıl olarak daha küçük değerler uygundurmodel1model2İki model kümelenmiş modeller olduğundan, iki\nmodel arasında AIC ve BIC değerlerinin\nkarşılaştırılmasına gerek\nyokturİki model kümelenmiş modeller olduğundan, iki\nmodel arasında AIC ve BIC değerlerinin\nkarşılaştırılmasına gerek\nyokturEğer model-veri uyumu zayıfsa, ilk olarak varsayılan\nmodel veriye uymaz.Eğer model-veri uyumu zayıfsa, ilk olarak varsayılan\nmodel veriye uymaz.Eğer model-veri uyumu iyiyse, model veri tarafından\ndesteklenir. Alternatif modelleri araştırmak veya daha\ntutumlu (parsimonious) bir model aramak için ilave\nanalizler yürütülebilir. Eğer model-veri uyumu iyiyse, model veri tarafından\ndesteklenir. Alternatif modelleri araştırmak veya daha\ntutumlu (parsimonious) bir model aramak için ilave\nanalizler yürütülebilir. Mükemmel veya iyi bir model-veri uyumu mutlaka modelin iyi\nolduğunu önermez. İyi bir model en basit şekilde olan (tutumluluk\nilkesi), ama hala veriye iyi uyan modeldir.Mükemmel veya iyi bir model-veri uyumu mutlaka modelin iyi\nolduğunu önermez. İyi bir model en basit şekilde olan (tutumluluk\nilkesi), ama hala veriye iyi uyan modeldir.İyi Uyuma karşı Model Tutumluluğu","code":"\nfitmeasures(yol_fit_v1,fit.measures = c(\"AIC\",\"BIC\"))##   aic   bic \n## 21423 21483\nfitmeasures(yol_fit_v2,fit.measures = c(\"AIC\",\"BIC\"))##   aic   bic \n## 21418 21466"},{"path":"yol-analizi.html","id":"modeli-tanımlama","chapter":"Bölüm 6 Yol Analizi","heading":"6.14.3 Modeli tanımlama","text":"MODEL bölümü modelin belirlenmesiYol analizinde, bir içsel (endogenous) değişkenin bir\nveya daha fazla değişken tarafından yordanması \\(~\\)\nifadesi ile belirtilir.Örneğin,\nform~egzersiz + dayaniklilik\nform~egzersiz + dayaniklilikifadesinin anlamı form’ın egzersiz + dayaniklilik tan\nyordandığıdır.ham veri kullanıldığı zaman, default\nmodeli değişkenler için ortalamaların/kesişimlerin\nkestirildiği ortalama yapıları içerecektir.ham veri kullanıldığı zaman, default\nmodeli değişkenler için ortalamaların/kesişimlerin\nkestirildiği ortalama yapıları içerecektir.Yol analizi modeli için kovaryans yapısına odaklanılır.\n“Means” ve “Intercepts” bölümü altındaki değerler göz\nardı edilir.Yol analizi modeli için kovaryans yapısına odaklanılır.\n“Means” ve “Intercepts” bölümü altındaki değerler göz\nardı edilir.Ortalamalar/kesişimler çıkarılınca, kestirilen\nparametre sayısı 14 olmalıdır.Ortalamalar/kesişimler çıkarılınca, kestirilen\nparametre sayısı 14 olmalıdır.bir kestirimin yorumu çoklu regresyondaki yorumlara\nbenzerdir.bir kestirimin yorumu çoklu regresyondaki yorumlara\nbenzerdir.Örneğin, form ~ egzersiz kestirimi 0.206’dır. Bu değer,\negzersiz puanındaki bir birimlik\nartışın yordanan form puanını 0.206 birimlik\nartıracağını önerir.Örneğin, form ~ egzersiz kestirimi 0.206’dır. Bu değer,\negzersiz puanındaki bir birimlik\nartışın yordanan form puanını 0.206 birimlik\nartıracağını önerir.Bu kestirimin standart hatası 0.025’tir. Kestirimin standart hatasına\nbölünmesiyle t istatistiği elde edilir:\n0.206 / 0.025 = 8.12Bu kestirimin standart hatası 0.025’tir. Kestirimin standart hatasına\nbölünmesiyle t istatistiği elde edilir:\n0.206 / 0.025 = 8.12İki yönlü t testi 0.206 değerinin\nanlamlı olarak 0’dan farklı\nolduğunu önerir.İki yönlü t testi 0.206 değerinin\nanlamlı olarak 0’dan farklı\nolduğunu önerir.Örneğin, form ~ egzersiz standartlaştırılmış kestirimi\n0.371’dir. Bu değer, egzersiz\npuanındaki bir standart sapmalık artışın yordanan\nform puanını 0.71 standart\nsapma artıracağını önerir.Örneğin, form ~ egzersiz standartlaştırılmış kestirimi\n0.371’dir. Bu değer, egzersiz\npuanındaki bir standart sapmalık artışın yordanan\nform puanını 0.71 standart\nsapma artıracağını önerir.Bu kestirimin standart hatası 0.043’tür.Bu kestirimin standart hatası 0.043’tür.Kestirimin standart hatasına bölünmesiyle t-istatistiği elde\nedilir:\n0.371 / 0.043 = 8.72Kestirimin standart hatasına bölünmesiyle t-istatistiği elde\nedilir:\n0.371 / 0.043 = 8.72İki-yönlü t-testi 0.371 değerinin\nanlamlı olarak 0’dan farklı\nolduğunu önerir.İki-yönlü t-testi 0.371 değerinin\nanlamlı olarak 0’dan farklı\nolduğunu önerir.egzersiz ~~ dayaniklilik değeri 9.105’tir. Bu değer egzersiz ve\ndayaniklilik değişkenleri arasındaki kovaryans\ntahminidir.egzersiz ~~ dayaniklilik değeri 9.105’tir. Bu değer egzersiz ve\ndayaniklilik değişkenleri arasındaki kovaryans\ntahminidir.","code":"\nsummary(yol_fit)## lavaan 0.6.17 ended normally after 8 iterations\n## \n##   Estimator                                         ML\n##   Optimization method                           NLMINB\n##   Number of model parameters                        14\n## \n##   Number of observations                           400\n## \n## Model Test User Model:\n##                                                       \n##   Test statistic                                12.307\n##   Degrees of freedom                                 1\n##   P-value (Chi-square)                           0.000\n## \n## Parameter Estimates:\n## \n##   Standard errors                             Standard\n##   Information                                 Expected\n##   Information saturated (h1) model          Structured\n## \n## Regressions:\n##                    Estimate  Std.Err  z-value  P(>|z|)\n##   stres ~                                             \n##     egzersiz         -0.080    0.048   -1.678    0.093\n##     dayaniklilik     -0.556    0.086   -6.475    0.000\n##   hastalik ~                                          \n##     egzersiz          0.047    0.042    1.115    0.265\n##     dayaniklilik     -0.010    0.075   -0.138    0.891\n##     form             -0.408    0.076   -5.342    0.000\n##     stres             0.314    0.041    7.704    0.000\n##   form ~                                              \n##     egzersiz          0.206    0.025    8.118    0.000\n##     dayaniklilik      0.161    0.046    3.506    0.000\n## \n## Covariances:\n##                    Estimate  Std.Err  z-value  P(>|z|)\n##   egzersiz ~~                                         \n##     dayaniklilik      0.000  135.170    0.000    1.000\n## \n## Variances:\n##                    Estimate  Std.Err  z-value  P(>|z|)\n##    .stres          4419.143  312.481   14.142    0.000\n##    .hastalik       2937.014  207.678   14.142    0.000\n##    .form           1261.565   89.206   14.142    0.000\n##     egzersiz       4883.673  345.328   14.142    0.000\n##     dayaniklilik   1496.499  105.818   14.142    0.000\nstandardizedsolution(yol_fit)"},{"path":"yol-analizi.html","id":"standartlaştırılmış-artık","chapter":"Bölüm 6 Yol Analizi","heading":"6.15 Standartlaştırılmış Artık","text":"Standartlaştırılmamış artık varyans (unstandardized\nresidual variance), bir içsel değişkendeki yordayıcılar\ntarafından açıklanmayan varyans miktarını söyler.Standartlaştırılmamış artık varyans (unstandardized\nresidual variance), bir içsel değişkendeki yordayıcılar\ntarafından açıklanmayan varyans miktarını söyler.Örneğin, form değişkenindeki açıklanmayan\nvaryans yaklaşık 1261.54’tür.Örneğin, form değişkenindeki açıklanmayan\nvaryans yaklaşık 1261.54’tür.Bu değer, form değişkeninin varyansı(1508.75) ile karşılaştırılarak\naçıklanmayan varyans yüzdesi hesaplanabilirBu değer, form değişkeninin varyansı(1508.75) ile karşılaştırılarak\naçıklanmayan varyans yüzdesi hesaplanabilirÖrneğin, form değişkenindeki açıklanmayan\nvaryans oranı yaklaşık 0.836’dır. form değişkeni\niçin toplam varyansın yaklaşık\n%83.6’sı açıklanmamıştır.Örneğin, form değişkenindeki açıklanmayan\nvaryans oranı yaklaşık 0.836’dır. form değişkeni\niçin toplam varyansın yaklaşık\n%83.6’sı açıklanmamıştır.1261.4 / 1508.75 = 0.8361261.4 / 1508.75 = 0.836","code":""},{"path":"yol-analizi.html","id":"kestirim","chapter":"Bölüm 6 Yol Analizi","heading":"6.16 Kestirim","text":"Standartlaştırılmamış sonuçlarÇıktı bir içsel değişken için \\(R^2\\) değerinin kestirimini\nverir. \\(R^2\\) değerinin anlamı çoklu regresyondakinin\nanlamına benzerdir: bağımlı değişkendeki varyansın\nyordayıcılar tarafından açıklanan yüzdesi.Çıktı bir içsel değişken için \\(R^2\\) değerinin kestirimini\nverir. \\(R^2\\) değerinin anlamı çoklu regresyondakinin\nanlamına benzerdir: bağımlı değişkendeki varyansın\nyordayıcılar tarafından açıklanan yüzdesi.Örneğin, form için \\(R^2\\) değeri 0.164 olarak tahmin edilmiştir. Bu\ndeğer, form değişkenindeki varyansın yaklaşık %16’sının\nyordayıcılar tarafından açıklandığını önerir.Örneğin, form için \\(R^2\\) değeri 0.164 olarak tahmin edilmiştir. Bu\ndeğer, form değişkenindeki varyansın yaklaşık %16’sının\nyordayıcılar tarafından açıklandığını önerir.: bir içsel değişken için \\(R^2\\) değeri ve standartlaştırılmış\nartık varyansının toplamı “1”e eşit olmalıdır:\n0.164 + 0.836 = 1R-Square:               Estimatestres 0.101hastalik 0.205form 0.164","code":"\nparameterEstimates(yol_fit,standardized = TRUE)\nout <- summary(yol_fit, rsquare=TRUE)\nout$PE[15:17,]               Estimate"},{"path":"yol-analizi.html","id":"model-sonuçlarının-rapor-edilmesi","chapter":"Bölüm 6 Yol Analizi","heading":"6.17 Model Sonuçlarının Rapor Edilmesi","text":"Tablo 6.1: Factor Loadings\nTablo 6.2: Model Comparison\n","code":"\nlibrary(knitr)\nstandardizedsolution(yol_fit) %>% \n  filter(op == \"~\") %>% \n  select('Bağımlı Değişkenler'=lhs, Gosterge=rhs,\n         B=est.std, SE=se, Z=z, 'p-value'=pvalue) %>% \n  knitr::kable(digits = 3, booktabs=TRUE, format=\"markdown\",\n               caption=\"Factor Loadings\")\nlibrary(semoutput)\nsem_anova(yol_fit_v2,yol_fit_v1)"},{"path":"yol-analizi.html","id":"model-karşılaştırmalarının-rapor-edilmesi","chapter":"Bölüm 6 Yol Analizi","heading":"6.18 Model Karşılaştırmalarının Rapor Edilmesi","text":"","code":"\nsem_modelcomp(yol_fit_v2,yol_fit_v1)"},{"path":"yol-analizi.html","id":"doğrudan-dolaylı-ve-toplam-etkiler","chapter":"Bölüm 6 Yol Analizi","heading":"6.19 Doğrudan, Dolaylı ve Toplam Etkiler","text":"Toplam etki, bir değişken bir birim değiştiğinde diğer bir\ndeğişkenin ne kadar değişeceğini belirtir.Toplam etki, bir değişken bir birim değiştiğinde diğer bir\ndeğişkenin ne kadar değişeceğini belirtir.Toplam etkinin iki bileşeni olabilir: doğrudan etki ve bazı\naraya giren değişkenler üzerinden dolaylı etkiler\nBir değişkenin diğer bir değişken üzerindeki doğrudan etkisi yol\nmodelindeki ağırlığıyla belirtilir.\nDolaylı etkiler doğrudan etkilerin çarpımları olarak istatistiksel\nolarak kestirilir.\nDoğrudan ve dolaylı etkiler ya standartlaştırılmamış ya da\nstandartlaştırılmış çözümlerin sonuçlarına dayanarak\nhesaplanabilir.\nAncak, eğer değişkenlerin birbirlerine göre etkileri\nkarşılaştırılacaksa standartlaştırılmış çözümler kullanılmalıdır.\n\nToplam etkinin iki bileşeni olabilir: doğrudan etki ve bazı\naraya giren değişkenler üzerinden dolaylı etkilerBir değişkenin diğer bir değişken üzerindeki doğrudan etkisi yol\nmodelindeki ağırlığıyla belirtilir.Bir değişkenin diğer bir değişken üzerindeki doğrudan etkisi yol\nmodelindeki ağırlığıyla belirtilir.Dolaylı etkiler doğrudan etkilerin çarpımları olarak istatistiksel\nolarak kestirilir.Dolaylı etkiler doğrudan etkilerin çarpımları olarak istatistiksel\nolarak kestirilir.Doğrudan ve dolaylı etkiler ya standartlaştırılmamış ya da\nstandartlaştırılmış çözümlerin sonuçlarına dayanarak\nhesaplanabilir.\nAncak, eğer değişkenlerin birbirlerine göre etkileri\nkarşılaştırılacaksa standartlaştırılmış çözümler kullanılmalıdır.\nDoğrudan ve dolaylı etkiler ya standartlaştırılmamış ya da\nstandartlaştırılmış çözümlerin sonuçlarına dayanarak\nhesaplanabilir.Ancak, eğer değişkenlerin birbirlerine göre etkileri\nkarşılaştırılacaksa standartlaştırılmış çözümler kullanılmalıdır.Egzersiz, hastalık üzerinde doğrudan etkiye sahiptir; bu doğrudan\netkinin standartlaştırılmış değeri 0.054’tür.Egzersiz, hastalık üzerinde doğrudan etkiye sahiptir; bu doğrudan\netkinin standartlaştırılmış değeri 0.054’tür.Egzersiz, hastalık üzerinde iki tane de dolaylı etkiye sahiptir; biri\nform üzerinden, diğeri ise stress üzerindendir. Dolaylı etki, ilgili\nstandartlaştırılmış yol katsayılarının çarpılması sonucu elde edilir:\nEgzersiz → Form → Hastalık: (0.371)(-0.260) = -0.096\nEgzersiz → Stres → Hastalık: (-0.080)(0.362) = -0.029\nEgzersiz, hastalık üzerinde iki tane de dolaylı etkiye sahiptir; biri\nform üzerinden, diğeri ise stress üzerindendir. Dolaylı etki, ilgili\nstandartlaştırılmış yol katsayılarının çarpılması sonucu elde edilir:Egzersiz → Form → Hastalık: (0.371)(-0.260) = -0.096Egzersiz → Stres → Hastalık: (-0.080)(0.362) = -0.029Böylece egzersiz’hastalık üzerindeki toplam etkisi:\ntoplam etki = doğrudan etki + toplam dolaylı etki\n= 0.054 + (-0.096) + (-0.029)\n= 0.054 + (-0.125)\n= - 0.071\nBöylece egzersiz’hastalık üzerindeki toplam etkisi:toplam etki = doğrudan etki + toplam dolaylı etki= 0.054 + (-0.096) + (-0.029)= 0.054 + (-0.125)= - 0.071egzersiz → form → hastalıkegzersiz → stres → hastalıkdayanıklılık → form → hastalıkdayanıklılık → stres → hastalıkExercise → Fitness → Illness: (0.371)(0.260) = 0.096Exercise → Fitness → Illness: (0.371)(0.260) = 0.096Exercise → Stress → Illness: (0.080)(0.362) = 0.029Exercise → Stress → Illness: (0.080)(0.362) = 0.029Böylece Exercise’Illness üzerindeki toplam etkisi:\ntoplam etki = doğrudan etki + toplam dolaylı etkiBöylece Exercise’Illness üzerindeki toplam etkisi:\ntoplam etki = doğrudan etki + toplam dolaylı etki= 0.054 + (0.096) + ( 0.029)= 0.054 + (0.096) + ( 0.029)= 0.054 - (0.125)= 0.054 - (0.125)= 0.071= 0.071","code":"\nyol_model <-  'stres     ~ s_e*egzersiz + dayaniklilik\n               hastalik  ~ h_e*egzersiz + dayaniklilik + h_f*form + h_s*stres\n               form      ~ f_e*egzersiz + dayaniklilik\n               egzersiz ~~ dayaniklilik\n               # Direct Effect\n               dir_fm:=h_f\n               dir_sh:=h_s\n\n               # InDirect Effect\n               ind_h1:=f_e*h_f\n               ind_h2:=s_e*h_s\n\n               # total InDirect Effect\n               tot_ind:=ind_h1 +  ind_h2\n\n               # Total Effect\n               tot:=tot_ind + h_e'\n\nfsem1 <- sem(yol_model,veri)\nstandardizedsolution(fsem1)"},{"path":"yol-analizi.html","id":"kaynaklar-3","chapter":"Bölüm 6 Yol Analizi","heading":"6.20 Kaynaklar","text":"Roth, D. L., Wiebe, D. J., Fillingim, R. B., & Shay, K. . (1989). Life events, fitness, hardiness, health: simultaneous analysis proposed stress-resistance effects. Journal Personality Social Psychology, 57(1), 136-142.Roth, D. L., Wiebe, D. J., Fillingim, R. B., & Shay, K. . (1989). Life events, fitness, hardiness, health: simultaneous analysis proposed stress-resistance effects. Journal Personality Social Psychology, 57(1), 136-142.Bentler, P. M. (1990). Comparative fit indexes structural models.\nPsychological Bulletin, 107,238-246.Bentler, P. M. (1990). Comparative fit indexes structural models.\nPsychological Bulletin, 107,238-246.Steiger, J. H. (1990). Structural model evaluation modification: \ninterval estimation approach. Multivariate Behavioral Research, 25, 173-80.Steiger, J. H. (1990). Structural model evaluation modification: \ninterval estimation approach. Multivariate Behavioral Research, 25, 173-80.Bentler, P. M. & Hu, L. (1999). Cutoff criteria fpr fit indexes \ncovariance structure analysis: Conventional criteri versus new\nalternatives. Structural Equation Modeling, 6(1), 1-55.Bentler, P. M. & Hu, L. (1999). Cutoff criteria fpr fit indexes \ncovariance structure analysis: Conventional criteri versus new\nalternatives. Structural Equation Modeling, 6(1), 1-55.Marsh, H. W., & Hau, K. T. (2007). Applications latent-variable models educational psychology: need methodological-substantive synergies. Contemporary educational psychology, 32(1), 151-170.Marsh, H. W., & Hau, K. T. (2007). Applications latent-variable models educational psychology: need methodological-substantive synergies. Contemporary educational psychology, 32(1), 151-170.","code":""},{"path":"afa.html","id":"afa","chapter":"Bölüm 7 AFA","heading":"Bölüm 7 AFA","text":"Bazı durumlarda, özellikle de ölçme araçları yeni geliştirildiyse:\nAraştırmacıların bir grup gözlenen/ölçülen değişkenin altında\nyatan faktör sayısı hakkında güçlü varsayımları yoktur.\nAraştırmacıların hangi grup değişkenlerin birbirleriyle\ndiğerlerine göre daha çok korelasyona sahip olduğu hakkında\ngüçlü varsayımları yoktur.\nBazen araştırmacılar belli değişkenlerin kuramsal yapıların\niyi göstergeleri olup olmadığı hakkında fikir sahibi\nolmayabilir.\nBazı durumlarda, özellikle de ölçme araçları yeni geliştirildiyse:Araştırmacıların bir grup gözlenen/ölçülen değişkenin altında\nyatan faktör sayısı hakkında güçlü varsayımları yoktur.Araştırmacıların bir grup gözlenen/ölçülen değişkenin altında\nyatan faktör sayısı hakkında güçlü varsayımları yoktur.Araştırmacıların hangi grup değişkenlerin birbirleriyle\ndiğerlerine göre daha çok korelasyona sahip olduğu hakkında\ngüçlü varsayımları yoktur.Araştırmacıların hangi grup değişkenlerin birbirleriyle\ndiğerlerine göre daha çok korelasyona sahip olduğu hakkında\ngüçlü varsayımları yoktur.Bazen araştırmacılar belli değişkenlerin kuramsal yapıların\niyi göstergeleri olup olmadığı hakkında fikir sahibi\nolmayabilir.Bazen araştırmacılar belli değişkenlerin kuramsal yapıların\niyi göstergeleri olup olmadığı hakkında fikir sahibi\nolmayabilir.Bu koşullarda AFA gözlenen/ölçülen değişkenler arasındaki altta\nyatan yapının incelenmesi için önemli bir araçtır. AFA’nın başlıca\namaçları aşağıdaki gibidir:\nGözlenen/ölçülen değişkenler arasındaki korelasyonların\nörüntüsünü özetlemek.\nÇok sayıdaki gözlenen/ölçülen değişkeni daha az sayıdaki\nfaktöre indirgemek.\nGözlenen/ölçülen değişkenleri kullanarak altta yatan yapının\noperasyonel tanımını sağlamak.\nBu koşullarda AFA gözlenen/ölçülen değişkenler arasındaki altta\nyatan yapının incelenmesi için önemli bir araçtır. AFA’nın başlıca\namaçları aşağıdaki gibidir:Gözlenen/ölçülen değişkenler arasındaki korelasyonların\nörüntüsünü özetlemek.Gözlenen/ölçülen değişkenler arasındaki korelasyonların\nörüntüsünü özetlemek.Çok sayıdaki gözlenen/ölçülen değişkeni daha az sayıdaki\nfaktöre indirgemek.Çok sayıdaki gözlenen/ölçülen değişkeni daha az sayıdaki\nfaktöre indirgemek.Gözlenen/ölçülen değişkenleri kullanarak altta yatan yapının\noperasyonel tanımını sağlamak.Gözlenen/ölçülen değişkenleri kullanarak altta yatan yapının\noperasyonel tanımını sağlamak.Varsayımsal bir veri olan Heuristic adlı veride 6 ölçülen\ndeğişken bulunmaktadır. Ancak bu ölçülen değişkenlerin altında yatan\nyapı hakkında bir fikir yoktur. Veri Thompson’ın (2004)\nkitabında sayfa 10’da verilmiş olup 6 ölçülen değişkene ilişkin 7\nöğrenci tarafından sağlanan derecelendirmeleri içermektedir\nBir faktör analizi yapıldığında, ölçülen değişkenler\narasındaki ilişkiler araştırılır ve bu ilişkilerin daha az\nsayıda gizil yapıda özetlenip özetlenemeyeceği belirlenmeye\nçalışılır. Değişkenler arasındaki ilişkileri özetlemek için\nbirkaç farklı istatistik kullanılabilir (örneğin, Pearson\nmomentler-çarpımı korelasyon katsayıları, Spearman'ın rho\nkatsayıları, tetrakorik korelasyon katsayısı).\nVarsayımsal bir veri olan Heuristic adlı veride 6 ölçülen\ndeğişken bulunmaktadır. Ancak bu ölçülen değişkenlerin altında yatan\nyapı hakkında bir fikir yoktur. Veri Thompson’ın (2004)\nkitabında sayfa 10’da verilmiş olup 6 ölçülen değişkene ilişkin 7\nöğrenci tarafından sağlanan derecelendirmeleri içermektedirBir faktör analizi yapıldığında, ölçülen değişkenler\narasındaki ilişkiler araştırılır ve bu ilişkilerin daha az\nsayıda gizil yapıda özetlenip özetlenemeyeceği belirlenmeye\nçalışılır. Değişkenler arasındaki ilişkileri özetlemek için\nbirkaç farklı istatistik kullanılabilir (örneğin, Pearson\nmomentler-çarpımı korelasyon katsayıları, Spearman'ın rho\nkatsayıları, tetrakorik korelasyon katsayısı).Verideki 6 değişken arasındaki Pearson korelasyon katsayıları\nmatrisi aşağıdaki gibidir:Korelasyon matrisindeki örüntülere dayanarak aşağıdakiler\nsöylenebilir:\nBireyi tarif etmek için Handsome, Beautiful ve Ugly\ndeğişkenlerini kullanmak yerine bu üç ölçülen değişken bir\ngizil değişken (faktör analizinde gizil değişken faktör olarak\nadlandırılır) olarak özetlenebilir. Bu gizil değişken physical\nattractiveness olarak etiketlenebilir.\nBenzer şekilde, bireyi tarif etmek için Brilliant, Smart\nve Dumb değişkenlerini kullanmak yerine bu üç ölçülen\ndeğişken bir gizil değişken kullanarak özetlenebilir. Bu\ngizil değişken intellectual prowess olarak etiketlenebilir.\nKorelasyon matrisindeki örüntülere dayanarak aşağıdakiler\nsöylenebilir:Bireyi tarif etmek için Handsome, Beautiful ve Ugly\ndeğişkenlerini kullanmak yerine bu üç ölçülen değişken bir\ngizil değişken (faktör analizinde gizil değişken faktör olarak\nadlandırılır) olarak özetlenebilir. Bu gizil değişken physical\nattractiveness olarak etiketlenebilir.Bireyi tarif etmek için Handsome, Beautiful ve Ugly\ndeğişkenlerini kullanmak yerine bu üç ölçülen değişken bir\ngizil değişken (faktör analizinde gizil değişken faktör olarak\nadlandırılır) olarak özetlenebilir. Bu gizil değişken physical\nattractiveness olarak etiketlenebilir.Benzer şekilde, bireyi tarif etmek için Brilliant, Smart\nve Dumb değişkenlerini kullanmak yerine bu üç ölçülen\ndeğişken bir gizil değişken kullanarak özetlenebilir. Bu\ngizil değişken intellectual prowess olarak etiketlenebilir.Benzer şekilde, bireyi tarif etmek için Brilliant, Smart\nve Dumb değişkenlerini kullanmak yerine bu üç ölçülen\ndeğişken bir gizil değişken kullanarak özetlenebilir. Bu\ngizil değişken intellectual prowess olarak etiketlenebilir.physical attractiveness ve intellectual prowess arasında\nkorelasyon yoktur.physical attractiveness ve intellectual prowess arasında\nkorelasyon yoktur.6 değişken yerine bu 2 faktör kullanılarak, 6 ölçülen değişken\narasındaki korelasyonun örüntüsü özetlenir. 6 ölçülen değişken\n2 gizil faktöre indirgenir.\nBu 3 değişkenlik 2 alt kümedeki korelasyonlar 1 veya -1\nolduğundan, gözlenen/ölçülen korelasyon matrisindeki bilgiden\nherhangi bir bilgi kaybedilmez. Diğer bir ifadeyle, bu iki\nfaktör kullanılarak gözlenen/ölçülen korelasyon matrisi\nmükemmel bir şekilde üretilebilir. Ancak gerçek veride bu\nolmayacaktır.\n6 değişken yerine bu 2 faktör kullanılarak, 6 ölçülen değişken\narasındaki korelasyonun örüntüsü özetlenir. 6 ölçülen değişken\n2 gizil faktöre indirgenir.Bu 3 değişkenlik 2 alt kümedeki korelasyonlar 1 veya -1\nolduğundan, gözlenen/ölçülen korelasyon matrisindeki bilgiden\nherhangi bir bilgi kaybedilmez. Diğer bir ifadeyle, bu iki\nfaktör kullanılarak gözlenen/ölçülen korelasyon matrisi\nmükemmel bir şekilde üretilebilir. Ancak gerçek veride bu\nolmayacaktır.","code":"\ndf <- data.frame(matrix(c(\n  1,6,5,4,8,6,2,\n  2,8,7,2,7,5,3,\n  3,9,8,1,9,7,1,\n  4,5,4,5,9,7,1,\n  5,4,3,6,9,7,1,\n  6,7,6,3,7,5,3,\n  7,3,2,7,7,5,3),nrow=7,byrow = TRUE))\ncolnames(df) <- c(\"id\", \"handsome\", \"beatiful\",\"ugly\",\"brillant\",\"smart\",\"dumb\")\ndf %>% kable(align = \"c\")\ncor(df[,-1])%>% kable(align = \"c\")"},{"path":"afa.html","id":"örüntü-katsayıları","chapter":"Bölüm 7 AFA","heading":"7.1 Örüntü Katsayıları","text":"Korelasyon matrisinin faktör analizi sonucunda elde edilen karesi\nalınmamış (MR1 ve MR2), karesi alınmış (MR1 ve\nMR2)faktör ağırlıkları aşağıdaki gibidir.Faktör analizinde örüntü katsayıları (pattern coefficients)\nfaktör analizindeki gizil değişkenler üzerinde puanlar (faktör\npuanları olarak adlandırılır) elde etmek için ölçülen değişkenlere\nuygulanan ağırlıklardır.Faktör analizinde örüntü katsayıları (pattern coefficients)\nfaktör analizindeki gizil değişkenler üzerinde puanlar (faktör\npuanları olarak adlandırılır) elde etmek için ölçülen değişkenlere\nuygulanan ağırlıklardır.Bu ağırlıklar\nçoklu regresyon analizindeki \\(\\beta\\) ağırlıklarına,\nbetimsel ayırma analizindeki standartlaştırılmış ayırma\nfonksiyonu katsayılarına benzerdir.\nBu ağırlıklarçoklu regresyon analizindeki \\(\\beta\\) ağırlıklarına,betimsel ayırma analizindeki standartlaştırılmış ayırma\nfonksiyonu katsayılarına benzerdir.Faktör örüntü katsayıları ( \\(P_{VxF}\\) ; V değişken sayısı, F faktör\nsayısı), kısmen, analiz edilen ve faktörlerin çıkarıldığı\nkorelasyon matrisinde temsil edilen varyansı yeniden ifade etmek\niçin hesaplanır.Faktör örüntü katsayıları ( \\(P_{VxF}\\) ; V değişken sayısı, F faktör\nsayısı), kısmen, analiz edilen ve faktörlerin çıkarıldığı\nkorelasyon matrisinde temsil edilen varyansı yeniden ifade etmek\niçin hesaplanır.Faktörler; birinci faktör analiz edilen matristeki en fazla\nvaryansı yeniden üretebilecek, ikinci faktör ikinci en fazla\nvaryansı yeniden üretebilecek ve bu şekilde devam edecek şekilde\nçıkarılır.Faktörler; birinci faktör analiz edilen matristeki en fazla\nvaryansı yeniden üretebilecek, ikinci faktör ikinci en fazla\nvaryansı yeniden üretebilecek ve bu şekilde devam edecek şekilde\nçıkarılır.Bir veya daha fazla faktörün, analiz edilen matrisi yeniden üretme\nyeteneği, üretilen (reproduced) korelasyon matrisi ( \\(R_{VxV^+}\\) )\nile ölçülür. Üretilen korelasyon matrisi aşağıdaki şekilde\nhesaplanabilir:\n\\(P_{VxF}P_{VxF'}=R_{VxV^+}\\)\nBir veya daha fazla faktörün, analiz edilen matrisi yeniden üretme\nyeteneği, üretilen (reproduced) korelasyon matrisi ( \\(R_{VxV^+}\\) )\nile ölçülür. Üretilen korelasyon matrisi aşağıdaki şekilde\nhesaplanabilir:\\(P_{VxF}P_{VxF'}=R_{VxV^+}\\)Faktörlerin analiz edilen korelasyon matrisini yeniden üretme\nyeteneği, belirli sayıda faktör çıkarıldıktan sonra kalan matrisin\nhesaplanmasıyla da ölçülebilir. Bu matris artık korelasyon\nmatrisi \\(R_{VxV^-}\\) olarak adlandırılır.Faktörlerin analiz edilen korelasyon matrisini yeniden üretme\nyeteneği, belirli sayıda faktör çıkarıldıktan sonra kalan matrisin\nhesaplanmasıyla da ölçülebilir. Bu matris artık korelasyon\nmatrisi \\(R_{VxV^-}\\) olarak adlandırılır.Faktör örüntü katsayıları, korelasyon matrisini mükemmel bir şekilde\nyeniden oluşturursa, \\(R_{VxV^-}\\) matrisinin girdileri tamamen\nsıfırlardan oluşur ve bu matriste hiçbir bilgi veya varyans\nkalmadığını gösterir. Faktör örüntü katsayıları korelasyon matrisini\nmükemmel şekilde yeniden oluşturursa, \\(R_{VxV^±}\\) matrisindeki\ngirdiler \\(R_{VxV}\\) matrisindeki girdilerle tam olarak eşleşir.Faktör örüntü katsayıları, korelasyon matrisini mükemmel bir şekilde\nyeniden oluşturursa, \\(R_{VxV^-}\\) matrisinin girdileri tamamen\nsıfırlardan oluşur ve bu matriste hiçbir bilgi veya varyans\nkalmadığını gösterir. Faktör örüntü katsayıları korelasyon matrisini\nmükemmel şekilde yeniden oluşturursa, \\(R_{VxV^±}\\) matrisindeki\ngirdiler \\(R_{VxV}\\) matrisindeki girdilerle tam olarak eşleşir.Regresyon analizinde, belirli bir analizde yalnızca tek bir eşitlik\n\\(\\beta\\) ağırlıkları seti vardır. Faktör analizinde ağırlık setlerine\n(örüntü katsayıları gibi) eşitlikler yerine faktörler denir.Regresyon analizinde, belirli bir analizde yalnızca tek bir eşitlik\n\\(\\beta\\) ağırlıkları seti vardır. Faktör analizinde ağırlık setlerine\n(örüntü katsayıları gibi) eşitlikler yerine faktörler denir.Örnekteki değişkenler arası korelasyon matrisindeki girdi +1\nveya -1 olsaydı\nölçülen değişken çifti arasındaki \\(r^2\\) değeri %100\nolacaktı. Bu da derecelendirmelerin altında tek bir faktörün\nyattığı anlamına gelecekti. Bu durumda sadece eksi veya artı\nörüntü katsayılarından \\(P_{6x1}\\) oluşan bir faktör\nçıkarılacaktı. Bu tek faktör, orijinal \\(P_{6x6}\\) matrisini\nmükemmel şekilde yeniden üretecekti.\nTeknik olarak, biri sadece sıfır değerindeki örüntü\nkatsayılarından oluşan, yani birinin hiçbir bilgi içermediği\nve değişkenliğin yeniden üretilmediği beş ek faktör\nolacaktı. Ancak bu tür faktörlerle ilgilenilmez.\nÖrnekteki değişkenler arası korelasyon matrisindeki girdi +1\nveya -1 olsaydıher ölçülen değişken çifti arasındaki \\(r^2\\) değeri %100\nolacaktı. Bu da derecelendirmelerin altında tek bir faktörün\nyattığı anlamına gelecekti. Bu durumda sadece eksi veya artı\nörüntü katsayılarından \\(P_{6x1}\\) oluşan bir faktör\nçıkarılacaktı. Bu tek faktör, orijinal \\(P_{6x6}\\) matrisini\nmükemmel şekilde yeniden üretecekti.ölçülen değişken çifti arasındaki \\(r^2\\) değeri %100\nolacaktı. Bu da derecelendirmelerin altında tek bir faktörün\nyattığı anlamına gelecekti. Bu durumda sadece eksi veya artı\nörüntü katsayılarından \\(P_{6x1}\\) oluşan bir faktör\nçıkarılacaktı. Bu tek faktör, orijinal \\(P_{6x6}\\) matrisini\nmükemmel şekilde yeniden üretecekti.Teknik olarak, biri sadece sıfır değerindeki örüntü\nkatsayılarından oluşan, yani birinin hiçbir bilgi içermediği\nve değişkenliğin yeniden üretilmediği beş ek faktör\nolacaktı. Ancak bu tür faktörlerle ilgilenilmez.Teknik olarak, biri sadece sıfır değerindeki örüntü\nkatsayılarından oluşan, yani birinin hiçbir bilgi içermediği\nve değişkenliğin yeniden üretilmediği beş ek faktör\nolacaktı. Ancak bu tür faktörlerle ilgilenilmez.Örnekteki değişkenler arasındaki korelasyon sıfır olsaydı,\nkorelasyon matrisindeki köşegen dışındaki girdi 0 olacaktı,\nölçülen değişken çifti arasındaki \\(r^2\\) değeri %0\nolacaktı.\nBu da bir faktör oluşturmak için iki değişken\nbirleştirilemeyeceği (yani ölçülen değişken kendi\nfaktörünü tanımlayacağı) anlamına gelecekti. Dolayısıyla 6\nfaktör olacaktı. faktör bir +1 değerinde örüntü\nkatsayısına sahip olacaktı ve geri kalan beş girdi sıfır\nolacaktı. Bu altı faktör, orijinal \\(P_{6x6}\\) matrisini\nmükemmel şekilde yeniden üretecekti.\nAslında, tüm olası faktörler çıkarıldığında (yani faktörlerin\nsayısı ölçülen değişkenlerin sayısına eşit olduğunda), örüntü\nkatsayıları analiz edilen orijinal korelasyon matrisini mükemmel\nbir şekilde yeniden üretecekti.\nÖrnekteki değişkenler arasındaki korelasyon sıfır olsaydı,\nkorelasyon matrisindeki köşegen dışındaki girdi 0 olacaktı,ölçülen değişken çifti arasındaki \\(r^2\\) değeri %0\nolacaktı.ölçülen değişken çifti arasındaki \\(r^2\\) değeri %0\nolacaktı.Bu da bir faktör oluşturmak için iki değişken\nbirleştirilemeyeceği (yani ölçülen değişken kendi\nfaktörünü tanımlayacağı) anlamına gelecekti. Dolayısıyla 6\nfaktör olacaktı. faktör bir +1 değerinde örüntü\nkatsayısına sahip olacaktı ve geri kalan beş girdi sıfır\nolacaktı. Bu altı faktör, orijinal \\(P_{6x6}\\) matrisini\nmükemmel şekilde yeniden üretecekti.Bu da bir faktör oluşturmak için iki değişken\nbirleştirilemeyeceği (yani ölçülen değişken kendi\nfaktörünü tanımlayacağı) anlamına gelecekti. Dolayısıyla 6\nfaktör olacaktı. faktör bir +1 değerinde örüntü\nkatsayısına sahip olacaktı ve geri kalan beş girdi sıfır\nolacaktı. Bu altı faktör, orijinal \\(P_{6x6}\\) matrisini\nmükemmel şekilde yeniden üretecekti.Aslında, tüm olası faktörler çıkarıldığında (yani faktörlerin\nsayısı ölçülen değişkenlerin sayısına eşit olduğunda), örüntü\nkatsayıları analiz edilen orijinal korelasyon matrisini mükemmel\nbir şekilde yeniden üretecekti.Aslında, tüm olası faktörler çıkarıldığında (yani faktörlerin\nsayısı ölçülen değişkenlerin sayısına eşit olduğunda), örüntü\nkatsayıları analiz edilen orijinal korelasyon matrisini mükemmel\nbir şekilde yeniden üretecekti.","code":"\nlibrary(psych)\nfa1 <- round(fa(df[,-1],2)$loading[,1:2],2)\ncbind(fa1,fa1^2)%>% kable(align = \"c\",col.names = c(\"MR1\",\"MR2\", \"MR1^2\",\"MR2^2\"))"},{"path":"afa.html","id":"yapı-katsayıları","chapter":"Bölüm 7 AFA","heading":"7.2 Yapı Katsayıları","text":"Faktör analizinde, örüntü katsayıları faktör puanlarını elde\netmek için ölçülen değişkenlere uygulanırlar. Bu katsayılar kimi\nzaman korelasyon katsayılarıdır, kimi zaman değildir.Faktör analizinde, örüntü katsayıları faktör puanlarını elde\netmek için ölçülen değişkenlere uygulanırlar. Bu katsayılar kimi\nzaman korelasyon katsayılarıdır, kimi zaman değildir.Ölçülen değişkenler ve faktör puanları arasındaki iki değişkenli\nkorelasyon katsayıları hesaplanabilir. Bu korelasyon katsayıları\nyapı katsayıları olarak adlandırılır. Faktör analizinde,\nörüntü katsayılarının yanı sıra yapı katsayıları (structure\ncoefficients) da önemlidir.Ölçülen değişkenler ve faktör puanları arasındaki iki değişkenli\nkorelasyon katsayıları hesaplanabilir. Bu korelasyon katsayıları\nyapı katsayıları olarak adlandırılır. Faktör analizinde,\nörüntü katsayılarının yanı sıra yapı katsayıları (structure\ncoefficients) da önemlidir.Yapı katsayıları aşağıdaki şekilde hesaplanabilir.\n\\(P_{VxF}R_{FxF}=S_{VxF}\\)\nYapı katsayıları aşağıdaki şekilde hesaplanabilir.\\(P_{VxF}R_{FxF}=S_{VxF}\\)Burada,\n\\(R_{FxF}\\) faktörler arasındaki korelasyon matrisidir.\nFaktörler arasındaki korelasyon sıfır olduğunda (yani\nfaktörler tamamen ilişkisiz olduğunda), faktörler arasındaki\nkorelasyon matrisi birim matrise eşit olacağından (\n\\(R_{FxF}=I_{FxF}\\) ), örüntü katsayıları matrisi de yapı\nkatsayıları matrisine eşit olacaktır ( \\(P_{VxF}=S_{VxF}\\) ).\nBurada,\\(R_{FxF}\\) faktörler arasındaki korelasyon matrisidir.\\(R_{FxF}\\) faktörler arasındaki korelasyon matrisidir.Faktörler arasındaki korelasyon sıfır olduğunda (yani\nfaktörler tamamen ilişkisiz olduğunda), faktörler arasındaki\nkorelasyon matrisi birim matrise eşit olacağından (\n\\(R_{FxF}=I_{FxF}\\) ), örüntü katsayıları matrisi de yapı\nkatsayıları matrisine eşit olacaktır ( \\(P_{VxF}=S_{VxF}\\) ).Faktörler arasındaki korelasyon sıfır olduğunda (yani\nfaktörler tamamen ilişkisiz olduğunda), faktörler arasındaki\nkorelasyon matrisi birim matrise eşit olacağından (\n\\(R_{FxF}=I_{FxF}\\) ), örüntü katsayıları matrisi de yapı\nkatsayıları matrisine eşit olacaktır ( \\(P_{VxF}=S_{VxF}\\) ).Faktörler ilk çıkarıldığında, faktörler zaman tamamen\nilişkisizdir.Faktörler ilk çıkarıldığında, faktörler zaman tamamen\nilişkisizdir.","code":""},{"path":"afa.html","id":"ortak-varyans-katsayıları","chapter":"Bölüm 7 AFA","heading":"7.3 Ortak Varyans Katsayıları","text":"Örnekte çıkarılan faktörler tamamen ilişkisiz olduğundan, karesi\nalınmamış katsayılar örüntü/yapı katsayılarıdır. Dolayısıyla bu\nkatsayıların değeri -1,0 ve +1,0 aralığındadır. Ancak bu\ndeğerler oran ölçeğinde değildir.\nÖrneğin, \\(r=1\\) değeri \\(r=0.5\\) değerinin iki katı büyük değildir.\nBu değerlerin karesi alınırsa, oransal olarak karşılaştırmalar\nyapılabilir. Örneğin, \\(r=1\\) değeri, \\(r=0.5\\) değerinin dört katı\nbüyüktür. Çünkü 1,0 değerinin karesi olan \\(r^2=1\\) değeri, 0.5\ndeğerinin karesi olan \\(r^2=0.25\\) değerinin dört katıdır.\nÖrnekte çıkarılan faktörler tamamen ilişkisiz olduğundan, karesi\nalınmamış katsayılar örüntü/yapı katsayılarıdır. Dolayısıyla bu\nkatsayıların değeri -1,0 ve +1,0 aralığındadır. Ancak bu\ndeğerler oran ölçeğinde değildir.Örneğin, \\(r=1\\) değeri \\(r=0.5\\) değerinin iki katı büyük değildir.\nBu değerlerin karesi alınırsa, oransal olarak karşılaştırmalar\nyapılabilir. Örneğin, \\(r=1\\) değeri, \\(r=0.5\\) değerinin dört katı\nbüyüktür. Çünkü 1,0 değerinin karesi olan \\(r^2=1\\) değeri, 0.5\ndeğerinin karesi olan \\(r^2=0.25\\) değerinin dört katıdır.Örnekteki örüntü/yapı katsayılar korelasyon katsayıları\nolduğundan, bu katsayıları karşılaştırabilmek için karelerinin\nalınması gerekmektedir.Örnekteki örüntü/yapı katsayılar korelasyon katsayıları\nolduğundan, bu katsayıları karşılaştırabilmek için karelerinin\nalınması gerekmektedir.Aralarında ilişki bulunmayan faktörler için örüntü/yapı\nkatsayılarının kareleri alınarak, katsayıların karesi satır\nboyunca toplanırsa, elde edilen katsayı ortak varyans\n(communality) olarak adlandırılır ve \\(h^2\\) ile gösterilir.Aralarında ilişki bulunmayan faktörler için örüntü/yapı\nkatsayılarının kareleri alınarak, katsayıların karesi satır\nboyunca toplanırsa, elde edilen katsayı ortak varyans\n(communality) olarak adlandırılır ve \\(h^2\\) ile gösterilir.Örneğin, \"Handsome\" değişkeni için ortak varyans değeri,\n\\((1.0)^2 + (0)^2 = 1.0\\)Örneğin, \"Handsome\" değişkeni için ortak varyans değeri,\n\\((1.0)^2 + (0)^2 = 1.0\\)Faktörler arasında ilişki bulunmadığından, ölçülen\ndeğişkenin bir faktör ile paylaştığı varyans kendine özgüdür.Faktörler arasında ilişki bulunmadığından, ölçülen\ndeğişkenin bir faktör ile paylaştığı varyans kendine özgüdür.Dolayısıyla ortak varyans faktörlerin ölçülen bir değişkendeki\nvaryansın ne kadarını üretebileceğini belirtir.\nÖlçülen bir değişken %0'yakın bir ortak varyans\nkatsayısına sahipse, bu, bu değişkenin faktörler içinde temsil\nedilmediği anlamına gelir. Araştırmacı, değişkenin faktörlerde\ntemsil edilmesini istiyorsa, ek faktörlerin çıkarılması\ngerekebilir.\nDolayısıyla ortak varyans faktörlerin ölçülen bir değişkendeki\nvaryansın ne kadarını üretebileceğini belirtir.Ölçülen bir değişken %0'yakın bir ortak varyans\nkatsayısına sahipse, bu, bu değişkenin faktörler içinde temsil\nedilmediği anlamına gelir. Araştırmacı, değişkenin faktörlerde\ntemsil edilmesini istiyorsa, ek faktörlerin çıkarılması\ngerekebilir.Ortak varyans ölçülen bir değişken için, belirli bir ölçülen\ndeğişkenin varyansının ne kadarının faktörleri bir küme olarak\ntanımlamada yararlı olduğunu yansıtır.Ortak varyans ölçülen bir değişken için, belirli bir ölçülen\ndeğişkenin varyansının ne kadarının faktörleri bir küme olarak\ntanımlamada yararlı olduğunu yansıtır.Bir değişken için ortak varyans katsayısı, değişken üzerindeki\npuanların güvenilirliğinin alt sınır tahminidir.\nÖrneğin, bir değişkenin % 50'lik bir ortak varyansa sahip\nolması, değişken üzerindeki puanların güvenilirliğinin 0.5'ten\ndüşük olmadığına işaret etmektedir.\nBir değişken için ortak varyans katsayısı, değişken üzerindeki\npuanların güvenilirliğinin alt sınır tahminidir.Örneğin, bir değişkenin % 50'lik bir ortak varyansa sahip\nolması, değişken üzerindeki puanların güvenilirliğinin 0.5'ten\ndüşük olmadığına işaret etmektedir.","code":"\nfa1 %>% target.rot()## \n## Call: NULL\n## Standardized loadings (pattern matrix) based upon correlation matrix\n##          MR1 MR2 h2 u2\n## handsome   1   0  1  0\n## beatiful   1   0  1  0\n## ugly      -1   0  1  0\n## brillant   0   1  1  0\n## smart      0   1  1  0\n## dumb       0  -1  1  0\n## \n##                       MR1 MR2\n## SS loadings           3.0 3.0\n## Proportion Var        0.5 0.5\n## Cumulative Var        0.5 1.0\n## Proportion Explained  0.5 0.5\n## Cumulative Proportion 0.5 1.0\n##     MR1 MR2\n## MR1   1   0\n## MR2   0   1"},{"path":"afa.html","id":"özdeğerler","chapter":"Bölüm 7 AFA","heading":"7.4 Özdeğerler","text":"Aralarında ilişki bulunmayan faktörler için örüntü/yapı\nkatsayılarının kareleri alınarak, katsayıların karesi sütun\nboyunca toplanırsa, elde edilen katsayı özdeğer (eigenvalue)\nolarak adlandırılır.Aralarında ilişki bulunmayan faktörler için örüntü/yapı\nkatsayılarının kareleri alınarak, katsayıların karesi sütun\nboyunca toplanırsa, elde edilen katsayı özdeğer (eigenvalue)\nolarak adlandırılır.Özdeğerler karakteristik kökler olarak da bilinmektedir.Özdeğerler karakteristik kökler olarak da bilinmektedir.Örneğin, birinci faktör ve ikinci faktör için özdeğerler 3 ve 3’dır.Örneğin, birinci faktör ve ikinci faktör için özdeğerler 3 ve 3’dır.Aşağıdaki dört ifade, bir AFA'daki özdeğerler için geçerlidir:\nÖzdeğerlerin sayısı, ölçülen değişkenlerin sayısına eşittir.\nÖzdeğerlerin toplamı, ölçülen değişkenlerin sayısına\neşittir.\nÖlçülen değişkenlerin sayısına bölünen bir özdeğer,\nbelirli bir faktörün analiz edilen korelasyon matrisindeki\nyeniden ürettiği bilgi oranını gösterir.\nÇıkarılan faktörlerin özdeğerlerinin toplamının ölçülen\ndeğişkenlerin sayısına bölünmesi, faktörlerin bir küme olarak\nanaliz edilen korelasyon matrisindeki yeniden ürettiği\nbilgilerin oranını gösterir.\nAşağıdaki dört ifade, bir AFA'daki özdeğerler için geçerlidir:Özdeğerlerin sayısı, ölçülen değişkenlerin sayısına eşittir.Özdeğerlerin sayısı, ölçülen değişkenlerin sayısına eşittir.Özdeğerlerin toplamı, ölçülen değişkenlerin sayısına\neşittir.Özdeğerlerin toplamı, ölçülen değişkenlerin sayısına\neşittir.Ölçülen değişkenlerin sayısına bölünen bir özdeğer,\nbelirli bir faktörün analiz edilen korelasyon matrisindeki\nyeniden ürettiği bilgi oranını gösterir.Ölçülen değişkenlerin sayısına bölünen bir özdeğer,\nbelirli bir faktörün analiz edilen korelasyon matrisindeki\nyeniden ürettiği bilgi oranını gösterir.Çıkarılan faktörlerin özdeğerlerinin toplamının ölçülen\ndeğişkenlerin sayısına bölünmesi, faktörlerin bir küme olarak\nanaliz edilen korelasyon matrisindeki yeniden ürettiği\nbilgilerin oranını gösterir.Çıkarılan faktörlerin özdeğerlerinin toplamının ölçülen\ndeğişkenlerin sayısına bölünmesi, faktörlerin bir küme olarak\nanaliz edilen korelasyon matrisindeki yeniden ürettiği\nbilgilerin oranını gösterir.Örnekte, ölçülen değişkenlerin sayısı altıdır. Bu nedenle,\nkorelasyon matrisi ile ilişkili altı özdeğer vardır.Örnekte, ölçülen değişkenlerin sayısı altıdır. Bu nedenle,\nkorelasyon matrisi ile ilişkili altı özdeğer vardır.Örnekteki özdeğerlerin toplamı 6 olduğundan, ilk iki özdeğerin 3\nve 3 olduğu göz önüne alındığında, kalan özdeğerlerin 0,0, 0.0,\n0.0 ve 0.0 olması gerekir.Örnekteki özdeğerlerin toplamı 6 olduğundan, ilk iki özdeğerin 3\nve 3 olduğu göz önüne alındığında, kalan özdeğerlerin 0,0, 0.0,\n0.0 ve 0.0 olması gerekir.\\(3/6= 0.5\\)'e eşit olduğu için, ilk özdeğer, Faktör ’korelasyon\nmatrisinde yer alan bilgilerin 0.5'ini (veya %50'sini) yeniden\nürettiğini gösterir.\\(3/6= 0.5\\)'e eşit olduğu için, ilk özdeğer, Faktör ’korelasyon\nmatrisinde yer alan bilgilerin 0.5'ini (veya %50'sini) yeniden\nürettiğini gösterir.DFA’da olduğu gibi AFA’da da ortak faktör modeli (common factor\nmodel) temeldir: bir değişken faktör puanlarının ve bir hata\npuanının bir fonksiyonudur. \\(X=\\Lambda\\xi +\\delta\\)DFA’da olduğu gibi AFA’da da ortak faktör modeli (common factor\nmodel) temeldir: bir değişken faktör puanlarının ve bir hata\npuanının bir fonksiyonudur. \\(X=\\Lambda\\xi +\\delta\\)Örnekte AFA modeli aşağıdaki gibidir: \\[\\begin{bmatrix}{}\nX_{1 handsome}\\\\\nX_{2 betutiful}\\\\\nX_{3 ugly}\\\\\nX_{4 brillant}\\\\\nX_{5 smart}\\\\\nX_{6 dumb}\\\\\n\\end{bmatrix} = \\begin{bmatrix}{}\n\\lambda_{11} & \\lambda_{12} \\\\\n\\lambda_{21} & \\lambda_{22} \\\\\n\\lambda_{31} & \\lambda_{32} \\\\\n\\lambda_{41} & \\lambda_{42} \\\\\n\\lambda_{51} & \\lambda_{52} \\\\\n\\lambda_{61} & \\lambda_{62} \\\\\n\\end{bmatrix}\n\\begin{bmatrix}{}\n\\xi_{1_{physical}}\\\\\n\\xi_{1_{intellectual}}\\\\\n\\end{bmatrix} + \\begin{bmatrix}{}\n\\delta_{1}\\\\\n\\delta_{2}\\\\\n\\delta_{3}\\\\\n\\delta_{4}\\\\\n\\delta_{5}\\\\\n\\delta_{6}\\\\\n\\end{bmatrix}\\]Örnekte AFA modeli aşağıdaki gibidir: \\[\\begin{bmatrix}{}\nX_{1 handsome}\\\\\nX_{2 betutiful}\\\\\nX_{3 ugly}\\\\\nX_{4 brillant}\\\\\nX_{5 smart}\\\\\nX_{6 dumb}\\\\\n\\end{bmatrix} = \\begin{bmatrix}{}\n\\lambda_{11} & \\lambda_{12} \\\\\n\\lambda_{21} & \\lambda_{22} \\\\\n\\lambda_{31} & \\lambda_{32} \\\\\n\\lambda_{41} & \\lambda_{42} \\\\\n\\lambda_{51} & \\lambda_{52} \\\\\n\\lambda_{61} & \\lambda_{62} \\\\\n\\end{bmatrix}\n\\begin{bmatrix}{}\n\\xi_{1_{physical}}\\\\\n\\xi_{1_{intellectual}}\\\\\n\\end{bmatrix} + \\begin{bmatrix}{}\n\\delta_{1}\\\\\n\\delta_{2}\\\\\n\\delta_{3}\\\\\n\\delta_{4}\\\\\n\\delta_{5}\\\\\n\\delta_{6}\\\\\n\\end{bmatrix}\\]\\(X\\) : gözlenen değişken matrisi ( \\(Vx1\\) )\\(\\Lambda\\) : yapısal katsayı matrisi ( \\(VxF\\) )\\(\\xi\\) : örtük değişken vektorü\\(\\delta\\) : ölçme hatası","code":"\n rbind(fa1*fa1, toplam= colSums(fa1*fa1)) %>% kable()"},{"path":"afa.html","id":"afa-modeli","chapter":"Bölüm 7 AFA","heading":"7.5 AFA Modeli","text":"AFA’da genellikle korelasyon matrisi analiz edildiğinden, AFA modeli\nmatris formunda aşağıdaki gibi temsil edilebilir:\n\\(R= \\Lambda\\Phi\\Lambda' + R_{res}\\)\nFaktörler ilk olarak dik olacak şekilde çıkarılacakları için,\n\\(\\Phi\\) bir birim matristir. Bu AFA modeli daha basit bir forma\nindirgenir: \\(R= \\Lambda\\Lambda' + R_{res}\\)\nAFA’da genellikle korelasyon matrisi analiz edildiğinden, AFA modeli\nmatris formunda aşağıdaki gibi temsil edilebilir:\\(R= \\Lambda\\Phi\\Lambda' + R_{res}\\)\\(R= \\Lambda\\Phi\\Lambda' + R_{res}\\)Faktörler ilk olarak dik olacak şekilde çıkarılacakları için,\n\\(\\Phi\\) bir birim matristir. Bu AFA modeli daha basit bir forma\nindirgenir: \\(R= \\Lambda\\Lambda' + R_{res}\\)Faktörler ilk olarak dik olacak şekilde çıkarılacakları için,\n\\(\\Phi\\) bir birim matristir. Bu AFA modeli daha basit bir forma\nindirgenir: \\(R= \\Lambda\\Lambda' + R_{res}\\)Asıl fikir üretilen korelasyon matrisinin \\(Ȓ\\) gözlenen\nkorelasyon matrisine \\(R\\) mümkün olduğunca yakın olmasını\nsağlayacak faktör yükleri matrisini \\(\\Lambda\\) bulmaktır.Asıl fikir üretilen korelasyon matrisinin \\(Ȓ\\) gözlenen\nkorelasyon matrisine \\(R\\) mümkün olduğunca yakın olmasını\nsağlayacak faktör yükleri matrisini \\(\\Lambda\\) bulmaktır.Sonuç olarak \\(R_{res}\\) mümkün olduğunca küçük olacaktır.Sonuç olarak \\(R_{res}\\) mümkün olduğunca küçük olacaktır.\\[\\begin{bmatrix}{}\n\\lambda_{11} & \\lambda_{12} \\\\\n\\lambda_{21} & \\lambda_{22} \\\\\n\\lambda_{31} & \\lambda_{32} \\\\\n\\lambda_{41} & \\lambda_{42} \\\\\n\\lambda_{51} & \\lambda_{52} \\\\\n\\lambda_{61} & \\lambda_{52} \\\\\n\\end{bmatrix}\\begin{bmatrix}{}\n\\lambda_{11} & \\lambda_{12} & \\lambda_{13} & \\lambda_{14} & \\lambda_{15} & \\lambda_{16}\\\\\n\\lambda_{21} & \\lambda_{22} & \\lambda_{23} & \\lambda_{24} & \\lambda_{25} & \\lambda_{26}\\\\\n\\end{bmatrix} + \\begin{bmatrix}{}\n\\Psi_{11}\\\\\n\\Psi_{11} & \\Psi_{21}\\\\\n\\Psi_{11} & \\Psi_{21} & \\Psi_{31}\\\\\n\\Psi_{11} & \\Psi_{21} & \\Psi_{31} & \\Psi_{41}\\\\\n\\Psi_{11} & \\Psi_{21} & \\Psi_{31} & \\Psi_{41} & \\Psi_{51}\\\\\n\\Psi_{11} & \\Psi_{21} & \\Psi_{31} & \\Psi_{41} & \\Psi_{51} & \\Psi_{61}\\\\\n\\end{bmatrix}\\]\\[=\\begin{bmatrix}{}\n\\lambda^2_{11} + \\lambda^2_{12} \\\\\n\\lambda_{21}\\lambda_{11}  + \\lambda_{22}\\lambda_{12} & \\lambda^2_{21}+ \\lambda^2_{22}\\\\\n\\lambda_{31}\\lambda_{11}  + \\lambda_{32}\\lambda_{12} &\\lambda_{31}\\lambda_{21}  + \\lambda_{32}\\lambda_{22}& \\lambda^2_{31}+ \\lambda^2_{32}\\\\\n\\lambda_{41}\\lambda_{11}  + \\lambda_{42}\\lambda_{12} &\\lambda_{41}\\lambda_{21}  + \\lambda_{42}\\lambda_{22}  &  \\lambda_{41}\\lambda_{31}+\\lambda_{42}\\lambda_{32}  & \\lambda^2_{41}+ \\lambda^2_{42}\\\\\n\\lambda_{51}\\lambda_{11}  + \\lambda_{52}\\lambda_{12} &\\lambda_{51}\\lambda_{21}  + \\lambda_{52}\\lambda_{22}  &  \\lambda_{51}\\lambda_{31}+\\lambda_{52}\\lambda_{32}  & \\lambda_{51}\\lambda_{41}+\\lambda_{52}\\lambda_{42}& \\lambda^2_{51}+ \\lambda^2_{52}\\\\\n\\lambda_{61}\\lambda_{11}  + \\lambda_{62}\\lambda_{12} &\\lambda_{61}\\lambda_{21}  + \\lambda_{62}\\lambda_{22}  &  \\lambda_{61}\\lambda_{31}+\\lambda_{62}\\lambda_{32}  & \\lambda_{61}\\lambda_{41}+\\lambda_{61}\\lambda_{42} &\n\\lambda_{61}\\lambda_{51}+\\lambda_{62}\\lambda_{52} & \\lambda^2_{61}+ \\lambda^2_{62}\\\\\n\\end{bmatrix} + \\begin{bmatrix}{}\n\\Psi_{11}\\\\\n\\Psi_{11} & \\Psi_{21}\\\\\n\\Psi_{11} & \\Psi_{21} & \\Psi_{31}\\\\\n\\Psi_{11} & \\Psi_{21} & \\Psi_{31} & \\Psi_{41}\\\\\n\\Psi_{11} & \\Psi_{21} & \\Psi_{31} & \\Psi_{41} & \\Psi_{51}\\\\\n\\Psi_{11} & \\Psi_{21} & \\Psi_{31} & \\Psi_{41} & \\Psi_{51} & \\Psi_{61}\\\\\n\\end{bmatrix}\\]","code":""},{"path":"afa.html","id":"afada-örneklem-büyüklüğü","chapter":"Bölüm 7 AFA","heading":"7.6 AFA’da Örneklem Büyüklüğü","text":"Örneklem büyüklüğü, AFA'da yapılanlar da dahil olmak üzere tüm\nistatistiksel tahminlerin kesinliğini etkiler.Örneklem büyüklüğü, AFA'da yapılanlar da dahil olmak üzere tüm\nistatistiksel tahminlerin kesinliğini etkiler.Çeşitli araştırmacılar, birey sayısının ölçülen değişkenlerin\nsayısına oranının bir fonksiyonu olan minimum örneklem büyüklüğü\niçin kurallar önermiştir. Önerilen oranlar genellikle\nölçülen değişken başına 10 ila 20 birey arasındadır.\nGorsuch (1983), mutlak minimum oranın değişken başına beş\nbirey olmasını, ancak herhangi bir analiz için örneklem\nbüyüklüğünün 100 bireyden az olmamasını önermiştir.\nÇeşitli araştırmacılar, birey sayısının ölçülen değişkenlerin\nsayısına oranının bir fonksiyonu olan minimum örneklem büyüklüğü\niçin kurallar önermiştir. Önerilen oranlar genellikleölçülen değişken başına 10 ila 20 birey arasındadır.ölçülen değişken başına 10 ila 20 birey arasındadır.Gorsuch (1983), mutlak minimum oranın değişken başına beş\nbirey olmasını, ancak herhangi bir analiz için örneklem\nbüyüklüğünün 100 bireyden az olmamasını önermiştir.Gorsuch (1983), mutlak minimum oranın değişken başına beş\nbirey olmasını, ancak herhangi bir analiz için örneklem\nbüyüklüğünün 100 bireyden az olmamasını önermiştir.Bazı Monte Carlo simülasyon araştırmaları şunları önermektedir\n(Guadagnoli & Velicer, 1988):\nFaktörlerin biri, örneklem büyüklüğüne bakılmaksızın,\n|0.6|’dan büyük yapı katsayılarına sahip dört veya daha\nfazla ölçülen değişken tarafından tanımlanır.\nFaktörlerin biri, örneklem büyüklüğü 150'den büyükse,\n|0.4|’dan civarında yapı katsayılarına sahip 10 veya\ndaha fazla ölçülen değişken tanımlanır.\nÖrneklem büyüklüğü en az 300 olmalıdır.\nBazı Monte Carlo simülasyon araştırmaları şunları önermektedir\n(Guadagnoli & Velicer, 1988):Faktörlerin biri, örneklem büyüklüğüne bakılmaksızın,\n|0.6|’dan büyük yapı katsayılarına sahip dört veya daha\nfazla ölçülen değişken tarafından tanımlanır.Faktörlerin biri, örneklem büyüklüğüne bakılmaksızın,\n|0.6|’dan büyük yapı katsayılarına sahip dört veya daha\nfazla ölçülen değişken tarafından tanımlanır.Faktörlerin biri, örneklem büyüklüğü 150'den büyükse,\n|0.4|’dan civarında yapı katsayılarına sahip 10 veya\ndaha fazla ölçülen değişken tanımlanır.Faktörlerin biri, örneklem büyüklüğü 150'den büyükse,\n|0.4|’dan civarında yapı katsayılarına sahip 10 veya\ndaha fazla ölçülen değişken tanımlanır.Örneklem büyüklüğü en az 300 olmalıdır.Örneklem büyüklüğü en az 300 olmalıdır.MacCallum, Widaman, Zhang ve Hong (1999), ortak varyansların tümü,\n.60 veya daha büyükse, örneklem büyüklüğü 60 kadar düşük olsa\nbile, örüntü katsayılarının doğru şekilde yeniden üretildiğini\nbulmuştur.MacCallum, Widaman, Zhang ve Hong (1999), ortak varyansların tümü,\n.60 veya daha büyükse, örneklem büyüklüğü 60 kadar düşük olsa\nbile, örüntü katsayılarının doğru şekilde yeniden üretildiğini\nbulmuştur.Ortak varyans değerleri 0.50 civarındaysa, 100 ila 200 arasında\nörneklem büyüklüğü gereklidir.Ortak varyans değerleri 0.50 civarındaysa, 100 ila 200 arasında\nörneklem büyüklüğü gereklidir.","code":""},{"path":"afa.html","id":"örnek-veri","chapter":"Bölüm 7 AFA","heading":"7.7 Örnek Veri","text":"Veri Amerika Birleşik Devletleri ve Kanada'daki üniversite\nkütüphanelerinde hizmet kalitesine ilişkin kullanıcı algıları\nçalışmasından (Cook & Thompson, 2001; Thompson, Cook, & Heath, 2001;\nThompson, Cook, & Thompson, 2002) rastgele örneklenmiştir.Veri Amerika Birleşik Devletleri ve Kanada'daki üniversite\nkütüphanelerinde hizmet kalitesine ilişkin kullanıcı algıları\nçalışmasından (Cook & Thompson, 2001; Thompson, Cook, & Heath, 2001;\nThompson, Cook, & Thompson, 2002) rastgele örneklenmiştir.Veri Thompson’ın (2004) kitabında Appendix ’da verilmiş olup 12\n(gözlenen/ölçülen) değişkene ilişkin 100 lisansüstü öğrenci ve 100\nakademik personel tarafından sağlanan derecelendirmeleri\niçermektedir.Veri Thompson’ın (2004) kitabında Appendix ’da verilmiş olup 12\n(gözlenen/ölçülen) değişkene ilişkin 100 lisansüstü öğrenci ve 100\nakademik personel tarafından sağlanan derecelendirmeleri\niçermektedir.Örnek veri 🔗EFA.sav için ilgili\nveriden ilk 11 değişkene ilişkin 100 lisansüstü öğrenci tarafından\nsağlanan derecelendirmeler alınmıştır. Örnek veride ele alınan 11\ngözlenen/ölçülen değişken aşağıdaki gibidir:Örnek veri 🔗EFA.sav için ilgili\nveriden ilk 11 değişkene ilişkin 100 lisansüstü öğrenci tarafından\nsağlanan derecelendirmeler alınmıştır. Örnek veride ele alınan 11\ngözlenen/ölçülen değişken aşağıdaki gibidir:","code":""},{"path":"afa.html","id":"ilişki-katsayıları-matrisi","chapter":"Bölüm 7 AFA","heading":"7.8 İlişki Katsayıları Matrisi","text":"Değişkenler için toplanan puanlar, değişkenler arasındaki iki\ndeğişkenli ilişkiler matrisini hesaplamak için kullanılır. AFA’da\nanaliz edilen bu ilişkiler matrisidir.Değişkenler için toplanan puanlar, değişkenler arasındaki iki\ndeğişkenli ilişkiler matrisini hesaplamak için kullanılır. AFA’da\nanaliz edilen bu ilişkiler matrisidir.Bir veri seti için ilişki matrisi verildiğinde (örneğin, \\(R_{11x11}\\)\n), faktör analizinin tüm adımları (faktör puanlarının hesaplanması\nhariç), orijinal verilere (örneğin, \\(X_{100x11}\\) erişim olmadan bile\ngerçekleştirilebilir.Bir veri seti için ilişki matrisi verildiğinde (örneğin, \\(R_{11x11}\\)\n), faktör analizinin tüm adımları (faktör puanlarının hesaplanması\nhariç), orijinal verilere (örneğin, \\(X_{100x11}\\) erişim olmadan bile\ngerçekleştirilebilir.Pearson momentler-çarpımı iki değişkenli korelasyon matrisi AFA’da\nen çok kullanılan ilişkiler matrisidir.\nÇoğu istatistiksel pakette, AFA'da varsayılan (kullanıcı\nvarsayılan seçimi değiştirmedikçe) ilişkilendirme matrisi\nPearson korelasyon matrisidir. Ancak başka seçenekler de vardır.\nPearson momentler-çarpımı iki değişkenli korelasyon matrisi AFA’da\nen çok kullanılan ilişkiler matrisidir.Çoğu istatistiksel pakette, AFA'da varsayılan (kullanıcı\nvarsayılan seçimi değiştirmedikçe) ilişkilendirme matrisi\nPearson korelasyon matrisidir. Ancak başka seçenekler de vardır.İlişkileri karakterize eden farklı istatistikler, verilerin farklı\nyönlerine duyarlıdır. Farklı ilişki istatistikleri, verilerin\naltında farklı ölçek düzeylerinin yattığını varsayar.İlişkileri karakterize eden farklı istatistikler, verilerin farklı\nyönlerine duyarlıdır. Farklı ilişki istatistikleri, verilerin\naltında farklı ölçek düzeylerinin yattığını varsayar.Örneğin, Pearson r, verilerin eşit aralıklı olarak\nölçeklenmesini gerektirir. Diğer yandan Spearman's rho, yalnızca\nverilerin en azından sıralı olarak ölçeklendiğini varsayar.Örneğin, Pearson r, verilerin eşit aralıklı olarak\nölçeklenmesini gerektirir. Diğer yandan Spearman's rho, yalnızca\nverilerin en azından sıralı olarak ölçeklendiğini varsayar.Spearman’s rho, aralık verileri bağları olmayan sıralamalara\ndönüştürüldüğünde, iki değişken arasındaki Pearson r'dir.Spearman’s rho, aralık verileri bağları olmayan sıralamalara\ndönüştürüldüğünde, iki değişken arasındaki Pearson r'dir.Aslında ister sıralı ister aralık verileriyle hesaplanmış olsun,\nSpearman’s rho şu soruya yanıt verir: İki değişken, bireyleri tam\nolarak aynı sırada mı sıralıyor? Pearson r bu soruyu da\ndeğerlendirir ancak sıralı puanlar arasındaki mesafeleri de hesaba\nkatar. Spearman’s rho, verilerde böyle bir bilginin bulunmadığını\nvarsayar (veya bu bilgiyi göz ardı eder), bu nedenle iki\ndeğişken de sıralı olarak ölçeklendiğinde rho kullanılabilir.Aslında ister sıralı ister aralık verileriyle hesaplanmış olsun,\nSpearman’s rho şu soruya yanıt verir: İki değişken, bireyleri tam\nolarak aynı sırada mı sıralıyor? Pearson r bu soruyu da\ndeğerlendirir ancak sıralı puanlar arasındaki mesafeleri de hesaba\nkatar. Spearman’s rho, verilerde böyle bir bilginin bulunmadığını\nvarsayar (veya bu bilgiyi göz ardı eder), bu nedenle iki\ndeğişken de sıralı olarak ölçeklendiğinde rho kullanılabilir.ikili puanlana veriler için ise korelasyon matrisinin tetrakorik\nkorelasyonlardan elde edilmesi gerekmektedir.ikili puanlana veriler için ise korelasyon matrisinin tetrakorik\nkorelasyonlardan elde edilmesi gerekmektedir.Bu iki ilişki matrisi, kovaryans matrisi de olabilir. Birçok\nbağlamda kovaryans, ilişkiyi veya ilişkiyi tanımlamak için değil,\nkorelasyon katsayısının elde edilmesinde bir ara hesaplama\nolarak kullanılır. Kovaryans nadiren kullanılır, çünkü\nkorelasyondan farklı olarak kovaryans, kesin bir olası değerler\naralığına sahip değildir.Bu iki ilişki matrisi, kovaryans matrisi de olabilir. Birçok\nbağlamda kovaryans, ilişkiyi veya ilişkiyi tanımlamak için değil,\nkorelasyon katsayısının elde edilmesinde bir ara hesaplama\nolarak kullanılır. Kovaryans nadiren kullanılır, çünkü\nkorelasyondan farklı olarak kovaryans, kesin bir olası değerler\naralığına sahip değildir.AFA’da analiz edilen ilişkiler matrisidir. Örnek veri için\n\\(R_{11 x 11}\\) korelasyon matrisi aşağıdaki gibidir","code":"\nlibrary(haven)\nEFA <- read_sav(\"import/EFA.sav\")\nmatris <- round(cor(EFA[,-c(1,13)]),2)\nmatris[upper.tri(matris)] <- NA\nmatris      per1 per2 per3 per4 per5 per6 per7 per8 per9 per10 per11\nper1  1.00   NA   NA   NA   NA   NA   NA   NA   NA    NA    NA\nper2  0.85 1.00   NA   NA   NA   NA   NA   NA   NA    NA    NA\nper3  0.79 0.72 1.00   NA   NA   NA   NA   NA   NA    NA    NA\nper4  0.78 0.70 0.69 1.00   NA   NA   NA   NA   NA    NA    NA\nper5  0.40 0.45 0.51 0.48 1.00   NA   NA   NA   NA    NA    NA\nper6  0.33 0.32 0.40 0.40 0.66 1.00   NA   NA   NA    NA    NA\nper7  0.48 0.50 0.50 0.52 0.80 0.71 1.00   NA   NA    NA    NA\nper8  0.42 0.45 0.49 0.43 0.78 0.63 0.71 1.00   NA    NA    NA\nper9  0.44 0.46 0.54 0.50 0.39 0.23 0.40 0.39 1.00    NA    NA\nper10 0.38 0.41 0.45 0.35 0.41 0.30 0.42 0.39 0.63  1.00    NA\nper11 0.43 0.49 0.55 0.42 0.46 0.25 0.42 0.44 0.68  0.59     1"},{"path":"afa.html","id":"kmo","chapter":"Bölüm 7 AFA","heading":"7.9 KMO","text":"AFA'da bir grup ölçülen değişkenden ortak faktör çıkarılması\nhedeflenmektedir. Bu nedenle değişkenler bazı ortak şeyler\npaylaşmalıdır. Eğer bu 11 değişkenin altında yatan hiçbir ortak\nfaktör yoksa evren korelasyon matrisi 11x11 boyutunda bir birim\nmatris olacaktır.\\[\\begin{bmatrix}{}\n1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\\n0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\\n0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\\n0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\\n0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0\\\\\n0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0\\\\\n0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0\\\\\n0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0\\\\\n0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0\\\\\n0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1\\\\\n\\end{bmatrix}\\]Bütün değişkenler birbirinden bağımsız olduğunda, veri indirgeme\nbaşarılamaz.Bütün değişkenler birbirinden bağımsız olduğunda, veri indirgeme\nbaşarılamaz.Kaiser-Meyer-Olkin measure sampling adequacy (KMO) değişkenler\narasındaki örtüşmenin derecesini inceler. Daha çok değişken ortak\nşeyler paylaşırsa, KMO değeri daha büyük olacaktır. Bu nedenle KMO\ndeğerinin büyük olması beklenir.Kaiser-Meyer-Olkin measure sampling adequacy (KMO) değişkenler\narasındaki örtüşmenin derecesini inceler. Daha çok değişken ortak\nşeyler paylaşırsa, KMO değeri daha büyük olacaktır. Bu nedenle KMO\ndeğerinin büyük olması beklenir.KMO değeri istatistiksel bir testle birlikte gelmez. Yeterliliğin\ndeğerlendirilmesi biraz kişiseldir.KMO değeri istatistiksel bir testle birlikte gelmez. Yeterliliğin\ndeğerlendirilmesi biraz kişiseldir.Araştırmacılar KMO değerinin ideal olarak 0,6’dan büyük olması\ngerektiğini önerirler. Örneğe 0,6 kuralı uygulanırsa, korelasyon\nmatrisinin evrendeki bir birim matrisinden farklı olduğu\nsöylenebilir.Araştırmacılar KMO değerinin ideal olarak 0,6’dan büyük olması\ngerektiğini önerirler. Örneğe 0,6 kuralı uygulanırsa, korelasyon\nmatrisinin evrendeki bir birim matrisinden farklı olduğu\nsöylenebilir.KMO() fonksiyonunun çıktısı incelendiğinde, hem tüm veri\niçin (Overall MSA) hem de bir madde için (MSA item)\nKMO değeri görülmektedir.KMO() fonksiyonunun çıktısı incelendiğinde, hem tüm veri\niçin (Overall MSA) hem de bir madde için (MSA item)\nKMO değeri görülmektedir.Çalışmalarda genellikle sadece tüm veri için elde edilen KMO değeri\nraporlanır. Madde bazında KMO değeri ise belirli bir maddenin\ntestin tamamından farklı olup olmadığına ilişkin bilgi verebilir.Çalışmalarda genellikle sadece tüm veri için elde edilen KMO değeri\nraporlanır. Madde bazında KMO değeri ise belirli bir maddenin\ntestin tamamından farklı olup olmadığına ilişkin bilgi verebilir.Veri seti iki kategorik ise KMO aşağıdaki şekilde hesaplanabilir.","code":"\nlibrary(psych)\nveri <- EFA[ ,-c(1,13)]\nKMO(veri)## Kaiser-Meyer-Olkin factor adequacy\n## Call: KMO(r = veri)\n## Overall MSA =  0.88\n## MSA for each item = \n##  per1  per2  per3  per4  per5  per6  per7  per8  per9 per10 per11 \n##  0.79  0.89  0.91  0.91  0.85  0.89  0.88  0.91  0.86  0.91  0.89\nkor_mat <- tetrachoric(veri)$rho\nKMO(kor_mat)"},{"path":"afa.html","id":"bartlettin-testi","chapter":"Bölüm 7 AFA","heading":"7.10 Bartlett’in Testi","text":"Korelasyon matrisinin bir birim matrisi (sıfır hipotezi) olup\nolmadığını test etmenin bir diğer yolu “Bartlett’s Test \nSphericity” olarak adlandırılır. Yaklaşık olarak bir ki-kare\ndağılımını izleyen istatistiksel bir testle birlikte gelir. Sıfır\nhipotezinin reddedilmesi beklenir.Burada sıfır hipotezi reddedilir. AFA analizi devam edebilir.","code":"\ncortest.bartlett(veri)## $chisq\n## [1] 808\n## \n## $p.value\n## [1] 2.51e-134\n## \n## $df\n## [1] 55"},{"path":"afa.html","id":"çıkarılacak-faktörlerin-sayısı","chapter":"Bölüm 7 AFA","heading":"7.11 Çıkarılacak Faktörlerin Sayısı","text":"AFA'da kritik kararlardan biri, kaç faktörün çıkarılacağını\nbelirlemektir. Bu kararı vermek için çok sayıda yaklaşım vardır. Bu\nyaklaşımlardan bazıları şunlardır:\nİstatistiksel anlamlılık testleri\nÖzdeğerin 1,0’dan büyük olması kuralı\nYamaç birikinti grafiği (scree plot)\nArtık korelasyon matrisinin incelenmesi\nParalel analiz\nAFA'da kritik kararlardan biri, kaç faktörün çıkarılacağını\nbelirlemektir. Bu kararı vermek için çok sayıda yaklaşım vardır. Bu\nyaklaşımlardan bazıları şunlardır:İstatistiksel anlamlılık testleriÖzdeğerin 1,0’dan büyük olması kuralıYamaç birikinti grafiği (scree plot)Artık korelasyon matrisinin incelenmesiParalel analizGenel olarak, bu kararı almak için farklı yaklaşımların birbirini\ndestekleyeceği umuduyla birkaç yaklaşım kullanılmalıdır.Genel olarak, bu kararı almak için farklı yaklaşımların birbirini\ndestekleyeceği umuduyla birkaç yaklaşım kullanılmalıdır.İstatistiksel Anlamlılık TestleriBartlett'e (1950) bağlı istatistiksel anlamlılık testleri,\nkorelasyon matrisinin bir birim matrisi olup olmadığını test etmek\niçin kullanılabilir. Korelasyon matrisinin bir birim matrisi\nolduğuna ilişkin sıfır hipotezi reddedilemezse, faktörler\nmatristen makul bir şekilde çıkarılamaz.Bartlett'e (1950) bağlı istatistiksel anlamlılık testleri,\nkorelasyon matrisinin bir birim matrisi olup olmadığını test etmek\niçin kullanılabilir. Korelasyon matrisinin bir birim matrisi\nolduğuna ilişkin sıfır hipotezi reddedilemezse, faktörler\nmatristen makul bir şekilde çıkarılamaz.Bu uygulamadaki sorun, tüm istatistiksel anlamlılık testlerinde\nkarşılaşılan genel sorundur. İstatistiksel anlamlılık, büyük ölçüde\nörneklem büyüklüğüne bağlıdır. Araştırmacılar genellikle AFA'yı\nyalnızca makul ölçüde büyük örneklemlerle kullandıklarından,\nönemsiz korelasyonlar veya faktörler bile istatistiksel olarak\nönemli olarak değerlendirilecektir. Bu nedenle, bu yaklaşım çok\nkullanışlı değildir.Bu uygulamadaki sorun, tüm istatistiksel anlamlılık testlerinde\nkarşılaşılan genel sorundur. İstatistiksel anlamlılık, büyük ölçüde\nörneklem büyüklüğüne bağlıdır. Araştırmacılar genellikle AFA'yı\nyalnızca makul ölçüde büyük örneklemlerle kullandıklarından,\nönemsiz korelasyonlar veya faktörler bile istatistiksel olarak\nönemli olarak değerlendirilecektir. Bu nedenle, bu yaklaşım çok\nkullanışlı değildir.Özdeğerin 1,0’dan Büyük Olması KuralıGuttman (1954), kayda değer faktörlerin özdeğerlerinin 1,0'dan\nbüyük olması gerektiğini düşünmüştür. Bazen bu mantık Kaiser'e\natfedilir ve K1 kuralı olarak adlandırılır.Guttman (1954), kayda değer faktörlerin özdeğerlerinin 1,0'dan\nbüyük olması gerektiğini düşünmüştür. Bazen bu mantık Kaiser'e\natfedilir ve K1 kuralı olarak adlandırılır.Faktörler, tanım gereği, gözlenen değişkenlerin toplamları olarak\noluşturulan gizli yapılardır ve bu nedenle birden fazla gözlenen\ndeğişkenden oluşmalıdır.Faktörler, tanım gereği, gözlenen değişkenlerin toplamları olarak\noluşturulan gizli yapılardır ve bu nedenle birden fazla gözlenen\ndeğişkenden oluşmalıdır.Bir faktör tek bir gözlenen değişkenden oluşuyorsa, gözlenen\ndeğişkenin örüntü/yapı katsayısı 1,0 (veya -1,0) olsa ve bu\nfaktördeki diğer tüm değişkenler 0 örüntü/yapı katsayılarına\nsahip olsa, faktörün özdeğeri 1,0 olacaktır. Dolayısıyla kayda\ndeğer faktörlerin (gözlenen değişkenlerin toplamlarını temsil eden\nyapıların) öz değerlerinin 1,0'dan büyük olması beklenmektedir.Bir faktör tek bir gözlenen değişkenden oluşuyorsa, gözlenen\ndeğişkenin örüntü/yapı katsayısı 1,0 (veya -1,0) olsa ve bu\nfaktördeki diğer tüm değişkenler 0 örüntü/yapı katsayılarına\nsahip olsa, faktörün özdeğeri 1,0 olacaktır. Dolayısıyla kayda\ndeğer faktörlerin (gözlenen değişkenlerin toplamlarını temsil eden\nyapıların) öz değerlerinin 1,0'dan büyük olması beklenmektedir.Özdeğerler, tüm örnek istatistikler gibi, bazı örnekleme hatalarına\nsahiptir. Bu nedenle bir araştırmacı kuram ve önceki ilgili AFA\naraştırmalarına dayanarak, özdeğeri ,999 veya ,950 olan bir\nfaktörü çıkarabilir veya özdeğeri 1,005 veya 1,100 olan bir\nfaktörü tutmayabilir.Özdeğerler, tüm örnek istatistikler gibi, bazı örnekleme hatalarına\nsahiptir. Bu nedenle bir araştırmacı kuram ve önceki ilgili AFA\naraştırmalarına dayanarak, özdeğeri ,999 veya ,950 olan bir\nfaktörü çıkarabilir veya özdeğeri 1,005 veya 1,100 olan bir\nfaktörü tutmayabilir.Bu kural çoğu istatistiksel paketteki faktörlerin sayısını\nbelirlemek için varsayılan karar verme stratejisidir.Bu kural çoğu istatistiksel paketteki faktörlerin sayısını\nbelirlemek için varsayılan karar verme stratejisidir.korelasyon matrisi için özdeğerleri rapor eder. Büyükten küçüğe\nsıralanan 11 özdeğer vardır.korelasyon matrisi için özdeğerleri rapor eder. Büyükten küçüğe\nsıralanan 11 özdeğer vardır.Bu özdeğerlerin toplamı 11’e (ölçülen değişkenlerin sayısına)\neşittir.Bu özdeğerlerin toplamı 11’e (ölçülen değişkenlerin sayısına)\neşittir.\\(6.078 + 1.521 + 1.154 + … + 0.168 + 0.099 = 11\\)İlk üç özdeğer 1’den büyüktür: 6,078, 1,521 ve 1,154. K1\nkuralına göre AFA’dan 3 faktör çıkarılacaktırİlk üç özdeğer 1’den büyüktür: 6,078, 1,521 ve 1,154. K1\nkuralına göre AFA’dan 3 faktör çıkarılacaktır3 faktör çıkarma işlemi3 faktör çıkarma işlemi","code":"\n fa(veri)$e.values\n sum(fa(veri)$e.values)##  [1] 6.078 1.521 1.154 0.456 0.400 0.333 0.301 0.254 0.236 0.168 0.099\n## [1] 11\nout <- fa(veri, nfactors = 3,fm=\"pa\",rotate=\"none\")\nout## Factor Analysis using method =  pa\n## Call: fa(r = veri, nfactors = 3, rotate = \"none\", fm = \"pa\")\n## Standardized loadings (pattern matrix) based upon correlation matrix\n##        PA1   PA2   PA3   h2    u2 com\n## per1  0.80 -0.45 -0.38 0.99 0.012 2.0\n## per2  0.78 -0.32 -0.21 0.75 0.252 1.5\n## per3  0.80 -0.25 -0.09 0.71 0.292 1.2\n## per4  0.75 -0.23 -0.21 0.67 0.335 1.4\n## per5  0.77  0.47 -0.01 0.82 0.179 1.7\n## per6  0.61  0.47 -0.14 0.61 0.388 2.0\n## per7  0.78  0.42 -0.08 0.80 0.204 1.6\n## per8  0.73  0.40 -0.01 0.68 0.315 1.5\n## per9  0.67 -0.22  0.48 0.72 0.280 2.1\n## per10 0.60 -0.07  0.41 0.53 0.465 1.8\n## per11 0.67 -0.14  0.44 0.67 0.334 1.8\n## \n##                        PA1  PA2  PA3\n## SS loadings           5.81 1.27 0.86\n## Proportion Var        0.53 0.12 0.08\n## Cumulative Var        0.53 0.64 0.72\n## Proportion Explained  0.73 0.16 0.11\n## Cumulative Proportion 0.73 0.89 1.00\n## \n## Mean item complexity =  1.7\n## Test of the hypothesis that 3 factors are sufficient.\n## \n## df null model =  55  with the objective function =  8.55 with Chi Square =  808\n## df of  the model are 25  and the objective function was  0.23 \n## \n## The root mean square of the residuals (RMSR) is  0.02 \n## The df corrected root mean square of the residuals is  0.03 \n## \n## The harmonic n.obs is  100 with the empirical chi square  3.49  with prob <  1 \n## The total n.obs was  100  with Likelihood Chi Square =  21.6  with prob <  0.66 \n## \n## Tucker Lewis Index of factoring reliability =  1.01\n## RMSEA index =  0  and the 90 % confidence intervals are  0 0.067\n## BIC =  -93.5\n## Fit based upon off diagonal values = 1\n## Measures of factor score adequacy             \n##                                                    PA1  PA2  PA3\n## Correlation of (regression) scores with factors   0.98 0.94 0.90\n## Multiple R square of scores with factors          0.97 0.89 0.81\n## Minimum correlation of possible factor scores     0.94 0.78 0.61"},{"path":"afa.html","id":"psych-fa","chapter":"Bölüm 7 AFA","heading":"7.12 psych fa()","text":"Yamaç Birikinti GrafiğiCattell (1966), faktörlerin sayısını belirlemek için grafiksel bir\ntest önermiştir. Cattell yöntemini dağ döküntüsü (scree) kavramına\ndayandırmıştır. Dağ döküntüsü, dağların eteklerinde toplanan,\ndağlara sağlam bir şekilde bağlanmamış gevşek kaya ve kaya\nparçalarının döküntüsüdür.Cattell (1966), faktörlerin sayısını belirlemek için grafiksel bir\ntest önermiştir. Cattell yöntemini dağ döküntüsü (scree) kavramına\ndayandırmıştır. Dağ döküntüsü, dağların eteklerinde toplanan,\ndağlara sağlam bir şekilde bağlanmamış gevşek kaya ve kaya\nparçalarının döküntüsüdür.Cattell büyük, sağlam, bozulmamış dağların; araştırmacıların\ntanıması ve tutması gereken sağlam, kayda değer faktörlere benzer\nolduğunu düşünmüştür. Bununla birlikte, önemsiz faktörler, dağ\ndöküntüsü ile benzerdir ve önemsiz faktörlerin faktör çıkarma\nsürecinde geride bırakılması gerekir.Cattell büyük, sağlam, bozulmamış dağların; araştırmacıların\ntanıması ve tutması gereken sağlam, kayda değer faktörlere benzer\nolduğunu düşünmüştür. Bununla birlikte, önemsiz faktörler, dağ\ndöküntüsü ile benzerdir ve önemsiz faktörlerin faktör çıkarma\nsürecinde geride bırakılması gerekir.Bir yamaç birikinti grafiğinde, yatay eksende özdeğer veya\nfaktör sayıları ile dikey eksende özdeğer büyüklüklerinin grafiği\nçizilir.Bir yamaç birikinti grafiğinde, yatay eksende özdeğer veya\nfaktör sayıları ile dikey eksende özdeğer büyüklüklerinin grafiği\nçizilir.Özdeğerler grafikte işaretlenir ve ardışık değerler bir çizgiyle\nbağlanır. Faktör çıkarma, bir dirsek bulunan noktada veya\ngrafiğin düzleştiği noktada durdurulmalıdır.Özdeğerler grafikte işaretlenir ve ardışık değerler bir çizgiyle\nbağlanır. Faktör çıkarma, bir dirsek bulunan noktada veya\ngrafiğin düzleştiği noktada durdurulmalıdır.İstatistiksel anlam içermeyen bu görsel yaklaşıma bazen kalem\ntesti denir, çünkü dirseğin veya düzleşmenin nerede oluştuğunu\nbelirlemek için ilgili grafiğin en sağ kısmına bir kalem\nyerleştirilebilir.\n\nscree(cor(veri), factors = FALSE)\nİstatistiksel anlam içermeyen bu görsel yaklaşıma bazen kalem\ntesti denir, çünkü dirseğin veya düzleşmenin nerede oluştuğunu\nbelirlemek için ilgili grafiğin en sağ kısmına bir kalem\nyerleştirilebilir.Artık Korelasyon Matrisinin İncelenmesiDaha fazla faktör çıkarıldıkça, artık korelasyon matrisindeki\ngirdiler sıfıra yaklaşır. Tüm olası faktörler çıkarılırsa, artık\nmatris zaman yalnızca sıfırlardan oluşacaktır.Daha fazla faktör çıkarıldıkça, artık korelasyon matrisindeki\ngirdiler sıfıra yaklaşır. Tüm olası faktörler çıkarılırsa, artık\nmatris zaman yalnızca sıfırlardan oluşacaktır.Dolayısıyla, kayda değer faktörlerin sayısını belirlemeye yönelik\ndiğer bir yaklaşım, ardışık faktörler çıkarılırken artık matrisin\nincelenmesini içerir.Dolayısıyla, kayda değer faktörlerin sayısını belirlemeye yönelik\ndiğer bir yaklaşım, ardışık faktörler çıkarılırken artık matrisin\nincelenmesini içerir.Yazılımlar talep üzerine artık matrisi sağlar. Ve bazı paketler\nartık matrisin bir üçgeninde |0.05|'den büyük olan girdilerin\nsayısını verir.Yazılımlar talep üzerine artık matrisi sağlar. Ve bazı paketler\nartık matrisin bir üçgeninde |0.05|'den büyük olan girdilerin\nsayısını verir.İdeal olarak artıkların değeri mümkün olduğunca sıfıra yakın\nolmalıdır.İdeal olarak artıkların değeri mümkün olduğunca sıfıra yakın\nolmalıdır.mutlak değeri ,05’ten büyük olan artıkların sayısını ve yüzdesini\nverir.mutlak değeri ,05’ten büyük olan artıkların sayısını ve yüzdesini\nverir.Paralel AnalizHorn (1965), kaç faktörün çıkarılacağına karar vermek için paralel\nanaliz adı verilen bir yaklaşım önermiştir.Horn (1965), kaç faktörün çıkarılacağına karar vermek için paralel\nanaliz adı verilen bir yaklaşım önermiştir.Paralel analiz veriden çıkarılacak faktör sayısının belirlenmesinde\nkullanılan, Monte Carlo simülasyonuna dayalı bir yöntemdir.Paralel analiz veriden çıkarılacak faktör sayısının belirlenmesinde\nkullanılan, Monte Carlo simülasyonuna dayalı bir yöntemdir.Paralel analiz veride herhangi bir baskın faktör olmasa bile\nörnekleme hatasının birden büyük öz değerlere neden olabileceği\nbilgisini temel alır.Paralel analiz veride herhangi bir baskın faktör olmasa bile\nörnekleme hatasının birden büyük öz değerlere neden olabileceği\nbilgisini temel alır.Veri ile aynı madde sayısı ve örneklem büyüklüğüne sahip rastgele\nmatrislerden öz değerler elde edilir ve bu değerler veriden elde\nedilen değerlerle karşılaştırılır.Veri ile aynı madde sayısı ve örneklem büyüklüğüne sahip rastgele\nmatrislerden öz değerler elde edilir ve bu değerler veriden elde\nedilen değerlerle karşılaştırılır.Faktör ya da bileşen sayısı, rastgele örneklemlerden elde edilen\nöz değerlerden büyük olan öz değer sayısına göre belirlenir\n(Franklin vd. 1995).\n\nfa.parallel(veri, fa = \"fa\")\n\n## Parallel analysis suggests number factors =  3  number components =  NAFaktör ya da bileşen sayısı, rastgele örneklemlerden elde edilen\nöz değerlerden büyük olan öz değer sayısına göre belirlenir\n(Franklin vd. 1995).Paralel analizde, gerçek verilerden ve rastgele sıralı verilerden\nardışık çiftlerdeki özdeğerler karşılaştırılır.Paralel analizde, gerçek verilerden ve rastgele sıralı verilerden\nardışık çiftlerdeki özdeğerler karşılaştırılır.Belirli bir faktör için gerçek verilerin özdeğeri, rastgele sıralı\nveriler için ilgili faktörün özdeğerini aştığında faktörler\nkorunur.Belirli bir faktör için gerçek verilerin özdeğeri, rastgele sıralı\nveriler için ilgili faktörün özdeğerini aştığında faktörler\nkorunur.","code":"\nscree(cor(veri), factors = FALSE)\n(residuals <-round(out$residual,2))##        per1  per2  per3  per4  per5  per6  per7  per8  per9 per10 per11\n## per1   0.01  0.01  0.00  0.00 -0.01 -0.01  0.01  0.01 -0.01  0.02 -0.01\n## per2   0.01  0.25  0.00 -0.01  0.01 -0.03  0.01  0.02 -0.03  0.00  0.02\n## per3   0.00  0.00  0.29  0.01  0.01  0.02 -0.04  0.00 -0.01 -0.01  0.02\n## per4   0.00 -0.01  0.01  0.33  0.00  0.02  0.01 -0.03  0.05 -0.03 -0.02\n## per5  -0.01  0.01  0.01  0.00  0.18 -0.03  0.00  0.03 -0.01 -0.02  0.02\n## per6  -0.01 -0.03  0.02  0.02 -0.03  0.39  0.03  0.00  0.00  0.02 -0.02\n## per7   0.01  0.01 -0.04  0.01  0.00  0.03  0.20 -0.03  0.01  0.01 -0.01\n## per8   0.01  0.02  0.00 -0.03  0.03  0.00 -0.03  0.32  0.00 -0.02  0.01\n## per9  -0.01 -0.03 -0.01  0.05 -0.01  0.00  0.01  0.00  0.28  0.02 -0.01\n## per10  0.02  0.00 -0.01 -0.03 -0.02  0.02  0.01 -0.02  0.02  0.47  0.00\n## per11 -0.01  0.02  0.02 -0.02  0.02 -0.02 -0.01  0.01 -0.01  0.00  0.33\nsum(abs(residuals[lower.tri(residuals)])>0.05)## [1] 0\nfa.parallel(veri, fa = \"fa\")## Parallel analysis suggests that the number of factors =  3  and the number of components =  NA\nlibrary(nFactors) \nPA<-nScree( x=out$e.values, aparallel=NULL,cor=TRUE, model=\"factors\", criteria=NULL) \nPA$Components\nplotnScree(PA, legend=TRUE, ylab=\"Ozdegerler\", main=\"Faktor Cozumu\")"},{"path":"afa.html","id":"örüntü-katsayıları-pattern-coefficients","chapter":"Bölüm 7 AFA","heading":"7.13 Örüntü Katsayıları (Pattern Coefficients)","text":"AFA modeli aşağıdaki gibidir.AFA modeli aşağıdaki gibidir.\\(X=\\Lambda\\xi +\\delta\\)\\(X=\\Lambda\\xi +\\delta\\)\\(\\Lambda\\) (lambda) matrisindeki katsayılara örüntü\nkatsayılarıdır. (DFA’daki faktör yüklerine ve çoklu regresyondaki\neğim katsayılarına benzerler).\\(\\Lambda\\) (lambda) matrisindeki katsayılara örüntü\nkatsayılarıdır. (DFA’daki faktör yüklerine ve çoklu regresyondaki\neğim katsayılarına benzerler).Örüntü katsayıları ölçülen değişkendeki puanları elde etmek için\nfaktöre uygulanan ağırlıklardır. bir faktörün bir ölçülen değişkendeki bireysel (unique) katkısını temsil ederler.Örüntü katsayıları ölçülen değişkendeki puanları elde etmek için\nfaktöre uygulanan ağırlıklardır. bir faktörün bir ölçülen değişkendeki bireysel (unique) katkısını temsil ederler.Bu tablo çıkarılan 3 faktör için örüntü katsayılarını listeler. Bu\ntabloya dayanarak bir değişken için eşitlik yazılabilir:\\(X=\\Lambda\\xi +\\delta\\)\\(per1= .80\\xi_1 + (-0.45)\\xi _2 + (-0.38)\\xi_3 + \\delta_1\\)\\(per2= .78\\xi_1 + (-0.32)\\xi_2 + (-0.21)\\xi_3 + \\delta_2\\)\n....................................................................................\\(per11= .67\\xi_1 + (-0.14)\\xi_2 + 0.44\\xi_3 + \\delta_3\\)Faktörler birbirinden bağımsız olduğundan, örüntü katsayısının\nkaresi, örneğin,Faktörler birbirinden bağımsız olduğundan, örüntü katsayısının\nkaresi, örneğin,\\(\\lambda^2_{11} = .80^2 = .64\\) değeri PER1 değişkenindeki varyansın\nyaklaşık %64,6’sının birinci faktör tarafından açıklandığını\nönerir. Benzer şekilde,\\(\\lambda^2_{11} = .80^2 = .64\\) değeri PER1 değişkenindeki varyansın\nyaklaşık %64,6’sının birinci faktör tarafından açıklandığını\nönerir. Benzer şekilde,\\(\\lambda^2_{12} = -0.45^2 = .20\\) , \\(\\lambda^2_{13} = -0.38^2 = .14\\) değeri PER1 değişkenindeki varyansın yaklaşık %20’inin\nve%14,4’ünün ikinci ve üçüncü faktör tarafından açıklandığını\nönerir.\\(\\lambda^2_{12} = -0.45^2 = .20\\) , \\(\\lambda^2_{13} = -0.38^2 = .14\\) değeri PER1 değişkenindeki varyansın yaklaşık %20’inin\nve%14,4’ünün ikinci ve üçüncü faktör tarafından açıklandığını\nönerir.Diğer örüntü katsayıları için de benzer açıklamalar yapılır.Diğer örüntü katsayıları için de benzer açıklamalar yapılır.","code":"\nout <- fa(veri,3,fm=\"pa\",rotate=\"none\")\nout$loadings[,1:3]##         PA1     PA2      PA3\n## per1  0.803 -0.4468 -0.37851\n## per2  0.775 -0.3224 -0.20784\n## per3  0.799 -0.2461 -0.09132\n## per4  0.753 -0.2298 -0.21389\n## per5  0.772  0.4739 -0.00517\n## per6  0.607  0.4716 -0.14484\n## per7  0.784  0.4178 -0.08044\n## per8  0.727  0.3954 -0.00837\n## per9  0.665 -0.2234  0.47732\n## per10 0.601 -0.0727  0.40929\n## per11 0.671 -0.1440  0.44205"},{"path":"afa.html","id":"ortak-varyans-katsayıları-communality-coefficients","chapter":"Bölüm 7 AFA","heading":"7.14 Ortak varyans Katsayıları (Communality Coefficients)","text":"Örüntü katsayıları ortak varyans katsayı ile yakından ilgilidir.\nOrtak varyans katsayısı \\(h^2\\) ile gösterilir.Örüntü katsayıları ortak varyans katsayı ile yakından ilgilidir.\nOrtak varyans katsayısı \\(h^2\\) ile gösterilir.Ortak varyans bir ölçülen değişkendeki varyansın ne kadarını bir\ngrup olarak faktörlerin üretebileceğini belirtir.Ortak varyans bir ölçülen değişkendeki varyansın ne kadarını bir\ngrup olarak faktörlerin üretebileceğini belirtir.Ortak varyans katsayısı DFA veya çoklu regresyondaki \\(R^2\\) değerine\nbenzer şekilde açıklanabilir.Ortak varyans katsayısı DFA veya çoklu regresyondaki \\(R^2\\) değerine\nbenzer şekilde açıklanabilir.bir gösterge için, ortak varyans katsayısı örüntü katsayılarının\nkareleri toplanarak hesaplanır.bir gösterge için, ortak varyans katsayısı örüntü katsayılarının\nkareleri toplanarak hesaplanır.Örneğin, PER1 değişkeni için:\n\\(\\lambda^2_{11} + \\lambda^2_{12} +\\lambda^2_{13} = .80^2 + (-0.45)^2 + (-0.38)^2 = .99\\)Örneğin, PER1 değişkeni için:\n\\(\\lambda^2_{11} + \\lambda^2_{12} +\\lambda^2_{13} = .80^2 + (-0.45)^2 + (-0.38)^2 = .99\\)Bu değer, toplamda PER1 değişkenindeki varyansın yaklaşık\n%99’unun çıkarılan 3 faktör tarafından açıklanacağını\nönerir.Bu değer, toplamda PER1 değişkenindeki varyansın yaklaşık\n%99’unun çıkarılan 3 faktör tarafından açıklanacağını\nönerir.bir değişken için ortak varyans hesaplanabilir. Örneğin per 11\niçinHer bir değişken için ortak varyans hesaplanabilir. Örneğin per 11\niçin\\(\\lambda^2_{11} + \\lambda^2_{12} +\\lambda^2_{13} = .67^2 + (-0.14)^2 + (-0.44)^2 = .67\\)Ortak varyans katsayısı 0 ile 1 arasında bir değer alır.Ortak varyans katsayısı 0 ile 1 arasında bir değer alır.İyi bir AFA modelinde, ortak varyans katsayılarının hepsinin\noldukça yüksek (1’e mümkün olduğunca yakın) olması beklenir.İyi bir AFA modelinde, ortak varyans katsayılarının hepsinin\noldukça yüksek (1’e mümkün olduğunca yakın) olması beklenir.Örneğin, PER1 için, varyansın yaklaşık %99’u 3 faktör tarafından\naçıklanır.Örneğin, PER1 için, varyansın yaklaşık %99’u 3 faktör tarafından\naçıklanır.PER1 için, varyansın yaklaşık %1’3 faktör tarafından\naçıklanmaz.PER1 için, varyansın yaklaşık %1’3 faktör tarafından\naçıklanmaz.%1 değeri PER1 maddesinin güvenilir olmayan kısmını belirtir.%1 değeri PER1 maddesinin güvenilir olmayan kısmını belirtir.Bazı alışılmadık durumlarda, %100’den büyük ortak varyans\nkatsayıları ile karşılaşmak mümkündür. Bu durumlar uygun olmayan\nçözümler olarak adlandırılır.Bazı alışılmadık durumlarda, %100’den büyük ortak varyans\nkatsayıları ile karşılaşmak mümkündür. Bu durumlar uygun olmayan\nçözümler olarak adlandırılır.","code":"\n  out## Factor Analysis using method =  pa\n## Call: fa(r = veri, nfactors = 3, rotate = \"none\", fm = \"pa\")\n## Standardized loadings (pattern matrix) based upon correlation matrix\n##        PA1   PA2   PA3   h2    u2 com\n## per1  0.80 -0.45 -0.38 0.99 0.012 2.0\n## per2  0.78 -0.32 -0.21 0.75 0.252 1.5\n## per3  0.80 -0.25 -0.09 0.71 0.292 1.2\n## per4  0.75 -0.23 -0.21 0.67 0.335 1.4\n## per5  0.77  0.47 -0.01 0.82 0.179 1.7\n## per6  0.61  0.47 -0.14 0.61 0.388 2.0\n## per7  0.78  0.42 -0.08 0.80 0.204 1.6\n## per8  0.73  0.40 -0.01 0.68 0.315 1.5\n## per9  0.67 -0.22  0.48 0.72 0.280 2.1\n## per10 0.60 -0.07  0.41 0.53 0.465 1.8\n## per11 0.67 -0.14  0.44 0.67 0.334 1.8\n## \n##                        PA1  PA2  PA3\n## SS loadings           5.81 1.27 0.86\n## Proportion Var        0.53 0.12 0.08\n## Cumulative Var        0.53 0.64 0.72\n## Proportion Explained  0.73 0.16 0.11\n## Cumulative Proportion 0.73 0.89 1.00\n## \n## Mean item complexity =  1.7\n## Test of the hypothesis that 3 factors are sufficient.\n## \n## df null model =  55  with the objective function =  8.55 with Chi Square =  808\n## df of  the model are 25  and the objective function was  0.23 \n## \n## The root mean square of the residuals (RMSR) is  0.02 \n## The df corrected root mean square of the residuals is  0.03 \n## \n## The harmonic n.obs is  100 with the empirical chi square  3.49  with prob <  1 \n## The total n.obs was  100  with Likelihood Chi Square =  21.6  with prob <  0.66 \n## \n## Tucker Lewis Index of factoring reliability =  1.01\n## RMSEA index =  0  and the 90 % confidence intervals are  0 0.067\n## BIC =  -93.5\n## Fit based upon off diagonal values = 1\n## Measures of factor score adequacy             \n##                                                    PA1  PA2  PA3\n## Correlation of (regression) scores with factors   0.98 0.94 0.90\n## Multiple R square of scores with factors          0.97 0.89 0.81\n## Minimum correlation of possible factor scores     0.94 0.78 0.61"},{"path":"afa.html","id":"yüklerin-kareleri-toplamı-açıklanan-varyans","chapter":"Bölüm 7 AFA","heading":"7.15 Yüklerin Kareleri Toplamı-Açıklanan Varyans","text":"bir faktör için, örüntü katsayılarının karesi toplanarak\nyüklerin kareleri toplamı hesaplanır.bir faktör için hesaplanan yüklerin karelerinin toplamının\nölçülen değişkenlerin sayısına bölünmesiyle elde edilen değer, \nbir faktör tarafından açıklanan varyans yüzdesini verir.Birinci faktör için:Bu değer 11 değişkendeki toplam varyansın birinci faktör\ntarafından açıklanan miktarıdır.Bu değer 11 değişkendeki toplam varyansın birinci faktör\ntarafından açıklanan miktarıdır.Örneğin, birinci faktör için elde edilen \\(5.814/11 = 52.85\\) değeri\n11 değişkendeki toplam varyansın yaklaşık % \\(52.85\\)’inin birinci\nfaktör tarafından açıklandığını önerirÖrneğin, birinci faktör için elde edilen \\(5.814/11 = 52.85\\) değeri\n11 değişkendeki toplam varyansın yaklaşık % \\(52.85\\)’inin birinci\nfaktör tarafından açıklandığını önerirİkinci faktör içinİkinci faktör içinBu değer 11 değişkendeki toplam varyansın ikini faktör tarafından\naçıklanan miktarıdır.Bu değer 11 değişkendeki toplam varyansın ikini faktör tarafından\naçıklanan miktarıdır.üçüncü faktör için\n\nsum($loadings[,3]^2)/11*100\n## [1] 7.81\nBu değer 11 değişkendeki toplam varyansın üçüncü faktör\ntarafından açıklanan miktarıdır.\nİkinci ve üçüncü faktör tarafından açıklanan varyans yüzdeleri\nde benzer şekilde hesaplanır.\nBöylece 3 faktör varyansların sırasıyla yaklaşık \\(52.86\\),\n\\(11.57\\) ve \\(7.81\\)’ini açıklar.\nüçüncü faktör içinBu değer 11 değişkendeki toplam varyansın üçüncü faktör\ntarafından açıklanan miktarıdır.Bu değer 11 değişkendeki toplam varyansın üçüncü faktör\ntarafından açıklanan miktarıdır.İkinci ve üçüncü faktör tarafından açıklanan varyans yüzdeleri\nde benzer şekilde hesaplanır.İkinci ve üçüncü faktör tarafından açıklanan varyans yüzdeleri\nde benzer şekilde hesaplanır.Böylece 3 faktör varyansların sırasıyla yaklaşık \\(52.86\\),\n\\(11.57\\) ve \\(7.81\\)’ini açıklar.Böylece 3 faktör varyansların sırasıyla yaklaşık \\(52.86\\),\n\\(11.57\\) ve \\(7.81\\)’ini açıklar.Eğer bu 3 faktör çıkarılmaya karar verilirse, 3 faktörün 11 değişkendeki\nvaryansın toplamda yaklaşık %72,23'ünü açıkladığı sonucuna\nvarılabilir","code":"\nsum(out$loadings[,1]^2)/11*100## [1] 52.9\nsum(out$loadings[,2]^2)/11*100## [1] 11.6\nsum(out$loadings[,3]^2)/11*100## [1] 7.81\nout$Vaccounted##                         PA1   PA2    PA3\n## SS loadings           5.814 1.271 0.8589\n## Proportion Var        0.529 0.116 0.0781\n## Cumulative Var        0.529 0.644 0.7222\n## Proportion Explained  0.732 0.160 0.1081\n## Cumulative Proportion 0.732 0.892 1.0000"},{"path":"afa.html","id":"üretilen-ve-artık-korelasyon-matrisleri","chapter":"Bölüm 7 AFA","heading":"7.16 Üretilen ve Artık Korelasyon Matrisleri","text":"Üretilen korelasyon matrisinin köşegenindeki öğeler çıkarılan ortak\nvaryanslardır.Üretilen korelasyon matrisinin köşegenindeki öğeler çıkarılan ortak\nvaryanslardır.","code":"\nfactor.model(out$loadings)##        per1  per2  per3  per4  per5  per6  per7  per8  per9 per10 per11\n## per1  0.988 0.845 0.787 0.788 0.410 0.332 0.474 0.410 0.453 0.361 0.436\n## per2  0.845 0.748 0.718 0.702 0.447 0.349 0.490 0.437 0.488 0.405 0.475\n## per3  0.787 0.718 0.708 0.678 0.501 0.383 0.531 0.484 0.543 0.461 0.531\n## per4  0.788 0.702 0.678 0.665 0.473 0.380 0.512 0.458 0.450 0.382 0.444\n## per5  0.410 0.447 0.501 0.473 0.821 0.693 0.804 0.749 0.405 0.428 0.447\n## per6  0.332 0.349 0.383 0.380 0.693 0.612 0.685 0.629 0.230 0.272 0.276\n## per7  0.474 0.490 0.531 0.512 0.804 0.685 0.796 0.736 0.390 0.408 0.430\n## per8  0.410 0.437 0.484 0.458 0.749 0.629 0.736 0.685 0.391 0.405 0.427\n## per9  0.453 0.488 0.543 0.450 0.405 0.230 0.390 0.391 0.720 0.612 0.689\n## per10 0.361 0.405 0.461 0.382 0.428 0.272 0.408 0.405 0.612 0.535 0.595\n## per11 0.436 0.475 0.531 0.444 0.447 0.276 0.430 0.427 0.689 0.595 0.666\nrep_matrix <- factor.model(out$loadings)\ndiag(rep_matrix)==out$communality##  per1  per2  per3  per4  per5  per6  per7  per8  per9 per10 per11 \n##  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE"},{"path":"afa.html","id":"faktörleştirme-yöntemi","chapter":"Bölüm 7 AFA","heading":"7.17 Faktörleştirme yöntemi","text":"psych paketinde kullanılan faktörleştirme yöntemlerinden\nbazıları: uls, ols, minres, wls, pa, ml...psych paketinde kullanılan faktörleştirme yöntemlerinden\nbazıları: uls, ols, minres, wls, pa, ml...pa (principial axis factoring) ve ml (maksimumum olabilirlik) en çok kullanılan yöntemlerdir.pa (principial axis factoring) ve ml (maksimumum olabilirlik) en çok kullanılan yöntemlerdir.ml çok değişkenli normalliği gerektirir. pa faktör yüklerinin nispetene küçük olduğu ve küçük örneklemlerde kararlı kestirimler yapar.ml çok değişkenli normalliği gerektirir. pa faktör yüklerinin nispetene küçük olduğu ve küçük örneklemlerde kararlı kestirimler yapar.","code":""},{"path":"afa.html","id":"faktörlerin-yorumlanması","chapter":"Bölüm 7 AFA","heading":"7.18 Faktörlerin Yorumlanması","text":"Örüntü katsayısı matrisi incelendiğinde aşağıdaki sonuçlar\nçıkarılabilir:11 değişkenin hepsinin birinci faktördeki yükleri orta veya\nyüksektir.11 değişkenin hepsinin birinci faktördeki yükleri orta veya\nyüksektir.İkinci ve üçüncü faktördeki yükler daha küçüktür, bazıları\nnegatif bazıları ise pozitif değerlerdedir.İkinci ve üçüncü faktördeki yükler daha küçüktür, bazıları\nnegatif bazıları ise pozitif değerlerdedir.Ancak örüntü matrisi tablosu incelenerek bu 11 değişkenden 3 faktörü\nayırmak ve yorumlamak oldukça zordur.Ancak örüntü matrisi tablosu incelenerek bu 11 değişkenden 3 faktörü\nayırmak ve yorumlamak oldukça zordur.Aşağıdaki grafikte 3 küme birikinti görünmektedir:Aşağıdaki grafikte 3 küme birikinti görünmektedir:PER1-4 birlikte, PER5-8 birlikte, PER9-11 birliktePER1-4 birlikte, PER5-8 birlikte, PER9-11 birlikteEğer faktör eksenleri faktör uzayında hareket ederse, altta yatan\nfaktörlerin doğası daha açık hale gelecektir. Bu da Faktör\nDöndürme (Factor Rotation) adı verilen bir yöntemle\ngerçekleştirilirEğer faktör eksenleri faktör uzayında hareket ederse, altta yatan\nfaktörlerin doğası daha açık hale gelecektir. Bu da Faktör\nDöndürme (Factor Rotation) adı verilen bir yöntemle\ngerçekleştirilir","code":"\nout$loadings## \n## Loadings:\n##       PA1    PA2    PA3   \n## per1   0.803 -0.447 -0.379\n## per2   0.775 -0.322 -0.208\n## per3   0.799 -0.246       \n## per4   0.753 -0.230 -0.214\n## per5   0.772  0.474       \n## per6   0.607  0.472 -0.145\n## per7   0.784  0.418       \n## per8   0.727  0.395       \n## per9   0.665 -0.223  0.477\n## per10  0.601         0.409\n## per11  0.671 -0.144  0.442\n## \n##                  PA1   PA2   PA3\n## SS loadings    5.814 1.271 0.859\n## Proportion Var 0.529 0.116 0.078\n## Cumulative Var 0.529 0.644 0.722"},{"path":"afa.html","id":"maddelerin-analizden-çıkarılması","chapter":"Bölüm 7 AFA","heading":"7.19 Maddelerin Analizden Çıkarılması","text":"Çoğu durumda, maddelerin ileri analizlerden çıkarılması\ndüşünülebilir. Bu durum aşağıdakiler ile karşılaşıldığında\ndüşünülebilir:\nMaddeler düşük ortak varyanslara sahipse\nMaddelerin diğer maddelerle aralarındaki korelasyon zayıfsa\nMaddeler beklenmeyen faktörlerde çapraz yüklere sahipse\nFaktörler yorumlanabilir değilse\nÇoğu durumda, maddelerin ileri analizlerden çıkarılması\ndüşünülebilir. Bu durum aşağıdakiler ile karşılaşıldığında\ndüşünülebilir:Maddeler düşük ortak varyanslara sahipseMaddeler düşük ortak varyanslara sahipseMaddelerin diğer maddelerle aralarındaki korelasyon zayıfsaMaddelerin diğer maddelerle aralarındaki korelasyon zayıfsaMaddeler beklenmeyen faktörlerde çapraz yüklere sahipseMaddeler beklenmeyen faktörlerde çapraz yüklere sahipseFaktörler yorumlanabilir değilseFaktörler yorumlanabilir değilseGenel olarak geride kalan maddelerle yeni bir AFA’nın\ngerçekleştirilmesi gerekmektedir.Genel olarak geride kalan maddelerle yeni bir AFA’nın\ngerçekleştirilmesi gerekmektedir.","code":""},{"path":"afa.html","id":"faktör-döndürmenin-amacı","chapter":"Bölüm 7 AFA","heading":"7.20 Faktör Döndürmenin Amacı","text":"İlk çözümde PER1-PER11 ölçülen değişkenlerinden 3 faktör çıkarıldı.İlk çözümde PER1-PER11 ölçülen değişkenlerinden 3 faktör çıkarıldı.Hem örüntü katsayısı matrisi hem de yük grafiği 3- faktörlü\nçözümün yorumlanmasının zor olduğunu gösterdi.Hem örüntü katsayısı matrisi hem de yük grafiği 3- faktörlü\nçözümün yorumlanmasının zor olduğunu gösterdi.İdeal olarak bir değişkenin sadece bir faktöre yüklenmesi(factor\ncomplexity = 1 u2) beklenir basit yapıİdeal olarak bir değişkenin sadece bir faktöre yüklenmesi(factor\ncomplexity = 1 u2) beklenir basit yapıAFA’dan elde edilen çoğu ilk çözümler ile basit bir yapı elde\nedilemeyebilir. Faktör döndürmenin amacı bu hedefe ulaşmaktır.AFA’dan elde edilen çoğu ilk çözümler ile basit bir yapı elde\nedilemeyebilir. Faktör döndürmenin amacı bu hedefe ulaşmaktır.Faktör döndürme, faktör uzayında ölçülen değişkenlerin\nkonumlarını ölçen faktör eksenlerinin hareket ettirilmesini\niçerir, böylece altta yatan yapıların doğası araştırmacı için daha\naçık hale gelir.Faktör döndürme, faktör uzayında ölçülen değişkenlerin\nkonumlarını ölçen faktör eksenlerinin hareket ettirilmesini\niçerir, böylece altta yatan yapıların doğası araştırmacı için daha\naçık hale gelir.Yalnızca bir faktör çıkarıldığında, döndürme mümkün değildir. Ancak,\niki veya daha fazla faktör içeren hemen hemen tüm durumlarda,\nyorumlama için döndürme genellikle gereklidir.\nİki tip faktör döndürme vardır:\nDik Döndürme (Orthogonal Rotation):\nÇıkarılan faktörler döndürme işleminden sonra dik olarak\nkalırlar. Bu yöntem genellikle araştırmacıların altta yatan\nfaktörler arasında korelasyon olmadığına inandığı zaman\nuygulanır.\n\nEğik Döndürme (Oblique Rotation):\nDöndürme işleminden sonra çıkarılan faktörlerin arasında\nkorelasyon olmasına izin verilir. Bu yöntem genellikle\naraştırmacıların altta yatan faktörlerin ilişkili olduğunu\nvarsaydıkları zaman uygulanır.\n\nYalnızca bir faktör çıkarıldığında, döndürme mümkün değildir. Ancak,\niki veya daha fazla faktör içeren hemen hemen tüm durumlarda,\nyorumlama için döndürme genellikle gereklidir.İki tip faktör döndürme vardır:\nDik Döndürme (Orthogonal Rotation):\nÇıkarılan faktörler döndürme işleminden sonra dik olarak\nkalırlar. Bu yöntem genellikle araştırmacıların altta yatan\nfaktörler arasında korelasyon olmadığına inandığı zaman\nuygulanır.\nİki tip faktör döndürme vardır:Dik Döndürme (Orthogonal Rotation):Dik Döndürme (Orthogonal Rotation):Çıkarılan faktörler döndürme işleminden sonra dik olarak\nkalırlar. Bu yöntem genellikle araştırmacıların altta yatan\nfaktörler arasında korelasyon olmadığına inandığı zaman\nuygulanır.Çıkarılan faktörler döndürme işleminden sonra dik olarak\nkalırlar. Bu yöntem genellikle araştırmacıların altta yatan\nfaktörler arasında korelasyon olmadığına inandığı zaman\nuygulanır.Eğik Döndürme (Oblique Rotation):\nDöndürme işleminden sonra çıkarılan faktörlerin arasında\nkorelasyon olmasına izin verilir. Bu yöntem genellikle\naraştırmacıların altta yatan faktörlerin ilişkili olduğunu\nvarsaydıkları zaman uygulanır.\nEğik Döndürme (Oblique Rotation):Döndürme işleminden sonra çıkarılan faktörlerin arasında\nkorelasyon olmasına izin verilir. Bu yöntem genellikle\naraştırmacıların altta yatan faktörlerin ilişkili olduğunu\nvarsaydıkları zaman uygulanır.Aşağıdaki örüntü katsayılarına sahip iki değişken olduğunu\nvarsayalım:Aşağıdaki örüntü katsayılarına sahip iki değişken olduğunu\nvarsayalım:bir değişken için eşitlik aşağıdaki gibidir:\\(x_1= .6\\xi_1 + .6\\xi_2 + \\delta_1\\)\\(x_2= .6\\xi_1 + (-6)\\xi_2 + \\delta_2\\)Faktörlere karşılık gelen örüntü katsayıları aşağıdaki grafikte\ngösterilebilir.İki değişkenin iki faktörde de yükü olduğundan, faktörleri\nyorumlamak çok zordur. Eğer bir değişken sadece bir faktöre\nyüklenip diğerlerine yüklenmezse, yorum yapmak daha kolay olacaktır.İki değişkenin iki faktörde de yükü olduğundan, faktörleri\nyorumlamak çok zordur. Eğer bir değişken sadece bir faktöre\nyüklenip diğerlerine yüklenmezse, yorum yapmak daha kolay olacaktır.Faktör döndürmenin amacı, faktör uzayındaki faktör eksenlerini\ndöndürmektir. Döndürme sonucunda altta yatan faktörler mümkün\nolduğunca basit bir yapıya sahip olacaktır.Faktör döndürmenin amacı, faktör uzayındaki faktör eksenlerini\ndöndürmektir. Döndürme sonucunda altta yatan faktörler mümkün\nolduğunca basit bir yapıya sahip olacaktır.Eğer iki eksen de saat yönünde 45° döndürülürse:Eğer iki eksen de saat yönünde 45° döndürülürse:X1 sadece yeni F2’de yüklenecek, X2 de sadece yeni F1’de\nyüklenecektir.X1 sadece yeni F2’de yüklenecek, X2 de sadece yeni F1’de\nyüklenecektir.İki yeni faktör arasında da korelasyon yoktur.İki yeni faktör arasında da korelasyon yoktur.X1 ve X2 arasındaki ilişki döndürmeden önce ve sonra değişmez.\nYeni faktör uzayındaki bir değişkenin faktörlerdeki yükleri\ndeğişir.X1 ve X2 arasındaki ilişki döndürmeden önce ve sonra değişmez.\nYeni faktör uzayındaki bir değişkenin faktörlerdeki yükleri\ndeğişir.Yeni yükler gözle bakarak kestirilebilir:\nX1’yeni F1’deki yükü 0’dır; X1’yeni F2’deki yükü 0,85\ncivarındadır;\nX2’nin yeni F1’deki yükü 0,85 civarındadır; X2’nin yeni F2’deki\nyükü 0’dır.\nYeni yükler gözle bakarak kestirilebilir:X1’yeni F1’deki yükü 0’dır; X1’yeni F2’deki yükü 0,85\ncivarındadır;X1’yeni F1’deki yükü 0’dır; X1’yeni F2’deki yükü 0,85\ncivarındadır;X2’nin yeni F1’deki yükü 0,85 civarındadır; X2’nin yeni F2’deki\nyükü 0’dır.X2’nin yeni F1’deki yükü 0,85 civarındadır; X2’nin yeni F2’deki\nyükü 0’dır.Böylece, yeni örüntü matrisiBöylece, yeni örüntü matrisiAsıl soru orijinal örüntü matrisinin döndürülen örüntü matrisine\nnasıl dönüştürüldüğüdür?Geometrik işlemler sonucu, dönüştürülen yük tam olarak aşağıdaki\ngibi elde edilir: \\(0.6\\sqrt{0.2}=.848\\)","code":""},{"path":"afa.html","id":"dik-döndürme","chapter":"Bölüm 7 AFA","heading":"7.21 Dik Döndürme","text":"AFA modeli aşağıdaki eşitlikle gösterilebilir:\n\\(x= \\Lambda\\xi + \\delta\\)\nAFA modeli aşağıdaki eşitlikle gösterilebilir:\\(x= \\Lambda\\xi + \\delta\\)Λ matrisinin bir birim matrisi ile çarpılması eşitliği\ndeğiştirmeyecektir:\n\\(x= \\Lambda**\\xi + \\delta\\)\nΛ matrisinin bir birim matrisi ile çarpılması eşitliği\ndeğiştirmeyecektir:\\(x= \\Lambda**\\xi + \\delta\\)Bir T matrisi transpozu olan T’ ile çarpılırsa, çarpım bir birim\nmatrisine eşit olacaktır:\n\\(x= \\Lambda*(TT')*\\xi + \\delta\\) =>\n\\(x= (\\Lambda*T)(T'*\\xi) + \\delta\\)\nBir T matrisi transpozu olan T’ ile çarpılırsa, çarpım bir birim\nmatrisine eşit olacaktır:\\(x= \\Lambda*(TT')*\\xi + \\delta\\) =>\\(x= (\\Lambda*T)(T'*\\xi) + \\delta\\)Bu yeni eşitliğe dayalı model, örüntü matrisindeki ve artık\nmatrisindeki değerler de dahil olmak üzere parametre kestirimlerini\ndeğiştirmeyecektir, çünkü:\n\\(x= (\\Lambda*T)(T'*\\xi) + \\delta\\)\n\\(x= \\Lambda*T \\phi T'*\\Lambda'+ R_{res}\\)\nBu yeni eşitliğe dayalı model, örüntü matrisindeki ve artık\nmatrisindeki değerler de dahil olmak üzere parametre kestirimlerini\ndeğiştirmeyecektir, çünkü:\\(x= (\\Lambda*T)(T'*\\xi) + \\delta\\)\\(x= \\Lambda*T \\phi T'*\\Lambda'+ R_{res}\\)Burada \\(\\phi\\) bir birim matristir. Böylece verilen eşitlik aşağıdaki\neşitliğe indirgenebilir:\n\\(x= \\Lambda*TT'TT'*\\Lambda' + R_{res}\\)\nBurada \\(\\phi\\) bir birim matristir. Böylece verilen eşitlik aşağıdaki\neşitliğe indirgenebilir:\\(x= \\Lambda*TT'TT'*\\Lambda' + R_{res}\\)Burada TT’TT’ iki tane birim matrise eşit olduğundan, verilen\neşitlik aşağıdaki eşitliğe indirgenebilir:\n\\(x= \\Lambda*\\Lambda' + R_{res}\\)\n\\(x= (\\Lambda*T)(T'*\\xi) + \\delta\\) eşitliğindeki T matrisi\ntransformasyon matrisi olarak adlandırılır ve ΛT matrislerinin\nçarpımıyla elde edilen matris döndürülen örüntü matrisi olarak\nadlandırılır.\nBurada TT’TT’ iki tane birim matrise eşit olduğundan, verilen\neşitlik aşağıdaki eşitliğe indirgenebilir:\\(x= \\Lambda*\\Lambda' + R_{res}\\)\\(x= \\Lambda*\\Lambda' + R_{res}\\)\\(x= (\\Lambda*T)(T'*\\xi) + \\delta\\) eşitliğindeki T matrisi\ntransformasyon matrisi olarak adlandırılır ve ΛT matrislerinin\nçarpımıyla elde edilen matris döndürülen örüntü matrisi olarak\nadlandırılır.\\(x= (\\Lambda*T)(T'*\\xi) + \\delta\\) eşitliğindeki T matrisi\ntransformasyon matrisi olarak adlandırılır ve ΛT matrislerinin\nçarpımıyla elde edilen matris döndürülen örüntü matrisi olarak\nadlandırılır.İki faktör olduğunda, T matrisi aşağıdaki gibidir:İki faktör olduğunda, T matrisi aşağıdaki gibidir:\\[\\begin{bmatrix}{}\ncos()  &   sin()\\\\\n-sin()  &  cos()\n\\end{bmatrix}\\]Burada \\(\\) saat yönünde döndürme açısıdır. Verilen örnekte\\[\\begin{bmatrix}{}\n.6 &   .6\\\\\n.6  &  -.6\n\\end{bmatrix} * \\begin{bmatrix}{}\n\\frac{\\sqrt{2}}{2} &   \\frac{\\sqrt{2}}{2}\\\\\n-\\frac{\\sqrt{2}}{2}  &  \\frac{\\sqrt{2}}{2}\n\\end{bmatrix} = \\begin{bmatrix}{}\n0 & 0.0848\\\\\n0.0848 & 0\\\\\n\\end{bmatrix}\\]Varimax: En yaygın olarak kullanılan dik döndürme yöntemidir. \nbir faktörde yüksek yüke sahip değişkenlerin sayısını küçültür. Sonuç\nolarak, bu yöntem faktörlerin yorumlanmasını sadeleştirir.Quartimax: değişkeni açıklamak için gerekli faktör sayısını\nküçültür. Sonuç olarak bu yöntem gözlenen değişkenlerin yorumlanmasını\nkolaylaştırır.Equamax: Varimax ve Quartimax’ın bileşimidir.Döndürmeden önce, bir faktör için yüklerin kareleri toplamı\nörüntü katsayılarının kareleri toplanarak hesaplanır.Döndürmeden önce, bir faktör için yüklerin kareleri toplamı\nörüntü katsayılarının kareleri toplanarak hesaplanır.Döndürülen yüklerin kareleri toplamı da aynı şekilde hesaplanır\nancak döndürülen örüntü matrisindeki yüklerin kareleri toplanırDöndürülen yüklerin kareleri toplamı da aynı şekilde hesaplanır\nancak döndürülen örüntü matrisindeki yüklerin kareleri toplanır\\(0.958^2 + 0.777^2 +...+0.263^2\\)Toplam Açıklanan Varyans3 faktör tarafından açıklanan toplam varyans döndürmeden önce ve\nsonra aynıdır (yaklaşık %72,23).3 faktör tarafından açıklanan toplam varyans döndürmeden önce ve\nsonra aynıdır (yaklaşık %72,23).Ancak bir faktör tarafından açıklanan varyans miktarı faktör\neksenleri faktör uzayında döndürüldükten sonra yeniden dağıtılır.Ancak bir faktör tarafından açıklanan varyans miktarı faktör\neksenleri faktör uzayında döndürüldükten sonra yeniden dağıtılır.","code":"\nout_dik <- fa(veri,3,fm=\"pa\",rotate=\"varimax\")\nprint(out_dik$loadings[,1:3], digits = 3, cut = 0.30)##         PA1   PA2    PA3\n## per1  0.957 0.186 0.1924\n## per2  0.777 0.242 0.2919\n## per3  0.686 0.299 0.3838\n## per4  0.713 0.302 0.2545\n## per5  0.210 0.836 0.2777\n## per6  0.184 0.756 0.0788\n## per7  0.290 0.811 0.2340\n## per8  0.229 0.748 0.2700\n## per9  0.287 0.152 0.7842\n## per10 0.197 0.243 0.6611\n## per11 0.263 0.223 0.7397\nsum(out_dik$loadings[,1]^2)## [1] 2.91\nout$Vaccounted[2:3,]\nout_dik$Vaccounted[2:3,]##                  PA1   PA2    PA3\n## Proportion Var 0.529 0.116 0.0781\n## Cumulative Var 0.529 0.644 0.7222\n##                  PA1   PA2   PA3\n## Proportion Var 0.264 0.263 0.195\n## Cumulative Var 0.264 0.527 0.722"},{"path":"afa.html","id":"dik-döndürmede-yük-grafiği","chapter":"Bölüm 7 AFA","heading":"7.21.1 Dik Döndürmede Yük Grafiği","text":"döndürmeden sonraki çözüm için yük grafiği verilirDöndürmeden önceki yük grafiğiylekarşılaştırınca değişkenler arasındaki ilişkiler değişmez ancak\nfaktör uzayındaki faktör eksenleri değişir.Döndürmeden önceki çözümle karşılaştırınca, dik döndürmeye dayalı\n3-faktörlü yapı daha basittir. Ancak halen yeterince basit\ndeğildir: Bazı değişkenlerin sadece bir faktöre mümkün olduğunca\nyüklenip diğerlerine yüklenmemesi beklenir.Döndürmeden önceki çözümle karşılaştırınca, dik döndürmeye dayalı\n3-faktörlü yapı daha basittir. Ancak halen yeterince basit\ndeğildir: Bazı değişkenlerin sadece bir faktöre mümkün olduğunca\nyüklenip diğerlerine yüklenmemesi beklenir.Örneğin, aşağıdaki 3 yük önemsiz değildir.Örneğin, aşağıdaki 3 yük önemsiz değildir.Eğik döndürme daha basit yapı bulmak için kullanılır. Eğik\ndöndürmeden sonra faktörler arasındaki ilişki sıfır olarak kalmaz.Eğik döndürme daha basit yapı bulmak için kullanılır. Eğik\ndöndürmeden sonra faktörler arasındaki ilişki sıfır olarak kalmaz.Direct oblimin eğik döndürme yöntemi döndürülen faktörler\narasındaki korelasyonların derecesini kontrol etmek üzere Delta adı\nverilen bir değere başvurur. Delta -9999 ile 0,8 arasında bir değer\nalır.\nDefault olarak delta değeri sıfıra eşittir. Bu değer daha yüksek\nkorelasyona sahip faktörler sağlar. Eksi değerler aralarında\nkorelasyon bulunmayan faktörler üretir.\nDirect oblimin eğik döndürme yöntemi döndürülen faktörler\narasındaki korelasyonların derecesini kontrol etmek üzere Delta adı\nverilen bir değere başvurur. Delta -9999 ile 0,8 arasında bir değer\nalır.Default olarak delta değeri sıfıra eşittir. Bu değer daha yüksek\nkorelasyona sahip faktörler sağlar. Eksi değerler aralarında\nkorelasyon bulunmayan faktörler üretir.: Eğik çözümün gerektiği durumlarda, promax genellikle daha iyi\nbir seçimdir.Promax eğik döndürme yöntemi döndürülen faktörler arasındaki\nkorelasyonların derecesini kontrol etmek üzere Kappa adı verilen bir\ndeğere başvurur. Kappa 1 ile 9999 arasında bir değer alır.\nDefault olarak kappa değeri 4’e eşittir. 4’ten küçük değerler\ndaha daha az korelasyona sahip faktörler, 4’ten büyük değerlerse\ndaha yüksek korelasyona sahip faktörler üretir.\nPromax eğik döndürme yöntemi döndürülen faktörler arasındaki\nkorelasyonların derecesini kontrol etmek üzere Kappa adı verilen bir\ndeğere başvurur. Kappa 1 ile 9999 arasında bir değer alır.Default olarak kappa değeri 4’e eşittir. 4’ten küçük değerler\ndaha daha az korelasyona sahip faktörler, 4’ten büyük değerlerse\ndaha yüksek korelasyona sahip faktörler üretir.: Promax döndürme direct oblimin döndürmeden daha hızlı\nhesaplanabildiğinden büyük veri setleri için kullanışlıdır.Faktörler arasında ilişki olduğundan, Φ korelasyon matrisi artık bir\nbirim matris değildir.Faktörler arasında ilişki olduğundan, Φ korelasyon matrisi artık bir\nbirim matris değildir.Bu nedenle, döndürülen çözüm için model eşitliği aşağıdaki şekilde\ngösterilir:Bu nedenle, döndürülen çözüm için model eşitliği aşağıdaki şekilde\ngösterilir:Burada \\(\\Lambda_T\\) döndürülen örüntü matrisini simgeler.\\(x= \\Lambda_T*\\Lambda'_T+ R_{res}\\)Burada \\(\\Lambda_T\\) döndürmeden önceki örüntü matrisidir.Hangi egik döndürme seçeneği seçilirse seçilsin,Hangi egik döndürme seçeneği seçilirse seçilsin,Örüntü matrisi (Pattern matrix): Döndürmeden önceki örüntü\nmatristir.Örüntü matrisi (Pattern matrix): Döndürmeden önceki örüntü\nmatristir.Döndürülen örüntü matrisi: Eğik döndürmeden sonraki örüntü\nmatrisidir.Döndürülen örüntü matrisi: Eğik döndürmeden sonraki örüntü\nmatrisidir.Ancak dik döndürmede olduğu gibi “Rotated Factor Matrix” olarak\ndeğil, “Pattern Matrix” olarak adlandırılır.Ancak dik döndürmede olduğu gibi “Rotated Factor Matrix” olarak\ndeğil, “Pattern Matrix” olarak adlandırılır.Yapı matrisi (Structure matrix)Yapı matrisi (Structure matrix)Faktörler arasındaki korelasyon matrisFaktörler arasındaki korelasyon matris","code":"\nprint(out_dik$loadings[2:3,], digits = 3, cutoff = 0.30)##        PA1   PA2   PA3\n## per2 0.777 0.242 0.292\n## per3 0.686 0.299 0.384"},{"path":"afa.html","id":"örüntü-katsayısı-ve-yapı-katsayısı","chapter":"Bölüm 7 AFA","heading":"7.22 Örüntü Katsayısı ve Yapı Katsayısı","text":"Yapı matrisi gözlenen değişkenlerle faktörler arasındaki iki\ndeğişkenli korelasyon katsayısını içerir; korelasyon katsayısı\nyapı katsayısı olarak adlandırılır.Yapı matrisi gözlenen değişkenlerle faktörler arasındaki iki\ndeğişkenli korelasyon katsayısını içerir; korelasyon katsayısı\nyapı katsayısı olarak adlandırılır.Örüntü katsayısı bir ölçülen değişkenin bir faktör\nüzerindeki bireysel (unique) katkısını temsil eder.\nBireysel (unique) katkı diğer faktörlerin etkisi kontrol\naltına alındıktan sonra, bir faktörün bir değişkene katkısı\nanlamına gelmektedir.\nFaktörler dikse (veya sadece bir faktör varsa),örüntü\nkatsayısı belli bir değişken ve bir faktör arasındaki iki\ndeğişkenli korelasyon katsayısı ile aynıdır.\nAncak faktörler dik değilse, örüntü katsayısı belli bir\ndeğişken ve bir faktör arasındaki iki değişkenli korelasyon\nkatsayısı ile aynı değildir.\nÖrüntü katsayısı bir ölçülen değişkenin bir faktör\nüzerindeki bireysel (unique) katkısını temsil eder.Bireysel (unique) katkı diğer faktörlerin etkisi kontrol\naltına alındıktan sonra, bir faktörün bir değişkene katkısı\nanlamına gelmektedir.Bireysel (unique) katkı diğer faktörlerin etkisi kontrol\naltına alındıktan sonra, bir faktörün bir değişkene katkısı\nanlamına gelmektedir.Faktörler dikse (veya sadece bir faktör varsa),örüntü\nkatsayısı belli bir değişken ve bir faktör arasındaki iki\ndeğişkenli korelasyon katsayısı ile aynıdır.Faktörler dikse (veya sadece bir faktör varsa),örüntü\nkatsayısı belli bir değişken ve bir faktör arasındaki iki\ndeğişkenli korelasyon katsayısı ile aynıdır.Ancak faktörler dik değilse, örüntü katsayısı belli bir\ndeğişken ve bir faktör arasındaki iki değişkenli korelasyon\nkatsayısı ile aynı değildir.Ancak faktörler dik değilse, örüntü katsayısı belli bir\ndeğişken ve bir faktör arasındaki iki değişkenli korelasyon\nkatsayısı ile aynı değildir.Örüntü matrisi ve yapı matrisi arasındaki ilişki aşağıdaki eşitlikle\ngösterilebilir: \\[\\Lambda _T\\Phi = S \\]Örüntü matrisi ve yapı matrisi arasındaki ilişki aşağıdaki eşitlikle\ngösterilebilir: \\[\\Lambda _T\\Phi = S \\]Burada,Burada,\\(\\Lambda _T\\) döndürülen örüntü matrisi\\(\\Lambda _T\\) döndürülen örüntü matrisi\\(\\Phi\\) faktörler arasındaki korelasyon matrisi\\(\\Phi\\) faktörler arasındaki korelasyon matrisi\\(S\\) yapı matrisi\\(S\\) yapı matrisi\\(\\Phi\\) bir birim matris olduğunda \\(\\Lambda _T=S\\)\\(\\Phi\\) bir birim matris olduğunda \\(\\Lambda _T=S\\)Döndürme olmadığında \\(\\Lambda=S\\)Döndürme olmadığında \\(\\Lambda=S\\)Eğik döndürme ile AFA gerçekleştirildiğinde, hangi grup katsayılar\nrapor edilmelidir: örüntü veya yapı? \\(\\Lambda_T\\Phi=S\\) eşitliğinden\ndolayı, çoğu makale örüntü katsayılarını ve faktörler arasındaki\nkorelasyon katsayılarını rapor eder.Eğik döndürme ile AFA gerçekleştirildiğinde, hangi grup katsayılar\nrapor edilmelidir: örüntü veya yapı? \\(\\Lambda_T\\Phi=S\\) eşitliğinden\ndolayı, çoğu makale örüntü katsayılarını ve faktörler arasındaki\nkorelasyon katsayılarını rapor eder.Bazı makalelerde hem örüntü hem de yapı katsayıları faktör yükleri\nadı altında rapor edilir. Karışıklığı önlemek amacıyla, hangi grup\nkatsayıların rapor edildiği açıkça belirtilmelidir.Bazı makalelerde hem örüntü hem de yapı katsayıları faktör yükleri\nadı altında rapor edilir. Karışıklığı önlemek amacıyla, hangi grup\nkatsayıların rapor edildiği açıkça belirtilmelidir.","code":"\nout_egik <- fa(veri,3,fm=\"pa\",rotate=\"promax\")\n\nprint(out_egik$loadings, digits = 3, cutoff = 0.30)## \n## Loadings:\n##       PA1    PA2    PA3   \n## per1   1.120              \n## per2   0.835              \n## per3   0.669              \n## per4   0.750              \n## per5          0.889       \n## per6          0.850       \n## per7          0.846       \n## per8          0.777       \n## per9                 0.872\n## per10                0.723\n## per11                0.806\n## \n##                 PA1   PA2   PA3\n## SS loadings    2.97 2.872 2.021\n## Proportion Var 0.27 0.261 0.184\n## Cumulative Var 0.27 0.531 0.715\nprint(out_egik$Structure, digits = 3, cutoff = 0.30)## \n## Loadings:\n##       PA1   PA2   PA3  \n## per1  0.983 0.474 0.523\n## per2  0.864 0.502 0.573\n## per3  0.824 0.554 0.644\n## per4  0.811 0.533 0.535\n## per5  0.507 0.904 0.542\n## per6  0.402 0.774 0.331\n## per7  0.560 0.890 0.520\n## per8  0.497 0.824 0.517\n## per9  0.537 0.409 0.845\n## per10 0.443 0.440 0.729\n## per11 0.522 0.458 0.816\n## \n##                  PA1   PA2   PA3\n## SS loadings    4.787 4.526 4.155\n## Proportion Var 0.435 0.411 0.378\n## Cumulative Var 0.435 0.847 1.224\nout_egik$Phi##       PA1   PA2   PA3\n## PA1 1.000 0.573 0.629\n## PA2 0.573 1.000 0.554\n## PA3 0.629 0.554 1.000"},{"path":"afa.html","id":"dik-ve-eğik-döndürme","chapter":"Bölüm 7 AFA","heading":"7.23 Dik ve Eğik Döndürme","text":"Dik döndürme ve eğik döndürme sonucu elde edilen faktör çözümleri\nkarşılaştırıldığında, eğik döndürme sonucu elde edilen faktör\nyapısının daha basit ve dahakolay yorumlanabilir olduğu\ngörülmektedir","code":""},{"path":"afa.html","id":"yorum","chapter":"Bölüm 7 AFA","heading":"7.24 Yorum","text":"AFA’dan uygun bir sonuç elde edildikten sonra, çıkarılan faktörlerin\nyorumlanması gerekir.Verilen örnekte aşağıdaki sonuçlar elde edilmiştir:Verilen örnekte aşağıdaki sonuçlar elde edilmiştir:Faktör 1 temel olarak PER1-4 tarafından açıklanır.Faktör 1 temel olarak PER1-4 tarafından açıklanır.Faktör 2 temel olarak PER5-8 tarafından açıklanır.Faktör 2 temel olarak PER5-8 tarafından açıklanır.Faktör 3 temel olarak PER9-11 tarafından açıklanır.Faktör 3 temel olarak PER9-11 tarafından açıklanır.Bu 3 faktör arasındaki korelasyon katsayıları orta-yüksek korelasyon\nkatsayılarıdır.Bu 3 faktör arasındaki korelasyon katsayıları orta-yüksek korelasyon\nkatsayılarıdır.Faktörler anlamları bakımından da yorumlanmalıdır. Verilen örnekteki\n11 değişkenin kütüphane servis kalitesi algısını ölçmesi\nhedeflenmiştir.Faktörler anlamları bakımından da yorumlanmalıdır. Verilen örnekteki\n11 değişkenin kütüphane servis kalitesi algısını ölçmesi\nhedeflenmiştir.AFA veri yapısı ile ilgili olarak herhangi bir önsel kuram\ngerektirmediğinden ve sadece ölçülen değişkenler arasındaki\nkorelasyon matrisine dayandığından, çıkarılan faktörler\nyorumlanabilir olmayabilir.AFA veri yapısı ile ilgili olarak herhangi bir önsel kuram\ngerektirmediğinden ve sadece ölçülen değişkenler arasındaki\nkorelasyon matrisine dayandığından, çıkarılan faktörler\nyorumlanabilir olmayabilir.Yorumlanabilir döndürülen çözüm bulunduğunda ve çıkarılan faktörlere\nanlam yüklendiğinde, bir bireyin bu gözlenmeyen boyutlarda\ndeğerlendirilmesi özellikle istenebilir.Yorumlanabilir döndürülen çözüm bulunduğunda ve çıkarılan faktörlere\nanlam yüklendiğinde, bir bireyin bu gözlenmeyen boyutlarda\ndeğerlendirilmesi özellikle istenebilir.Bu faktör puanı kestirimi adı verilen yöntemin amacıdır ve bu\nyöntemle bir birey için faktörlerin kestirimi elde edilir.Bu faktör puanı kestirimi adı verilen yöntemin amacıdır ve bu\nyöntemle bir birey için faktörlerin kestirimi elde edilir.Kestirilen faktör puanı daha ileri analizlerde kullanılabilir\n(örneğin, faktörlere göre gruplardaki ortalama farklarının\nkarşılaştırılması).Kestirilen faktör puanı daha ileri analizlerde kullanılabilir\n(örneğin, faktörlere göre gruplardaki ortalama farklarının\nkarşılaştırılması).","code":""},{"path":"afa.html","id":"faktör-puanı-kestirimi","chapter":"Bölüm 7 AFA","heading":"7.25 Faktör Puanı Kestirimi:","text":"Regresyon yöntemiyle elde edilen faktör puanlarının ortalaması\nsıfırdırRegresyon yöntemiyle elde edilen faktör puanlarının ortalaması\nsıfırdırBartlett yöntemiyle elde edilen faktör puanlarının ortalaması\nsıfırdır.Bartlett yöntemiyle elde edilen faktör puanlarının ortalaması\nsıfırdır.Anderson-Rubin yöntemiyle elde edilen faktör puanlarının\nortalaması 0 ve standart sapması 1’dir. Faktör puanları arasında\nilişki yoktur. Bartlett yönteminin kestirilen faktörlerin dikliğini\nsağlaması için modifiye edilmiş halidir.Anderson-Rubin yöntemiyle elde edilen faktör puanlarının\nortalaması 0 ve standart sapması 1’dir. Faktör puanları arasında\nilişki yoktur. Bartlett yönteminin kestirilen faktörlerin dikliğini\nsağlaması için modifiye edilmiş halidir.","code":"\nfa_egik <- fa(veri, nfactors=3, rotate=\"promax\", scores=\"regression\")\nhead(fa_egik$scores)##          MR1    MR2    MR3\n## [1,]  0.2099 -1.673 -0.607\n## [2,] -1.4363 -0.573 -1.511\n## [3,] -0.8530 -0.811 -1.358\n## [4,] -1.3834 -1.040 -1.844\n## [5,] -1.2752 -0.659 -1.057\n## [6,]  0.0253  0.679  0.299"},{"path":"afa.html","id":"eganet","chapter":"Bölüm 7 AFA","heading":"7.26 EGAnet","text":"Boyutsallık ve psikometrik değerlendirme için Keşifsel Grafik\nAnalizi (EGA) çerçevesini uygular.\nEGA, ağ tahmin yöntemlerini ve\ntopluluk tespit algoritmalarını kullanarak psikolojik verilerdeki\nboyut sayısını tahmin eder.\nBoyutsallık ve psikometrik değerlendirme için Keşifsel Grafik\nAnalizi (EGA) çerçevesini uygular.EGA, ağ tahmin yöntemlerini ve\ntopluluk tespit algoritmalarını kullanarak psikolojik verilerdeki\nboyut sayısını tahmin eder.Boyutların ve maddelerin kararlılığını\ndeğerlendirmek için bir bootstrap yöntemi sağlanmıştır.\nUyum, Entropi Uyum endeks ailesi kullanılarak değerlendirilir. Benzersiz Değişken Analizi, maddelerin ne ölçüde yerel olarak bağımlı (veya gereksiz) olduğunu değerlendirir.\nBoyutların ve maddelerin kararlılığını\ndeğerlendirmek için bir bootstrap yöntemi sağlanmıştır.Uyum, Entropi Uyum endeks ailesi kullanılarak değerlendirilir. Benzersiz Değişken Analizi, maddelerin ne ölçüde yerel olarak bağımlı (veya gereksiz) olduğunu değerlendirir.","code":"\nlibrary(EGAnet); library(psychTools)\n\n# Perform Unique Variable Analysis\nbfi_uva <- UVA(\n  data = veri\n)\n# Print results\nbfi_uva$keep_remove## $keep\n## [1] \"per1\" \"per5\" \"per6\" \"per9\"\n## \n## $remove\n## [1] \"per2\"  \"per3\"  \"per4\"  \"per7\"  \"per7\"  \"per8\"  \"per10\" \"per11\"\nEGA(veri)## Model: GLASSO (EBIC with gamma = 0.5)\n## Correlations: auto\n## Lambda: 0.0935127102774255 (n = 100, ratio = 0.1)\n## \n## Number of nodes: 11\n## Number of edges: 32\n## Edge density: 0.582\n## \n## Non-zero edge weights: \n##      M    SD   Min   Max\n##  0.148 0.165 0.001 0.589\n## \n## ----\n## \n## Algorithm:  Walktrap\n## \n## Number of communities:  3\n## \n##  per1  per2  per3  per4  per5  per6  per7  per8  per9 per10 per11 \n##     1     1     1     1     2     2     2     2     3     3     3 \n## \n## ----\n## \n## Unidimensional Method: Louvain\n## Unidimensional: No\n## \n## ----\n## \n## TEFI: -5.507"},{"path":"afa.html","id":"kaynaklar-4","chapter":"Bölüm 7 AFA","heading":"7.27 Kaynaklar","text":"Thompson, B. (2004). Exploratory confirmatory factor analysis:\nUnderstanding concepts applications. Washington, DC: American\nPsychological Association.Thompson, B. (2004). Exploratory confirmatory factor analysis:\nUnderstanding concepts applications. Washington, DC: American\nPsychological Association.Gorsuch, R. L. (1983). Factor analysis (2nd ed.). Hillsdale, NJ:\nErlbaumGorsuch, R. L. (1983). Factor analysis (2nd ed.). Hillsdale, NJ:\nErlbaumCook, C., &. Thompson, B. (2001). Psychometric properties scores\nWeb-based LibQUAL+™ study perceptions library service\nquality. Library Trends, 49, 585-604.Cook, C., &. Thompson, B. (2001). Psychometric properties scores\nWeb-based LibQUAL+™ study perceptions library service\nquality. Library Trends, 49, 585-604.Thompson, B. (2004).Exploratory confirmatory factor analysis:\nUnderstanding concepts applications. Washington, DC: American\nPsychological Association.Thompson, B. (2004).Exploratory confirmatory factor analysis:\nUnderstanding concepts applications. Washington, DC: American\nPsychological Association.Thompson, B., Cook, C., & Heath, F. (2001). many dimensions\ntake measure users' perceptions libraries?: \n\"LibQUAL+™\" study,portal:Libraries Academy, 1,* 129-138.Thompson, B., Cook, C., & Heath, F. (2001). many dimensions\ntake measure users' perceptions libraries?: \n\"LibQUAL+™\" study,portal:Libraries Academy, 1,* 129-138.Thompson, B., Cook, C.,& Thompson, R. L. (2002). Reliability \nstructure LibQUAL+™ scores:Measuring perceived library service\nquality, portal: Libraries Academy, 2, 3-12.Thompson, B., Cook, C.,& Thompson, R. L. (2002). Reliability \nstructure LibQUAL+™ scores:Measuring perceived library service\nquality, portal: Libraries Academy, 2, 3-12.Guadagnoli, E., & Velicer, W. (1988). Relation sample size \nstability component patterns. Psychological Bulletin, 103,\n265—275.Guadagnoli, E., & Velicer, W. (1988). Relation sample size \nstability component patterns. Psychological Bulletin, 103,\n265—275.MacCallum, R. C., Widaman, K. F., Zhang, S., & Hong, S. (1999).\nSample size factor analysis. Psychological Methods, 4, 84-99.MacCallum, R. C., Widaman, K. F., Zhang, S., & Hong, S. (1999).\nSample size factor analysis. Psychological Methods, 4, 84-99.Guttman, L. (1954). necessary conditions common-factor\nanalysis. Psychometrika,19, 149-161.Guttman, L. (1954). necessary conditions common-factor\nanalysis. Psychometrika,19, 149-161.Cattell, R. B. (1966). scree test number factors.\nMultivariate Behavioral Research, 1, 245-276.Cattell, R. B. (1966). scree test number factors.\nMultivariate Behavioral Research, 1, 245-276.","code":""},{"path":"dfa.html","id":"dfa","chapter":"Bölüm 8 DFA","heading":"Bölüm 8 DFA","text":"Hipotez edilen modelin veri ile uyumunun incelendiği YEM analizlerinde, model ile veri uyumu sağlandığında, veri hipotez edilen modeli destekler ancak alternatif hipotezleri/modelleri reddetmez.Hipotez edilen modelin veri ile uyumunun incelendiği YEM analizlerinde, model ile veri uyumu sağlandığında, veri hipotez edilen modeli destekler ancak alternatif hipotezleri/modelleri reddetmez.Diğer bir ifadeyle farklı modeller de veriye uyum sağlayabilir. Dolayısıyla araştırmacı birden fazla modelin veri ile uyumunu inceleyebilir ve\nen iyi uyum gösteren modeli belirleyebilir.\nDiğer bir ifadeyle farklı modeller de veriye uyum sağlayabilir. Dolayısıyla araştırmacı birden fazla modelin veri ile uyumunu inceleyebilir veen iyi uyum gösteren modeli belirleyebilir.YEM analizlerinde Rosseel vd. (2018) tarafından geliştirilen lavaan paketi;YEM analizlerinde Rosseel vd. (2018) tarafından geliştirilen lavaan paketi;YEM analizleri çıktılarında Tsukahara (2022) tarafından geliştirilen semoutput paketi;YEM analizleri çıktılarında Tsukahara (2022) tarafından geliştirilen semoutput paketi;analizlere ilişkin diyagramların elde edilmesinde ise Epskamp vd. (2017) tarafından geliştirilen semPlot paketi kullanılacaktır.analizlere ilişkin diyagramların elde edilmesinde ise Epskamp vd. (2017) tarafından geliştirilen semPlot paketi kullanılacaktır.Veri modellemenin amacı, verinin yapısını daha anlaşılabilecek ve kolay yorumlanabilecek şekilde tanımlamaktır.Veri modellemenin amacı, verinin yapısını daha anlaşılabilecek ve kolay yorumlanabilecek şekilde tanımlamaktır.Yapısal eşitlik modelleri (YEM) farklı modellerin test edilebilmesi için esnek bir çerçeve sağlar.Yapısal eşitlik modelleri (YEM) farklı modellerin test edilebilmesi için esnek bir çerçeve sağlar.Temelde gözlenenen değişkenlerin varyanslarına ve gözlenen değişkenler arasındaki kovaryanslara dayalı olan YEM analizlerinin amacı bir grup gözlenen değişken arasındaki kovaryans örüntüsünü anlamak ve araştırma modeli ile gözlenen değişkenlerin varyanslarını açıklamaktır.Temelde gözlenenen değişkenlerin varyanslarına ve gözlenen değişkenler arasındaki kovaryanslara dayalı olan YEM analizlerinin amacı bir grup gözlenen değişken arasındaki kovaryans örüntüsünü anlamak ve araştırma modeli ile gözlenen değişkenlerin varyanslarını açıklamaktır.Gözlenen DeğişkenGözlenen değişkenler YEM dilinde göstergeler (indicators) olarak ifade edilir ve bunlar araştırmacının doğrudan ölçtüğü ya da gözlediği değişkenleri ifade eder.\nYEM terminolojisinde gözlenen değişkenler, gizil değişkenleri yordamaz; aksine gizil değişkenler kendi gözlenen değişkenlerini yordar.\nGözlenen değişkenler YEM dilinde göstergeler (indicators) olarak ifade edilir ve bunlar araştırmacının doğrudan ölçtüğü ya da gözlediği değişkenleri ifade eder.YEM terminolojisinde gözlenen değişkenler, gizil değişkenleri yordamaz; aksine gizil değişkenler kendi gözlenen değişkenlerini yordar.Gizil DeğişkenGizil değişkenler YEM’en önemli kavramlarından biridir ve araştırmacıların ilgilendikleri zeka, güdü, duygu, tutum gibi soyut kavramlar ya da psikolojik yapılara karşılık gelir.\nBu yapıları ancak dolaylı olarak, belirli davranışlar ya da göstergeler temelinde ölçülen değişkenler yardımıyla gözlenebilir .\nDiğer bir ifade ile gizil değişkenler doğrudan gözlenemedikleri için bağlantılı oldukları gözlenebilen başka değişkenler aracılığıyla kestirilmeye çalışılır.\nGizil değişkenler YEM’en önemli kavramlarından biridir ve araştırmacıların ilgilendikleri zeka, güdü, duygu, tutum gibi soyut kavramlar ya da psikolojik yapılara karşılık gelir.Bu yapıları ancak dolaylı olarak, belirli davranışlar ya da göstergeler temelinde ölçülen değişkenler yardımıyla gözlenebilir .Bu yapıları ancak dolaylı olarak, belirli davranışlar ya da göstergeler temelinde ölçülen değişkenler yardımıyla gözlenebilir .Diğer bir ifade ile gizil değişkenler doğrudan gözlenemedikleri için bağlantılı oldukları gözlenebilen başka değişkenler aracılığıyla kestirilmeye çalışılır.Diğer bir ifade ile gizil değişkenler doğrudan gözlenemedikleri için bağlantılı oldukları gözlenebilen başka değişkenler aracılığıyla kestirilmeye çalışılır.DFA, daha önceden tanımlanmış ve sınırlandırılmış bir yapının, bir model olarak doğrulanıp doğrulanmadığının test edildiği bir analizdir.DFA, daha önceden tanımlanmış ve sınırlandırılmış bir yapının, bir model olarak doğrulanıp doğrulanmadığının test edildiği bir analizdir.DFA, psikoloji alan yazınında daha çok ölçek geliştirmede ve geçerlik analizlerinde kullanılmaktadır.\nBu analizlerde, önceden belirlenmiş ya da kurgulanmış bir yapının doğrulanması amaçlanmaktadır.\nDFA, psikoloji alan yazınında daha çok ölçek geliştirmede ve geçerlik analizlerinde kullanılmaktadır.Bu analizlerde, önceden belirlenmiş ya da kurgulanmış bir yapının doğrulanması amaçlanmaktadır.Araştırmacı, DFA’da kuramsal bilgilere dayalı olarak belirlediği\ngözlenen değişkenlerin gizil değişkenlerle ve\ngizil değişkenlerin de kendi aralarında birbiri ile ilişkili olduğunu kanıtlamaya çalışır.\nAraştırmacı, DFA’da kuramsal bilgilere dayalı olarak belirlediğigözlenen değişkenlerin gizil değişkenlerle vegizil değişkenlerin de kendi aralarında birbiri ile ilişkili olduğunu kanıtlamaya çalışır.Araştırmacı, kurama dayalı olarak\ngeliştirdiği modelin doğrulanıp doğrulanmadığını ya da\nbeklenen modelle gözlenen modelin ne ölçüde uyum gösterdiğini belirlemeye çalışır.\nAraştırmacı, kurama dayalı olarakgeliştirdiği modelin doğrulanıp doğrulanmadığını ya dabeklenen modelle gözlenen modelin ne ölçüde uyum gösterdiğini belirlemeye çalışır.DFA, gizil değişkenler arasındaki ilişkileri betimleyen (önerilen) model ile elde edilen (gözlenen) verinin ne oranda uyuştuğuna ilişkin ayrıntılı istatistikler sunar.DFA, gizil değişkenler arasındaki ilişkileri betimleyen (önerilen) model ile elde edilen (gözlenen) verinin ne oranda uyuştuğuna ilişkin ayrıntılı istatistikler sunar.Geleneksel testlerin aksine, tek bir anlamlılık değeri vermez. Bu doğrultuda bulgular, verinin uygunluğuna göre ve ölçülen parametrelere ilişkin çok sayıda istatistiksel ölçüt kullanılarak değerlendirilir.Geleneksel testlerin aksine, tek bir anlamlılık değeri vermez. Bu doğrultuda bulgular, verinin uygunluğuna göre ve ölçülen parametrelere ilişkin çok sayıda istatistiksel ölçüt kullanılarak değerlendirilir.DFA’da süreç, korelasyon ya da kovaryans matrisi oluşturarak başlar.DFA’da süreç, korelasyon ya da kovaryans matrisi oluşturarak başlar.Bir ölçme modelinin DFA sonuçlarında\nfaktörler arasındaki korelasyon kestirimleri,\ngöstergelerin bağlı bulunduğu faktörler altındaki yükler ve\nbir gösterge için ölçme hatalarının miktarını verir.\nBir ölçme modelinin DFA sonuçlarındafaktörler arasındaki korelasyon kestirimleri,faktörler arasındaki korelasyon kestirimleri,göstergelerin bağlı bulunduğu faktörler altındaki yükler vegöstergelerin bağlı bulunduğu faktörler altındaki yükler veher bir gösterge için ölçme hatalarının miktarını verir.bir gösterge için ölçme hatalarının miktarını verir.Eğer araştırmacının başlangıçtaki ölçme modeli mantıklı bir biçimde doğrulanıyor ise dikkat edilmesi gereken durumlar şunlardır:Eğer araştırmacının başlangıçtaki ölçme modeli mantıklı bir biçimde doğrulanıyor ise dikkat edilmesi gereken durumlar şunlardır:Ortak bir faktör altında ölçme yapmak için belirlenen göstergelerin tümünün, o faktörde oldukça yüksek yüklere sahip olması - yakınsak (convergent) geçerlikOrtak bir faktör altında ölçme yapmak için belirlenen göstergelerin tümünün, o faktörde oldukça yüksek yüklere sahip olması - yakınsak (convergent) geçerlikFaktörler arasındaki korelasyon kestirimlerinin aşırı yüksek olmaması (örneğin >0,85) - ayırt edici geçerlikFaktörler arasındaki korelasyon kestirimlerinin aşırı yüksek olmaması (örneğin >0,85) - ayırt edici geçerlik","code":"\n# install.packages(c(\"lavaan\",\"semPlot\"))\nlibrary(lavaan)## This is lavaan 0.6-17\n## lavaan is FREE software! Please report any bugs.\nlibrary(semoutput)\nlibrary(semPlot)"},{"path":"dfa.html","id":"dfa-vs-afa","chapter":"Bölüm 8 DFA","heading":"8.1 DFA vs AFA","text":"Açımlayıcı analizlerde temel amaç, yapısal bir modele ulaşmak ya da kuram üretmek olmasına karşın, kurama ilişkin ilk ya da temel bilgilere ulaşılabilir.Açımlayıcı analizlerde temel amaç, yapısal bir modele ulaşmak ya da kuram üretmek olmasına karşın, kurama ilişkin ilk ya da temel bilgilere ulaşılabilir.Diğer taraftan doğrulayıcı analizlerde, daha önceki kapsamlı araştırmalardan elde edilen bilgi ya da tecrübeye dayanan durumlardan ve gözlemler çerçevesinde varsayımlar için model oluşturulur.\nBu varsayımlar temelinde önceden kurulan modelin, bazı parametreler açısından doğruluğu test edilir.\nDiğer taraftan doğrulayıcı analizlerde, daha önceki kapsamlı araştırmalardan elde edilen bilgi ya da tecrübeye dayanan durumlardan ve gözlemler çerçevesinde varsayımlar için model oluşturulur.Bu varsayımlar temelinde önceden kurulan modelin, bazı parametreler açısından doğruluğu test edilir.Tek Faktörlü DFA Modeli ÖrneğiX1, X2 ve X3 gizil faktörün göstergeleridir. Gizil faktör bu üç göstergenin altında yatan tek ortak yapıdır.X1, X2 ve X3 gizil faktörün göstergeleridir. Gizil faktör bu üç göstergenin altında yatan tek ortak yapıdır.Diğer bir ifadeyle, göstergeler arasındaki kovaryansı üretecek gizil faktörden başka kaynaklar yoktur.Diğer bir ifadeyle, göstergeler arasındaki kovaryansı üretecek gizil faktörden başka kaynaklar yoktur.bir gözlenen puan iki bileşene sahiptir: faktörün neden olduğu puan ve faktörün neden olmadığı puan.bir gözlenen puan iki bileşene sahiptir: faktörün neden olduğu puan ve faktörün neden olmadığı puan.Faktörün neden olmadığı kısım bir hata terimi ile gösterilir. Bu hata terimleri şemada \\(\\delta_1\\), \\(\\delta_2\\) ve \\(\\delta_3\\) ile temsil edilmektedir.Faktörün neden olmadığı kısım bir hata terimi ile gösterilir. Bu hata terimleri şemada \\(\\delta_1\\), \\(\\delta_2\\) ve \\(\\delta_3\\) ile temsil edilmektedir.\\(\\delta_1\\) gibi bir hata terimi iki bileşenden oluşur:\nbir göstergeye özel olan güvenilir bir puan\nÖlçme hatasından dolayı güvenilir olmayan bir hata puanı\n\\(\\delta_1\\) gibi bir hata terimi iki bileşenden oluşur:bir göstergeye özel olan güvenilir bir puanÖlçme hatasından dolayı güvenilir olmayan bir hata puanıKuramsal olarak bu iki bileşen ayırt edilemez.Kuramsal olarak bu iki bileşen ayırt edilemez.DFA’da \\(\\delta_1\\) gibi bir hata terimi ölçme hatası olarak adlandırılır ancak bu terim iki bileşenin kombinasyonudur.DFA’da \\(\\delta_1\\) gibi bir hata terimi ölçme hatası olarak adlandırılır ancak bu terim iki bileşenin kombinasyonudur.tesadüfi hataları güvenilir olmayan değerler, ölçülen özellik dışında ölçmeye karışan diğer özellikler güvenilir olan değerlertesadüfi hataları güvenilir olmayan değerler, ölçülen özellik dışında ölçmeye karışan diğer özellikler güvenilir olan değerler |Faktör ve göstergeyi bağlayan yola faktör yükü adı verilir.Faktör ve göstergeyi bağlayan yola faktör yükü adı verilir.Faktör yükü \\(\\lambda\\) simgesi ile gösterilir. \\(\\lambda_2\\) , X2 göstergesinin gizil faktördeki yüküdür. \\(\\lambda_3\\) , X3 göstergesinin gizil faktördeki yüküdür.Faktör yükü \\(\\lambda\\) simgesi ile gösterilir. \\(\\lambda_2\\) , X2 göstergesinin gizil faktördeki yüküdür. \\(\\lambda_3\\) , X3 göstergesinin gizil faktördeki yüküdür.\\(\\lambda_1\\) , X1 göstergesinin gizil faktördeki yüküdür ancak 1 değerine sabitlenmiştir.\\(\\lambda_1\\) , X1 göstergesinin gizil faktördeki yüküdür ancak 1 değerine sabitlenmiştir.Gizil değişken F, gizil olduğundan sabit bir ölçeğe sahip değildir. Bu nedenle, faktör yüklerinin ölçekleri belirlenemez. İki olası çözüm aşağıdaki gibidir:\nFaktör yüklerin ölçeği sabitlenir ve gizil değişkenin ölçeği serbestçe kestirilir.\nGizil değişkenin ölçeği sabitlenir ve faktör yüklerinin ölçekleri serbestçe kestirilir.\nFaktör yüklerin ölçeği sabitlenir ve gizil değişkenin ölçeği serbestçe kestirilir.Gizil değişkenin ölçeği sabitlenir ve faktör yüklerinin ölçekleri serbestçe kestirilir.X1 ve X2 F1’göstergeleridir.X1 ve X2 F1’göstergeleridir.X3 ve X4 F2’nin göstergeleridir.X3 ve X4 F2’nin göstergeleridir.F1 ve F2 arasında bir korelasyon vardır.F1 ve F2 arasında bir korelasyon vardır.X1, X2, X3 ve X4 göstergeleri etki göstergeleri (effect indicators) veya yansıtıcı göstergeler (reflective indicators) olarak adlandırılırlar.X1, X2, X3 ve X4 göstergeleri etki göstergeleri (effect indicators) veya yansıtıcı göstergeler (reflective indicators) olarak adlandırılırlar.X1, X2, X3 ve X4 göstergeleri etki göstergeleri (effect indicators) veya yansıtıcı göstergeler (reflective indicators) olarak adlandırılırlar.\\[X=\\Lambda\\xi +\\delta\\]\\[\\begin{bmatrix}{}\nX_{1}\\\\\nX_{2}\\\\\nX_{3}\\\\\nX_{4}\\\\\n\\end{bmatrix} = \\begin{bmatrix}{}\n1 & 0 \\\\\n\\lambda_{21} & 0 \\\\\n0 & 1 \\\\\n0 & \\lambda_{42} \\\\\n\\end{bmatrix}\n\\begin{bmatrix}{}\n\\xi_{1}\\\\\n\\xi_{1}\\\\\n\\end{bmatrix} + \\begin{bmatrix}{}\n\\delta_{1}\\\\\n\\delta_{2}\\\\\n\\delta_{3}\\\\\n\\delta_{4}\\\\\n\\end{bmatrix}\\]DFA modelinde 3 tip kovaryans matrisi tanımlanmalıdır:DFA modelinde 3 tip kovaryans matrisi tanımlanmalıdır:\\(\\sum\\) (sigma): ölçülen gözlenen değişkenleri kovaryans matrisi\\(\\sum\\) (sigma): ölçülen gözlenen değişkenleri kovaryans matrisi\\(\\phi\\) (phi): gizil faktörlerin kovaryans matrisi\\(\\phi\\) (phi): gizil faktörlerin kovaryans matrisi\\(\\Psi\\) (psi): ölçme hatalarının kovaryans matrisi\\(\\Psi\\) (psi): ölçme hatalarının kovaryans matrisi","code":""},{"path":"dfa.html","id":"dfa-modeli-kovaryans-matrisi","chapter":"Bölüm 8 DFA","heading":"8.2 DFA Modeli: Kovaryans Matrisi","text":"Model için kovaryans matrisi model parametrelerinin bir fonksiyonu \\(\\sum(\\theta) = \\Lambda\\phi\\Lambda' + \\Psi\\) olarak temsil edilebilir:\\[\\begin{bmatrix}{}\nVAR_{X_1}\\\\\nCOV_{X_1,X_2} & VAR_{X_2}\\\\\nCOV_{X_1,X_3} & COV_{X_2,X_3} & VAR_{X_3}\\\\\nCOV_{X_1,X_4} & COV_{X_2,X_4} & COV_{X_3,X_4} & VAR_{X_4}\\\\\n\\end{bmatrix}\\]\\[= \\begin{bmatrix}{}1 & 0 \\\\\n\\lambda_{21} & 0 \\\\\n0 & 1 \\\\\n0 & \\lambda_{42} \\\\\n\\end{bmatrix}\n\\begin{bmatrix}{}\n\\phi_{11}\\\\\n\\phi_{21} & \\phi_{22}\\\\\n\\end{bmatrix}\\begin{bmatrix}{}\n1 & \\lambda_{21} & 0 & 0\\\\\n0 & 0 & 1 & \\lambda_{42}\\\\\n\\end{bmatrix} + \\begin{bmatrix}{}\n\\Psi_{11}\\\\\n0 & \\Psi_{22}\\\\\n0 & 0 & \\Psi_{33}\\\\\n0 & 0 & 0 & \\Psi_{44}\\\\\n\\end{bmatrix}\\]\\(\\sum(\\theta)\\), \\(\\phi\\), \\(\\psi\\) matrisleri simetrik matrislerdir ancak eşitlikte sadece alt üçgen sunulur.Kovaryans matrislerinden model için serbestçe kestirilecek parametreler sayılabilir:Bu nedenle,\\(\\lambda_{21}\\) X2’nin Faktör 1’deki yüküdür.\\(\\lambda_{21}\\) X2’nin Faktör 1’deki yüküdür.\\(\\lambda_{42}\\) X4’ün Faktör 2’deki yüküdür.\\(\\lambda_{42}\\) X4’ün Faktör 2’deki yüküdür.\\(\\lambda_{11}\\) ve \\(\\lambda_{32}\\) şemada değerleri 1’e sabitlenmiş olarak gösterilmektedir\\(\\lambda_{11}\\) ve \\(\\lambda_{32}\\) şemada değerleri 1’e sabitlenmiş olarak gösterilmektedirStandart DFA modelleri aşağıdaki özelliklere sahiptir:Standart DFA modelleri aşağıdaki özelliklere sahiptir:bir gösterge sürekli bir değişkendir ve tek bir faktörün (factor complexity = 1) ve ölçme hatasının bir fonksiyonudur.bir gösterge sürekli bir değişkendir ve tek bir faktörün (factor complexity = 1) ve ölçme hatasının bir fonksiyonudur.Ölçme hataları birbirlerinden ve faktörlerden bağımsızdır.Ölçme hataları birbirlerinden ve faktörlerden bağımsızdır.Faktörlerin arasında korelasyon vardır.Faktörlerin arasında korelasyon vardır.Standart DFA modellerinde, faktörler dışsal değişkenlerdir. Dışsal değişkenlerin varyansları ve kovaryanslarıdır.Standart DFA modellerinde, faktörler dışsal değişkenlerdir. Dışsal değişkenlerin varyansları ve kovaryanslarıdır.Faktörlerin göstergeler üzerindeki doğrudan etkileridir. (örneğin, faktör yükleri)Faktörlerin göstergeler üzerindeki doğrudan etkileridir. (örneğin, faktör yükleri)Faktörlerin varyansları: 2Faktörlerin varyansları: 2Faktörlerin kovaryansları: 1Faktörlerin kovaryansları: 1Hataların varyansları: 4Hataların varyansları: 4Faktör yükleri: 2 (diğer iki faktör yükü 1’e sabitlenmiştir)Faktör yükleri: 2 (diğer iki faktör yükü 1’e sabitlenmiştir)Modelden serbestçe kestirilecek 9 parametre vardır.Modelden serbestçe kestirilecek 9 parametre vardır.DFA literatüründe bir gizil faktörü temsil etmek üzere genellikle F yerine \\(\\xi\\) kullanılır.DFA literatüründe bir gizil faktörü temsil etmek üzere genellikle F yerine \\(\\xi\\) kullanılır.Faktor yukleri 1'eFaktor yukleri 1'eFaktor varyansları 1'eHer ikisinde de 9 tane serbestce kestirilecek parametre bulunmaktadır.","code":""},{"path":"dfa.html","id":"modelin-tanımlanması","chapter":"Bölüm 8 DFA","heading":"8.2.1 Modelin Tanımlanması","text":"DFA modelinde gözlemlerin sayısı yol analizi modelindeki gibi hesaplanır:\n\\(v (v + 1) / 2\\)\nDFA modelinde gözlemlerin sayısı yol analizi modelindeki gibi hesaplanır:\\(v (v + 1) / 2\\)İki faktörlü DFA modeli örneğinde gözlemlerin sayısı:İki faktörlü DFA modeli örneğinde gözlemlerin sayısı:\\(4 (4 + 1) / 2 = 10\\) (v = 4, gözlenen değişken sayısı)\\(4 (4 + 1) / 2 = 10\\) (v = 4, gözlenen değişken sayısı)Yönlü ilişkili (recursive) yol modellerinde , eğer gözlemlerin sayısı model parametrelerinin sayısına eşit veya daha büyükse sd ≥ 0 model tanımlanır. Ancak DFA’da, sd ≥ 0 koşulunun sağlanması zorunlu fakat yeterli değildir.Yönlü ilişkili (recursive) yol modellerinde , eğer gözlemlerin sayısı model parametrelerinin sayısına eşit veya daha büyükse sd ≥ 0 model tanımlanır. Ancak DFA’da, sd ≥ 0 koşulunun sağlanması zorunlu fakat yeterli değildir.dört gözlenen değişkenli DFA modeli örneğinde gözlemlerin sayısı:dört gözlenen değişkenli DFA modeli örneğinde gözlemlerin sayısı:\\[\\begin{bmatrix}{}\nVAR_{X_1}\\\\\nCOV_{X_1,X_2} & VAR_{X_2}\\\\\nCOV_{X_1,X_3} & COV_{X_2,X_3} & VAR_{X_3}\\\\\nCOV_{X_1,X_4} & COV_{X_2,X_4} & COV_{X_3,X_4} & VAR_{X_4}\\\\\n\\end{bmatrix}{}\\]","code":""},{"path":"dfa.html","id":"modifikasyon","chapter":"Bölüm 8 DFA","heading":"8.3 Modifikasyon","text":"DFA modelleri hatalar arasında korelasyonun tanımlanmasına izin verir.DFA modelleri hatalar arasında korelasyonun tanımlanmasına izin verir.Araştırmacılar bir ölçüm için hataların arasında korelasyon olmaması sayıltısının olağan olarak ihlal edildiğini tartışırlar (Schmidt & Hunter, 1996).Araştırmacılar bir ölçüm için hataların arasında korelasyon olmaması sayıltısının olağan olarak ihlal edildiğini tartışırlar (Schmidt & Hunter, 1996).Ancak hatalar arasındaki korelasyonun modele eklenmesi tanımlama problemlerine neden olabilir.Ancak hatalar arasındaki korelasyonun modele eklenmesi tanımlama problemlerine neden olabilir.","code":""},{"path":"dfa.html","id":"yeterli-gereklilikler","chapter":"Bölüm 8 DFA","heading":"8.4 Yeterli Gereklilikler","text":"Zorunlu gerekliliklerin karşılanması DFA modelinin tanımlanmasını garantilemez. Yeterli gereklilikler.Zorunlu gerekliliklerin karşılanması DFA modelinin tanımlanmasını garantilemez. Yeterli gereklilikler.Eğer\nstandart bir tek faktörlü DFA modeli en az üç göstergeye sahipse,\nstandart bir iki veya daha fazla faktörlü DFA modelinde bir faktör için en az iki göstergeye varsa,\nEğerstandart bir tek faktörlü DFA modeli en az üç göstergeye sahipse,standart bir tek faktörlü DFA modeli en az üç göstergeye sahipse,standart bir iki veya daha fazla faktörlü DFA modelinde bir faktör için en az iki göstergeye varsa,standart bir iki veya daha fazla faktörlü DFA modelinde bir faktör için en az iki göstergeye varsa,model tanımlanır.Çapraz yüklü veya hatalar arasında korelasyona sahip bir DFA modeli için ise kolayca uygulanan yeterli koşul yoktur.Çapraz yüklü veya hatalar arasında korelasyona sahip bir DFA modeli için ise kolayca uygulanan yeterli koşul yoktur.Model parametresi araştırmacının tanımlamasına bağlı olarak serbest (free), sabit (fixed) veya sınırlandırılmış (constrained) olabilir.\nSerbest parametre (free parameter) örneklem verisinden bilgisayar yazılımı tarafından kestirilen parametredir.\nSabit parametre (fixed parameter) bir sabite eşit olarak belirlenen parametredir; yazılım bu sabiti veriye bağlı olmaksızın parametrenin kestirimi olarak kabul eder.\nSınırlandırılmış parametre (constrained parameter) yazılım tarafından belli sınırlılıklar içerisinde kestirilir ancak bir sabite eşit olmak üzere sabitlenmez.\nModel parametresi araştırmacının tanımlamasına bağlı olarak serbest (free), sabit (fixed) veya sınırlandırılmış (constrained) olabilir.Serbest parametre (free parameter) örneklem verisinden bilgisayar yazılımı tarafından kestirilen parametredir.Serbest parametre (free parameter) örneklem verisinden bilgisayar yazılımı tarafından kestirilen parametredir.Sabit parametre (fixed parameter) bir sabite eşit olarak belirlenen parametredir; yazılım bu sabiti veriye bağlı olmaksızın parametrenin kestirimi olarak kabul eder.Sabit parametre (fixed parameter) bir sabite eşit olarak belirlenen parametredir; yazılım bu sabiti veriye bağlı olmaksızın parametrenin kestirimi olarak kabul eder.Sınırlandırılmış parametre (constrained parameter) yazılım tarafından belli sınırlılıklar içerisinde kestirilir ancak bir sabite eşit olmak üzere sabitlenmez.Sınırlandırılmış parametre (constrained parameter) yazılım tarafından belli sınırlılıklar içerisinde kestirilir ancak bir sabite eşit olmak üzere sabitlenmez.Bir modelinin tanımlanabilmesi için kestirilecek olan model parametre sayısının gözlenen parametre sayısına eşit veya gözlenen parametre sayısından küçük olması gerekir.\nsd<0 olduğunda model tanımlanamaz.\nsd=0, model ancak tanımlanır (just identification) ve kuramsal olarak parametrenin tek bir çözümü vardır. Ancak tanımlanan modellerde model veriye mükemmel uyum gösterir.\nsd>0, model aşırı tanımlanmış (identification) olur. Aşırı tanımlanan modellerde kuramsal olarak bir parametrenin birden fazla çözümü vardır.\nBir modelinin tanımlanabilmesi için kestirilecek olan model parametre sayısının gözlenen parametre sayısına eşit veya gözlenen parametre sayısından küçük olması gerekir.sd<0 olduğunda model tanımlanamaz.sd<0 olduğunda model tanımlanamaz.sd=0, model ancak tanımlanır (just identification) ve kuramsal olarak parametrenin tek bir çözümü vardır. Ancak tanımlanan modellerde model veriye mükemmel uyum gösterir.sd=0, model ancak tanımlanır (just identification) ve kuramsal olarak parametrenin tek bir çözümü vardır. Ancak tanımlanan modellerde model veriye mükemmel uyum gösterir.sd>0, model aşırı tanımlanmış (identification) olur. Aşırı tanımlanan modellerde kuramsal olarak bir parametrenin birden fazla çözümü vardır.sd>0, model aşırı tanımlanmış (identification) olur. Aşırı tanımlanan modellerde kuramsal olarak bir parametrenin birden fazla çözümü vardır.X1’faktör yükü 1’e sabitlendiğinde, F1’ölçme birimi X1’ölçme birimiyle aynı olur. Bu durumda X1 işaret veya referans değişken adını alır.X1’faktör yükü 1’e sabitlendiğinde, F1’ölçme birimi X1’ölçme birimiyle aynı olur. Bu durumda X1 işaret veya referans değişken adını alır.Benzer şekilde, X3 de F2 için referans değişkendir.Benzer şekilde, X3 de F2 için referans değişkendir.Referans değişken birinci gösterge olmak zorunda değildir. Örneğin, X2 de F1 için referans değişken olarak seçilebilir.\nReferans değişken belirlendiginde, değişkenin örneklem varyansının bir kısmı gizil değişkene geçer\nReferans değişken birinci gösterge olmak zorunda değildir. Örneğin, X2 de F1 için referans değişken olarak seçilebilir.Referans değişken belirlendiginde, değişkenin örneklem varyansının bir kısmı gizil değişkene geçerhem F1 hem de F2 puanları ortalaması 0 ve standart sapması 1 olan bir ölçeğe sahip olurlar.hem F1 hem de F2 puanları ortalaması 0 ve standart sapması 1 olan bir ölçeğe sahip olurlar.bütün faktör yükleri serbestçe kestirilir.bütün faktör yükleri serbestçe kestirilir.Model parametreleri:\nFaktörlerin varyansları: 0\n1’e sabitlenmişlerdir\n\nFaktörlerin kovaryansları: 1\nHataların varyansları: 4\nFaktör yükleri: 4\nModel parametreleri:Faktörlerin varyansları: 0\n1’e sabitlenmişlerdir\n1’e sabitlenmişlerdirFaktörlerin kovaryansları: 1Hataların varyansları: 4Faktör yükleri: 4","code":""},{"path":"dfa.html","id":"çapraz-yüklü-dfa-modelleri","chapter":"Bölüm 8 DFA","heading":"8.5 Çapraz Yüklü DFA Modelleri","text":"Verilen örnekte X2 hem F1 hem de F2’nin göstergesidir.Verilen örnekte X2 hem F1 hem de F2’nin göstergesidir.Bazen bazı göstergeler birden fazla faktörü ölçmek için tasarlanmıştır (factor complexity > 1). Böyle bir DFA modeli artık standart bir DFA modeli değildir.Bazen bazı göstergeler birden fazla faktörü ölçmek için tasarlanmıştır (factor complexity > 1). Böyle bir DFA modeli artık standart bir DFA modeli değildir.","code":""},{"path":"dfa.html","id":"model-veri-uyumunun-değerlendirilmesi-1","chapter":"Bölüm 8 DFA","heading":"8.6 Model-Veri Uyumunun Değerlendirilmesi","text":"Kestirilen parametre sayısından daha fazla sayıda gözleme sahip olan aşırı tanımlanan (overidentified) modeller genellikle veriye mükemmel uyum sağlamaz.Kestirilen parametre sayısından daha fazla sayıda gözleme sahip olan aşırı tanımlanan (overidentified) modeller genellikle veriye mükemmel uyum sağlamaz.Bu durumda böyle modellerin veriyle ne derece uyumlu olduğunu ölçmeye ihtiyaç vardır.Bu durumda böyle modellerin veriyle ne derece uyumlu olduğunu ölçmeye ihtiyaç vardır.YEM literatüründe tanımlanan çok sayıda model uyum indeksi vardır ve sürekli olarak yeni indeksler geliştirilmektedir.YEM literatüründe tanımlanan çok sayıda model uyum indeksi vardır ve sürekli olarak yeni indeksler geliştirilmektedir.Çok sayıda farklı uyum indeksinin olması bazı problemleri de beraberinde getirir:\nFarklı makalelerde farklı uyum indeksleri rapor edilir.\nAynı makale için farklı hakemler kendi bildikleri veya tercih ettikleri farklı indekslerin rapor edilmesini isteyebilirler.\nUyum indekslerinin değerlerini rapor ederken seçici davranma olasılığı vardır (örneğin, sadece iyi uyum öneren uyum indekslerinin rapor edilmesi gibi).\nÇok sayıda farklı uyum indeksinin olması bazı problemleri de beraberinde getirir:Farklı makalelerde farklı uyum indeksleri rapor edilir.Farklı makalelerde farklı uyum indeksleri rapor edilir.Aynı makale için farklı hakemler kendi bildikleri veya tercih ettikleri farklı indekslerin rapor edilmesini isteyebilirler.Aynı makale için farklı hakemler kendi bildikleri veya tercih ettikleri farklı indekslerin rapor edilmesini isteyebilirler.Uyum indekslerinin değerlerini rapor ederken seçici davranma olasılığı vardır (örneğin, sadece iyi uyum öneren uyum indekslerinin rapor edilmesi gibi).Uyum indekslerinin değerlerini rapor ederken seçici davranma olasılığı vardır (örneğin, sadece iyi uyum öneren uyum indekslerinin rapor edilmesi gibi).YEM uygulamalarına ve simülasyon çalışmalarına göre YEM analizinin sonuçlarını rapor ederken sunulacak ve yorumlanacak uyum indeksleri aşağıdaki gibidir:YEM uygulamalarına ve simülasyon çalışmalarına göre YEM analizinin sonuçlarını rapor ederken sunulacak ve yorumlanacak uyum indeksleri aşağıdaki gibidir:Model Ki-Kare DeğeriModel Ki-Kare DeğeriSteiger-Lind Root Mean Square Error Approximation RMSEA (Steiger, 1990) (%90 güven aralığı ile birlikte)Steiger-Lind Root Mean Square Error Approximation RMSEA (Steiger, 1990) (%90 güven aralığı ile birlikte)Bentler Comparative Fit Index CFI (Bentler, 1990)Bentler Comparative Fit Index CFI (Bentler, 1990)Standardized Root Mean Square Residual SRMRStandardized Root Mean Square Residual SRMRÇoklu indekslerin kullanılması bir modelin uyumu ile ilgili en doğru yaklaşımı verecektir.Çoklu indekslerin kullanılması bir modelin uyumu ile ilgili en doğru yaklaşımı verecektir.: Bu kesme değerlerin kullanılmasıyla ilgili çok sayıda tartışma vardır.","code":""},{"path":"dfa.html","id":"uyum-indekslerini-raporlarken-öneriler-1","chapter":"Bölüm 8 DFA","heading":"8.6.1 Uyum İndekslerini Raporlarken Öneriler","text":"örneğin, CFI, örneklem büyüklüğüne duyarlıdır.örneğin, CFI, örneklem büyüklüğüne duyarlıdır.Oldukça küçük bir örneklem (örneğin, N = 200) hemen hemen zaman oldukça büyük bir örneklemden (örneğin, N = 1000) daha küçük CFI'ler üretecektir.Oldukça küçük bir örneklem (örneğin, N = 200) hemen hemen zaman oldukça büyük bir örneklemden (örneğin, N = 1000) daha küçük CFI'ler üretecektir.Bu nedenle, .95 gibi CFI için sabit eşikler, küçük örneklem boyutları için daha doğru modelleri uyumlu göstermeyecek ve daha büyük örneklem boyutları için ise muhtemelen daha az uyumlu modelleri kabul edecektir.Bu nedenle, .95 gibi CFI için sabit eşikler, küçük örneklem boyutları için daha doğru modelleri uyumlu göstermeyecek ve daha büyük örneklem boyutları için ise muhtemelen daha az uyumlu modelleri kabul edecektir.Esnek kesim noktaları belirli bir model ve örneklem özelliklerine uygun alternatif eşik değerleri sağlar. Bu amaçla FCO paketi kullanılabilir.Esnek kesim noktaları belirli bir model ve örneklem özelliklerine uygun alternatif eşik değerleri sağlar. Bu amaçla FCO paketi kullanılabilir.","code":"\nlibrary(FCO)"},{"path":"dfa.html","id":"esnek-kesim-noktaları","chapter":"Bölüm 8 DFA","heading":"8.7 Esnek Kesim Noktaları","text":"Esnek kesim noktaları, gizli değişken sayısı (veya faktörler), gizil değişken başına gösterge sayısı, örneklem boyutları, faktör yükleri ve normal ve normal olmayan veriler için doğru şekilde belirlenmiş Doğrulayıcı Faktör Analizi (DFA) modellerinin simüle edilmiş dağılımlarından türetilir.Esnek kesim noktaları, gizli değişken sayısı (veya faktörler), gizil değişken başına gösterge sayısı, örneklem boyutları, faktör yükleri ve normal ve normal olmayan veriler için doğru şekilde belirlenmiş Doğrulayıcı Faktör Analizi (DFA) modellerinin simüle edilmiş dağılımlarından türetilir.Esnek kesim noktaları, önceden tanımlanmış bir belirsizlik için belirli bir değerin ampirik niceliği olarak anlaşılabilir.Esnek kesim noktaları, önceden tanımlanmış bir belirsizlik için belirli bir değerin ampirik niceliği olarak anlaşılabilir.Öncelikli olarak yüzde 5'lik (veya .05) bir belirsizlik kabul edilirse, verilen model ve örneklem özellikleriyle doğru şekilde belirlenmiş DFA modelleri için simüle edilmiş dağılımın yüzde 5'lik niceliği esnek sınırı belirleyecektir.Öncelikli olarak yüzde 5'lik (veya .05) bir belirsizlik kabul edilirse, verilen model ve örneklem özellikleriyle doğru şekilde belirlenmiş DFA modelleri için simüle edilmiş dağılımın yüzde 5'lik niceliği esnek sınırı belirleyecektir.Niemand, T., Mai, R. Flexible cutoff values fit indices evaluation structural equation models. J. Acad. Mark. Sci. 46, 1148–1172 (2018)","code":""},{"path":"dfa.html","id":"model-seçimi","chapter":"Bölüm 8 DFA","heading":"8.8 Model Seçimi","text":"analizlerinde birden fazla model veriye uyum sağlayabilir.analizlerinde birden fazla model veriye uyum sağlayabilir.Bu durumda veriye daha iyi uyum sağlayan modelin belirlenmesi için model uyumları karşılaştırılır.Bu durumda veriye daha iyi uyum sağlayan modelin belirlenmesi için model uyumları karşılaştırılır.Modellerden biri diğerinin alt kümesi olduğunda modeller yuvalanmıştır. Örneğin, araştırmacılar farklı amaçlarla model içinde bazı parametreleri sınırlandırabilir. Bu durumda sınırlandırılmış olan model sınırlandırılmamış olan serbest model içinde yuvalanmış olur.Modellerden biri diğerinin alt kümesi olduğunda modeller yuvalanmıştır. Örneğin, araştırmacılar farklı amaçlarla model içinde bazı parametreleri sınırlandırabilir. Bu durumda sınırlandırılmış olan model sınırlandırılmamış olan serbest model içinde yuvalanmış olur.Yuvalanmış modeller karşılaştırılırken, modellerin ki-kare değerleri arasındaki farkın anlamlılığı incelenir.Yuvalanmış modeller karşılaştırılırken, modellerin ki-kare değerleri arasındaki farkın anlamlılığı incelenir.Eğer iki model hiyerarşikse ve ikisi de veriye kabul edilebilir ölçüde uyum sağlıyorsa, iki modelin veriye uyumunu karşılaştırmak için ki-kare fark test uygulanabilir.Eğer iki model hiyerarşikse ve ikisi de veriye kabul edilebilir ölçüde uyum sağlıyorsa, iki modelin veriye uyumunu karşılaştırmak için ki-kare fark test uygulanabilir.Yuvalanmamış modellerin karşılaştırılmasında kullanılacak en uygun yaklaşım bilgi kriter değerleridir. Yaygın olarak kullanılan bilgi kriterleri Akaike bilgi kriteri (AIC) ve Bayes bilgi kriteridir (BIC).Yuvalanmamış modellerin karşılaştırılmasında kullanılacak en uygun yaklaşım bilgi kriter değerleridir. Yaygın olarak kullanılan bilgi kriterleri Akaike bilgi kriteri (AIC) ve Bayes bilgi kriteridir (BIC).Model seçimi yapılırken bilgi kriteri değeri daha küçük olan model tercih edilir. Bilgi kriterleri hem yuvalanmış hem de yuvalanmamış modellerin karşılaştırılmasında kullanılabilir.Model seçimi yapılırken bilgi kriteri değeri daha küçük olan model tercih edilir. Bilgi kriterleri hem yuvalanmış hem de yuvalanmamış modellerin karşılaştırılmasında kullanılabilir.","code":""},{"path":"dfa.html","id":"varsayımlar","chapter":"Bölüm 8 DFA","heading":"8.9 Varsayımlar","text":"YEM analizleri genellikle büyük örneklemler gerektirir.YEM analizleri genellikle büyük örneklemler gerektirir.Örneklem büyüklüğü model karmaşıklığı ile oldukça ilişkidir ve daha karmaşık modeller daha büyük örneklemler gerektirir.Örneklem büyüklüğü model karmaşıklığı ile oldukça ilişkidir ve daha karmaşık modeller daha büyük örneklemler gerektirir.YEM analizlerine ilişkin varsayımlar ise kestirim yöntemine bağlı olarak değişmektedir.YEM analizlerine ilişkin varsayımlar ise kestirim yöntemine bağlı olarak değişmektedir.Kullanılan kestirim yönteminin varsayımlarının sağlanmaması model veri uyumu, parametre ve parametrelere ilişkin hata kestirimlerinde yanlılığa neden olabilir. Dolayısıyla, test edilen kuram hakkında hatalı sonuçlar alınmasına yol açabilir.Kullanılan kestirim yönteminin varsayımlarının sağlanmaması model veri uyumu, parametre ve parametrelere ilişkin hata kestirimlerinde yanlılığa neden olabilir. Dolayısıyla, test edilen kuram hakkında hatalı sonuçlar alınmasına yol açabilir.Bu nedenle veri yapısına ve çalışma desenine uygun bir kestirim yöntemi seçilmesi oldukça önemlidir.Bu nedenle veri yapısına ve çalışma desenine uygun bir kestirim yöntemi seçilmesi oldukça önemlidir.YEM analizlerinde yaygın olarak maksimum olabilirlik ML kestirim yöntemi kullanılmaktadır.YEM analizlerinde yaygın olarak maksimum olabilirlik ML kestirim yöntemi kullanılmaktadır.Benzer şekilde en küçük kareler GLS kestirim yöntemi de normallik varsayımı gerektirir.Benzer şekilde en küçük kareler GLS kestirim yöntemi de normallik varsayımı gerektirir.Bu yöntemler normal teori yöntemleri olarak da adlandırılır.Bu yöntemler normal teori yöntemleri olarak da adlandırılır.Normal teori yöntemleri altında yatan beş varsayımdan bahsedilebilir. Bunlar\ngözlemlerin bağımsızlığı,\nbüyük örneklem, doğru tanımlanmış model,\nçok değişkenli normallik ve verilerin sürekliliğidir.\nNormal teori yöntemleri altında yatan beş varsayımdan bahsedilebilir. Bunlargözlemlerin bağımsızlığı,büyük örneklem, doğru tanımlanmış model,çok değişkenli normallik ve verilerin sürekliliğidir.Normal teori yöntemleri varsayımları sağlandığında yansız, yeterli ve tutarlı kestirimler üretir. - doğrulayıcı faktör analizi için cfa(), yapısal modeller için sem() fonksiyonu tanımlanmıştır.ML yöntemi paketin varsayılan kestirim yöntemidir. Parametre kestirimleri açısından normallik varsayımının ihlaline dayanıklıdır.ML yöntemi paketin varsayılan kestirim yöntemidir. Parametre kestirimleri açısından normallik varsayımının ihlaline dayanıklıdır.Normal olmayan veriler için alan yazında yaygın olarak kullanılan kestirim yöntemi\nağırlıklandırılmış en küçük kareler yöntemidir WLS\nAyrıca ağırlıklandırılmamış en küçük kareler ULS,\ndiyagonal olarak ağırlıklandırılmış en küçük kareler DWLS,\nkestirim yöntemleri de normal dağılmayan verilerde kullanılabilir.\nNormal olmayan veriler için alan yazında yaygın olarak kullanılan kestirim yöntemiağırlıklandırılmış en küçük kareler yöntemidir WLSAyrıca ağırlıklandırılmamış en küçük kareler ULS,diyagonal olarak ağırlıklandırılmış en küçük kareler DWLS,kestirim yöntemleri de normal dağılmayan verilerde kullanılabilir.Kestirim yöntemlerinin kısaltmaları programlar arasında farklılık gösterebilir.Kestirim yöntemlerinin kısaltmaları programlar arasında farklılık gösterebilir.cfa() fonksiyonu hem ham veriyle hem de gözlenen değişkenlere ilişkin varyans-kovaryans matrisiyle çalışabilir.cfa() fonksiyonu hem ham veriyle hem de gözlenen değişkenlere ilişkin varyans-kovaryans matrisiyle çalışabilir.Girdi olarak varyans-kovaryans matrisi kullanıldığında, matriste madde adlarına karşılık gelecek şekilde satır ve sütun adları mutlaka bulunmalıdır. Ayrıca örneklem ortalamasının (sample.mean) ve gözlem sayısının tanımlanması (sample.nobs) gerekir.Girdi olarak varyans-kovaryans matrisi kullanıldığında, matriste madde adlarına karşılık gelecek şekilde satır ve sütun adları mutlaka bulunmalıdır. Ayrıca örneklem ortalamasının (sample.mean) ve gözlem sayısının tanımlanması (sample.nobs) gerekir.Girdi olarak doğrudan verinin kendisi girildiğindeyse, örneklem ortalaması ve gözlem sayısının tanımlanmasına gerek yoktur.Girdi olarak doğrudan verinin kendisi girildiğindeyse, örneklem ortalaması ve gözlem sayısının tanımlanmasına gerek yoktur.Tüm YEM fonksiyonlarında olduğu gibi cfa() fonksiyonu için de ilk olarak DFA modelinin tanımlanması gerekir.Tüm YEM fonksiyonlarında olduğu gibi cfa() fonksiyonu için de ilk olarak DFA modelinin tanımlanması gerekir.DFA modeli tırnak işareti içinde tanımlanır ve faktörler maddeler ile '=~' işaretiyle ilişkilendirilir.DFA modeli tırnak işareti içinde tanımlanır ve faktörler maddeler ile '=~' işaretiyle ilişkilendirilir.İşaretin sol tarafında faktörler sağ tarafında maddeler yer alır. bir faktörde yer alan maddelerin adları sırasıyla + operatörüyle eklenir.İşaretin sol tarafında faktörler sağ tarafında maddeler yer alır. bir faktörde yer alan maddelerin adları sırasıyla + operatörüyle eklenir.","code":"\n' F1  =~ m1 + m2 +m3'"},{"path":"dfa.html","id":"uygulama","chapter":"Bölüm 8 DFA","heading":"8.10 Uygulama","text":"Yaşam doyumu verileri, yaşam doyumunun farklı yönlerine/alanlarına ilişkin 10 maddeden oluşmaktadır. Ne kadar mennunsun:1 = “hiç memnun değilim” ile 7 = “çok memnunum” arasında 7 puanlık bir ölçekle alınmış sonuçlar.Verinin okunması (veriseti)[import/yasamdoyum.xlsx]Modelin tanımlanmasıDFA modelinin testiAnalizin çıktıları incelendiğinde, ilk olarak iterasyon sayısı, modelde kestirilen parametre sayısı, gözlem sayısı ve kullanılan kestirim yöntemi bilgileri yer almaktadır.Analizin çıktıları incelendiğinde, ilk olarak iterasyon sayısı, modelde kestirilen parametre sayısı, gözlem sayısı ve kullanılan kestirim yöntemi bilgileri yer almaktadır.Sonrasında ki-kare istatistikleri ve model uyum indeksleri raporlanmıştır.Sonrasında ki-kare istatistikleri ve model uyum indeksleri raporlanmıştır.Bu çıktıları daha düzgün elde etmek içi semoutput paketi kullanılabilir.Bu çıktıları daha düzgün elde etmek içi semoutput paketi kullanılabilir.Model uyum istatistikleri semoutputtan aşağıdaki şekilde elde edilebilir.Model uyum istatistikleri fitmeasures fonkisyonu ile aşağıdaki şekilde elde edilebilir.Esnek kesim noktalarıModel uyum indekslerini takiben faktör yükleri, standart hataları,z değerleri ve p değerleri gelmektedir.Model uyum indekslerini takiben faktör yükleri, standart hataları,z değerleri ve p değerleri gelmektedir.p değerleri maddelere ilişkin faktör yüklerinin sıfırdan anlamlı düzeyde farklı olup olmadığına ilişkin bilgi verir.p değerleri maddelere ilişkin faktör yüklerinin sıfırdan anlamlı düzeyde farklı olup olmadığına ilişkin bilgi verir.Faktör yükleri incelendiğinde, bir faktörün ilk maddesinin referans madde olarak tanımlandığı ve faktör yüklerinin bire eşitlendiği görülmektedir.Faktör yükleri incelendiğinde, bir faktörün ilk maddesinin referans madde olarak tanımlandığı ve faktör yüklerinin bire eşitlendiği görülmektedir.Bu maddelere ilişkin standart hatalar, z ve p değerleri hesaplanmamıştır. Faktör yükler tablosunun ardından ise faktörler arası kovaryans, madde ve faktör varyans kestirimleri, standart hataları, z ve p değerleri yer almaktadır.Bu maddelere ilişkin standart hatalar, z ve p değerleri hesaplanmamıştır. Faktör yükler tablosunun ardından ise faktörler arası kovaryans, madde ve faktör varyans kestirimleri, standart hataları, z ve p değerleri yer almaktadır.DFA modelinin testiDFA modelinin testiokul2 göstergesinin yükü 1.431 olarak kestirilmiştir. Bu değer faktör puanındaki birbirimlik değişikliğin okul2 puanında 1.431 birimlik değişikliğe yol açacağı şeklinde yorumlanır. Ancak bu değerler kendi başlarına çok anlamlı olmadığından standartlaştırılmamış yüklerin yorumlanmasında dikkatli olmak gerekir.okul2 göstergesinin yükü 1.431 olarak kestirilmiştir. Bu değer faktör puanındaki birbirimlik değişikliğin okul2 puanında 1.431 birimlik değişikliğe yol açacağı şeklinde yorumlanır. Ancak bu değerler kendi başlarına çok anlamlı olmadığından standartlaştırılmamış yüklerin yorumlanmasında dikkatli olmak gerekir.Ölçülen göstergelerde faktörün yordayıcı gücünü karşılaştırmak için daha anlamlı bir yaklaşım standartlaştırılmış yüklerin yorumlanmasıdır.Ölçülen göstergelerde faktörün yordayıcı gücünü karşılaştırmak için daha anlamlı bir yaklaşım standartlaştırılmış yüklerin yorumlanmasıdır.","code":"\nlibrary(openxlsx)\nyasamdoyum <- read.xlsx(\"import/yasamdoyum.xlsx\")\nhead(yasamdoyum)\nmodel_1 <- \n\"\nokul =~ okul1 + okul2 + okul3\nkisi =~ kisi1 + kisi2\narkadas =~ arkadas1 + arkadas2\naile =~ aile1 + aile2 + aile3\n\"\nmodel_1_fit <- cfa(model_1, data = yasamdoyum)\nsummary(model_1_fit, fit.measures = TRUE, standardized = TRUE)## lavaan 0.6.17 ended normally after 40 iterations\n## \n##   Estimator                                         ML\n##   Optimization method                           NLMINB\n##   Number of model parameters                        26\n## \n##   Number of observations                           255\n## \n## Model Test User Model:\n##                                                       \n##   Test statistic                                51.433\n##   Degrees of freedom                                29\n##   P-value (Chi-square)                           0.006\n## \n## Model Test Baseline Model:\n## \n##   Test statistic                               583.039\n##   Degrees of freedom                                45\n##   P-value                                        0.000\n## \n## User Model versus Baseline Model:\n## \n##   Comparative Fit Index (CFI)                    0.958\n##   Tucker-Lewis Index (TLI)                       0.935\n## \n## Loglikelihood and Information Criteria:\n## \n##   Loglikelihood user model (H0)              -3427.760\n##   Loglikelihood unrestricted model (H1)      -3402.044\n##                                                       \n##   Akaike (AIC)                                6907.520\n##   Bayesian (BIC)                              6999.593\n##   Sample-size adjusted Bayesian (SABIC)       6917.166\n## \n## Root Mean Square Error of Approximation:\n## \n##   RMSEA                                          0.055\n##   90 Percent confidence interval - lower         0.029\n##   90 Percent confidence interval - upper         0.079\n##   P-value H_0: RMSEA <= 0.050                    0.341\n##   P-value H_0: RMSEA >= 0.080                    0.045\n## \n## Standardized Root Mean Square Residual:\n## \n##   SRMR                                           0.053\n## \n## Parameter Estimates:\n## \n##   Standard errors                             Standard\n##   Information                                 Expected\n##   Information saturated (h1) model          Structured\n## \n## Latent Variables:\n##                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n##   okul =~                                                               \n##     okul1             1.000                               0.572    0.420\n##     okul2             1.431    0.257    5.572    0.000    0.819    0.638\n##     okul3             1.995    0.403    4.947    0.000    1.141    0.858\n##   kisi =~                                                               \n##     kisi1             1.000                               0.730    0.669\n##     kisi2             0.940    0.156    6.028    0.000    0.685    0.784\n##   arkadas =~                                                            \n##     arkadas1          1.000                               0.661    0.791\n##     arkadas2          0.614    0.117    5.235    0.000    0.406    0.531\n##   aile =~                                                               \n##     aile1             1.000                               0.782    0.742\n##     aile2             1.061    0.129    8.233    0.000    0.830    0.846\n##     aile3             0.598    0.084    7.136    0.000    0.467    0.510\n## \n## Covariances:\n##                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n##   okul ~~                                                               \n##     kisi              0.075    0.039    1.947    0.052    0.180    0.180\n##     arkadas           0.111    0.039    2.862    0.004    0.293    0.293\n##     aile              0.098    0.040    2.427    0.015    0.219    0.219\n##   kisi ~~                                                               \n##     arkadas           0.296    0.059    5.049    0.000    0.614    0.614\n##     aile              0.142    0.052    2.735    0.006    0.249    0.249\n##   arkadas ~~                                                            \n##     aile              0.178    0.048    3.700    0.000    0.344    0.344\n## \n## Variances:\n##                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n##    .okul1             1.528    0.147   10.414    0.000    1.528    0.824\n##    .okul2             0.978    0.137    7.130    0.000    0.978    0.593\n##    .okul3             0.469    0.209    2.245    0.025    0.469    0.265\n##    .kisi1             0.656    0.100    6.575    0.000    0.656    0.552\n##    .kisi2             0.295    0.076    3.865    0.000    0.295    0.386\n##    .arkadas1          0.262    0.079    3.301    0.001    0.262    0.375\n##    .arkadas2          0.419    0.047    8.948    0.000    0.419    0.718\n##    .aile1             0.498    0.079    6.336    0.000    0.498    0.449\n##    .aile2             0.274    0.077    3.574    0.000    0.274    0.285\n##    .aile3             0.622    0.061   10.240    0.000    0.622    0.740\n##     okul              0.327    0.109    3.001    0.003    1.000    1.000\n##     kisi              0.532    0.120    4.452    0.000    1.000    1.000\n##     arkadas           0.437    0.095    4.594    0.000    1.000    1.000\n##     aile              0.611    0.109    5.593    0.000    1.000    1.000\n# devtools::install_github(\"dr-JT/semoutput\")\nlibrary(semoutput)\nsem_sig(model_1_fit)\nlibrary(semoutput)\n # sem_fitmeasures(model_1_fit)\nfitmeasures(model_1_fit,fit.measures = c(\"chisq\" ,\"df\" , \"pvalue\",\"cfi\",\"tli\",\"rmsea\",\"rmsea.ci.lower\",   \n\"rmsea.ci.upper\",\"srmr\"))##          chisq             df         pvalue            cfi            tli \n##         51.433         29.000          0.006          0.958          0.935 \n##          rmsea rmsea.ci.lower rmsea.ci.upper           srmr \n##          0.055          0.029          0.079          0.053\nlibrary(FCO)\nfits.esnek <- gen_fit(mod1 = model_1, x = yasamdoyum[,4:13], rep = 100)\nflex_co(fits = fits.esnek, index = c(\"CFI\", \"SRMR\"))$cutoff##        CFI       SRMR \n## 0.94664848 0.04558631\nrecommend(fits.esnek)$cutoffs## Warning in recommend(fits.esnek): The number of replications is lower than the\n## recommended minimum of 500. Consider with care.\nsem_factorloadings(model_1_fit,standardized = FALSE)"},{"path":"dfa.html","id":"dfa-modelinin-testi","chapter":"Bölüm 8 DFA","heading":"8.11 DFA modelinin testi","text":"","code":"\nsem_factorloadings(model_1_fit,standardized = TRUE)"},{"path":"dfa.html","id":"kestitimler","chapter":"Bölüm 8 DFA","heading":"8.11.1 Kestitimler","text":"parametre kestirimleri ise coef(), parameterEstimates() fonksiyonlarıyla elde edilebilir.parametre kestirimleri ise coef(), parameterEstimates() fonksiyonlarıyla elde edilebilir.coef() fonksiyonu faktör yükleri, madde varyansları, faktör varyansları ve kovaryanslarının sadece parametre kestirimlerini verirken,coef() fonksiyonu faktör yükleri, madde varyansları, faktör varyansları ve kovaryanslarının sadece parametre kestirimlerini verirken,parameterEstimates() fonksiyonu parametre kestirimlerinin yanı sıra kestirimlerin standart hatalarını, güven aralıklarını, istenmesi durumunda standartlaştırılmış değerlerini ve \\(R^2\\) değerlerini verir.parameterEstimates() fonksiyonu parametre kestirimlerinin yanı sıra kestirimlerin standart hatalarını, güven aralıklarını, istenmesi durumunda standartlaştırılmış değerlerini ve \\(R^2\\) değerlerini verir.Açıklanan varyansAçıklanan varyansAçıklanan varyansGenel olarak \\(R^2\\) değeri aşağıdaki formülle elde edilir:\\(R^2_{X_i}=\\frac{\\lambda^2_{}\\sigma^2_{\\xi}}{\\sigma^2_{X_i}}\\)Örneğin okul2 değişkenin açıkladığı varyans 0.407 olarak kestirilmiştir.Örneğin okul2 değişkenin açıkladığı varyans 0.407 olarak kestirilmiştir.Bu kestirim okul2 değişkenin faktör yükünün karesinin, okul gizil değişkeninin açıkladığı varyans ile çarpımının, okul2 değişkeninin varyansına bölümü ile hesaplanır.Bu kestirim okul2 değişkenin faktör yükünün karesinin, okul gizil değişkeninin açıkladığı varyans ile çarpımının, okul2 değişkeninin varyansına bölümü ile hesaplanır.Bu değer okul2’deki varyansın yaklaşık %41inin faktör tarafından açıklandığı şeklinde yorumlanır.Bu değer okul2’deki varyansın yaklaşık %41inin faktör tarafından açıklandığı şeklinde yorumlanır.\\(R^2\\) değerinin kare kökü, faktör ve ilgili gösterge arasındaki korelasyon katsayısıdır.\\(R^2\\) değerinin kare kökü, faktör ve ilgili gösterge arasındaki korelasyon katsayısıdır.okul2 göstergesi için \\(R^2\\) değeri 0.407’tür. Bu değerin karekökü 0.638 değerine eşit olup okul2 göstergesinin standartlaştırılmış faktör yüküdür.okul2 göstergesi için \\(R^2\\) değeri 0.407’tür. Bu değerin karekökü 0.638 değerine eşit olup okul2 göstergesinin standartlaştırılmış faktör yüküdür.okul2 göstergesi standartlaştırılmış faktör yükü 0.638; okul2 göstergesin standartlaştırılmış hata varyansı 1 -0.638^2=0.593okul2 göstergesi standartlaştırılmış faktör yükü 0.638; okul2 göstergesin standartlaştırılmış hata varyansı 1 -0.638^2=0.593okul3 göstergesi için \\(R^2\\) değeri 0.735’dur. Bu değerin karekökü 0.857 değerine eşit olup okul3 göstergesinin standartlaştırılmış faktör yüküdür.okul3 göstergesi için \\(R^2\\) değeri 0.735’dur. Bu değerin karekökü 0.857 değerine eşit olup okul3 göstergesinin standartlaştırılmış faktör yüküdür.okul3 göstergesi standartlaştırılmış faktör yükü 0.857; okul2 göstergesin standartlaştırılmış hata varyansı 1 -0.857^2=0.265okul3 göstergesi standartlaştırılmış faktör yükü 0.857; okul2 göstergesin standartlaştırılmış hata varyansı 1 -0.857^2=0.265Ayrıca maddelere ilişkin kovaryans matrisi fitted() fonksiyonuyla; atıklar resid() fonksiyonuyla elde edilebilir.2.58'gecen değerler p<0.01 için,2.58'gecen değerler p<0.01 için,1.96'yı gecen değerler ise p<0.05 için anlamlıdır.\naile1 ~~ okul1\naile3 ~~ kisi2\n1.96'yı gecen değerler ise p<0.05 için anlamlıdır.aile1 ~~ okul1aile3 ~~ kisi2","code":"\n # summary(model_1_fit, rsquare=TRUE)\n# R-Square:\n#                    Estimate\n#     okul1             0.176\n#     okul2             0.407\n#     okul3             0.735\n#     kisi1             0.448\n#     kisi2             0.614\n#     arkadas1          0.625\n#     arkadas2          0.282\n#     aile1             0.551\n#     aile2             0.715\n#     aile3             0.260\nsem_factorvar(model_1_fit)\n(1.431^2 * 0.327) / var(yasamdoyum$okul2)## [1] 0.4046344\nresid(model_1_fit, type = \"normalized\")## $type\n## [1] \"normalized\"\n## \n## $cov\n##           okul1  okul2  okul3  kisi1  kisi2 arkds1 arkds2  aile1  aile2  aile3\n## okul1     0.000                                                               \n## okul2    -0.214  0.000                                                        \n## okul3    -0.105  0.077  0.000                                                 \n## kisi1     0.304  0.551  0.920  0.000                                          \n## kisi2     1.276 -1.224 -0.488  0.000  0.000                                   \n## arkadas1  1.134 -1.044  0.391  0.270 -0.139  0.000                            \n## arkadas2 -0.385 -0.036 -0.593 -0.587  0.285  0.000  0.000                     \n## aile1     2.922 -0.077 -0.420 -0.088  0.941 -0.138  1.139  0.000              \n## aile2     1.807  0.160 -0.862 -1.256 -0.429 -0.464  0.012  0.091  0.000       \n## aile3     0.984  1.192  1.605  0.935  2.290  1.091  0.757 -0.621  0.096  0.000"},{"path":"dfa.html","id":"artık-varyanslar-ve-r²","chapter":"Bölüm 8 DFA","heading":"8.11.2 Artık Varyanslar ve R²","text":"Artık varyans bir ölçülen değişkenin faktör tarafından açıklanmayan varyans miktarıdır.Artık varyans bir ölçülen değişkenin faktör tarafından açıklanmayan varyans miktarıdır.Örneğin, okul2 değişkenin varyansı 1.65 olarak kestirilmiştir.Örneğin, okul2 değişkenin varyansı 1.65 olarak kestirilmiştir.okul2 değişkenin okul faktörü tarafından açıklanmayan varyans miktarı 0.978 olarak kestirilmiştir.Bu nedenle, okul2 değişkenin okul faktörü tarafından açıklanan varyans miktarı \\(1.65 -0.978 = 0.672\\)Bu nedenle, okul2 değişkenin okul faktörü tarafından açıklanan varyans miktarı \\(1.65 -0.978 = 0.672\\)\\(R^2\\) okul faktörü tarafından açıklanan açıklanan varyans oranıdır: \\(R^2 = 0.672/1.65 = 0.407\\)\\(R^2\\) okul faktörü tarafından açıklanan açıklanan varyans oranıdır: \\(R^2 = 0.672/1.65 = 0.407\\)okul faktörü faktörü tarafından açıklanmayan varyans oranı ise: \\(1 - 0.407= 0.593\\)okul faktörü faktörü tarafından açıklanmayan varyans oranı ise: \\(1 - 0.407= 0.593\\)okul faktörü tarafından açıklanmayan varyans oranı ise: \\(1 - 0.407 = 0.593\\)okul faktörü tarafından açıklanmayan varyans oranı ise: \\(1 - 0.407 = 0.593\\)Artık varyans ve \\(R^2\\) arasındaki genel ilişki:Artık varyans ve \\(R^2\\) arasındaki genel ilişki:Standartlaştırılmamış çözüm için:\n\\(\\sigma^2_{X_i}(1-R^2)\\)\nStandartlaştırılmamış çözüm için:\\(\\sigma^2_{X_i}(1-R^2)\\)Standartlaştırılmış çözüm için:\n\\((1-R^2)\\)\n\\((1-\\lambda_i^2)\\)\nStandartlaştırılmış çözüm için:\\((1-R^2)\\)\\((1-\\lambda_i^2)\\)Bu iki formül standartlaştırılmış artık ve \\(R^2\\) arasındaki ilişki ve standartlaştırılmış artık ve standartlaştırılmış yük arasındaki ilişki hakkında bilgi verir.Bu iki formül standartlaştırılmış artık ve \\(R^2\\) arasındaki ilişki ve standartlaştırılmış artık ve standartlaştırılmış yük arasındaki ilişki hakkında bilgi verir.","code":"\nvar(yasamdoyum$okul2)## [1] 1.654871\npars <- parameterEstimates(model_1_fit,standardized = TRUE)\npars[12,]"},{"path":"dfa.html","id":"faktör-yüklerinden-geçerlik-ve-güvenirlik","chapter":"Bölüm 8 DFA","heading":"8.12 Faktör Yüklerinden Geçerlik ve Güvenirlik","text":"Yakınsak geçerlik için ortalama varyans (Average variance Extracted-AVE) değeri incelenebilir. Bu katsayının 0.50'den büyük olması istenir. Faktörler ile maddelerin arasındaki varyansın en az %50'si açıklanması anlamına gelir.Yakınsak geçerlik için ortalama varyans (Average variance Extracted-AVE) değeri incelenebilir. Bu katsayının 0.50'den büyük olması istenir. Faktörler ile maddelerin arasındaki varyansın en az %50'si açıklanması anlamına gelir.Bunun yanı sırasına iç tutarlılık bakılabilir.Bunun yanı sırasına iç tutarlılık bakılabilir.semTools paketinin reliability fonkisyonu AVE, alpha ve omega değerlerini vermektedir. omega1 ve omega2 model kovaryans modelini dikkate alır. Modifikasyon yapılmadığı durumda aynı çıkar. omega2 ilişkilendirilmiş hataları hesaba katar. omega3 ise hiyerarşik omega olarak bilinir ve gözlenenkovarynas matrisini kullanır.semTools paketinin reliability fonkisyonu AVE, alpha ve omega değerlerini vermektedir. omega1 ve omega2 model kovaryans modelini dikkate alır. Modifikasyon yapılmadığı durumda aynı çıkar. omega2 ilişkilendirilmiş hataları hesaba katar. omega3 ise hiyerarşik omega olarak bilinir ve gözlenenkovarynas matrisini kullanır.Standartlaştırılmamış ÇözümlerStandartlaştırılmamış ÇözümlerStandartlaştırılmış Çözümler","code":"\nsemTools::reliability(model_1_fit)##             okul      kisi   arkadas      aile\n## alpha  0.6521208 0.6772692 0.5897284 0.7284332\n## omega  0.6831115 0.6779276 0.6256012 0.7559986\n## omega2 0.6831115 0.6779276 0.6256012 0.7559986\n## omega3 0.6871330 0.6779277 0.6256008 0.7631365\n## avevar 0.4360858 0.5130189 0.4690402 0.5211590\nlibrary(semPlot)\nsemPaths(model_1_fit, what=\"par\",\nstyle=\"lisrel\",layout=\"tree\",residuals = TRUE,rotation = 2 )\nsemPaths(model_1_fit, what=\"std\",\nstyle=\"lisrel\",layout=\"tree\",residuals = TRUE,rotation = 2)"},{"path":"dfa.html","id":"faktorler-arası-korelasyon","chapter":"Bölüm 8 DFA","heading":"8.12.1 Faktorler arası korelasyon","text":"Standartlaştırılmamış Çözümleraynı standartlaştırılmış çözümleri sağlar.","code":"\nsem_factorcor(model_1_fit)\n library(lavaan)\n\nmodel_1_v1 <- \n\"\nokul =~ NA*okul1 + okul2 + okul3\nkisi =~ NA*kisi1 + kisi2\narkadas =~ NA*arkadas1 + arkadas2\naile =~ NA*aile1 + aile2 + aile3\n okul ~~ 1*okul\n kisi ~~ 1*kisi\n arkadas ~~ 1*arkadas\n aile ~~ 1*aile\n\"\nmodel_1_v1_fit <- cfa(model_1_v1,yasamdoyum)\nlibrary(DT)\ndatatable(parameterestimates(model_1_v1_fit,standardized = TRUE)) %>%\n    formatRound(columns=c('est', 'se',\"z\",\"pvalue\",\"ci.lower\",\"ci.upper\",\n                          \"std.lv\",\"std.all\",\"std.nox\"), digits=2)"},{"path":"dfa.html","id":"modifikasyon-indeksleri-1","chapter":"Bölüm 8 DFA","heading":"8.12.2 Modifikasyon indeksleri","text":"modindices() fonksiyonu doğrudan cfa() fonksiyonun çıktılarının atandığı ile çalıştırıldığında tüm modifikasyonları, modifikasyon yapıldığında ki-karedeki değişimi (mi değeri), parametrelerdeki beklenen değişimi (epc) ve istenmesi durumunda epc değerinin standartlaştırılmış değerlerini verir.Aynı faktör altında ve benzer ifadelere sahip olan iki madddeye ait hata varyanslarının ilişkilendirilmesi, kabul edilebilir bir gerekçe olarak değerlendirilebilir.","code":"\nmodindices(model_1_fit, sort=TRUE, standardized=FALSE) %>%  head(6)"},{"path":"dfa.html","id":"üç-faktörlü-model","chapter":"Bölüm 8 DFA","heading":"8.12.3 Üç faktörlü model","text":"","code":"\nmodel_2f <- \"\nokul =~ okul1 + okul2 + okul3\nkisi_arkadas =~ kisi1 + kisi2 + arkadas1 + arkadas2\naile =~ aile1 + aile2 + aile3\n\"\nmodel_2_fit <- cfa(model_2f, data = yasamdoyum)\nsem_sig(model_2_fit)\n# sem_fitmeasures(model_2_fit)\nfits.esnek2 <- gen_fit(mod1 = model_2f , x = yasamdoyum[,4:13], rep = 100)## Warning in pop_mod(mod = mod1, x = x, type = type, standardized =\n## standardized): At least one loading is > 1. Consider revision of standardized.\nflex_co(fits = fits.esnek2, index = c(\"CFI\", \"SRMR\"))$cutoff## Warning in flex_co(fits = fits.esnek2, index = c(\"CFI\", \"SRMR\")): The number of\n## replications is lower than the recommended minimum of 500. Consider with care.##        CFI       SRMR \n## 0.94518618 0.05021492\nsem_factorloadings(model_2_fit)"},{"path":"dfa.html","id":"model-karşılaştırma","chapter":"Bölüm 8 DFA","heading":"8.12.4 Model karşılaştırma","text":"Eğer iki model hiyerarşikse ve ikisi de veriye kabul edilebilir ölçüde uyum sağlıyorsa, iki modelin veriye uyumunu karşılaştırmak için ki-kare fark test uygulanabilir.Eğer iki model hiyerarşikse ve ikisi de veriye kabul edilebilir ölçüde uyum sağlıyorsa, iki modelin veriye uyumunu karşılaştırmak için ki-kare fark test uygulanabilir.üç faktörlü model iyi uyum göstermediği için sadece örnek amaçlı:üç faktörlü model iyi uyum göstermediği için sadece örnek amaçlı:Verilen örneklerde, üç faktörlü model dört faktörlü modelin içinde kümelenmiştir.Verilen örneklerde, üç faktörlü model dört faktörlü modelin içinde kümelenmiştir.Üç faktörlü model veriye iyi uyum sağlamamıştır, dört faktörlü model çeşitli uyum indekslerinin de gösterdiği üzere çok daha iyi uyum sağlamıştır. Bu nedenle, dört faktörlü modelin seçimini desteklemek için ki-kare fark testi uygulamaya gerek yokturÜç faktörlü model veriye iyi uyum sağlamamıştır, dört faktörlü model çeşitli uyum indekslerinin de gösterdiği üzere çok daha iyi uyum sağlamıştır. Bu nedenle, dört faktörlü modelin seçimini desteklemek için ki-kare fark testi uygulamaya gerek yokturKi-kare fark testi dört faktörlü modelin üç faktörlü modelden anlamlı olarak daha iyi uyum sağladığını önerir. Bu nedenle dört faktörlü model tercih edilir.Ki-kare fark testi dört faktörlü modelin üç faktörlü modelden anlamlı olarak daha iyi uyum sağladığını önerir. Bu nedenle dört faktörlü model tercih edilir.","code":"\nanova(model_1_fit,model_2_fit )"},{"path":"dfa.html","id":"daha-yüksek-dereceli-faktör-modelleri","chapter":"Bölüm 8 DFA","heading":"8.13 Daha Yüksek Dereceli Faktör Modelleri","text":"Bazı durumlarda sadece ölçümler arasındaki kovaryansları değil, faktörler arasındaki kovaryansları açılayacak faktörlerin hipotez edildiği daha yüksek dereceli faktör modelleri geliştirilebilir.\nBirinci dereceli faktörler (First-order factors): Bir grup göstergenin altında yatan faktörler.\nİkinci dereceli faktörler (Second-order factors): Birinci dereceli faktörlerin altında yatan faktörler.\nDaha yüksek dereceli faktörler (Higher-order factors): Potensiyel olarak eğer aralarında korelasyon bulunan bir grup ikinci dereceli faktör varsa, bu faktörlerin altında yatan daha yüksek dereceli faktörler önerilebilir.\nBazı durumlarda sadece ölçümler arasındaki kovaryansları değil, faktörler arasındaki kovaryansları açılayacak faktörlerin hipotez edildiği daha yüksek dereceli faktör modelleri geliştirilebilir.Birinci dereceli faktörler (First-order factors): Bir grup göstergenin altında yatan faktörler.Birinci dereceli faktörler (First-order factors): Bir grup göstergenin altında yatan faktörler.İkinci dereceli faktörler (Second-order factors): Birinci dereceli faktörlerin altında yatan faktörler.İkinci dereceli faktörler (Second-order factors): Birinci dereceli faktörlerin altında yatan faktörler.Daha yüksek dereceli faktörler (Higher-order factors): Potensiyel olarak eğer aralarında korelasyon bulunan bir grup ikinci dereceli faktör varsa, bu faktörlerin altında yatan daha yüksek dereceli faktörler önerilebilir.Daha yüksek dereceli faktörler (Higher-order factors): Potensiyel olarak eğer aralarında korelasyon bulunan bir grup ikinci dereceli faktör varsa, bu faktörlerin altında yatan daha yüksek dereceli faktörler önerilebilir.Bir Örnek: ZekaBazı zeka araştırmacıları zeka ölçümlerinin hiyerarşik faktör yapılarıyla daha doğru bir şekilde modellenebileceğini belirtmişlerdir:\nBirinci dereceli faktörler (First-order factors): sözel, sayısal, mekanik bilgi, uzamsal ve psikomotor beceriler\nİkinci dereceli faktörler (Second-order factors):\nSözel/eğitimsel faktör: Birinci-dereceli faktörlerden sözel ve sayısal faktörleri kontrol edebilir.\nBeceri/pratik faktör: Birinci-dereceli faktörlerden mekanik bilgi, uzamsal ve psikomotor beceriler faktörlerini kontrol edebilir.\nÜçüncü dereceli faktör (Third-order factor): genel zeka\n\nBazı zeka araştırmacıları zeka ölçümlerinin hiyerarşik faktör yapılarıyla daha doğru bir şekilde modellenebileceğini belirtmişlerdir:Birinci dereceli faktörler (First-order factors): sözel, sayısal, mekanik bilgi, uzamsal ve psikomotor becerilerİkinci dereceli faktörler (Second-order factors):\nSözel/eğitimsel faktör: Birinci-dereceli faktörlerden sözel ve sayısal faktörleri kontrol edebilir.\nBeceri/pratik faktör: Birinci-dereceli faktörlerden mekanik bilgi, uzamsal ve psikomotor beceriler faktörlerini kontrol edebilir.\nÜçüncü dereceli faktör (Third-order factor): genel zeka\nSözel/eğitimsel faktör: Birinci-dereceli faktörlerden sözel ve sayısal faktörleri kontrol edebilir.Beceri/pratik faktör: Birinci-dereceli faktörlerden mekanik bilgi, uzamsal ve psikomotor beceriler faktörlerini kontrol edebilir.Üçüncü dereceli faktör (Third-order factor): genel zekaF1, F2 ve F3 faktörleri arasındaki kovaryanslar daha yüksek dereceli bir faktör tarafından açıklanır: F4Standart bir DFA modelinde faktörler - dışsaldır ve - içsel olan ölçülen değişkenleri etkilerler. Bu nedenle, hem ULI hem de UVI faktörlere ölçek atanmasında uygundur.Daha yüksek dereceli faktör modellerinde, daha yüksek dereceli faktörler dışsaldır ve\niçsel olan ölçülen değişkenleri daha düşük faktörler aracılığıyla dolaylı olarak etkilerler.\nDaha yüksek dereceli faktör modellerinde, daha yüksek dereceli faktörler dışsaldır veiçsel olan ölçülen değişkenleri daha düşük faktörler aracılığıyla dolaylı olarak etkilerler.Bu nedenle, hem ULI hem de UVI daha yüksek dereceli faktörlere ölçek atanmasında uygundur.Bu nedenle, hem ULI hem de UVI daha yüksek dereceli faktörlere ölçek atanmasında uygundur.Ancak yüksek dereceli bir faktör modelinde, bütün daha düşük dereceli faktörler artık dışsal değildir (örneğin, F1, F2 ve F3 faktörleri F4 faktöründen etkilenir. Bu nedenle F1, F2 ve F3 faktörleri içseldir).Ancak yüksek dereceli bir faktör modelinde, bütün daha düşük dereceli faktörler artık dışsal değildir (örneğin, F1, F2 ve F3 faktörleri F4 faktöründen etkilenir. Bu nedenle F1, F2 ve F3 faktörleri içseldir).\\(F_2= \\beta_2*F_4 + \\zeta_2\\) - Sonuç olarak, bir daha düşük dereceli faktörün bir artığı vardır (örneğin, F2 faktörü için ζ2)\\(\\zeta_2\\)’nin varyansı F4 faktörü tarafından açıklanmayan F2 faktörünün varyansının bir parçası olarak açıklanabilir.\\(\\zeta_2\\)’nin varyansı F4 faktörü tarafından açıklanmayan F2 faktörünün varyansının bir parçası olarak açıklanabilir.Bu nedenle daha düşük dereceli faktörlerin varyansları 1’e eşitlenemez, diğer bir ifadeyle UVI uygun olmayacaktır.Bu nedenle daha düşük dereceli faktörlerin varyansları 1’e eşitlenemez, diğer bir ifadeyle UVI uygun olmayacaktır.Bunun yerine bir daha düşük dereceli faktör için ölçekleme yüklerinden birinin 1’e sabitlenmesiyle tanımlanabilir, diğer bir ifadeyle ULI uygun olacaktır.Bunun yerine bir daha düşük dereceli faktör için ölçekleme yüklerinden birinin 1’e sabitlenmesiyle tanımlanabilir, diğer bir ifadeyle ULI uygun olacaktır.Rindskopf ve Rose (1988) daha yüksek dereceli bir modelin değerlendirilmesinin diğer üç modelle karşılaştırılmasını içermesi gerektiğini önermişlerdir. Adımsal modelleme yöntemi önermişlerdir:Adım 1: Genel, tek faktörlü modelin uyumuAdım 2: İkinci dereceli faktör modeliyle karşılaştırmaAdım 3: Korelasyonlu grup faktör modeliyle karşılaştırmaAdım 4: İkili faktörlü (bi-factor) modelle karşılaştırma-- Şemalar Rindskopf ve Rose (1988)’dan alınmıştır.","code":"\nmodel_2order <-  \"\nokul =~ okul1 + okul2 + okul3\nkisi =~ kisi1 + kisi2\narkadas =~ arkadas1 + arkadas2\naile =~ aile1 + aile2 + aile3\n\n# ikinci düzey model\ndoyum =~ okul + kisi + arkadas + aile\n\"\nfit_model_2order <- cfa(model_2order, yasamdoyum)\nsummary(fit_model_2order, fit.measures = TRUE, standardized = TRUE)## lavaan 0.6.17 ended normally after 67 iterations\n## \n##   Estimator                                         ML\n##   Optimization method                           NLMINB\n##   Number of model parameters                        24\n## \n##   Number of observations                           255\n## \n## Model Test User Model:\n##                                                       \n##   Test statistic                                53.372\n##   Degrees of freedom                                31\n##   P-value (Chi-square)                           0.008\n## \n## Model Test Baseline Model:\n## \n##   Test statistic                               583.039\n##   Degrees of freedom                                45\n##   P-value                                        0.000\n## \n## User Model versus Baseline Model:\n## \n##   Comparative Fit Index (CFI)                    0.958\n##   Tucker-Lewis Index (TLI)                       0.940\n## \n## Loglikelihood and Information Criteria:\n## \n##   Loglikelihood user model (H0)              -3428.730\n##   Loglikelihood unrestricted model (H1)      -3402.044\n##                                                       \n##   Akaike (AIC)                                6905.459\n##   Bayesian (BIC)                              6990.450\n##   Sample-size adjusted Bayesian (SABIC)       6914.364\n## \n## Root Mean Square Error of Approximation:\n## \n##   RMSEA                                          0.053\n##   90 Percent confidence interval - lower         0.027\n##   90 Percent confidence interval - upper         0.077\n##   P-value H_0: RMSEA <= 0.050                    0.387\n##   P-value H_0: RMSEA >= 0.080                    0.030\n## \n## Standardized Root Mean Square Residual:\n## \n##   SRMR                                           0.060\n## \n## Parameter Estimates:\n## \n##   Standard errors                             Standard\n##   Information                                 Expected\n##   Information saturated (h1) model          Structured\n## \n## Latent Variables:\n##                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n##   okul =~                                                               \n##     okul1             1.000                               0.555    0.407\n##     okul2             1.439    0.261    5.508    0.000    0.799    0.622\n##     okul3             2.118    0.449    4.713    0.000    1.175    0.883\n##   kisi =~                                                               \n##     kisi1             1.000                               0.736    0.675\n##     kisi2             0.924    0.153    6.040    0.000    0.680    0.777\n##   arkadas =~                                                            \n##     arkadas1          1.000                               0.662    0.792\n##     arkadas2          0.612    0.117    5.229    0.000    0.405    0.530\n##   aile =~                                                               \n##     aile1             1.000                               0.780    0.741\n##     aile2             1.068    0.131    8.136    0.000    0.833    0.849\n##     aile3             0.595    0.084    7.106    0.000    0.465    0.507\n##   doyum =~                                                              \n##     okul              1.000                               0.322    0.322\n##     kisi              2.720    0.985    2.763    0.006    0.661    0.661\n##     arkadas           3.397    1.250    2.717    0.007    0.917    0.917\n##     aile              1.686    0.661    2.550    0.011    0.386    0.386\n## \n## Variances:\n##                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n##    .okul1             1.547    0.148   10.481    0.000    1.547    0.834\n##    .okul2             1.011    0.139    7.278    0.000    1.011    0.613\n##    .okul3             0.390    0.231    1.689    0.091    0.390    0.220\n##    .kisi1             0.647    0.100    6.442    0.000    0.647    0.544\n##    .kisi2             0.303    0.075    4.020    0.000    0.303    0.396\n##    .arkadas1          0.261    0.080    3.277    0.001    0.261    0.373\n##    .arkadas2          0.420    0.047    8.958    0.000    0.420    0.719\n##    .aile1             0.501    0.079    6.317    0.000    0.501    0.452\n##    .aile2             0.268    0.078    3.429    0.001    0.268    0.279\n##    .aile3             0.625    0.061   10.256    0.000    0.625    0.743\n##    .okul              0.276    0.095    2.915    0.004    0.896    0.896\n##    .kisi              0.305    0.091    3.369    0.001    0.563    0.563\n##    .arkadas           0.070    0.106    0.661    0.509    0.159    0.159\n##    .aile              0.518    0.097    5.360    0.000    0.851    0.851\n##     doyum             0.032    0.021    1.536    0.125    1.000    1.000\n# sem_fitmeasures(fit_model_2order)\nsem_factorloadings(fit_model_2order,standardized = TRUE)\nanova(fit_model_2order, model_2_fit, model_1_fit )\nsemPaths(fit_model_2order, \"std\", weighted = FALSE, nCharNodes = 7, \n         shapeMan = \"rectangle\", sizeMan = 8, sizeMan2 = 5)\nsemTools::reliability(fit_model_2order)##             okul      kisi   arkadas      aile\n## alpha  0.6521208 0.6772692 0.5897284 0.7284332\n## omega  0.6844920 0.6783398 0.6260070 0.7559295\n## omega2 0.6844920 0.6783398 0.6260070 0.7559295\n## omega3 0.6853071 0.6783398 0.6260070 0.7624866\n## avevar 0.4411637 0.5136422 0.4696157 0.5213877\nsemTools::reliability(model_2_fit)##             okul kisi_arkadas      aile\n## alpha  0.6521208    0.6802465 0.7284332\n## omega  0.6823834    0.6958670 0.7559432\n## omega2 0.6823834    0.6958670 0.7559432\n## omega3 0.6872796    0.6984813 0.7633658\n## avevar 0.4340664    0.3767532 0.5208713"},{"path":"dfa.html","id":"kaynaklar-5","chapter":"Bölüm 8 DFA","heading":"8.14 Kaynaklar","text":"Rindskopf, D. & Rose, T. (1988. theory applications confirmatory second-order factor analysis. Multivariate Behavioral Research, 23(1), 51-67Rindskopf, D. & Rose, T. (1988. theory applications confirmatory second-order factor analysis. Multivariate Behavioral Research, 23(1), 51-67Bentler, P. M. & Hu, L. (1999). Cutoff criteria fpr fit indexes covariance structure analysis: Conventional criteri versus new alternatives. Structural Equation Modeling, 6(1), 1-55.Bentler, P. M. & Hu, L. (1999). Cutoff criteria fpr fit indexes covariance structure analysis: Conventional criteri versus new alternatives. Structural Equation Modeling, 6(1), 1-55.Bentler, P. M. (1990). Comparative fit indexes structural models. Psychological Bulletin, 107, 238-246. - Steiger, J. H. (1990). Structural model evaluation modification: interval estimation approach. Multivariate Behavioral Research, 25, 173-80.Bentler, P. M. (1990). Comparative fit indexes structural models. Psychological Bulletin, 107, 238-246. - Steiger, J. H. (1990). Structural model evaluation modification: interval estimation approach. Multivariate Behavioral Research, 25, 173-80.","code":""},{"path":"ölçme-değişmezliği.html","id":"ölçme-değişmezliği","chapter":"Bölüm 9 Ölçme Değişmezliği","heading":"Bölüm 9 Ölçme Değişmezliği","text":"Ölçme araçlarından elde edilen puanları genellikle bireylerin davranışları hakkında çıkarımlarda bulunmak için kullanılır.Ölçme araçlarından elde edilen puanları genellikle bireylerin davranışları hakkında çıkarımlarda bulunmak için kullanılır.Yüksek bir güvenirlik katsayısı bireylerin puanlarında tutarlık olduğunu belirtir ancak bireylerle ilgili savunulabilir çıkarımlarda bulunmayı garantilemez!Yüksek bir güvenirlik katsayısı bireylerin puanlarında tutarlık olduğunu belirtir ancak bireylerle ilgili savunulabilir çıkarımlarda bulunmayı garantilemez!Test puanlarından yapılacak çıkarımların doğruluğunun derecesi geçerlik olarak tanımlanır.Test puanlarından yapılacak çıkarımların doğruluğunun derecesi geçerlik olarak tanımlanır.Geçerlik; elde edilen puanların anlamlarının ve kullanımlarının, değerlendirmenin yapılış amacına uygunluğu ve bu amaç için yeterliliğidir.Geçerlik, tekil bir kavramdır. Farklı geçerlik türleri yoktur. Farklı geçerlik kanıtı sağlama yolları ve farklı geçerlik kanıtı kaynakları vardır.Geçerlik İçin Olası KaynaklarTest kapsamına dayalı kanıtYanıtlama süreçlerine dayalı kanıtDiğer değişlenlerle ilişkilere dayalı kayıtİç yapıya dayalı kanıtTest sonuçlarına dayalı kanıtİç yapıya dayalı kanıt-Olcme Degismezligi\n\nİç yapıya dayalı kanıt-Olcme DegismezligiÖlçme değişmezliği incelemeleri iki genel yaklaşımla incelebilmektedir.Yapısal Eşitlik Modelleri (YEM)Yapısal Eşitlik Modelleri (YEM)Madde Tepki Kuramı'na (MTK)Madde Tepki Kuramı'na (MTK)","code":""},{"path":"ölçme-değişmezliği.html","id":"ölçme-değişmezliği-aşamları","chapter":"Bölüm 9 Ölçme Değişmezliği","heading":"9.1 Ölçme Değişmezliği Aşamları","text":"Modeli belirleme (model specification)Modeli belirleme (model specification)Tanımlama (identification)Tanımlama (identification)Hesaplama (estimation)Hesaplama (estimation)Uyumun testi (testing fit)Uyumun testi (testing fit)Yeniden belirleme (respecification) aşamalarından oluşmaktadır.Yeniden belirleme (respecification) aşamalarından oluşmaktadır.","code":""},{"path":"ölçme-değişmezliği.html","id":"yem-aşamaları","chapter":"Bölüm 9 Ölçme Değişmezliği","heading":"9.2 YEM-Aşamaları","text":"Model UyumuModel Uyum İndeksleri","code":""},{"path":"ölçme-değişmezliği.html","id":"ölçme-değişmezliği-modelleri","chapter":"Bölüm 9 Ölçme Değişmezliği","heading":"9.2.1 Ölçme Değişmezliği Modelleri","text":"Şekil değişmezliği (configural invariance) modeliŞekil değişmezliği (configural invariance) modeliZayıf değişmezlik (weak invariance) modeliZayıf değişmezlik (weak invariance) modeliGüçlü değişmezlik (strong invariance) modeliGüçlü değişmezlik (strong invariance) modeliKatı değişmezlik (strict invariance) modeliKatı değişmezlik (strict invariance) modeli2 faktör 6 gösterge de toplam hesaplanabilen parametre sayısıSerbest model ve sınırlandırılmış model yuvalanmış modeller olup sınırlandırılmış model serbest modelin içinde yuvalanmıştır.Serbest model ve sınırlandırılmış model yuvalanmış modeller olup sınırlandırılmış model serbest modelin içinde yuvalanmıştır.Bu nedenle sınırlandırılmış modelin veriye serbest modele göre anlamlı olarak daha kötü uyum sağlayıp sağlamadığını belirlemek için ki-kare fark testi kullanılabilir.\n\\[X^2_{dif} = X^2_{sinir} -  X^2_{serbest}\\]\n\\[df_{dif} =  df_{sinir} - df_{serbest}\\]Bu nedenle sınırlandırılmış modelin veriye serbest modele göre anlamlı olarak daha kötü uyum sağlayıp sağlamadığını belirlemek için ki-kare fark testi kullanılabilir.\\[X^2_{dif} = X^2_{sinir} -  X^2_{serbest}\\]\\[df_{dif} =  df_{sinir} - df_{serbest}\\]Şekil değişmezliği (configural /pattern invariance)Gruplar aynı genel faktör yapısına sahip mi?en az kısıtlayıcı modelen az kısıtlayıcı modelmodel veri ile uyumlu değilse, hiç bir temel düzeyde geçerli olmaz.model veri ile uyumlu değilse, hiç bir temel düzeyde geçerli olmaz.Alt indislerin ilki madde, ikincisi grup için kullanılmıştır.\nAlt indislerin ilki madde, ikincisi grup için kullanılmıştır.Zayıf Değişmezlik (Metric/Weak factorial invariance)Gruplar aynı faktör yüklerine sahip mi?bir göstergenin yükü (standartlaştırılmış katsayısı üzerinde gruplarda eşitlik kısıtı getirilir.Güçlü Değişmezlik (Strong/Scalar invariance)Gruplar aynı gösterge sabitlerine sahip mi?eşit standartlaştırılmış kesen değere sahip mi?Gruplar aynı artık varyanslara sahip mi?","code":""},{"path":"ölçme-değişmezliği.html","id":"özet","chapter":"Bölüm 9 Ölçme Değişmezliği","heading":"9.3 Özet","text":"Ölçme Değişmezliği Hiyerarşik Modellerinde Serbest Tahminlenen ve Sabitlenen Parametreler [Gregorich, 2006]","code":""},{"path":"ölçme-değişmezliği.html","id":"özet-1","chapter":"Bölüm 9 Ölçme Değişmezliği","heading":"9.4 Özet","text":"DFA modelini grupta ayrı ayrı test ediniz.DFA modelini grupta ayrı ayrı test ediniz.Özdeş faktör yapısını eş zamanlı test ediniz.Özdeş faktör yapısını eş zamanlı test ediniz.Faktör yüklerinin eşitliğini test ediniz.Faktör yüklerinin eşitliğini test ediniz.Gösterge sabitlerinin eşitliğini test ediniz.Gösterge sabitlerinin eşitliğini test ediniz.Gösterge artık varyanslarının eşitliğini test ediniz.Gösterge artık varyanslarının eşitliğini test ediniz.Faktör varyanslarının eşitliğini test ediniz.Faktör varyanslarının eşitliğini test ediniz.Faktör kovaryanslarının eşitliğini test ediniz.Faktör kovaryanslarının eşitliğini test ediniz.Faktör ortalamalarını test ediniz.\n(Brown, 2015; Şen, 2020)Faktör ortalamalarını test ediniz.(Brown, 2015; Şen, 2020)","code":""},{"path":"ölçme-değişmezliği.html","id":"uygulama-1","chapter":"Bölüm 9 Ölçme Değişmezliği","heading":"9.5 Uygulama","text":"DFA modelini grupta ayrı ayrı test ediniz.Özdeş faktör yapısını eş zamanlı test ediniz.Faktör yüklerinin eşitliğini test ediniz.Modeller arası uyumu degerlendirmeZayıf degismezlikte kestirilen faktor yukleriZayıf degismezlikte kestirilen faktor yukleriTablo 9.1: Factor LoadingsZayıf degismezlikte kestirilen madde sabitleriTablo 9.2: InterceptsGösterge sabitlerinin eşitliğini test ediniz.Modeller arası uyumu degerlendirme","code":"\nlibrary(lavaan)\nHS.model <- 'visual =~ x1 + x2 + x3\ntextual =~ x4 + x5 + x6\nspeed =~ x7 + x8 + x9'\nPasteur <- subset(HolzingerSwineford1939,\n          school==\"Pasteur\")\nGrandwhite <- subset( HolzingerSwineford1939, \n              school==\"Grant-White\")\nPasteur_cfa <- cfa(HS.model, data=Pasteur)\nGrandwhite_cfa <- cfa(HS.model, data=Grandwhite)\nfit <- c(\"chisq\", \"df\", \"pvalue\",\"rmsea\", \"srmr\",\"cfi\")\nfitmeasures(Pasteur_cfa, fit.measures = fit)\nfitmeasures(Grandwhite_cfa,fit) chisq     df pvalue  rmsea   srmr    cfi \n64.309 24.000  0.000  0.104  0.077  0.903 \n chisq     df pvalue  rmsea   srmr    cfi \n51.542 24.000  0.001  0.089  0.072  0.941 \nconfigural <- cfa(HS.model, data=HolzingerSwineford1939, \ngroup = \"school\")\n# bicimsel degimezlik\nfitmeasures(configural, fit.measures = fit)  chisq      df  pvalue   rmsea    srmr     cfi \n115.851  48.000   0.000   0.097   0.068   0.923 \nweak <- cfa(HS.model,data=HolzingerSwineford1939, group = \"school\",\ngroup.equal=c(\"loadings\"))\n# bicimsel degimezlik\nfitmeasures(configural, fit.measures = fit)\n# zayıf degimezlik\nfitmeasures(weak, fit.measures = fit)  chisq      df  pvalue   rmsea    srmr     cfi \n115.851  48.000   0.000   0.097   0.068   0.923 \n  chisq      df  pvalue   rmsea    srmr     cfi \n124.044  54.000   0.000   0.093   0.072   0.921 \n# anova(weak, configural)\n\nknitr::kable(anova(weak, configural)) \nparEst <- parameterEstimates(weak) %>% \n  filter(op == \"=~\") %>% \n  select('Latent Factor'=lhs, Indicator=rhs, B=est) \nstrong <- cfa(HS.model, data=HolzingerSwineford1939, \ngroup = \"school\", group.equal=c(\"loadings\",\"intercepts\"))\nfitmeasures(weak,fit.measures = fit)\n# guclu degimezlik\nfitmeasures(strong,fit.measures = fit)  chisq      df  pvalue   rmsea    srmr     cfi \n124.044  54.000   0.000   0.093   0.072   0.921 \n  chisq      df  pvalue   rmsea    srmr     cfi \n164.103  60.000   0.000   0.107   0.082   0.882 \n# anova(strong, weak)\n\nknitr::kable(anova(strong, weak)) "},{"path":"ölçme-değişmezliği.html","id":"kaynakca","chapter":"Bölüm 9 Ölçme Değişmezliği","heading":"9.6 Kaynakca","text":"Kelecioğlu, H. & Göçer Şahin, S . (2014). Geçmişten günümüze geçerlik . Journal Measurement Evaluation Education Psychology , 5 (2) , 1-11 . DOI: 10.21031/epod.41706 linkAERA,APA, & NCME (2004). Standards Educational Psychological Testing. Washington, DC: American Educational Research Association linkKline, R. B. (2006). Structural equation modeling.Guilford Press.Şen, S. Mplus ile Yapısal Eşitlik Modellemesi Uygulamaları. Nobel Yayınevi.Vandenberg RJ, Lance CE. Review Synthesis Measurement Invariance Literature: Suggestions, Practices, Recommendations Organizational Research. Organizational Research Methods. 2000,3(1), 4-70. doi:10.1177/109442810031002Wu, . D., Li, Z., & Zumbo, B. D. (2007). Decoding meaning factorial invariance updating practice multi-group confirmatory factor analysis: demonstration TIMSS data. Practical Assessment, Research Evaluation, 12(3). https://doi.org/10.7275/mhqa-cd89","code":""},{"path":"kontrol-yapıları.html","id":"kontrol-yapıları","chapter":"Bölüm 10 Kontrol Yapıları","heading":"Bölüm 10 Kontrol Yapıları","text":"R'deki kontrol yapıları, bir dizi R ifadesinin yürütme akışını kontrol etmenize olanak tanır. Temel olarak kontrol yapıları, zaman aynı R kodunu çalıştırmak yerine kod satırlarında mantığımızı kullanmamızı sağlar.Kontrol yapıları, girdilere veya verilerin özelliklerine yanıt vermenize ve buna göre farklı R ifadeleri yürütmenize olanak tanır.Yaygın olarak kullanılan kontrol yapıları:ve else: bir koşulu test etmek ve ona göre hareket etmekif ve else: bir koşulu test etmek ve ona göre hareket etmekfor: bir döngüyü sabit sayıda çalıştırmafor: bir döngüyü sabit sayıda çalıştırmawhile: bir koşul doğru iken bir döngü yürütmekwhile: bir koşul doğru iken bir döngü yürütmekrepeat: sonsuz bir döngü yürütmek (durdurmak için break gerekir)repeat: sonsuz bir döngü yürütmek (durdurmak için break gerekir)break: bir döngünün yürütülmesini keserbreak: bir döngünün yürütülmesini kesernext: bir döngü arasını atlamanext: bir döngü arasını atlamaÇoğu kontrol yapısı etkileşimli oturumlarda değil, daha ziyade fonksiyonlar veya daha uzun ifadeler yazarken kullanılır. Ancak, bu yapılar fonksiyonlarda kullanılmak zorunda değildir ve progralama öğrenmek için bu yapılara aşina olmak gereklidir.Döngüler diğer bütün programa dillerinde sıklıkla kullanılan akış kontrolü (flow control) mekanizmasının bir parçasıdır.Döngüler diğer bütün programa dillerinde sıklıkla kullanılan akış kontrolü (flow control) mekanizmasının bir parçasıdır.ne kadar R vektörel elementler üzerine kurulmuş olsa da bazı durumlarda döngülerin kullanılması gerekebilir.ne kadar R vektörel elementler üzerine kurulmuş olsa da bazı durumlarda döngülerin kullanılması gerekebilir.Örneğin, simulasyon çalışmaları genellikle iterasyonel ve tekrar eden süreçleri içermektedir.Örneğin, simulasyon çalışmaları genellikle iterasyonel ve tekrar eden süreçleri içermektedir.Döngüler sonuç elde etmek yerine süreçteki işlemleri dikkate aldığından, simulasyon çalışmalarında kullanılır.Döngüler sonuç elde etmek yerine süreçteki işlemleri dikkate aldığından, simulasyon çalışmalarında kullanılır.() döngüsü ile belirlenen sayıda işlem tekrarı yapılırken () ya da repeat() döngülerinde bir sayaç ya da bir dizin ile kontrol sağlanarak işlemlerin tekrarlı yapılmasını sağlar.() döngüsü ile belirlenen sayıda işlem tekrarı yapılırken () ya da repeat() döngülerinde bir sayaç ya da bir dizin ile kontrol sağlanarak işlemlerin tekrarlı yapılmasını sağlar.() bir vektör, liste ya da matris içindeki bir elemanın bir değişken yardımıyla belirlenen komutu veya kodu sırasıyla yapması için oluşturulan bir döngüdür.() bir vektör, liste ya da matris içindeki bir elemanın bir değişken yardımıyla belirlenen komutu veya kodu sırasıyla yapması için oluşturulan bir döngüdür.","code":""},{"path":"kontrol-yapıları.html","id":"if-else","chapter":"Bölüm 10 Kontrol Yapıları","heading":"10.1 if-else","text":"-else kombinasyonu muhtemelen R'de (veya belki de herhangi bir dilde) en sık kullanılan kontrol yapısıdır. Bu yapı, bir koşulu test etmenize ve doğru ya da yanlış olmasına bağlı olarak ona göre hareket etmenize olanak tanır.Öncelilke koşullu ifadesinin kullanımını gösterelim:Yukarıdaki kod, koşul yanlışsa hiçbir şey yapmaz. Koşul yanlış olduğunda yürütmek istediğiniz bir eyleminiz varsa, o zaman bir else cümlesine ihtiyacınız vardır.ifi herhangi bir ile takip ederek bir dizi test yapabilirsiniz. else kullanabilirsiniz.İşte geçerli bir /else yapısına bir örnek.y değeri x > 3 olup olmamasına bağlı olarak ayarlanır. Bu ifade eşdeğer bir şekilde de yazılabilir.Bu ifadeyi yazmanın hiçbir yolu diğerinden daha doğru değildir. Hangisini kullanacağınız sizin tercihlerinize bağlıdırElbette else cümlesi gerekli değildir. Kendi koşulları doğruysa zaman çalıştırılan bir dizi cümlesine sahip olabilirsiniz.","code":"if(<koşul>) {\n        ## kodlar\n} if(<koşul>) {\n        ## kodlar\n} \nelse {\n        ## kodlar\n}if(<kosul1>) {\n        ## kodlar\n} else if(<kosul2>)  {\n        ## kodlar\n} else {\n        ## kodlar\n}##  bir rastgele sayı oluşturun\nx <- runif(1, 0, 10)\nif(x > 3) {\n        y <- 10\n} else {\n        y <- 0\n}\nx;y\n[1] 1.747449\n[1] 0\ny <- if(x > 3) {\n        10\n} else { \n        0\n}if(<kosul1>) {\n\n}\n\nif(<kosul2>) {\n\n}"},{"path":"kontrol-yapıları.html","id":"örnekler","chapter":"Bölüm 10 Kontrol Yapıları","heading":"10.1.1 Örnekler","text":"Ölçme açısından bakılacak olursa koşul bir ölçütü, durum\ncümlesi ise değerlendirmeyi gösterilebilir.\nÖrneğin, yapılan bir sınavda geçme notu 60 olarak belirlendiğinde, 75 alan bir öğrencinin durumu aşağıdaki () durum cümlesiyle belirlenebilmektedir.Ancak kontrol durumu çoğunlukla tek önermeye bağlı değildir.\n- Aşağıdaki kod çıktı vermeyecektirelse kullanımı ile çıktı alabilirizKoşul zaman iki kategori ile tanımlanamayabilir. Bu durumda kullanımı\nelse () ile destekleyebiliriz","code":"x <-75\nif(x>=65){\nprint(\"Basarılı\")\n}\n[1] \"Basarılı\"\nx <-60\nif(x>=65){\nprint(\"Basarılı\")\n}x <-60\n# Başarılı Durum\nif(x>=65){\nprint(\"Basarılı\")\n}else{\nprint(\"Basarisiz\")\n}\n[1] \"Basarisiz\"x <- 75 # Başarılı Durum\nif(x>=90){\nprint(\"AA\")\n}else if(x>=80){\nprint(\"BA\")\n}else if(x>=70){\nprint(\"BB\")\n}else if(x>=65){\nprint(\"CB\")\n}else if(x>=60){\nprint(\"CC\")\n}else if(x>=50){\nprint(\"DD\")\n}else if(x>=30){\nprint(\"FD\")\n}else{\nprint(\"FF\")\n}\n[1] \"BB\""},{"path":"kontrol-yapıları.html","id":"sıra-sizde","chapter":"Bölüm 10 Kontrol Yapıları","heading":"10.1.2 Sıra sizde","text":"sayısının çarpmaya göre tersi 1/'dir. Ancak bu durum 0 için tanımsızdır.\n() durum cümlesi kullanarak bu durumu kodlayınız. x <- 5ve x<-0 için\niçin test ediniz.x <- 0için test ediniz.-2 ile 2 arasinda sayilar üretip, bunu x değişkenine atayalım.Random olarak üretilen sayının 1'den büyük olması durumunda çıktı \"1'den büyük\" -1 ile 1 arasında olması durumunda \"-1 ile +1 arasında\" -1'den küçük olması durumunda ise \"-1'den küçük\" çıktısı versin.","code":"[1] \"5'in carpmaya gore tersi 1/5\"[1] \"1/0 tanımsızdır.\"x <- rnorm(1)\nx\n[1] 0.2225745[1] 0.3295714\n[1] \"sayı -1 ile +1 arasında\""},{"path":"kontrol-yapıları.html","id":"if-all","chapter":"Bölüm 10 Kontrol Yapıları","heading":"10.2 if() & all()","text":"ne kadar () önermesi bir elemanlı vektörlerde çıktı verirken () önermesi içinde kullanılabilen fonkisyonu ile vektörün tüm elemanları için kosul test edilebilir.","code":"x <- c(1,2,-3,4)\nif(all(x>0)){\n  \n  print(\"tum sayilar 0'dan buyuktur\")\n  \n} else{\n  \n  print(\"tum sayilar 0'dan buyuk degildir\")\n}\n[1] \"tum sayilar 0'dan buyuk degildir\""},{"path":"kontrol-yapıları.html","id":"if-any","chapter":"Bölüm 10 Kontrol Yapıları","heading":"10.3 if() & any()","text":"Bir vektörde icinde yer alan hangi bir elemana dair test ise () fonksiyonu içinde () fonksiyonu ile sağlanabilir.","code":"x <- c(1,2,-3,4)\nif(any(x<0)){\n  \n  print(\"nesne en az bir negatif sayi icerir\")\n  \n} else{\n  \n  print(\"nesne negatif sayi icermez\")\n}\n[1] \"nesne en az bir negatif sayi icerir\""},{"path":"kontrol-yapıları.html","id":"if-çoklu-islem","chapter":"Bölüm 10 Kontrol Yapıları","heading":"10.4 if() çoklu islem","text":"","code":"x <- 2\nif(x == 2) {\n  \n  goster3 <- \"Dogru\"  \n  goster3b <- c(1,2,3)\n  goster3c <- sample(1:1000,4)\n} else  {\n  \n  goster3 <- \"Yanlis\"  \n  goster3b <- c(3,2,1)\n  goster3c <- 10000 + sample(1:1000,4)\n  \n}\n\ngoster3\ngoster3b\ngoster3c\n[1] \"Dogru\"\n[1] 1 2 3\n[1] 670 921 301 355"},{"path":"kontrol-yapıları.html","id":"ifelse","chapter":"Bölüm 10 Kontrol Yapıları","heading":"10.5 ifelse()","text":"ifelse() durum cümlesi, () durum cümlelerinde vektörlerin kullanımından kaynaklı sıkıntılara çözüm sunar. Bu bakımdan ifelse(), () durum cümlelerinin vektörler için kullanılabilir halidir.ifelse() durum cümlesinin genel kullanımı aşağıdaki gibidir.ifelse(koşul, Doğru İfade, Yanlış İfade)ifelse() eksik veri atamakiçin de kullanılabilir. Eksik verinin 99 ile gösterildiği bir vektörde eksik veri yerine NA atama örneği","code":"x <- 20\nifelse(x>= 65, \"Başarılı\" ,\"Başarısız\")\n[1] \"Başarısız\"(x <- c(1,2,3,4,99,5))\nifelse(x==99, NA, x)\n[1]  1  2  3  4 99  5\n[1]  1  2  3  4 NA  5"},{"path":"kontrol-yapıları.html","id":"sıra-sizde-1","chapter":"Bölüm 10 Kontrol Yapıları","heading":"10.5.1 Sıra Sizde","text":"Elimizdeki bir nesnede yer alan sayıların tek ya da çift olduğunu yazdırmaElimizdeki bir nesnede yer alan sayıların 0, pozitif ya negatif oldugu belirlemeFinalden 50 ve üzeri alan ve en az 11 derse devam edem öğrencilerin geçme notları finalin %60 ve vizenin %40 alınarak hesaplansın, 11'den az derse devam eden öğrencilerin geçme notu final notunun %60' olarak alınsın.","code":"set.seed(41)\nsayilar <- sample(50:90,27)\nsayilar\n [1] 89 84 54 81 57 78 55 71 80 62 87 67 70 83 82 61 66 53 50 69 79 64 85 51 73\n[26] 74 88 [1] \"Tek Sayi\"  \"Cift Sayi\" \"Cift Sayi\" \"Tek Sayi\"  \"Tek Sayi\"  \"Cift Sayi\"\n [7] \"Tek Sayi\"  \"Tek Sayi\"  \"Cift Sayi\" \"Cift Sayi\" \"Tek Sayi\"  \"Tek Sayi\" \n[13] \"Cift Sayi\" \"Tek Sayi\"  \"Cift Sayi\" \"Tek Sayi\"  \"Cift Sayi\" \"Tek Sayi\" \n[19] \"Cift Sayi\" \"Tek Sayi\"  \"Tek Sayi\"  \"Cift Sayi\" \"Tek Sayi\"  \"Tek Sayi\" \n[25] \"Tek Sayi\"  \"Cift Sayi\" \"Cift Sayi\"set.seed(987)\nsayilar <- sample(-10:10,27,replace=TRUE)\nsayilar\n [1]   4   3   4   2   1   7 -10   5   6  -8   7  -3   9   7  -9  10   4  -1  -8\n[20]   8  -3   0   4   5   8   1   3 [1] \"Pozitif\" \"Pozitif\" \"Pozitif\" \"Pozitif\" \"Pozitif\" \"Pozitif\" \"Negatif\"\n [8] \"Pozitif\" \"Pozitif\" \"Negatif\" \"Pozitif\" \"Negatif\" \"Pozitif\" \"Pozitif\"\n[15] \"Negatif\" \"Pozitif\" \"Pozitif\" \"Negatif\" \"Negatif\" \"Pozitif\" \"Negatif\"\n[22] \"Sıfır\"   \"Pozitif\" \"Pozitif\" \"Pozitif\" \"Pozitif\" \"Pozitif\"\nvize <- c(60,70,80,90,55)\nfinal <- c(45,65,70,50,80)\ndevam <- c(14,10,13,12,11)"},{"path":"for.html","id":"for","chapter":"Bölüm 11 for","heading":"Bölüm 11 for","text":"Zaman zaman diğer döngü türlerine ihtiyaç duysanız da, döngüsünün yeterli olmadığı nadir durum vardır.\nR'de döngüleri bir ara değişken alır ve ona bir dizi ya da vektörden ardışık değerler atar. döngüleri en yaygın olarak bir nesnenin (liste, vektör, vb.) elemanları üzerinde yineleme yapmak için kullanılır.Bu döngü değişkenini alır ve döngünün iterasyonunda ona 1, 2, 3, ..., 10 değerlerini verir, küme parantezleri içindeki kodu çalıştırır ve ardından döngüden çıkar.Aşağıdaki üç döngünün hepsi aynı davranışa sahiptir.seq_along() fonksiyonu genellikle bir nesnenin (bu durumda x nesnesi) uzunluğuna bağlı olarak bir tamsayı dizisi oluşturmak için döngüleriyle birlikte kullanılır.İndeks değişken kullanmak gerekli değildir.Bir satırlık döngüler için, küme parantezleri kesinlikle gerekli değildir.Bununla birlikte, tek satırlık döngüler için bile küme parantezleri kullanmayı seviyorum, çünkü bu şekilde döngüyü birden fazla satıra genişletmeye karar verirseniz, küme parantezleri eklemeyi unuttuğunuz için hata alamazsınız.Döngüde indeks değişkeni herhangi bir nesne ile tanımlanabilir. Örneğin , ayrıca indeks değerinin başlangıcı 1 olmak zorunda değildir.karakter yazımında indeks sadece tekrar amaçlı kullanılır.Aşağıdaki çıktıyı sağlayacak kodu yazınız.Döngüdelerde bir degişken yeniden tanımlanacak ise mutlaka döngü öncesi o değişken tanımlanmalıdır.Döngüdelerde bir degişken yeniden tanımlanacak ise mutlaka döngü öncesi o değişken tanımlanmalıdır.Oluşturulan bir matrisin satırlarında yer alan sayıların toplamını başka bir nesneye atamaOluşturulan bir matrisin satırlarında yer alan sayıların toplamını başka bir nesneye atamacat(), paste() gibi fonksiyonları uzun bir döngüde, döngünün durumunu görmek için de kullanabilirsiniz .Döngülerde zaman indeksini kullanmak zorunda değiliz.","code":"for(i in 1:10) {\n        print(i)\n}\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 5\n[1] 6\n[1] 7\n[1] 8\n[1] 9\n[1] 10x <- c(\"a\", \"b\", \"c\", \"d\")\n\nfor(i in 1:4) {\n        ## 'x'in her bir öğesini yazdırır\n        print(x[i])  \n}\n[1] \"a\"\n[1] \"b\"\n[1] \"c\"\n[1] \"d\"## 'x' uzunluğuna göre bir dizi oluşturun\nfor(i in seq_along(x)) {   \n        print(x[i])\n}\n[1] \"a\"\n[1] \"b\"\n[1] \"c\"\n[1] \"d\"for(letter in x) {\n        print(letter)\n}\n[1] \"a\"\n[1] \"b\"\n[1] \"c\"\n[1] \"d\"for(i in 1:4) print(x[i])\n[1] \"a\"\n[1] \"b\"\n[1] \"c\"\n[1] \"d\"for(i in 1:10) {\n print(i)\n}\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 5\n[1] 6\n[1] 7\n[1] 8\n[1] 9\n[1] 10for(i in 5:8) {\n print(i)\n}\n[1] 5\n[1] 6\n[1] 7\n[1] 8for(i in 5:10){\n  print(\"Merhaba\")\n}\n[1] \"Merhaba\"\n[1] \"Merhaba\"\n[1] \"Merhaba\"\n[1] \"Merhaba\"\n[1] \"Merhaba\"\n[1] \"Merhaba\"1  +   1  =  2 \n2  +   2  =  4 \n3  +   3  =  6 \n4  +   4  =  8 \n5  +   5  =  10 \n6  +   6  =  12 \n7  +   7  =  14 \n8  +   8  =  16 \n9  +   9  =  18 \n10  +   10  =  20 (X <- cbind(a = 1:5, b=2:6))\nY <- array()\nfor(i in 1:nrow(X)) {\nY[i] <- X[i,1] + X[i,2]\n}\nY\n     a b\n[1,] 1 2\n[2,] 2 3\n[3,] 3 4\n[4,] 4 5\n[5,] 5 6\n[1]  3  5  7  9 11islem.kontrol <- array()\nfor(i in 1:10){\n  islem.kontrol[i] <- paste(\"Islem \", i, \" tamamlandi\", sep=\"\")\n}\nislem.kontrol\n [1] \"Islem 1 tamamlandi\"  \"Islem 2 tamamlandi\"  \"Islem 3 tamamlandi\" \n [4] \"Islem 4 tamamlandi\"  \"Islem 5 tamamlandi\"  \"Islem 6 tamamlandi\" \n [7] \"Islem 7 tamamlandi\"  \"Islem 8 tamamlandi\"  \"Islem 9 tamamlandi\" \n[10] \"Islem 10 tamamlandi\"set.seed(10)\nx <- sample(1:10000,100)\n\nsayac <- 0\nfor (val in x) {\n  if(val %% 2 == 0){\nsayac = sayac+1\n  }\n}\nprint(sayac)\n[1] 46"},{"path":"for.html","id":"for-döngüsü-ve-kontrol","chapter":"Bölüm 11 for","heading":"11.1 for() Döngüsü ve Kontrol","text":"zaman işlemi tüm elemanlara uygulamak istemeyebiliriz. Bunun önlemek icin akış kontrolü yapmak gerekir.Kontrol mantıksal operatörlerle ya da koşul cümleleri ile sağlanabilir.Döngünün indeksi zaman bir tam sayı olmak zorunda değildir. Liste, veri seti, matris de olabilir.Döngünün indeksi zaman bir tam sayı olmak zorunda değildir. Liste, veri seti, matris de olabilir.sadece numerik değer ve vektörlerle çalışmaz. Aynı zamanda veri seti, matris ve listelerle de çalışabilir.sadece numerik değer ve vektörlerle çalışmaz. Aynı zamanda veri seti, matris ve listelerle de çalışabilir.Aşağıdaki çıktıyı elde etmek için gerekli kodu yazınız.","code":"for(i in 1:3){\n  if (i==2) cat(\"indeks cift sayidir:\",\"\\n\")\n  else cat(i,\"\\n\")\n}\n1 \nindeks cift sayidir: \n3 for(i in 1:3){\n  if (i==2) {\ncat(\"indeks degeri ikidir:\",i,\"\\n\") \n  }else{cat(\"indeks degeri iki degildir\",\"\\n\")}\n}\nindeks degeri iki degildir \nindeks degeri ikidir: 2 \nindeks degeri iki degildir \nd <- data.frame(a = 1:5, b=2:6)\nd\nfor(x in d) {\n  cat(\"sutun toplamlari:\", sum(x), \"\\n\")\n}sutun toplamlari: 15 \nsutun toplamlari: 20 X <- cbind(1:5, 21:25)\nX\n     [,1] [,2]\n[1,]    1   21\n[2,]    2   22\n[3,]    3   23\n[4,]    4   24\n[5,]    5   251 satirdaki degerlerin carpimi 21 olarak hesaplanmistir. \n2 satirdaki degerlerin carpimi 44 olarak hesaplanmistir. \n3 satirdaki degerlerin carpimi 69 olarak hesaplanmistir. \n4 satirdaki degerlerin carpimi 96 olarak hesaplanmistir. \n5 satirdaki degerlerin carpimi 125 olarak hesaplanmistir. "},{"path":"for.html","id":"next-ve-break","chapter":"Bölüm 11 for","heading":"11.2 next() ve break()","text":"next() ve break() fonksiyonları döngülerde kontrol mekanizmasıdır. Döngüyü sadece belirli bir koşulda çalıştırmak istemezseniz next() fonksiyonunu kullanabilirsiniz.Döngüyü sadece belirli bir koşulda durdurmak isterseniz break() fonksiyonunu kullanabilirsiniz.Döngüler uzun zamanda çalışır. ilk olarak başlangıç noktasını belirleyelimişlemi döngü ile yapalım.ayni islemi dongusuz yapma","code":"for(i in 1:6){\n  if(i==3){\nnext\n  }\n  print (i)}\n[1] 1\n[1] 2\n[1] 4\n[1] 5\n[1] 6for(i in 1:12){\n  if(i==3){\nbreak\n  }\n  print (i)}\n[1] 1\n[1] 2\nset.seed(853)\ny<-matrix(rnorm(1000000),nrow=1000)\nz<-0*y\ntime1<-as.numeric(Sys.time())#loop:\ntime2 <- system.time(\n  for(i in 1:1000){\n  for(j in 1:1000){\nz[i,j]<-y[i,j]^2\n  }\n})\n\ntime2\n   user  system elapsed \n   0.07    0.00    0.08 \ntime3 <- system.time(z<-y^2)\ntime3\n   user  system elapsed \n   0.01    0.00    0.02 "},{"path":"for.html","id":"içiçe-for-döngüleri","chapter":"Bölüm 11 for","heading":"11.3 İçiçe for döngüleri","text":"döngüler birbirinin içinde yuvalanabilir.İç içe döngüler genellikle çok boyutlu veya hiyerarşik veri yapıları (örn. matrisler, listeler) için gereklidir. Yine de iç içe geçme konusunda dikkatli olun. 2-3 seviyeden fazla iç içe geçme genellikle kodun okunmasını/anlaşılmasını zorlaştırır. Çok sayıda iç içe döngüye ihtiyaç duyuyorsanız, fonksiyonları kullanarak döngüleri parçalamak isteyebilirsiniz (daha sonra tartışılacaktır).sıra sizdesıra sizdeBazen döngüler iç içe kullanılabilir 5X5 bir matrisin bir elemanı satır ve sütun indeksleri çarpımı olsun orneğin m[2,5]=10 olsun. Bu işlemi yapmak için öncelikle boş bir matris oluştumak lazım.Bazen döngüler iç içe kullanılabilir 5X5 bir matrisin bir elemanı satır ve sütun indeksleri çarpımı olsun orneğin m[2,5]=10 olsun. Bu işlemi yapmak için öncelikle boş bir matris oluştumak lazım.Aşağıdaki çıktıyı elde edecek kodu oluşturmaya çalışın","code":"\nx <- matrix(1:6, 2, 3)\n\nfor(i in seq_len(nrow(x))) {\n        for(j in seq_len(ncol(x))) {\n                print(x[i, j])\n        }   \n}m2 <- matrix(0,nrow=5,ncol=5)\nm2\n     [,1] [,2] [,3] [,4] [,5]\n[1,]    0    0    0    0    0\n[2,]    0    0    0    0    0\n[3,]    0    0    0    0    0\n[4,]    0    0    0    0    0\n[5,]    0    0    0    0    0     [,1] [,2] [,3] [,4] [,5]\n[1,]    1    2    3    4    5\n[2,]    2    4    6    8   10\n[3,]    3    6    9   12   15\n[4,]    4    8   12   16   20\n[5,]    5   10   15   20   25"},{"path":"for.html","id":"ödev-1","chapter":"Bölüm 11 for","heading":"11.4 Ödev-1","text":"Kullanıcı tarafından belirlenen nxn boyutunda bir matris oluşturulsun. nxn bir matrisin bir elemanı satır ve sütun indeksleri çarpımı olsun. örneğin m[2,5]=10 olsun.Kullanıcı tarafından belirlenen nxn boyutunda bir matris oluşturulsun. nxn bir matrisin bir elemanı satır ve sütun indeksleri çarpımı olsun. örneğin m[2,5]=10 olsun.Eger matrisin boyutları 10x10'dan büyükse sadece 10 satırını yazsın eğer matrisi boyutları 10x10'dan küçükse hepsini yazsın.Eger matrisin boyutları 10x10'dan büyükse sadece 10 satırını yazsın eğer matrisi boyutları 10x10'dan küçükse hepsini yazsın.Kullancı üç girdiğinde oluşacak çıktı:Kullancı üç girdiğinde oluşacak çıktı:","code":"     [,1] [,2] [,3]\n[1,]    1    2    3\n[2,]    2    4    6\n[3,]    3    6    9"},{"path":"while-döngüsü.html","id":"while-döngüsü","chapter":"Bölüm 12 while döngüsü","heading":"Bölüm 12 while döngüsü","text":"döngüleri bir koşulu test ederek başlar. Koşul doğruysa, döngü gövdesini çalıştırır. Döngü gövdesi yürütüldükten sonra, koşul tekrar test edilir ve koşul yanlış olana kadar bu şekilde devam eder, ardından döngüden çıkılır.döngüleri düzgün yazılmazsa sonsuz döngülere neden olabilir. Dikkatli kullanın!Bazen testte birden fazla koşul olabilir.Koşullar zaman soldan sağa doğru değerlendirilir. Örneğin, yukarıdaki kodda z 3'ten küçük olsaydı, ikinci test değerlendirilmezdi.","code":"count <- 0\nwhile(count < 10) {\n        print(count)\n        count <- count + 1\n}\n[1] 0\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 5\n[1] 6\n[1] 7\n[1] 8\n[1] 9z <- 5\nset.seed(1)\n\nwhile(z >= 3 && z <= 10) {\n        coin <- rbinom(1, 1, 0.5)\n        \n        if(coin == 1) {  ## rastgele çalışır\n                z <- z + 1\n        } else {\n                z <- z - 1\n        } \n}\nprint(z)\n[1] 2"},{"path":"while-döngüsü.html","id":"repeat-döngüler","chapter":"Bölüm 12 while döngüsü","heading":"12.1 repeat Döngüler","text":"repeat başlangıçtan itibaren sonsuz bir döngü başlatır. Bunlar istatistiksel veya veri analizi uygulamalarında yaygın olarak kullanılmaz, ancak kullanım alanları vardır. Bir repeat döngüsünden çıkmanın tek yolu break çağrısı yapmaktır.Olası bir paradigma, bir çözüm arıyor olabileceğiniz ve çözüme ulaşana kadar durmak istemediğiniz yinelemeli bir algoritmada olabilir.Yukarıdaki kodun computeEstimate() fonksiyonu tanımlanmamışsa çalışmayacağını unutmayın (bunu sadece bu gösterimin amaçları için uydurdum).Yukarıdaki döngü biraz tehlikelidir çünkü duracağının garantisi yoktur. x0 vex1 değerlerinin ileri geri salındığı ve asla yakınsamadığı bir duruma girebilirsiniz. Bir döngüsü kullanarak iterasyon sayısına sabit bir sınır koymak ve ardından yakınsamanın sağlanıp sağlanmadığını rapor etmek daha iyidir.","code":"\nx0 <- 1\ntol <- 1e-8\n\nrepeat {\n        x1 <- computeEstimate()\n        \n        if(abs(x1 - x0) < tol) {  ## Yeterince yakın mı?\n                break\n        } else {\n                x0 <- x1\n        } \n}"},{"path":"while-döngüsü.html","id":"özet-2","chapter":"Bölüm 12 while döngüsü","heading":"12.2 Özet","text":",whilevefor gibi kontrol yapıları bir R programının akışını kontrol etmenizi sağlarif,whilevefor gibi kontrol yapıları bir R programının akışını kontrol etmenizi sağlarSonsuz döngülerden, teorik olarak doğru olduklarına inansanız bile, genellikle kaçınılmalıdır.Sonsuz döngülerden, teorik olarak doğru olduklarına inansanız bile, genellikle kaçınılmalıdır.Burada bahsedilen kontrol yapıları öncelikle program yazmak için kullanışlıdır; komut satırı etkileşimli çalışmalar için \"apply\" fonksiyonları daha kullanışlıdır.Burada bahsedilen kontrol yapıları öncelikle program yazmak için kullanışlıdır; komut satırı etkileşimli çalışmalar için \"apply\" fonksiyonları daha kullanışlıdır.","code":""},{"path":"while-döngüsü.html","id":"ödev-1-1","chapter":"Bölüm 12 while döngüsü","heading":"12.3 Ödev-1","text":"Fibonacci dizisinin elemanlari 1 1 2 3 5 8 13 21 34 55 89 ... dizinin elemanlarını () ve/ve ya () döngüsü ile oluşturmaya çalışınız.","code":""},{"path":"while-döngüsü.html","id":"ödev-2","chapter":"Bölüm 12 while döngüsü","heading":"12.4 Ödev-2","text":"ornek veri setinde . satırda negatif sayı yok ise çıktıda . satırın ortalaması....dir yazsin.ornek veri setinde . satırda negatif sayı yok ise çıktıda . satırın ortalaması....dir yazsin.Eğer veri setinde hangi bir satırda negatif sayı var ise satır negatif sayı bulunmaktadır.Eğer veri setinde hangi bir satırda negatif sayı var ise satır negatif sayı bulunmaktadır.veri setindeki satırlardaki toplam negatif sayı toplamı üçü geçerse çktıda cok sayıda negatif sayı yazsın ve döngü çalışmayı durdursun.veri setindeki satırlardaki toplam negatif sayı toplamı üçü geçerse çktıda cok sayıda negatif sayı yazsın ve döngü çalışmayı durdursun.Matris yazdırma","code":"set.seed(1786)\nornek<-exp(matrix(rnorm(2000),nrow=100))\nindex1.temp<-sample(1:100,10)\nindex2.temp<-sample(1:20,10)\nfor(i in 1:10){\n  ornek[index1.temp[i],index2.temp[i]]<--1\n}\n head(ornek,6)\n          [,1]      [,2]      [,3]      [,4]      [,5]      [,6]     [,7]\n[1,] 0.5549525 0.3247338 0.5236032 0.3821027 0.4187483 0.1588847 5.226161\n[2,] 0.5671734 1.2431592 0.8812069 2.6695443 0.6984453 1.0838792 1.079946\n[3,] 4.8068457 0.3449856 0.6079096 0.9194116 1.5361330 1.9082522 0.671977\n[4,] 1.3509234 2.3569582 0.1931423 4.0707377 0.3527276 2.3498825 1.198514\n[5,] 0.9012032 0.2310683 0.2317487 1.3809955 0.9168741 0.6237213 1.609403\n[6,] 1.2331483 1.1066056 0.3546027 0.3705946 0.9002303 0.2528151 3.337512\n          [,8]      [,9]     [,10]     [,11]     [,12]     [,13]     [,14]\n[1,] 2.6280057 1.2251526 0.4760966 5.2379018 1.4782655 1.3761338 1.0202608\n[2,] 2.2087385 0.5195551 0.3757409 0.9004808 0.7409205 2.0543842 0.3668661\n[3,] 1.5310016 0.6735007 2.2069776 0.5060078 0.7171477 1.2378655 0.3651527\n[4,] 2.5592899 1.8205257 1.2624052 0.1524106 0.3828322 1.2406799 0.7954326\n[5,] 1.1005990 1.0619758 2.1047783 2.7816902 1.4010878 0.6140937 0.5136842\n[6,] 0.9799103 2.7520425 2.5407624 1.3889136 0.4346808 1.0637950 0.1859157\n         [,15]     [,16]      [,17]     [,18]    [,19]     [,20]\n[1,] 0.1437680 4.1807643  1.7389423 3.0760640 1.550557 4.4838291\n[2,] 3.8674407 1.9349214  0.6333922 0.4862532 5.275571 0.1161029\n[3,] 1.4724240 0.5971116 11.5869157 0.7580736 4.755297 1.0583051\n[4,] 0.1243085 0.8376231  1.3723291 2.0884571 2.506128 1.2094517\n[5,] 6.2971803 0.8422164  1.5335222 0.3079718 2.729447 1.7164885\n[6,] 3.8052219 2.1611055  0.3280288 2.7773368 1.726558 1.3193446[1] \"Satir 1 ortalamasi 0.986111423178787\"\n[1] \"Satir 2 ortalamasi 1.66440473890558\"\n[1] \"Satir 3 ortalamasi 1.86445460243509\"\n[1] \"Satir 4 negatif sayi icermektedir.\"\n[1] \"Satir 5 negatif sayi icermektedir.\"\n[1] \"Satir 6 ortalamasi 2.18755744815693\"\n[1] \"Satir 7 ortalamasi 2.42896783600747\"\n[1] \"Satir 8 ortalamasi 1.11152186047931\"\n[1] \"Satir 9 ortalamasi 1.28348082027049\"\n[1] \"Satir 10 ortalamasi 1.49790135754768\"\n[1] \"Satir 11 ortalamasi 1.00823845594998\"\n[1] \"Satir 12 ortalamasi 1.84432161490249\"\n[1] \"Satir 13 ortalamasi 2.30730516248531\"\n[1] \"Satir 14 ortalamasi 1.32997520232501\"\n[1] \"Satir 15 ortalamasi 1.40736423997693\"\n[1] \"Satir 16 ortalamasi 0.930694377568197\"\n[1] \"Satir 17 ortalamasi 1.09683802891735\"\n[1] \"Satir 18 ortalamasi 1.34543057465283\"\n[1] \"Satir 19 ortalamasi 1.91931890408157\"\n[1] \"Satir 20 ortalamasi 1.46149447129439\"\n[1] \"Satir 21 ortalamasi 1.48698773010654\"\n[1] \"Satir 22 ortalamasi 2.50083591324982\"\n[1] \"Satir 23 ortalamasi 2.49403230671112\"\n[1] \"Satir 24 ortalamasi 2.03307899444367\"\n[1] \"Satir 25 ortalamasi 1.47358418101605\"\n[1] \"Satir 26 ortalamasi 1.77152589640626\"\n[1] \"Satir 27 ortalamasi 1.25135003349089\"\n[1] \"Satir 28 ortalamasi 1.33894076274636\"\n[1] \"Satir 29 ortalamasi 1.82874224246664\"\n[1] \"Satir 30 ortalamasi 1.23831471787453\"\n[1] \"Satir 31 ortalamasi 1.82082600141082\"\n[1] \"Satir 32 ortalamasi 1.12466160143214\"\n[1] \"Satir 33 ortalamasi 1.32597664522914\"\n[1] \"Satir 34 negatif sayi icermektedir.\"\n[1] \"Satir 35 ortalamasi 2.32162456679167\"\n[1] \"Satir 36 ortalamasi 2.23274928866424\"\n[1] \"Satir 37 negatif sayi icermektedir.\"\n[1] \"Satir 38 ortalamasi 2.275511227626\"\n[1] \"Satir 39 ortalamasi 1.7921160361432\"\n[1] \"Satir 40 ortalamasi 0.970509167208986\"\n[1] \"Satir 41 ortalamasi 1.24765799189581\"\n[1] \"Satir 42 ortalamasi 2.51234120817512\"\n[1] \"Satir 43 ortalamasi 2.31828043397862\"\n[1] \"Satir 44 negatif sayi icermektedir.\"\n[1] \"Satir 45 ortalamasi 1.95647545685842\"\n[1] \"Satir 46 negatif sayi icermektedir.\"\n[1] \"Satir 47 ortalamasi 2.36551615481398\"\n[1] \"Satir 48 ortalamasi 1.97786024664016\"\n[1] \"Satir 49 ortalamasi 1.6393028512105\"\n[1] \"Satir 50 ortalamasi 3.73629039983628\"\n[1] \"Satir 51 ortalamasi 1.82116726064836\"\n[1] \"Satir 52 ortalamasi 1.87732770333814\"\n[1] \"Satir 53 ortalamasi 2.7020031804201\"\n[1] \"Satir 54 ortalamasi 1.05164097984234\"\n[1] \"Satir 55 ortalamasi 1.88981004324099\"\n[1] \"Satir 56 ortalamasi 1.54248819505925\"\n[1] \"Satir 57 ortalamasi 1.65731581957976\"\n[1] \"Satir 58 ortalamasi 1.36890435340706\"\n[1] \"Satir 59 negatif sayi icermektedir.\"\n[1] \"Satir 60 ortalamasi 2.22046851034413\"\n[1] \"Satir 61 ortalamasi 1.0408644748318\"\n[1] \"Satir 62 ortalamasi 1.72072095294252\"\n[1] \"Satir 63 ortalamasi 1.53167534425738\"\n[1] \"Satir 64 ortalamasi 1.72856879470484\"\n[1] \"Satir 65 ortalamasi 1.37607074870477\"\n[1] \"Satir 66 ortalamasi 1.42295571491744\"\n[1] \"Satir 67 ortalamasi 0.88385039568476\"\n[1] \"Satir 68 ortalamasi 2.35701379888311\"\n[1] \"Satir 69 ortalamasi 1.35179926755423\"\n[1] \"Satir 70 ortalamasi 1.28012686374286\"\n[1] \"Satir 71 negatif sayi icermektedir.\"\n[1] \"Satir 72 ortalamasi 1.67406636870506\"\n[1] \"Satir 73 ortalamasi 1.37691945587952\"\n[1] \"Satir 74 ortalamasi 2.00099153014073\"\n[1] \"Satir 75 negatif sayi icermektedir.\"\n[1] \"Satir 76 ortalamasi 1.60454610453076\"\n[1] \"Satir 77 ortalamasi 2.0804975152321\"\n[1] \"Satir 78 ortalamasi 1.67436426400702\"\n[1] \"Satir 79 ortalamasi 2.04712004349156\"\n[1] \"Satir 80 ortalamasi 1.2963699279751\"\n[1] \"Satir 81 ortalamasi 2.06864424004881\"\n[1] \"Satir 82 ortalamasi 2.18401195176334\"\n[1] \"Satir 83 ortalamasi 2.38233635418165\"\n[1] \"Satir 84 ortalamasi 1.65733160944781\"\n[1] \"Satir 85 ortalamasi 1.53913327407787\"\n[1] \"Satir 86 ortalamasi 1.5977866331596\"\n[1] \"Satir 87 ortalamasi 1.53640423869466\"\n[1] \"Satir 88 ortalamasi 1.4151688443321\"\n[1] \"Satir 89 ortalamasi 1.65657353958559\"\n[1] \"Satir 90 ortalamasi 1.09930366562984\"\n[1] \"Satir 91 ortalamasi 2.04289262764082\"\n[1] \"Satir 92 ortalamasi 1.49359077505866\"\n[1] \"Satir 93 ortalamasi 1.59542242961016\"\n[1] \"Satir 94 negatif sayi icermektedir.\"\n[1] \"Satir 95 ortalamasi 1.63562964801907\"\n[1] \"Satir 96 ortalamasi 1.25826462716513\"\n[1] \"Satir 97 ortalamasi 3.88578289773781\"\n[1] \"Satir 98 ortalamasi 2.05151453891869\"\n[1] \"Satir 99 ortalamasi 1.96874159472044\"\n[1] \"Satir 100 ortalamasi 1.5918224514213\"\n\nn<-as.numeric(readline(prompt = \"Kare matriste satir/sutun sayisi olarak kullanilmak uzere bir sayi yaziniz: \"))\nmatris<-matrix(0,n,n)\nfor(satir in 1:n){\n  for(sutun in 1:n){\n    matris[satir,sutun]<- satir*sutun\n  }\n}\n\nif(nrow(matris)<=10){\n  matris\n}else{\n  matris[1:10,1:10]\n}"},{"path":"fonksiyonlar.html","id":"fonksiyonlar","chapter":"Bölüm 13 Fonksiyonlar","heading":"Bölüm 13 Fonksiyonlar","text":"En sık kullandığımız fonksiyonlar[ ] (vektör için), [ , j] (matris ve data frame için),[ , j, k, …] (dizi için), [ [ k ] ] (liste için)j, k, tam sayı, karakter ya da mantıksal ifade olabilirFonksiyon yazmak, bir R programcısının temel faaliyetlerinden biridir.\nSadece bir \"kullanıcıdan\" R için yeni fonksiyonlar yaratan bir geliştiriciye geçişin temel adımını temsil eder.\nFonksiyonlar genellikle, belki de biraz farklı koşullar altında birçok kez yürütülmesi gereken bir dizi ifadeyi kapsüllemek için kullanılır.\nFonksiyonlar ayrıca genellikle kodun başkalarıyla veya kamuyla paylaşılması gerektiğinde yazılır.Bir fonksiyonun yazılması, bir geliştiricinin koda bir dizi parametre ile açıkça belirtilen bir arayüz oluşturmasına olanak tanır.\nBu arayüz, potansiyel kullanıcılara kodun bir soyutlamasını sağlar.\nBu soyutlama kullanıcıların hayatını kolaylaştırır çünkü onları kodun nasıl çalıştığına dair ayrıntıyı bilmek zorunda bırakmaz.\nBuna ek olarak, bir arayüzün oluşturulması, geliştiricinin kullanıcıya kodun önemli veya en alakalı yönlerini iletmesine olanak tanır.","code":""},{"path":"fonksiyonlar.html","id":"rda-fonkisyonlar","chapter":"Bölüm 13 Fonksiyonlar","heading":"13.1 R'da Fonkisyonlar","text":"R'deki fonksiyonlar \"birinci sınıf nesnelerdir\", yani diğer R nesneleri gibi ele alınabilirler.\nDaha da önemlisi,Fonksiyonlar diğer fonksiyonlara argüman olarak aktarılabilir.\nBu, lapply() ve sapply() gibi çeşitli döngü fonksiyonları için çok kullanışlıdır.Fonksiyonlar diğer fonksiyonlara argüman olarak aktarılabilir.\nBu, lapply() ve sapply() gibi çeşitli döngü fonksiyonları için çok kullanışlıdır.Fonksiyonlar iç içe geçebilir, böylece bir fonksiyonu başka bir fonksiyonun içinde tanımlayabilirsinizFonksiyonlar iç içe geçebilir, böylece bir fonksiyonu başka bir fonksiyonun içinde tanımlayabilirsiniz","code":""},{"path":"fonksiyonlar.html","id":"ilk-fonksiyon","chapter":"Bölüm 13 Fonksiyonlar","heading":"13.2 İlk fonksiyon","text":"Fonksiyonlar function() kullanılarak tanımlanır ve diğer şey gibi R nesneleri olarak saklanır.\nÖzellikle, \"function\" sınıfının R nesneleridirler.İşte hiçbir argüman almayan ve hiçbir şey yapmayan basit bir fonksiyon.Çok ilginç değil ama bu da bir başlangıç.\nYapabileceğimiz bir sonraki şey, aslında önemsiz olmayan bir fonksiyon gövdesine sahip bir fonksiyon oluşturmaktır.Temel bir fonksiyonun son unsuru fonksiyon argümanlarıdır.\nBunlar, kullanıcıya belirtebileceğiniz ve kullanıcının açıkça ayarlayabileceği seçeneklerdir.\nBu temel fonksiyon için, konsola kaç kez \"Merhaba!\" yazdırılacağını belirleyen bir argüman ekleyebiliriz.Açıkçası, aynı etki için sadece cat(\"Merhaba!\\n\") üç kere kesip yapıştırabilirdik.\nAma o zaman programlama yapmıyor olurduk.\nAyrıca, kodunuzu bir başkasına vermeniz ve onu kodu istediği kadar kesip yapıştırmaya zorlamanız da iyi olmayacaktır:) \"Merhaba!\".Genel olarak, kendinizi çok fazla kesme ve yapıştırma yaparken bulursanız, bu genellikle bir fonksiyon yazmanız gerekebileceğine dair iyi bir işarettir.R'da uzmanlaştıkça ve yapılan işler karmaşıklaştıkça fonksiyon yazma ihtiyacı duyulmaktadır.\nFonksiyon yazma gereksinimi özellikle tekrarlı işlemler yapılması gerektiği durumda ortaya çıkmaktadır.\nFonksiyon yazmak- pratiklik kazandırır (ekonomiktir)- Paylaşılmasını koylaştırır.- Tekrar kullanılabilirlik sağlar.Tekrarlı işlemlerde hatalardan kurtulmanın yolu fonksiyon kullanmaktır.\nFonksiyonlar, koşullu önermeler ve döngüler ile kullanılarak çok sayıda komut ile yapılabilecek olan işlemler tek bir komut satırı ile yapılabilir hale gelmektedirSon olarak, yukarıdaki fonksiyon hiçbir şey döndürmez.\nSadece konsola tekrar sayıda \"Merhaba!\" yazdırır ve sonra çıkar.\nAncak bir fonksiyonun, belki de kodun başka bir bölümüne beslenebilecek bir şey döndürmesi genellikle yararlıdır.Sıradaki fonksiyon konsola yazdırılan toplam karakter sayısını döndürür.Yukarıdaki fonksiyonda, fonksiyonun karakter sayısını döndürmesi için özel bir şey belirtmemiz gerekmedi.\nR'de, bir fonksiyonun geri dönüş değeri zaman değerlendirilen en son ifadedir.\nBu fonksiyonda değerlendirilen son ifade chars değişkeni olduğu için, fonksiyonun dönüş değeri de bu olur.Bir fonksiyondan açık bir değer döndürmek için kullanılabilecek bir return() fonksiyonu olduğunu unutmayın, ancak nadiren kullanılır.Son olarak, yukarıdaki fonksiyonda, kullanıcı tekrar argümanının değerini belirtmelidir.\nEğer kullanıcı tarafından belirtilmezse, R bir hata verecektir.Bu davranışı tekrar argümanı için bir varsayılan değer belirleyerek değiştirebiliriz.\nBelirtmek isterseniz, herhangi bir fonksiyon argümanının varsayılan bir değeri olabilir.\nBazen, argüman değerleri nadiren değiştirilir (özel durumlar hariç) ve bu argüman için bir varsayılan değer ayarlamak mantıklıdır.\nBu, kullanıcıyı fonksiyon çağrıldığında bu argümanın değerini belirtme zorunluluğundan kurtarır.Örneğin, burada tekrar için varsayılan değeri 1 olarak ayarlayabiliriz, böylece fonksiyon tekrar argümanı açıkça belirtilmeden çağrılırsa, konsola bir kez \"Merhaba!\" yazdırır.Fonksiyonun hala konsola yazdırılan karakter sayısını döndürdüğünü unutmayın.Bu noktada, bir fonksiyon yazdıkfonksiyonunun tekrar adında ve varsayılan değeri 1 olan bir formal argümanı vardır.\nformal argümanlar fonksiyon tanımına dahil edilen argümanlardır.\nformals() fonksiyonu bir fonksiyonun tüm biçimsel argümanlarının bir listesini döndürürfonksiyonunun tekrar adında ve varsayılan değeri 1 olan bir formal argümanı vardır.\nformal argümanlar fonksiyon tanımına dahil edilen argümanlardır.\nformals() fonksiyonu bir fonksiyonun tüm biçimsel argümanlarının bir listesini döndürür\"Merhaba!\" mesajını tekrar argümanıyla belirtilen sayıda konsola yazdırır\"Merhaba!\" mesajını tekrar argümanıyla belirtilen sayıda konsola yazdırır*konsola yazdırılan karakter sayısını döndürür*konsola yazdırılan karakter sayısını döndürürFonksiyonlar, isteğe bağlı olarak varsayılan değerlere sahip olabilen isimli argümanlara sahiptir.\nTüm fonksiyon argümanlarının adları olduğundan, bunlar adları kullanılarak belirtilebilir.Bir fonksiyonun çok sayıda argümanı varsa ve hangi argümanın belirtildiği zaman net olmayabilirse, bir argümanı adıyla belirtmek bazen yararlıdır.\nBurada, fonksiyonumuzun yalnızca bir argümanı vardır, bu nedenle herhangi bir karışıklık olmaz.","code":"> f <- function() {\n+         ## Bu boş bir fonksiyondur\n+ }\n> ## Fonksiyonların kendi sınıfları vardır\n> class(f)  \n> ## Bu işlevi çalıştırın\n> f()       \n[1] \"function\"\nNULL> f <- function() {\n+         cat(\"Merhaba!\\n\")\n+ }\n> f()\nMerhaba!> f <- function(num) {\n+         for(i in seq_len(num)) {\n+                 cat(\"Merhaba!\\n\")\n+         }\n+ }\n> f(3)\nMerhaba!\nMerhaba!\nMerhaba!> f <- function(tekrar) {\n+         Merhaba <- \"Merhaba!\\n\"\n+         for(i in seq_len(tekrar)) {\n+                 cat(Merhaba)\n+         }\n+         chars <- nchar(Merhaba) * tekrar\n+         chars\n+ }\n> f(3)\nMerhaba!\nMerhaba!\nMerhaba!\n[1] 27> f()\nError in f(): argument \"tekrar\" is missing, with no default> f <- function(tekrar = 1) {\n+         Merhaba <- \"Merhaba!\\n\"\n+         for(i in seq_len(tekrar)) {\n+                 cat(Merhaba)\n+         }\n+         chars <- nchar(Merhaba) * tekrar\n+         chars\n+ }\n> f()    ## 'tekrar' için varsayılan değeri kullan\n> f(2)   ## Kullanıcı tarafından belirtilen değeri kullan\nMerhaba!\n[1] 9\nMerhaba!\nMerhaba!\n[1] 18> f(tekrar = 2)\nMerhaba!\nMerhaba!\n[1] 18"},{"path":"fonksiyonlar.html","id":"argüman-eşleştirme","chapter":"Bölüm 13 Fonksiyonlar","heading":"13.3 Argüman Eşleştirme","text":"Bir R fonksiyonunu argümanlarla çağırmak çeşitli şekillerde yapılabilir.\nBu ilk başta kafa karıştırıcı olabilir, ancak komut satırında etkileşimli çalışma yaparken gerçekten kullanışlıdır.\nR fonksiyonları argümanları konumsal olarak veya isme göre eşleştirilebilir.\nKonumsal eşleştirme, R'nin ilk değeri ilk argümana, ikinci değeri ikinci argümana vb.\natadığı anlamına gelir.\nYani aşağıdaki rnorm() çağrısında100, n argümanına, 2 ortalama argümanına ve 1 sd argümanına atanır, hepsi de konum eşleştirmesi ile yapılır.Aşağıdaki sd() fonksiyonu (bir sayı vektörünün ampirik standart sapmasını hesaplar) çağrılarının tümü eşdeğerdir.\nsd()fonksiyonunun iki argümanı olduğunu unutmayın: x sayı vektörünü gösterir ve na.rm eksik değerlerin kaldırılıp kaldırılmayacağını belirten bir mantıksaldır.Fonksiyon argümanlarını isimle belirtirken, bunları hangi sırada belirttiğiniz önemli değildir.\nAşağıdaki örnekte, fonksiyon tanımında tanımlanan ilk argüman x olmasına rağmen, önce na.rm argümanını, ardından x argümanını belirtiyoruz.Konumsal eşleştirme ile ada göre eşleştirmeyi karıştırabilirsiniz.\nBir argüman isme göre eşleştirildiğinde, argüman listesinden \"çıkarılır\" ve kalan isimsiz argümanlar fonksiyon tanımında listelendikleri sırayla eşleştirilir.Burada, mydata nesnesi x argümanına atanır, çünkü henüz belirtilmemiş tek argüman budur.Aşağıda, bir veri kümesine doğrusal modeller uyduran lm() fonksiyonunun argüman listesi yer almaktadır.Aşağıdaki iki kod satırı eşdeğerdir.Bu işlem güvenli olsa da, bazı karışıklıklara yol açabileceğinden, argümanların sırası ile çok fazla uğraşmanızı önermem.Çoğu zaman, adlandırılmış argümanlar komut satırında uzun bir argüman listeniz olduğunda ve listenin sonuna yakın bir argüman dışında şey için varsayılanları kullanmak istediğinizde kullanışlıdır.\nAdlandırılmış argümanlar, konumunu değil, argüman adını hatırlayabiliyorsanız da yardımcı olur.\nÖrneğin, çizim fonksiyonları genellikle özelleştirmeye izin vermek için çok sayıda seçeneğe sahiptir, ancak bu, argüman listesindeki argümanın konumunu tam olarak hatırlamayı zorlaştırır.Varsayılan bir değer belirtmemenin yanı sıra, bir argümanın değerini NULL olarak da ayarlayabilirsiniz.Bir R nesnesinin NULL olup olmadığını .null() fonksiyonu ile kontrol edebilirsiniz.\nBazen bir argümanın NULL değerini almasına izin vermek yararlıdır, bu da fonksiyonun belirli bir işlem yapması gerektiğini gösterebilir.Kullanışlı bir fonksiyon yazmak için mümkün olduğunca kısa isimler kullanılmalıdır; bununla birlikte bu isimler kullanıcıya yapılacak işlemi anlaşılırkılmalıdır.\nBunun yanında R'da özel anlamı olan c,C,D,F,,q,t,T gibi tek harfl ik fonksiyon isimleri kullanmaktan ve R'da hazır olan fonksiyon isimlerini kişisel tanımlı fonksiyonlara vermekten kaçınılmalıdır.","code":"> str(rnorm)\n> mydata <- rnorm(100, 2, 1)              ## Bazı veriler oluşturun\nfunction (n, mean = 0, sd = 1)  > ## Konumsal eşleşme ilk argüman, na.rm için varsayılan\n> sd(mydata)                     \n> ## 'x' argümanını isimle belirtin, varsayılan 'na.rm'\n> sd(x = mydata)                 \n> ## Her iki argümanı da adla belirtin\n> sd(x = mydata, na.rm = FALSE)  \n[1] 1.142303\n[1] 1.142303\n[1] 1.142303> ## Her iki argümanı da adla belirtin\n> sd(na.rm = FALSE, x = mydata)     \n[1] 1.142303> sd(na.rm = FALSE, mydata)\n[1] 1.142303> args(lm)\nfunction (formula, data, subset, weights, na.action, method = \"qr\", \n    model = TRUE, x = FALSE, y = FALSE, qr = TRUE, singular.ok = TRUE, \n    contrasts = NULL, offset, ...) \nNULL\nlm(data = mydata, y ~ x, model = FALSE, 1:100)\nlm(y ~ x, mydata, 1:100, model = FALSE)\nf <- function(a, b = 1, c = 2, d = NULL) {\n\n}"},{"path":"fonksiyonlar.html","id":"argümanı","chapter":"Bölüm 13 Fonksiyonlar","heading":"13.4 ... argümanı","text":"R'de ... argümanı olarak bilinen ve genellikle diğer fonksiyonlara aktarılan değişken sayıda argümanı gösteren özel bir argüman vardır.\n... argümanı genellikle başka bir fonksiyonu genişletirken kullanılır ve orijinal fonksiyonun tüm argüman listesini kopyalamak istemezsinizÖrneğin, özel bir çizim fonksiyonu varsayılan plot() fonksiyonunu tüm argüman listesiyle birlikte kullanmak isteyebilir.\nAşağıdaki fonksiyon type argümanı için varsayılanı type = \"l\" değerine değiştirir (orijinal varsayılan type = \"p\" idi).Jenerik fonksiyonlar, metotlara ekstra argümanlar aktarılabilmesi için ... kullanır.Fonksiyona aktarılan argüman sayısı önceden bilinemediğinde ... argümanı gereklidir.\nBu durum paste() ve cat() gibi fonksiyonlarda açıkça görülmektedir.Hem paste() hem de cat() birden fazla karakter vektörünü bir araya getirerek konsola metin yazdırdığından, bu fonksiyonların kullanıcı tarafından fonksiyona kaç karakter vektörü aktarılacağını önceden bilmesi imkansızdır.\nBu yüzden iki fonksiyonun da ilk argümanı ... şeklindedir.","code":"\nmyplot <- function(x, y, type = \"l\", ...) {\n        plot(x, y, type = type, ...)         ## '...'yi 'plot' işlevine geçirin\n}> mean\nfunction (x, ...) \nUseMethod(\"mean\")\n<bytecode: 0x00000228e80bd2a8>\n<environment: namespace:base>> args(paste)\n> args(cat)\nfunction (..., sep = \" \", collapse = NULL, recycle0 = FALSE) \nNULL\nfunction (..., file = \"\", sep = \" \", fill = FALSE, labels = NULL, \n    append = FALSE) \nNULL"},{"path":"fonksiyonlar.html","id":"argümanından-sonra-gelen-argümanlar","chapter":"Bölüm 13 Fonksiyonlar","heading":"13.5 ... argümanından sonra gelen argümanlar","text":"... ile ilgili bir sorun, argüman listesinde ... olarak görünen herhangi bir argümanın açıkça adlandırılması gerektiği ve kısmen eşleştirilemeyeceği veya konum olarak eşleştirilemeyeceğidir.paste() fonksiyonunun argümanlarına bir göz atın.paste() fonksiyonu ile,sepvecollapse argümanları, varsayılan değerler kullanılmayacaksa, açıkça ve tam olarak adlandırılmalıdır.Burada \"\" ve \"b \"nin birlikte yapıştırılmasını ve iki nokta üst üste ile ayrılmasını istediğimi belirtiyorum.Eğer sep argümanını tam olarak belirtmezsem ve kısmi eşleştirmeye güvenmeye çalışırsam, beklenen sonucu alamıyorum.","code":"> args(paste)\nfunction (..., sep = \" \", collapse = NULL, recycle0 = FALSE) \nNULL> paste(\"a\", \"b\", sep = \":\")\n[1] \"a:b\"> paste(\"a\", \"b\", se = \":\")\n[1] \"a b :\""},{"path":"fonksiyonlar.html","id":"yazım-aşamaları","chapter":"Bölüm 13 Fonksiyonlar","heading":"13.6 Yazım Aşamaları","text":"Fonksiyon yazmak kadar iyi bir fonksiyon yazmak da önemlidir.\nİyi bir fonksiyonun ilk özelliği doğru sonucu veriyor olmasıdır.Bunu sağlayabilmek için fonksiyon yazmadan önce problemi iyi tanımlamakve problemin çözümünü komut satırları ile yazmak daha sonra bunufonksiyona dönüştürmek gereklidir.Bir fonksiyonun doğru sonucu vermesi kadar diğer kullanıcılar tarafından anlaşılır olması da önemlidir.Önce bir taslak oluşturun.Taslağınızı içine komut satırlarınıza yapıştırınFonksiyonun argümanları belirleyinArgüman isimlerinizi kullanacağınız değişkenlerle değiştirin","code":""},{"path":"fonksiyonlar.html","id":"çoklu-veri-seti-oluşturma-ve-dışarı-aktarma","chapter":"Bölüm 13 Fonksiyonlar","heading":"13.7 Çoklu veri seti oluşturma ve dışarı aktarma","text":"İstenilen sayıda veri seti oluşturan bir fonksiyon yazalım. Fonksiyonun ilk girdisi veri seti sayısı olmalı, varsayılan olarak bir veri seti oluşturalan fonksiyon taslağı oluşturalım.Kullanıcı oluşturmak istediği bir veri seti için satır ve sütun sayısını belirleyebilirsin. Satır ve sütun sayısını argüman olarak tanımlayalım. Örneğin oluşturduğu ilk veri setin 5 satır, 10 sütunlu ikincisi olsun. Bunun için argümana varsayalin değerler atayalımOluşturacak olan bir veri setinin bir sütunu standart normal dağılıma uygun olacak şekilde üretilsin. Oluşturulan veri setlerinden ilki \"veri_1.xlsx\" şeklinde çalışma alanına yazdırılsınŞimdi ise bu fonksiyonu çoklu dosya yazımına uygun hale getirelim","code":"\nfonksiyon_adi <- function(sayi=1){\n\n}\nfonksiyon_adi <- function(sayi=1,satir=c(5),sutun=c(10)){\n\n}> fonksiyon_adi <- function(sayi=1,satir=c(5),sutun=c(10)){\n+ \n+     df <- data.frame(matrix(0,nrow=satir, ncol=sutun))\n+      writexl::write_xlsx(df,\"veri_1.xlsx\")\n+ }\n> fonksiyon_adi(sayi=1,satir=c(5),sutun=c(10))> \n> fonksiyon_adi <- function(sayi=3,satir=c(5,5,5),sutun=c(10,10,10)){\n+     \n+   df_list <- list() ## her bir veri setinin atanacağı yeni nesne\n+     \n+     for( i in 1:sayi){\n+     df <- data.frame(matrix(0,nrow=satir[i], ncol=sutun[i])) # veri seti istenilen ozelliklerde olusturulur\n+     }\n+      for(j in 1:sutun[i]){\n+      df[,j] <- round(rnorm(satir[i],0,1),2) #  her bir veri setinin her bir sütunu standart normal dağılıma uygun uretilir\n+     }\n+      df_list[[i]] <- df\n+       df_list\n+       writexl::write_xlsx(df_list[[i]],paste(\"veri\",i,\".xlsx\", sep=\"\"))\n+ }\n> fonksiyon_adi(sayi=3,satir=c(5,4,3),sutun=c(10,5,4))"},{"path":"fonksiyonlar.html","id":"sıra-sizde-2","chapter":"Bölüm 13 Fonksiyonlar","heading":"13.7.1 Sıra Sizde","text":"Geometrik ortalamanın farklı hesaplama yolları bulunmaktadır.\nLogaritma değerlerine dayalı olarak hesaplandığında, geometrik ortalama,gözlem değerlerinin logaritmalarının aritmetik ortalamasıdır.\nBir x vektorunun geometrik ortalamaasını logartimalara dayalı olarakhesaplayan bir fonsiyon yazıp, x <- 1:100 için çalıştırınız.","code":""},{"path":"fonksiyonlar.html","id":"özet-3","chapter":"Bölüm 13 Fonksiyonlar","heading":"13.8 Özet","text":"Fonksiyonlar function() direktifi kullanılarak tanımlanabilir ve diğer R nesneleri gibi R nesnelerine atanırFonksiyonlar function() direktifi kullanılarak tanımlanabilir ve diğer R nesneleri gibi R nesnelerine atanırFonksiyonlar adlandırılmış argümanlarla tanımlanabilir; bu fonksiyon argümanlarının varsayılan değerleri olabilirFonksiyonlar adlandırılmış argümanlarla tanımlanabilir; bu fonksiyon argümanlarının varsayılan değerleri olabilirFonksiyon argümanları isme göre veya argüman listesindeki konuma göre belirtilebilirFonksiyon argümanları isme göre veya argüman listesindeki konuma göre belirtilebilirFonksiyonlar zaman fonkisyon gövdesinde değerlendirilen son ifadeyi döndürürFonksiyonlar zaman fonkisyon gövdesinde değerlendirilen son ifadeyi döndürürBir fonksiyon tanımında özel ... argümanı kullanılarak değişken sayıda argüman belirtilebilir.Bir fonksiyon tanımında özel ... argümanı kullanılarak değişken sayıda argüman belirtilebilir.","code":""},{"path":"döngü-fonkisyonları.html","id":"döngü-fonkisyonları","chapter":"Bölüm 14 Döngü Fonkisyonları","heading":"Bölüm 14 Döngü Fonkisyonları","text":"","code":""},{"path":"döngü-fonkisyonları.html","id":"komut-satırında-döngü-oluşturma","chapter":"Bölüm 14 Döngü Fonkisyonları","heading":"14.1 Komut Satırında Döngü Oluşturma","text":"Programlama yaparken ve döngüleri yazmak yararlıdır, ancak komut satırında etkileşimli olarak çalışırken özellikle kolay değildir. Küme parantezleri içeren çok satırlı ifadeleri komut satırında çalışırken sıralamak o kadar kolay değildir. R, hayatınızı kolaylaştırmak için döngüleri kompakt bir biçimde uygulayan bazı fonksiyonlara sahiptir.lapply(): Bir liste üzerinde döngü ve öğe üzerinde bir işlevi değerlendirmelapply(): Bir liste üzerinde döngü ve öğe üzerinde bir işlevi değerlendirmesapply(): lapply ile aynıdır ancak sonucu basitleştirmeye çalışınsapply(): lapply ile aynıdır ancak sonucu basitleştirmeye çalışınapply(): Bir dizinin kenar boşlukları üzerinde bir işlev uygulamaapply(): Bir dizinin kenar boşlukları üzerinde bir işlev uygulamatapply(): Bir vektörün alt kümeleri üzerinde bir fonksiyon uygulamatapply(): Bir vektörün alt kümeleri üzerinde bir fonksiyon uygulamamapply(): lapply nin çok değişkenli versiyonumapply(): lapply nin çok değişkenli versiyonuYardımcı bir fonksiyonlardan biri olan split de özellikle lapply ile birlikte kullanışlıdır.","code":""},{"path":"döngü-fonkisyonları.html","id":"lapply","chapter":"Bölüm 14 Döngü Fonkisyonları","heading":"14.2 lapply()","text":"lapply() fonksiyonu aşağıdaki basit işlemler dizisini gerçekleştirir:Bir liste üzerinde döngü yaparak, listedeki bir öğe üzerinde yineleme yaparListenin bir öğesine bir fonksiyon uygular (sizin belirlediğiniz bir fonksiyon)ve bir liste döndürür (l \"liste\" içindir).Bu fonksiyon üç argüman alır: (1) bir liste X; (2) bir fonksiyon (veya bir fonksiyonun adı) FUN; (3) ... argümanı aracılığıyla diğer argümanlar. Eğer X bir liste değilse, .list() kullanılarak bir listeye zorlanacaktır.lapply()` fonksiyonunun gövdesi burada görülebilir.Girdinin sınıfından bağımsız olarak lapply() fonksiyonunun zaman bir liste döndürdüğünü unutmamak önemlidir.İşte mean() fonksiyonunun bir listenin tüm elemanlarına uygulanmasına bir örnek. Orijinal listede isimler varsa, isimler çıktıda korunacaktır.Burada mean() fonksiyonunu lapply() fonksiyonuna bir argüman olarak aktardığımıza dikkat edin. R'deki fonksiyonlar bu şekilde kullanılabilir ve tıpkı diğer nesneler gibi argüman olarak ileri geri aktarılabilir. Bir fonksiyonu başka bir fonksiyona aktardığınızda, bir fonksiyonu çağırırken yaptığınız gibi () açık ve kapalı parantezlerini eklemeniz gerekmez.İşte lapply() kullanımına başka bir örnek.Bir fonksiyonu biri farklı bir argümanla birden çok kez değerlendirmek için lapply() fonksiyonunu kullanabilirsiniz. Aşağıda, runif() fonksiyonunu (düzgün dağılımlı rastgele değişkenler üretmek için) seferinde farklı sayıda rastgele sayı üreterek dört kez çağırdığım bir örnek yer almaktadır.Bir fonksiyonu lapply() fonksiyonuna aktardığınızda, lapply() listenin elemanlarını alır ve bunları uyguladığınız fonksiyonun ilk argümanı olarak geçirir. Yukarıdaki örnekte, runif() fonksiyonunun ilk argümanı ndir ve bu nedenle 1:4 dizisinin tüm elemanları runif() fonksiyonunun n argümanına aktarılır.lapply() fonksiyonuna aktardığınız fonksiyonlar başka argümanlara sahip olabilir. Örneğin, runif() fonksiyonunun bir min ve max argümanı da vardır. Yukarıdaki örnekte min ve max için varsayılan değerleri kullandım. Bunun için lapply() bağlamında farklı değerleri nasıl belirtebilirsiniz?İşte burada lapply() fonksiyonunun ... argümanı devreye girer. ... argümanına yerleştirdiğiniz tüm argümanlar, listenin öğelerine uygulanan fonksiyona aktarılacaktır.Burada, min = 0 ve max = 10 argümanları çağrıldığında runif() fonksiyonuna aktarılır.Yani artık rastgele sayılar 0 ile 1 arasında (varsayılan) olmak yerine, hepsi 0 ile 10 arasındadır.lapply() fonksiyonu ve arkadaşları anonim/isimsiz fonksiyonları yoğun bir şekilde kullanır. Anonim fonksiyonların isimleri yoktur. Bu fonksiyonlar siz lapply() fonksiyonunu kullanırken \"anında\" oluşturulur. lapply() çağrısı tamamlandığında, fonksiyon kaybolur ve çalışma alanında görünmez.Burada iki matris içeren bir liste oluşturuyorum.Listedeki matrisin ilk sütununu almak istediğimi varsayalım. Şöyle yazabilirim\nmatrisin ilk sütununu çıkarmak için anonim bir fonksiyon.Dikkat ederseniz function() tanımını doğrudan lapply() çağrısının içinde. Bu tamamen kabul edilebilir bir durumdur. Keyfi olarak karmaşık bir fonksiyon tanımını lapply() içine koyabilirsiniz, ancak daha karmaşık olacaksa, fonksiyonu ayrı olarak tanımlamak muhtemelen daha iyi bir fikirdir.Örneğin, aşağıdakileri yapabilirdim.Artık fonksiyon anonim değildir; adı fdir. Anonim bir fonksiyon mu kullanacağınız yoksa önce bir fonksiyon mu tanımlayacağınız bağlamınıza bağlıdır. Eğer f fonksiyonunun kodunuzun diğer bölümlerinde çok ihtiyaç duyacağınız bir şey olduğunu düşünüyorsanız, onu ayrıca tanımlamak isteyebilirsiniz. Ancak sadece bu lapply() çağrısı için kullanacaksanız, muhtemelen anonim bir fonksiyon kullanmak daha basittir.","code":"> lapply\nfunction (X, FUN, ...) \n{\n    FUN <- match.fun(FUN)\n    if (!is.vector(X) || is.object(X)) \n        X <- as.list(X)\n    .Internal(lapply(X, FUN))\n}\n<bytecode: 0x00000297ed8f4438>\n<environment: namespace:base>> x <- list(a = 1:5, b = rnorm(10))\n> lapply(x, mean)\n$a\n[1] 3\n\n$b\n[1] 0.1322028> x <- list(a = 1:4, b = rnorm(10), c = rnorm(20, 1), d = rnorm(100, 5))\n> lapply(x, mean)\n$a\n[1] 2.5\n\n$b\n[1] 0.248845\n\n$c\n[1] 0.9935285\n\n$d\n[1] 5.051388> x <- 1:4\n> lapply(x, runif)\n[[1]]\n[1] 0.02778712\n\n[[2]]\n[1] 0.5273108 0.8803191\n\n[[3]]\n[1] 0.37306337 0.04795913 0.13862825\n\n[[4]]\n[1] 0.3214921 0.1548316 0.1322282 0.2213059> x <- 1:4\n> lapply(x, runif, min = 0, max = 10)\n[[1]]\n[1] 2.263808\n\n[[2]]\n[1] 1.314165 9.815635\n\n[[3]]\n[1] 3.270137 5.069395 6.814425\n\n[[4]]\n[1] 0.9916910 1.1890256 0.5043966 9.2925392> x <- list(a = matrix(1:4, 2, 2), b = matrix(1:6, 3, 2)) \n> x\n$a\n     [,1] [,2]\n[1,]    1    3\n[2,]    2    4\n\n$b\n     [,1] [,2]\n[1,]    1    4\n[2,]    2    5\n[3,]    3    6> lapply(x, function(elt) { elt[,1] })\n$a\n[1] 1 2\n\n$b\n[1] 1 2 3> f <- function(elt) {\n+         elt[, 1]\n+ }\n> lapply(x, f)\n$a\n[1] 1 2\n\n$b\n[1] 1 2 3"},{"path":"döngü-fonkisyonları.html","id":"sapply","chapter":"Bölüm 14 Döngü Fonkisyonları","heading":"14.3 sapply()","text":"sapply() fonksiyonu lapply() fonksiyonuna benzer şekilde davranır; tek gerçek fark dönüş değerindedir. sapply() mümkünse lapply() sonucunu basitleştirmeye çalışacaktır. Esasen, sapply() girdisi üzerinde lapply() çağırır ve ardından aşağıdaki algoritmayı uygular:Eğer sonuç elemanın uzunluğu 1 olan bir liste ise, o zaman bir vektör döndürülürEğer sonuç elemanın uzunluğu 1 olan bir liste ise, o zaman bir vektör döndürülürSonuç, elemanı aynı uzunlukta (> 1) bir vektör olan bir liste ise, bir matris döndürülür.Sonuç, elemanı aynı uzunlukta (> 1) bir vektör olan bir liste ise, bir matris döndürülür.İşleri çözemezse, bir liste döndürülürİşleri çözemezse, bir liste döndürülürİşte lapply() çağrısının sonucu.lapply()` işlevinin (zamanki gibi) bir liste döndürdüğüne, ancak listenin bir öğesinin uzunluğunun 1 olduğuna dikkat edin.İşte aynı liste üzerinde sapply() çağrısının sonucu.lapply()işlevinin sonucu, öğesinin uzunluğu 1 olan bir liste olduğundan,sapply()` işlevi çıktıyı, genellikle bir listeden daha kullanışlı olan sayısal bir vektöre daraltmıştır.","code":"> x <- list(a = 1:4, b = rnorm(10), c = rnorm(20, 1), d = rnorm(100, 5))\n> lapply(x, mean)\n$a\n[1] 2.5\n\n$b\n[1] -0.251483\n\n$c\n[1] 1.481246\n\n$d\n[1] 4.968715> sapply(x, mean) \n        a         b         c         d \n 2.500000 -0.251483  1.481246  4.968715 "},{"path":"döngü-fonkisyonları.html","id":"split","chapter":"Bölüm 14 Döngü Fonkisyonları","heading":"14.4 split()","text":"split()` fonksiyonu bir vektörü veya diğer nesneleri alır ve bunları bir faktör veya faktörler listesi tarafından belirlenen gruplara böler.split() fonksiyonunun argümanları şunlardırneredex` bir vektör (veya liste) veya veri setidirf` bir faktör (veya bir faktöre zorlanmış) veya bir faktörler listesidrop boş faktör seviyelerinin bırakılıp bırakılmayacağını belirtirsplit() ve lapply() veya sapply() gibi bir fonksiyonun kombinasyonu R'de yaygın bir paradigmadır. Temel fikir, bir veri yapısını alıp başka bir değişken tarafından tanımlanan alt kümelere bölebilmeniz ve bu alt kümeler üzerinde bir fonksiyon uygulayabilmenizdir. Bu fonksiyonun alt kümeler üzerinde uygulanmasının sonuçları daha sonra harmanlanır ve bir nesne olarak döndürülür. Bu işlem dizisi bazen başka bağlamlarda \"map-reduce\" olarak adlandırılır.Burada bazı verileri simüle ediyoruz ve bir faktör değişkenine göre bölüyoruz. Bir faktör değişkeninde \"seviyeler oluşturmak\" için gl() fonksiyonunu kullandığımıza dikkat edin.Yaygın bir deyim split ve ardından lapplydir.","code":"> str(split)\nfunction (x, f, drop = FALSE, ...)  > x <- c(rnorm(10), runif(10), rnorm(10, 5)) # 30 elemanlı vektor\n> f <- gl(3, 10) # 3 kaetgorili bagimsiz değişken\n> split(x, f)\n$`1`\n [1]  0.3981302 -0.4075286  1.3242586 -0.7012317 -0.5806143 -1.0010722\n [7] -0.6681786  0.9451850  0.4337021  1.0051592\n\n$`2`\n [1] 0.34822440 0.94893818 0.64667919 0.03527777 0.59644846 0.41531800\n [7] 0.07689704 0.52804888 0.96233331 0.70874005\n\n$`3`\n [1] 5.134448 5.765599 5.955137 4.949434 4.694185 5.893674 3.952702 6.971337\n [9] 4.616368 6.654145> lapply(split(x, f), mean)\n$`1`\n[1] 0.07478098\n\n$`2`\n[1] 0.5266905\n\n$`3`\n[1] 5.458703"},{"path":"döngü-fonkisyonları.html","id":"veri-setini-bölme","chapter":"Bölüm 14 Döngü Fonkisyonları","heading":"14.4.1 Veri Setini Bölme","text":"ay için ayrı alt veri seti olduğu için airquality veri setini Month değişkenine göre bölebiliriz.Daha sonra bir alt veri seti için Ozone, Solar.R ve Wind sütun ortalamalarını alabiliriz.Daha okunabilir bir çıktı için burada sapply() kullanmak daha iyi olabilir.Ne yazık ki, verilerde NAlar vardır, bu nedenle bu değişkenlerin ortalamalarını alamayız. Ancak, colMeans fonksiyonuna ortalamayı hesaplamadan önce NAları kaldırmasını söyleyebiliriz.","code":"> library(datasets)\n> head(airquality)> s <- split(airquality, airquality$Month)\n> str(s)\nList of 5\n $ 5:'data.frame':  31 obs. of  6 variables:\n  ..$ Ozone  : int [1:31] 41 36 12 18 NA 28 23 19 8 NA ...\n  ..$ Solar.R: int [1:31] 190 118 149 313 NA NA 299 99 19 194 ...\n  ..$ Wind   : num [1:31] 7.4 8 12.6 11.5 14.3 14.9 8.6 13.8 20.1 8.6 ...\n  ..$ Temp   : int [1:31] 67 72 74 62 56 66 65 59 61 69 ...\n  ..$ Month  : int [1:31] 5 5 5 5 5 5 5 5 5 5 ...\n  ..$ Day    : int [1:31] 1 2 3 4 5 6 7 8 9 10 ...\n $ 6:'data.frame':  30 obs. of  6 variables:\n  ..$ Ozone  : int [1:30] NA NA NA NA NA NA 29 NA 71 39 ...\n  ..$ Solar.R: int [1:30] 286 287 242 186 220 264 127 273 291 323 ...\n  ..$ Wind   : num [1:30] 8.6 9.7 16.1 9.2 8.6 14.3 9.7 6.9 13.8 11.5 ...\n  ..$ Temp   : int [1:30] 78 74 67 84 85 79 82 87 90 87 ...\n  ..$ Month  : int [1:30] 6 6 6 6 6 6 6 6 6 6 ...\n  ..$ Day    : int [1:30] 1 2 3 4 5 6 7 8 9 10 ...\n $ 7:'data.frame':  31 obs. of  6 variables:\n  ..$ Ozone  : int [1:31] 135 49 32 NA 64 40 77 97 97 85 ...\n  ..$ Solar.R: int [1:31] 269 248 236 101 175 314 276 267 272 175 ...\n  ..$ Wind   : num [1:31] 4.1 9.2 9.2 10.9 4.6 10.9 5.1 6.3 5.7 7.4 ...\n  ..$ Temp   : int [1:31] 84 85 81 84 83 83 88 92 92 89 ...\n  ..$ Month  : int [1:31] 7 7 7 7 7 7 7 7 7 7 ...\n  ..$ Day    : int [1:31] 1 2 3 4 5 6 7 8 9 10 ...\n $ 8:'data.frame':  31 obs. of  6 variables:\n  ..$ Ozone  : int [1:31] 39 9 16 78 35 66 122 89 110 NA ...\n  ..$ Solar.R: int [1:31] 83 24 77 NA NA NA 255 229 207 222 ...\n  ..$ Wind   : num [1:31] 6.9 13.8 7.4 6.9 7.4 4.6 4 10.3 8 8.6 ...\n  ..$ Temp   : int [1:31] 81 81 82 86 85 87 89 90 90 92 ...\n  ..$ Month  : int [1:31] 8 8 8 8 8 8 8 8 8 8 ...\n  ..$ Day    : int [1:31] 1 2 3 4 5 6 7 8 9 10 ...\n $ 9:'data.frame':  30 obs. of  6 variables:\n  ..$ Ozone  : int [1:30] 96 78 73 91 47 32 20 23 21 24 ...\n  ..$ Solar.R: int [1:30] 167 197 183 189 95 92 252 220 230 259 ...\n  ..$ Wind   : num [1:30] 6.9 5.1 2.8 4.6 7.4 15.5 10.9 10.3 10.9 9.7 ...\n  ..$ Temp   : int [1:30] 91 92 93 93 87 84 80 78 75 73 ...\n  ..$ Month  : int [1:30] 9 9 9 9 9 9 9 9 9 9 ...\n  ..$ Day    : int [1:30] 1 2 3 4 5 6 7 8 9 10 ...> lapply(s, function(x) {\n+         colMeans(x[, c(\"Ozone\", \"Solar.R\", \"Wind\")])\n+ }) ## anaomin fonkisyon kullanıldığına dikkat ediniz.\n$`5`\n   Ozone  Solar.R     Wind \n      NA       NA 11.62258 \n\n$`6`\n    Ozone   Solar.R      Wind \n       NA 190.16667  10.26667 \n\n$`7`\n     Ozone    Solar.R       Wind \n        NA 216.483871   8.941935 \n\n$`8`\n   Ozone  Solar.R     Wind \n      NA       NA 8.793548 \n\n$`9`\n   Ozone  Solar.R     Wind \n      NA 167.4333  10.1800 > sapply(s, function(x) {\n+         colMeans(x[, c(\"Ozone\", \"Solar.R\", \"Wind\")])\n+ })\n               5         6          7        8        9\nOzone         NA        NA         NA       NA       NA\nSolar.R       NA 190.16667 216.483871       NA 167.4333\nWind    11.62258  10.26667   8.941935 8.793548  10.1800> sapply(s, function(x) {\n+         colMeans(x[, c(\"Ozone\", \"Solar.R\", \"Wind\")], \n+                  na.rm = TRUE)\n+ })\n                5         6          7          8         9\nOzone    23.61538  29.44444  59.115385  59.961538  31.44828\nSolar.R 181.29630 190.16667 216.483871 171.857143 167.43333\nWind     11.62258  10.26667   8.941935   8.793548  10.18000"},{"path":"döngü-fonkisyonları.html","id":"tapply","chapter":"Bölüm 14 Döngü Fonkisyonları","heading":"14.5 tapply","text":"tapply() fonksiyonun temel görevi verileri belirlenen grup veya faktör değişkenine göre özetlemektir.Fonksiyonda bulunan x argümanı vektör, veri seti ve liste şeklindeki nesneleri, index argümanı \"x\" nesnesinin alt boyut, grup veya faktör değişkenini, FUN argümanı ise uygulanacak fonksiyonu belirtir.\\(tapply(x, Index, FUN, …)\\)\\(tapply(x, Index, FUN, …)\\)tapply() liste ve veri seti yapısındaki nesnelere uygulandığında, grup veya faktör değişkenine ilişkin fonksiyon değerlerini fonksiyon türüne gore vektör ya da liste şeklinde verir.tapply() liste ve veri seti yapısındaki nesnelere uygulandığında, grup veya faktör değişkenine ilişkin fonksiyon değerlerini fonksiyon türüne gore vektör ya da liste şeklinde verir.Eğer tapply() içinde kullanılan fonksiyon tek bir değer veriyorsa, çıktı vektör; birden fazla değer veriyorsa, çıktı liste yapısındadır.Eğer tapply() içinde kullanılan fonksiyon tek bir değer veriyorsa, çıktı vektör; birden fazla değer veriyorsa, çıktı liste yapısındadır.tapply()` işlevinin argümanları aşağıdaki gibidir:X` bir vektördürINDEX bir faktör ya da faktörler listesidir (ya da faktörlere zorlanırlar)FUN` uygulanacak bir işlevdir... geçirilecek diğer argümanları içerir FUNbasitleştir, sonucu basitleştirmeli miyiz?Sayılardan oluşan bir vektör verildiğinde, basit bir işlem grup ortalamalarını almaktır.Sonucu sadeleştirmeden grup ortalamalarını da alabiliriz, bu da bize bir liste verecektir. Tek bir değer döndüren fonksiyonlar için genellikle istediğimiz bu değildir, ancak yapılabilir.Tek bir değerden daha fazlasını döndüren fonksiyonları da uygulayabiliriz. Bu durumda, tapply() sonucu basitleştirmeyecek ve bir liste döndürecektir. İşte bir alt grubun ranjını bulmak için bir örnek.","code":"> str(tapply)\nfunction (X, INDEX, FUN = NULL, ..., default = NA, simplify = TRUE)  > ## veri üret\n> x <- c(rnorm(10), runif(10), rnorm(10, 1))\n> ## factor değişken\n> f <- gl(3, 10)   \n> f\n> tapply(x, f, mean)\n [1] 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3\nLevels: 1 2 3\n        1         2         3 \n0.1457707 0.4659058 1.2320306 > tapply(x, f, mean, simplify = FALSE)\n$`1`\n[1] 0.1457707\n\n$`2`\n[1] 0.4659058\n\n$`3`\n[1] 1.232031> tapply(x, f, range)\n$`1`\n[1] -1.024548  1.512213\n\n$`2`\n[1] 0.06490054 0.85750154\n\n$`3`\n[1] -0.8697888  2.4970410> \n> isim <- c(\"Ali\",\"Elif\",\"Su\",\"Deniz\",\"Aras\",\"Berk\",\"Can\",\"Ece\",\"Efe\",\"Arda\")\n> boy <- c(160,165,170,155,167,162,169,158,160,164)\n> kilo <- c(55,55,57,50,48,65,58,62,45,47)\n> cinsiyet <- c(\"erkek\",\"kadin\",\"kadin\",\"kadin\",\"erkek\",\n+ \"erkek\",\"erkek\",\"kadin\",\"erkek\",\"erkek\")\n> cinsiyet <- factor(cinsiyet)\n> beden <- c(\"S\",\"M\",\"S\",\"M\",\"S\",\"L\",\"M\",\"L\",\"S\",\"S\")\n> beden <- factor(beden)\n> # tapply() fonksiyonunun liste veri yapısına uygulanması\n> Liste <- list(isim=isim,boy=boy,cinsiyet=cinsiyet,beden=beden,kilo=kilo)\n> df <- data.frame(isim=isim,boy=boy,cinsiyet=cinsiyet,beden=beden,kilo=kilo)\n> tapply(Liste$boy, Liste$cinsiyet, sort)\n$erkek\n[1] 160 160 162 164 167 169\n\n$kadin\n[1] 155 158 165 170> \n> tapply(Liste$boy, Liste$cinsiyet, sort, decreasing=TRUE)\n$erkek\n[1] 169 167 164 162 160 160\n\n$kadin\n[1] 170 165 158 155> \n> tapply(df$boy, Liste$cinsiyet, sort)\n> \n$erkek\n[1] 160 160 162 164 167 169\n\n$kadin\n[1] 155 158 165 170> \n> tapply(df$boy, Liste$cinsiyet, mean)\n   erkek    kadin \n163.6667 162.0000 > tapply(df$boy, Liste$cinsiyet, sort, decreasing=TRUE)\n$erkek\n[1] 169 167 164 162 160 160\n\n$kadin\n[1] 170 165 158 155"},{"path":"döngü-fonkisyonları.html","id":"by-fonksiyonu","chapter":"Bölüm 14 Döngü Fonkisyonları","heading":"14.6 by() Fonksiyonu","text":"","code":"> \n> \n> by(df$boy, Liste$cinsiyet, sort)\n> \n> by(df$boy, Liste$cinsiyet, sort, decreasing=TRUE)\n> \n> by(df$boy, Liste$cinsiyet, mean)\n> \n> by(df$boy, Liste$cinsiyet, mean)\nListe$cinsiyet: erkek\n[1] 160 160 162 164 167 169\n------------------------------------------------------------ \nListe$cinsiyet: kadin\n[1] 155 158 165 170\nListe$cinsiyet: erkek\n[1] 169 167 164 162 160 160\n------------------------------------------------------------ \nListe$cinsiyet: kadin\n[1] 170 165 158 155\nListe$cinsiyet: erkek\n[1] 163.6667\n------------------------------------------------------------ \nListe$cinsiyet: kadin\n[1] 162\nListe$cinsiyet: erkek\n[1] 163.6667\n------------------------------------------------------------ \nListe$cinsiyet: kadin\n[1] 162> \n> by(df$boy, Liste$cinsiyet, mean)\n> \n> by(df$boy, Liste$cinsiyet, mean)\nListe$cinsiyet: erkek\n[1] 163.6667\n------------------------------------------------------------ \nListe$cinsiyet: kadin\n[1] 162\nListe$cinsiyet: erkek\n[1] 163.6667\n------------------------------------------------------------ \nListe$cinsiyet: kadin\n[1] 162"},{"path":"döngü-fonkisyonları.html","id":"apply","chapter":"Bölüm 14 Döngü Fonkisyonları","heading":"14.7 apply()","text":"apply() fonksiyonu, bir dizinin kenar boşlukları üzerinde bir fonksiyonu (genellikle anonim bir fonksiyon) değerlendirmek için kullanılır. Çoğunlukla bir matrisin (sadece 2 boyutlu bir dizi) satırlarına veya sütunlarına bir fonksiyon uygulamak için kullanılır. Ancak, örneğin bir dizi matrisin ortalamasını almak gibi genel dizilerde de kullanılabilir. apply() kullanmak bir döngü yazmaktan gerçekten daha hızlı değildir, ancak tek satırda çalışır ve oldukça kompakttır.apply()` işlevinin argümanları şunlardırX` bir dizidirMARGIN` hangi kenar boşluklarının \"tutulması\" gerektiğini gösteren bir tamsayı vektörüdür.FUN` uygulanacak bir fonksiyondur...,FUN`aktarılacak diğer argümanlar içindirBurada 20'ye 10'luk bir normal rastgele sayılar matrisi oluşturuyorum. Daha sonra bir sütunun ortalamasını hesaplıyorum.Ayrıca satırın toplamını da hesaplayabilirim.iki apply() çağrısında da dönüş değerinin bir sayı vektörü olduğuna dikkat edin.Muhtemelen ikinci argümanın, satır istatistikleri mi yoksa sütun istatistikleri mi istediğimize bağlı olarak 1 veya 2 olduğunu fark etmişsinizdir. Peki apply() fonksiyonunun ikinci argümanı tam olarak nedir?MARGIN argümanı esasen apply() fonksiyonuna dizinin hangi boyutunu korumak veya saklamak istediğinizi belirtir. Yani bir sütunun ortalamasını alırken şunu belirtirimçünkü ortalamayı alarak ilk boyutu (satırları) daraltmak istiyorum ve sütun sayısını korumak istiyorum. Benzer şekilde, satır toplamlarını istediğimdeçünkü sütunları (ikinci boyut) daraltmak ve satır sayısını (ilk boyut) korumak istiyorum.","code":"> str(apply)\nfunction (X, MARGIN, FUN, ..., simplify = TRUE)  > x <- matrix(rnorm(200), 20, 10)\n> apply(x, 2, mean)  ## Her sütunun ortalamasını alın\n [1] -0.05285811 -0.07607188 -0.14416325  0.26788937 -0.04893217 -0.31775109\n [7]  0.04588463 -0.02798894  0.07064680 -0.23878366> apply(x, 1, sum)   ## Her satırın ortalamasını alın\n [1] -3.81001275  0.28069148 -2.84131594 -0.34383521  3.35432798 -1.41790398\n [7]  4.16348869 -3.12614772 -5.05668423  5.08399986 -0.48483448  5.33222301\n[13] -3.33862932 -1.39998450  2.37859098  0.01082604 -6.29457190 -0.26287700\n[19]  0.71133578 -3.38125293> apply(x, 2, mean)> apply(x, 1, mean)"},{"path":"döngü-fonkisyonları.html","id":"sütunsatır-toplamları-ve-ortalamaları","chapter":"Bölüm 14 Döngü Fonkisyonları","heading":"14.7.1 Sütun/Satır Toplamları ve Ortalamaları","text":"Matrislerin sütun/satır toplamları ve sütun/satır ortalamalarının özel durumları için bazı kullanışlı kısa yollarımız vardır.rowSums = apply(x, 1, sum)rowMeans = apply(x, 1, mean)colSums = apply(x, 2, sum)colMeans = apply(x, 2, mean)Kısayol fonksiyonları yoğun bir şekilde optimize edilmiştir ve bu nedenle çok daha hızlıdır, ancak büyük bir matris kullanmadığınız sürece muhtemelen fark etmeyeceksiniz. Bu fonksiyonların bir başka güzel yönü de biraz daha açıklayıcı olmalarıdır. Kodunuzda colMeans(x) yazmak, apply(x, 2, mean) yazmaktan muhtemelen daha anlaşılırdır.Ortalaması 50, standart sapması 5 olan normal dağılıma sahip 100 elemanlı\n\"S1\" vektöründen 20 satırlı ve 5 sütunlu matrisin oluşturulmasımean() fonksiyonunun \"Matris1\" nesnesinin bir sütununa uygulanarak sütunların ortalamasının alınmasısummary() fonksiyonunun \"Matris1\" nesnesinin bir sütununa uygulanmasısummary() fonksiyonunun \"Matris1\" nesnesinin bir satırına uygulanması","code":"> set.seed(12)\n> S1 <- sample(rnorm(10000, 50, 5), 100, replace=TRUE)\n> Matris1 <- matrix(S1, nrow=20, ncol=5)> apply(Matris1, 2, mean) # Fonksiyonun ikinci girdisi olan 2  sütun elamanlarını temsil etmektedir.\n[1] 48.20485 52.13701 49.38658 50.61689 48.60479> apply(Matris1, 2, summary)\n            [,1]     [,2]     [,3]     [,4]     [,5]\nMin.    39.00080 40.23309 39.04749 39.32974 37.74364\n1st Qu. 45.21933 48.44165 45.57123 47.36401 43.71252\nMedian  49.31295 52.24410 49.49029 51.08794 47.62144\nMean    48.20485 52.13701 49.38658 50.61689 48.60479\n3rd Qu. 52.40540 55.97719 52.70180 54.36235 53.32016\nMax.    55.24910 63.33272 58.88203 59.93019 60.51715> apply(Matris1, 1, summary)\n            [,1]     [,2]     [,3]     [,4]     [,5]     [,6]     [,7]     [,8]\nMin.    45.82396 39.16789 51.63544 40.23309 39.04749 44.81304 39.73637 51.11418\n1st Qu. 47.78055 39.32974 52.46878 43.82775 47.16408 47.46234 46.19462 51.96290\nMedian  48.36804 46.24689 53.43269 47.65095 49.56534 49.64774 49.12984 52.65739\nMean    50.47126 45.82933 54.50679 47.52181 48.65629 52.22224 50.10067 54.92558\n3rd Qu. 54.95931 51.70256 56.11501 49.31343 52.65050 59.25790 55.94640 55.56069\nMax.    55.42443 52.69959 58.88203 56.58380 54.85404 59.93019 59.49613 63.33272\n            [,9]    [,10]    [,11]    [,12]    [,13]    [,14]    [,15]    [,16]\nMin.    44.96852 39.00080 43.36682 48.42947 42.13211 42.73818 40.55680 41.37856\n1st Qu. 48.34900 48.83882 52.38428 50.17014 48.46619 46.50319 43.21988 42.18138\nMedian  52.21976 53.65437 52.38428 51.40809 48.88713 50.98943 45.46715 47.83169\nMean    50.61489 50.35382 51.18599 53.07152 50.44334 49.60777 46.24742 47.67032\n3rd Qu. 53.31388 54.20555 52.91266 54.83276 55.24910 51.36429 46.82348 50.54044\nMax.    54.22331 56.06955 54.88190 60.51715 57.48218 56.44375 55.16980 56.41952\n           [,17]    [,18]    [,19]    [,20]\nMin.    40.53528 40.55680 37.74364 46.71473\n1st Qu. 46.04637 44.03153 47.73063 49.31247\nMedian  47.98124 44.46635 49.30321 51.96828\nMean    48.55872 45.45876 47.52113 50.83282\n3rd Qu. 49.85073 46.40143 50.16318 52.82962\nMax.    58.37998 51.83770 52.66500 53.33901"},{"path":"döngü-fonkisyonları.html","id":"kisisel-tanımlı-fonksiyon-ile-kullanılması","chapter":"Bölüm 14 Döngü Fonkisyonları","heading":"14.7.2 kisisel tanımlı fonksiyon ile kullanılması","text":"Yazılan bagil_degiskenlik() fonksiyonunun \"Matris1\" nesnesinin\nbir sütununa uygulanarak bir değişkenin bağıl değişkenlik\nkatsayısının hesaplanmasıAdsız (anonymous) fonksiyonlar ile kullanılması","code":"> \n> bagil_degiskenlik <- function(x){\n+ (sd(x)/mean(x))*100\n+ }\n> apply(Matris1, 2, bagil_degiskenlik)\n[1] 11.24914 10.05771 11.02709 10.59998 12.97312> \n> apply(Matris1, 2, function(x){(sd(x)/mean(x))*100})\n> \n[1] 11.24914 10.05771 11.02709 10.59998 12.97312"},{"path":"döngü-fonkisyonları.html","id":"mapply","chapter":"Bölüm 14 Döngü Fonkisyonları","heading":"14.8 mapply()","text":"mapply() fonksiyonu, bir dizi argüman üzerinde paralel olarak bir fonksiyon uygulayan bir tür çok değişkenli uygulamadır. lapply() ve arkadaşlarının yalnızca tek bir R nesnesi üzerinde yineleme yaptığını hatırlayın. Peki ya birden fazla R nesnesi üzerinde paralel olarak yineleme yapmak isterseniz? İşte mapply() bunun içindir.mapply()` işlevinin argümanları şunlardırFUN` uygulanacak bir işlevdir...` üzerine uygulanacak R nesnelerini içerirMoreArgs FUN için diğer argümanların bir listesidir.SIMPLIFY` sonucun basitleştirilip basitleştirilmeyeceğini belirtirmapply() fonksiyonu, lapply() fonksiyonundan farklı bir argüman sırasına sahiptir, çünkü üzerinde yinelenecek nesne yerine uygulanacak fonksiyon önce gelir. Fonksiyonu uyguladığımız R nesneleri ... argümanında verilir, çünkü keyfi sayıda R nesnesi üzerinde uygulama yapabiliriz.Örneğin, aşağıdakileri yazmak sıkıcıdırlist(rep(1, 4), rep(2, 3), rep(3, 2), rep(4, 1))Bunun yerine mapply() ile şunları yapabilirizBu, rep()ilk argümanına 1:4 dizisini ve ikinci argümanına 4:1 dizisini geçirir.İşte randon Normal değişkenleri simüle etmek için başka bir örnek.Burada mapply() fonksiyonunu kullanarak 1:5 dizisini ayrı ayrı noise() fonksiyonuna aktarabiliriz, böylece biri farklı uzunluk ve ortalamaya sahip 5 rastgele sayı kümesi elde edebiliriz.Yukarıdaki mapply() çağrısı aşağıdaki ile aynıdır","code":"> str(mapply)\nfunction (FUN, ..., MoreArgs = NULL, SIMPLIFY = TRUE, USE.NAMES = TRUE)  >  mapply(rep, 1:4, 4:1)\n[[1]]\n[1] 1 1 1 1\n\n[[2]]\n[1] 2 2 2\n\n[[3]]\n[1] 3 3\n\n[[4]]\n[1] 4> noise <- function(n, mean, sd) {\n+       rnorm(n, mean, sd)\n+ }\n> ## 5 random sayı\n> noise(5, 1, 2)        \n> \n> ##  sadece 1 sayı kümesini simüle ediyor, 5 değil\n> noise(1:5, 1:5, 2)    \n[1] -4.327419  1.768021  1.886192  1.184867  3.169347\n[1] -0.7104655  5.0691634  3.3646210  6.2241624  6.4295708> mapply(noise, 1:5, 1:5, 2)\n[[1]]\n[1] 3.242948\n\n[[2]]\n[1] 6.278157 4.074560\n\n[[3]]\n[1] 2.4963123 0.7828741 1.7470981\n\n[[4]]\n[1]  3.237684302  8.405556702 -0.004281222  4.864798044\n\n[[5]]\n[1] 2.960924 3.354030 5.848408 4.250261 4.707497> list(noise(1, 1, 2), noise(2, 2, 2),\n+      noise(3, 3, 2), noise(4, 4, 2),\n+      noise(5, 5, 2))\n[[1]]\n[1] 0.3604737\n\n[[2]]\n[1] 0.8376833 3.0033085\n\n[[3]]\n[1] 1.944540 1.339083 4.066594\n\n[[4]]\n[1] 3.941666 4.764200 4.716390 5.835816\n\n[[5]]\n[1] 4.662944 2.941786 4.114172 4.941673 8.722601"},{"path":"döngü-fonkisyonları.html","id":"bir-fonksiyonu-vektörleştirme","chapter":"Bölüm 14 Döngü Fonkisyonları","heading":"14.9 Bir Fonksiyonu Vektörleştirme","text":"mapply() fonksiyonu bir fonksiyonu otomatik olarak \"vektörleştirmek\" için kullanılabilir. Bunun anlamı, tipik olarak yalnızca tek argüman alan bir fonksiyonu almak ve vektör argümanları alabilen yeni bir fonksiyon oluşturmak için kullanılabileceğidir.İşte bazı veriler, bir ortalama ve bir standart sapma verildiğinde kareler toplamını hesaplayan bir fonksiyon örneği. Formül \\(\\sum_{=1}^n(x_i-\\mu)^2/\\sigma^2\\) şeklindedir.Bu fonksiyon bir ortalama mu, bir standart sapma sigma ve bir vektör x içinde bazı veriler alır.Birçok istatistiksel uygulamada, en uygun mu ve sigma değerlerini bulmak için kareler toplamını minimize etmek isteriz. Bunu yapmadan önce, birçok farklı mu veya sigma değeri için fonksiyonu değerlendirmek veya çizmek isteyebiliriz. Ancak, bir mu veya sigma vektörü geçmek bu fonksiyonla çalışmayacaktır çünkü vektörleştirilmemiştir.sumsq() çağrısının 10 değer yerine yalnızca bir değer ürettiğine dikkat edin.Ancak, yapmak istediğimizi mapply() kullanarak yapabiliriz.Hatta R'de Vectorize() adında, fonksiyonunuzun vektörleştirilmiş bir versiyonunu otomatik olarak oluşturabilen bir fonksiyon bile vardır. Böylece aşağıdaki gibi tamamen vektörleştirilmiş bir vsumsq() fonksiyonu oluşturabiliriz.Çok havalı, değil mi?","code":"> sumsq <- function(mu, sigma, x) {\n+         sum(((x - mu) / sigma)^2)\n+ }> x <- rnorm(100)       ## veri üret\n> sumsq(1:10, 1:10, x)  ## İstediğimiz bu değil\n[1] 135.6538> mapply(sumsq, 1:10, 1:10, MoreArgs = list(x = x))\n [1] 234.7801 142.9820 123.2306 115.3890 111.3348 108.9033 107.2993 106.1690\n [9] 105.3329 104.6911> vsumsq <- Vectorize(sumsq, c(\"mu\", \"sigma\"))\n> vsumsq(1:10, 1:10, x)\n [1] 234.7801 142.9820 123.2306 115.3890 111.3348 108.9033 107.2993 106.1690\n [9] 105.3329 104.6911"},{"path":"döngü-fonkisyonları.html","id":"özet-4","chapter":"Bölüm 14 Döngü Fonkisyonları","heading":"14.10 Özet","text":"R'deki döngü fonksiyonları çok güçlüdür çünkü kompakt bir form kullanarak veriler üzerinde bir dizi işlem yapmanıza olanak tanırR'deki döngü fonksiyonları çok güçlüdür çünkü kompakt bir form kullanarak veriler üzerinde bir dizi işlem yapmanıza olanak tanırBir döngü fonksiyonunun çalışması, bir R nesnesi (örneğin bir liste, vektör veya matris) üzerinde yinelemeyi, nesnenin bir öğesine bir fonksiyon uygulamayı ve sonuçları harmanlayıp harmanlanmış sonuçları döndürmeyi içerir.Bir döngü fonksiyonunun çalışması, bir R nesnesi (örneğin bir liste, vektör veya matris) üzerinde yinelemeyi, nesnenin bir öğesine bir fonksiyon uygulamayı ve sonuçları harmanlayıp harmanlanmış sonuçları döndürmeyi içerir.Döngü fonksiyonları, döngü fonksiyonunun ömrü boyunca var olan ancak hiçbir yerde saklanmayan anonim fonksiyonları yoğun bir şekilde kullanırDöngü fonksiyonları, döngü fonksiyonunun ömrü boyunca var olan ancak hiçbir yerde saklanmayan anonim fonksiyonları yoğun bir şekilde kullanırsplit() fonksiyonu, bir R nesnesini başka bir değişken tarafından belirlenen ve daha sonra döngü fonksiyonları kullanılarak üzerinde döngü yapılabilen alt kümelere bölmek için kullanılabilir.split() fonksiyonu, bir R nesnesini başka bir değişken tarafından belirlenen ve daha sonra döngü fonksiyonları kullanılarak üzerinde döngü yapılabilen alt kümelere bölmek için kullanılabilir.","code":""},{"path":"hata-ayıklamadebugging.html","id":"hata-ayıklamadebugging","chapter":"Bölüm 15 Hata Ayıklama/Debugging","heading":"Bölüm 15 Hata Ayıklama/Debugging","text":"","code":""},{"path":"hata-ayıklamadebugging.html","id":"yanlış-bir-şeyler-var","chapter":"Bölüm 15 Hata Ayıklama/Debugging","heading":"15.1 Yanlış bir şeyler var!","text":"R, size bir şeylerin yolunda gitmediğini göstermek için çeşitli yollara sahiptir. Sadece bildirimden ölümcül hataya kadar kullanılabilecek farklı gösterge seviyeleri vardır. R'de herhangi bir fonksiyonun çalıştırılması aşağıdaki koşullarla sonuçlanabilir.message() fonksiyonu tarafından üretilen genel bir bildirim/teşhis mesajı; fonksiyonun yürütülmesi devam ederwarning: Bir şeylerin yanlış gittiğine dair bir gösterge, ancak ölümcül olması gerekmez; işlevin yürütülmesi devam eder. Uyarılar warning() fonksiyonu tarafından oluşturulurerror: Ölümcül bir sorun oluştuğunu ve işlevin yürütülmesinin durduğunu gösteren bir gösterge. Hatalar stop() fonksiyonu tarafından üretilir.condition: Beklenmedik bir şeyin meydana geldiğini gösteren genel bir kavramdır; programcılar isterlerse kendi özel koşullarını oluşturabilirler.İşte R'yi kullanırken alabileceğiniz bir uyarı örneği.Bu uyarı, negatif bir sayının logunu almanın NaN değeriyle sonuçlandığını bilmenizi sağlar, çünkü negatif sayıların logunu alamazsınız. Bununla birlikte, R bir hata vermez, çünkü döndürebileceği yararlı bir değere, NaN değerine sahiptir. Uyarı sadece beklenmedik bir şey olduğunu size bildirmek için vardır. Ne programladığınıza bağlı olarak, kodun başka bir bölümüne geçmek için kasıtlı olarak negatif bir sayının logunu almış olabilirsiniz.İşte girdisinin niteliğine bağlı olarak konsola bir mesaj yazdırmak üzere tasarlanmış başka bir fonksiyon.Bu fonksiyon basittir---x`sıfırdan büyük mü yoksa sıfırdan küçük mü ya da sıfıra eşit mi olduğunu belirten bir mesaj yazdırır. Ayrıca girdisini görünmez olarak döndürür, bu da \"print\" fonksiyonlarında yaygın bir uygulamadır. Bir nesneyi görünmez olarak döndürmek, fonksiyon çağrıldığında dönüş değerinin otomatik olarak yazdırılmayacağı anlamına gelir.Yukarıdaki fonksiyona dikkatlice bakın ve herhangi bir hata ya da sorun tespit edip edemeyeceğinize bakın.Fonksiyonu aşağıdaki gibi çalıştırabiliriz.İşlev bu noktada iyi çalışıyor gibi görünüyor. Hata, uyarı veya mesaj yok.Ne oldu?Fonksiyonun yaptığı ilk şey x > 0 olup olmadığını test etmektir. Ancak x bir NA veya NaN değeri ise bu testi yapamazsınız. R bu durumda ne yapacağını bilemez, bu yüzden ölümcül bir hata ile durur.Bu sorunu NA değerlerinin olasılığını öngörerek ve .na() fonksiyonu ile girdinin NA olup olmadığını kontrol ederek çözebiliriz.Şimdi aşağıdakileri çalıştırabiliriz.Ve şey yolunda.Peki ya aşağıdaki durum.Burada bazı NaNlar bekliyoruz çünkü negatif bir sayının logunu almak mantıklı değildir.Şimdi ne olacak? Neden bu hatayı alıyoruz?Buradaki sorun, printmessage2() fonksiyonuna 1 yerine 2 uzunluğunda bir x vektörü vermiş olmamdır. printmessage2() fonksiyonunun gövdesi içinde .na(x) ifadesi, deyiminde test edilen bir vektör döndürür. Ancak, vektör argümanları alamaz, bu nedenle bir hata alırsınız (R'nin önceki sürümlerinde yalnızca bir uyarı alırdınız). Buradaki temel sorun printmessage2() ifadesinin vektörleştirilmemiş olmasıdır.Bu sorunu iki şekilde çözebiliriz. Birincisi basitçe vektör argümanlarına izin vermemektir. Diğer yol ise printmessage2() fonksiyonunu vektör argümanları almasına izin verecek şekilde vektörleştirmektir.İlk yol için, basitçe girdinin uzunluğunu kontrol etmemiz gerekir.Şimdi printmessage3() fonksiyonuna bir vektör verdiğimizde bir hata almamız gerekir.Fonksiyonun vektörleştirilmesi Vectorize() fonksiyonu ile kolayca gerçekleştirilebilir.Şimdi doğru mesajların herhangi bir uyarı veya hata olmadan yazdırıldığını görebilirsiniz. printmessage4() fonksiyonunun geri dönüş değerini adında ayrı bir R nesnesinde sakladığıma dikkat edin. Bunun nedeni, Vectorize() fonksiyonunu kullandığımda artık dönüş değerinin görünmezliğini korumamasıdır.","code":"> log(-1)\nWarning in log(-1): NaNs produced\n[1] NaN> printmessage <- function(x) {\n+         if(x > 0)\n+                 print(\"x  sifirdan büyüktür\")\n+         else\n+                 print(\"x sifirdan küçük ve ya eşittir\")\n+         invisible(x)        \n+ }> printmessage(1)\n[1] \"x  sifirdan büyüktür\"> printmessage(NA)\nError in if (x > 0) print(\"x  sifirdan büyüktür\") else print(\"x sifirdan küçük ve ya eşittir\"): missing value where TRUE/FALSE needed> printmessage2 <- function(x) {\n+         if(is.na(x))\n+                 print(\"x in eksik degeri var!\")\n+         else if(x > 0)\n+                 print(\"x 0'dan buyuk\")\n+         else\n+                 print(\"x sifirdan küçük ve ya eşittir\")\n+         invisible(x)\n+ }> printmessage2(NA)\n[1] \"x in eksik degeri var!\"> x <- log(c(-1, 2))\nWarning in log(c(-1, 2)): NaNs produced> printmessage2(x)\nError in if (is.na(x)) print(\"x in eksik degeri var!\") else if (x > 0) print(\"x 0'dan buyuk\") else print(\"x sifirdan küçük ve ya eşittir\"): the condition has length > 1> printmessage3 <- function(x) {\n+         if(length(x) > 1L)\n+                 stop(\"'x' vektörünün uzunluğu 1'den büyüktür\")\n+         if(is.na(x))\n+                 print(\"x'in eksik değeri var\")\n+         else if(x > 0)\n+                 print(\"x 0'dan büyük\")\n+         else\n+                 print(\"x sifirdan küçük ve ya eşittir\")\n+         invisible(x)\n+ }> printmessage3(1:2)\nError in printmessage3(1:2): 'x' vektörünün uzunluğu 1'den büyüktür> printmessage4 <- Vectorize(printmessage2)\n> out <- printmessage4(c(-1, 2))\n[1] \"x sifirdan küçük ve ya eşittir\"\n[1] \"x 0'dan buyuk\""},{"path":"hata-ayıklamadebugging.html","id":"neyin-yanlış-olduğunu-anlamak","chapter":"Bölüm 15 Hata Ayıklama/Debugging","heading":"15.2 Neyin Yanlış Olduğunu Anlamak","text":"Herhangi bir R kodunda hata ayıklamanın birincil görevi, sorunun ne olduğunu doğru bir şekilde teşhis etmektir. Kodunuzla (veya bir başkasının koduyla) ilgili bir sorunu teşhis ederken, öncelikle ne olmasını beklediğinizi anlamanız önemlidir. Daha sonra neyin olduğunu ve beklentilerinizden nasıl saptığını belirlemeniz gerekir. Sormanız gereken bazı temel sorular şunlardırGirdiniz neydi? Fonksiyonu nasıl çağırdınız?Ne bekliyordunuz? Çıktı, mesajlar, diğer sonuçlar?Ne elde ettiniz?Elde ettiğiniz şey beklediğinizden nasıl farklıydı?Beklentileriniz ilk etapta doğru muydu?Sorunu (tam olarak) yeniden üretebilir misiniz?Bu soruları yanıtlayabilmek sadece kendi iyiliğiniz için değil, aynı zamanda sorunu ayıklamak için başka birinden yardım istemeniz gerekebilecek durumlarda da önemlidir. Tecrübeli programcılar size tam olarak bu soruları soracaktır.","code":""},{"path":"hata-ayıklamadebugging.html","id":"rde-hata-ayıklama-araçları","chapter":"Bölüm 15 Hata Ayıklama/Debugging","heading":"15.3 R'de Hata Ayıklama Araçları","text":"R, kodunuzda hata ayıklama yapmanıza yardımcı olacak bir dizi araç sağlar. R'de fonksiyonlarda hata ayıklamak için kullanılan başlıca araçlar şunlardırtraceback(): bir hata oluştuktan sonra fonksiyon çağrı yığınını yazdırır; hata yoksa hiçbir şey yapmazdebug(): bir fonksiyonu \"hata ayıklama\" modu için işaretler, bu da bir fonksiyonun yürütülmesinde seferinde bir satır adım atmanızı sağlarbrowser(): çağrıldığı yerde bir fonksiyonun yürütülmesini askıya alır ve fonksiyonu hata ayıklama moduna geçirirtrace(): bir fonksiyonun belirli yerlerine hata ayıklama kodu eklemenizi sağlarrecover(): fonksiyon çağrı yığınına göz atabilmeniz için hata davranışını değiştirmenize olanak tanırBu fonksiyonlar, bir fonksiyonun içinden geçmenizi sağlamak için özel olarak tasarlanmış etkileşimli araçlardır. Ayrıca, fonksiyona print() veya cat() deyimlerini eklemek gibi daha kör bir teknik de vardır.","code":""},{"path":"hata-ayıklamadebugging.html","id":"traceback","chapter":"Bölüm 15 Hata Ayıklama/Debugging","heading":"15.4 traceback()","text":"traceback() fonksiyonu, bir hata oluştuktan sonra fonksiyon çağrı yığınını yazdırır. Fonksiyon çağrı yığını, hata oluşmadan önce çağrılan fonksiyonlar dizisidir.Örneğin, bir () fonksiyonunuz olabilir. Bu fonksiyonda c() ve d() fonksiyonlarını çağıran b() fonksiyonuna bağlı çalışabilir. Bir hata oluşursa, hatanın hangi fonksiyonda oluştuğu hemen anlaşılamayabilir. traceback() fonksiyonu hata oluştuğunda kaç seviye derinde olduğunuzu gösterir.Burada, x nesnesi mevcut olmadığı için hatanın mean() fonksiyonunun içinde meydana geldiği açıktır.Bir hata oluştuktan hemen sonra traceback() fonksiyonu çağrılmalıdır. Başka bir fonksiyon çağrıldığında, geri izleme özelliğini kaybedersiniz.Burada doğrusal modelleme için lm() fonksiyonunu kullanan biraz daha karmaşık bir örnek verilmiştir.Şimdi hatanın fonksiyon çağrı yığınının 7. seviyesine kadar atılmadığını görebilirsiniz, bu durumda eval() fonksiyonu y ~ x formülünü değerlendirmeye çalışmış ve y nesnesinin mevcut olmadığını fark etmiştir.Geri izlemeye bakmak, hatanın kabaca nerede oluştuğunu anlamak için yararlıdır, ancak daha ayrıntılı hata ayıklama için kullanışlı değildir. Bunun için debug() fonksiyonuna başvurabilirsiniz.","code":"> mean(x)\nError in mean(x) : object 'x' not found\n> traceback()\n1: mean(x)> lm(y ~ x)\nError in eval(expr, envir, enclos) : object ’y’ not found\n> traceback()\n7: eval(expr, envir, enclos)\n6: eval(predvars, data, env)\n5: model.frame.default(formula = y ~ x, drop.unused.levels = TRUE)\n4: model.frame(formula = y ~ x, drop.unused.levels = TRUE)\n3: eval(expr, envir, enclos)\n2: eval(mf, parent.frame())\n1: lm(y ~ x)"},{"path":"hata-ayıklamadebugging.html","id":"debug","chapter":"Bölüm 15 Hata Ayıklama/Debugging","heading":"15.5 debug()","text":"debug() fonksiyonu, bir işlev için etkileşimli bir hata ayıklayıcı (R'de \"tarayıcı\" olarak da bilinir) başlatır. Hata ayıklayıcıyla, bir hatanın tam olarak nerede oluştuğunu saptamak için bir R işlevini seferinde bir ifadeyle adımlayabilirsiniz.debug() fonksiyonu ilk argüman olarak bir fonksiyon alır. Burada lm() fonksiyonunun hata ayıklamasına bir örnek verilmiştir.Şimdi, lm() fonksiyonunu çağırdığınızda etkileşimli hata ayıklayıcıyı başlatacaktır. Bu davranışı kapatmak için undebug() fonksiyonunu çağırmanız gerekir.Hata ayıklayıcı, tarayıcıyı fonksiyon gövdesinin en üst seviyesinde çağırır. Buradan gövdedeki bir ifade boyunca adım atabilirsiniz. Tarayıcıda çağırabileceğiniz birkaç özel komut vardır:n geçerli ifadeyi yürütür ve sonraki ifadeye geçerc fonksiyonun yürütülmesine devam eder ve bir hata oluşana ya da fonksiyondan çıkılana kadar durmazQ tarayıcıdan çıkarİşte lm() fonksiyonunu kullanan bir tarayıcı oturumu örneği.Tarayıcıdayken, normal bir oturumda kullanabileceğiniz diğer R işlevlerini çalıştırabilirsiniz. Özellikle, mevcut ortamınızda (fonksiyon ortamı) ne olduğunu görmek için ls() ve fonksiyon ortamındaki R nesnelerinin değerlerini yazdırmak için print() fonksiyonlarını kullanabilirsiniz.undebug() fonksiyonu ile etkileşimli hata ayıklamayı kapatabilirsiniz.","code":"> debug(lm)      \n> lm(y ~ x)\ndebugging in: lm(y ~ x)\ndebug: {\n    ret.x <- x\n    ret.y <- y\n    cl <- match.call()\n    ...\n    if (!qr)\n        z$qr <- NULL \n    z\n} \nBrowse[2]>\nBrowse[2]> n   ##  geçerli ifadeyi yürütür ve sonraki ifadeye geçer\ndebug: ret.x <- x\nBrowse[2]> n\ndebug: ret.y <- y\nBrowse[2]> n\ndebug: cl <- match.call()\nBrowse[2]> n\ndebug: mf <- match.call(expand.dots = FALSE)\nBrowse[2]> n\ndebug: m <- match(c(\"formula\", \"data\", \"subset\", \"weights\", \"na.action\",\n    \"offset\"), names(mf), 0L)\nundebug(lm)    ## Unflag the 'lm()' function for debugging"},{"path":"hata-ayıklamadebugging.html","id":"recover","chapter":"Bölüm 15 Hata Ayıklama/Debugging","heading":"15.6 recover()","text":"recover() fonksiyonu, bir hata oluştuğunda R'nin hata davranışını değiştirmek için kullanılabilir. Normalde, bir fonksiyonda hata oluştuğunda, R bir hata mesajı yazdırır, fonksiyondan çıkar ve diğer komutları beklemek üzere sizi çalışma alanınıza geri döndürür.recover() ile R'ye bir hata oluştuğunda, hatanın oluştuğu tam noktada yürütmeyi durdurması gerektiğini söyleyebilirsiniz. Bu size hatanın oluştuğu ortamı kurcalama fırsatı verebilir. Bu, bozulmuş veya yanlışlıkla değiştirilmiş herhangi bir R nesnesi veya verisi olup olmadığını görmek için yararlı olabilir.recover() fonksiyonu, bir hata oluştuğunda ilk olarak fonksiyon çağrı yığınını yazdıracaktır. Daha sonra, çağrı yığınının etrafında atlamayı ve sorunu araştırmayı seçebilirsiniz. Bir kare numarası seçtiğinizde, tarayıcıya yerleştirileceksiniz (tıpkı debug() ile tetiklenen etkileşimli hata ayıklayıcı gibi) ve etrafı kurcalayabileceksiniz.","code":"> options(error = recover)    ## Change default R error behavior\n> read.csv(\"nosuchfile\")      ## This code doesn't work\nError in file(file, \"rt\") : cannot open the connection\nIn addition: Warning message:\nIn file(file, \"rt\") :\n  cannot open file ’nosuchfile’: No such file or directory\n  \nEnter a frame number, or 0 to exit\n\n1: read.csv(\"nosuchfile\")\n2: read.table(file = file, header = header, sep = sep, quote = quote, dec =\n3: file(file, \"rt\")\n\nSelection:"},{"path":"hata-ayıklamadebugging.html","id":"özet-5","chapter":"Bölüm 15 Hata Ayıklama/Debugging","heading":"15.7 Özet","text":"Bir sorunun/durumun üç ana göstergesi vardır: message, warning, error; sadece bir error ölümcüldürProblemli bir fonksiyonu analiz ederken, problemi yeniden üretebildiğinizden emin olun, beklentilerinizi ve çıktının beklentinizden nasıl farklı olduğunu açıkça belirtinEtkileşimli hata ayıklama araçları traceback, debug, browser, trace ve recover işlevlerdeki sorunlu kodları bulmak için kullanılabilirHata ayıklama araçları düşünmenin yerini tutmaz!","code":""},{"path":"klasik-test-teorisi.html","id":"klasik-test-teorisi","chapter":"Bölüm 16 Klasik Test Teorisi","heading":"Bölüm 16 Klasik Test Teorisi","text":"Düşünme İhtiyacı Ölçeğine (NFC Ölçeğine) ait verileri Klasik Test Teorisine (CTT) dayalı çeşitli psikometrik analizler yapmak ve bu aracın güvenilirlik ve geçerliliğinin nasıl değerlendirileceğini göstermek için kullanacağız. Örnek verilerin yer aldığı çalışma: (Thinking action: Need Cognition predicts Self-Control together Action Orientation, Grass et al. 2019), NFC ile diğer gizli özellikler (örneğin, özkontrol) arasındaki ilişkiye odaklanmıştır.NFC’nin gizil özelliğini ölçmek için Cacioppo ve Petty geliştirmiştir.NFC (need Cognition) bilişsel olarak zorlayıcı görevlere ve çaba gerektiren düşünmeye katılma arzusu olarak tanımlanan psikolojik bir gizli özelliktir.Yüksek düzeyde NFC’ye sahip bireyler bilgiyi arama, edinme, üzerinde düşünme ve yansıtma eğilimindeyken, düşük düzeyde NFC’ye sahip bireyler dünya hakkında ayrıntılı bilgiden kaçınma ve bilişsel olarak karmaşık görevleri stresli bulma eğilimindedir.Maddelere verilen yanıtlar 1 (hiç katılmıyorum) ile 7 (tamamen katılıyorum) arasında değişen 7 puanlık bir derecelendirme ölçeğine göre kaydedilmiştir.Ancak, NFC Ölçeğindeki toplam puanları hesaplamak için, madde yanıtları -3 (tamamen katılmıyorum) ile +3 (tamamen katılıyorum) olarak yeniden kodlanmalıdır.Grass et al. (2019 ) veri dosyalarını ve diğer materyalleri paylaşmıştır.Aşağıdaki analiz için, NFC Ölçeğine verilen yanıtlar, demografik değişkenler ve Öz Denetim Ölçeği gibi ölçüt ölçümlerinden elde edilen ek puanları içeren orijinal verilerin bir alt kümesini kullanacağız. Bu veri seti 🔗 import/nfc_data.csv indirilebilir.","code":""},{"path":"klasik-test-teorisi.html","id":"veri-inceleme-1","chapter":"Bölüm 16 Klasik Test Teorisi","heading":"16.1 Veri İnceleme","text":"Verileri özetlemek için genellikle hem istatistiksel hem de veri görselleştirme araçlarını kullanırız. Daha ayrıntılı bilgi için 🔗sayfayı inceleyebilirsiniz.Ayrıca fonksiyonunu ile veri setinin yapısını incelyebilirsiniz.Veri kümesi 1209 satırdan (yani katılımcılar) ve 23 değişkenden (id, yaş, cinsiyet, eğitim, NFC Ölçeği maddelerine verilen yanıtları temsil eden nfc01 ila nfc16 ve ölçüt ölçümleri için üç puan) oluşmaktadır. DataExplorer paketindeki (Cui, 2024) introduce() ve plot_intro() fonksiyonlarını kullanarak veri seti hakkında biraz daha bilgi edinebiliriz:değişkenlerin çoğunun sürekli olduğunu (R Likert maddeleri de aslında sıralı olmalarına rağmen sürekli değişkenler olarak tanımlanır), kesikli (yani kategorik) değişkenler (yani cinsiyet ve eğitim) olduğunu göstermektedir. Ayrıca veri setindeki bazı değişkenlerin kayıp değerlere sahip olduğunu ancak kayıp veri oranının çok küçük olduğunu görüyoruz (sadece %0,029).Eksik değerlere daha yakından bakmak için, bir değişken için eksiklik oranını görselleştirebiliriz. grafik, yaş ve cinsiyetin bazı kayıp değerlere sahip olduğunu ancak kayıp oranının çok küçük olduğunu (%1’den az) göstermektedir.Tüm özet istatistikleri tek bir rapor halinde düzenlemek için create_report() fonksiyonunu kullanabiliriz. Bu fonksiyon DataExplorer içindeki çoğu fonksiyonu çalıştırır ve bir HTML rapor dosyası çıktısı verir.🔗 onincelemeTek bir analizde nfc veri setinin ayrıntılı bir özetini elde etmek için skimr paketindeki (Waring et al., 2022) skim() fonksiyonunu kullanabiliriz. Çıktıdan da görebileceğiniz gibi, nfc veri setindeki değişkenler için benzer tanımlayıcı istatistikler elde edilirTablo 16.1: Data summaryVariable type: characterVariable type: numericveriler için temel tanımlayıcı istatistikleri elde etmek için psych paketindeki (2024) describe() fonksiyonu kullanılabilir.","code":"\nnfc <- read.csv(\"import/nfc_data.csv\", header = TRUE)\nhead(nfc)\nstr(nfc)## 'data.frame':    1209 obs. of  23 variables:\n##  $ id                : int  1 4 7 8 11 12 15 16 21 23 ...\n##  $ age               : int  26 19 23 24 24 20 25 27 21 25 ...\n##  $ sex               : chr  \"Male\" \"Female\" \"Female\" \"Female\" ...\n##  $ education         : chr  \"Abitur\" \"Abitur\" \"Abitur\" \"Abitur\" ...\n##  $ nfc01             : int  5 5 5 5 2 6 3 7 7 6 ...\n##  $ nfc02             : int  7 5 6 5 3 6 4 4 5 7 ...\n##  $ nfc03             : int  5 3 5 4 3 6 4 5 3 7 ...\n##  $ nfc04             : int  1 2 1 2 5 1 1 6 1 1 ...\n##  $ nfc05             : int  6 5 7 5 3 6 6 6 6 7 ...\n##  $ nfc06             : int  2 3 3 5 5 3 5 3 6 2 ...\n##  $ nfc07             : int  2 3 2 2 6 1 3 1 1 1 ...\n##  $ nfc08             : int  5 3 3 2 1 1 2 2 2 2 ...\n##  $ nfc09             : int  2 2 1 2 6 1 3 2 1 1 ...\n##  $ nfc10             : int  1 4 3 2 6 1 3 2 2 2 ...\n##  $ nfc11             : int  2 3 3 4 6 1 1 1 1 1 ...\n##  $ nfc12             : int  2 2 1 3 6 1 1 1 1 1 ...\n##  $ nfc13             : int  6 3 6 2 2 6 3 4 6 5 ...\n##  $ nfc14             : int  5 2 5 3 1 6 3 4 4 5 ...\n##  $ nfc15             : int  2 4 1 1 5 2 1 2 2 1 ...\n##  $ nfc16             : int  1 4 1 1 5 2 2 2 2 2 ...\n##  $ action_orientation: int  10 11 13 5 18 20 6 16 12 8 ...\n##  $ effortful_control : int  11 32 10 0 10 24 -3 2 -6 21 ...\n##  $ self_control      : int  5 16 -2 -4 11 11 -4 3 -10 5 ...\nDataExplorer::introduce(nfc)\nkbl(t(introduce(nfc)), \n    row.names = TRUE, col.names = \"\", \n    format.args = list(big.mark = \",\")) %>%\n  kable_styling()\nDataExplorer::plot_intro(nfc)\nDataExplorer::plot_missing(nfc)\nDataExplorer::plot_bar(data = nfc[, c(\"education\", \"sex\")])\nDataExplorer::plot_histogram(data = \n            nfc[, c(\"age\", \"self_control\", \n                    \"action_orientation\", \n                    \"effortful_control\")])\nDataExplorer::plot_boxplot(data = nfc[!is.na(nfc$sex), # cinsiyet değişkeninde eksik verisi olmayanlar\nc(\"sex\", \"self_control\", \n  \"action_orientation\", \n  \"effortful_control\")],  \nby = \"sex\") # Kategorik değişken düzeyleri için\n## # id değişkeni analizlere dahil edilmediği için çıkarıldı\nnfc <- DataExplorer::drop_columns(nfc, \"id\")\n#\n# DataExplorer::create_report(data = nfc,\n#                              report_title = \"Veri On Inceleme\",\n#                              output_file = \"oninceleme.html\")\nskimr::skim(nfc)\npsych::describe(x = nfc) %>% \n  kable(digit=2)"},{"path":"klasik-test-teorisi.html","id":"korelasyon","chapter":"Bölüm 16 Klasik Test Teorisi","heading":"16.2 Korelasyon","text":"Madde analizine geçmeden önce, maddelerin birbirleriyle ne kadar güçlü bir şekilde ilişkili olduğunu incelemek için maddeler arasındaki korelasyonları da kontrol etmeliyiz. Maddelerin birbirleriyle belirli bir dereceye kadar ilişkili olmasını bekleriz çünkü maddelerin aynı örtük özelliği (bu örnekte NFC yapısı) ölçtüğünü varsayarız.Buna ek olarak, NFC Ölçeğindeki bazı maddelerin olumsuz ifadeler içerdiğini ve dolayısıyla bu maddelere verilen yanıtların diğer maddelerle ters yönde olabileceğini biliyoruz. Örneğin, yüksek NFC’ye sahip bireylerin “Problem çözmeyi içeren görevlerden keyif alma” gibi olumlu ifadeler içeren bir madde için “7 = tamamen katılıyorum” seçeneğini işaretlemeleri beklenirken, “Derinlemesine düşünmeyi gerektirebilecek durumları öngörme ve bunlardan kaçınma” gibi olumsuz ifadeler içeren bir madde için “1 = tamamen katılmıyorum” seçeneğini işaretlemeleri beklenmektedir.Maddeler arasındaki ilişkileri değerlendirmek için ggcorrplot paketini (Kassambara, 2023) kullanarak bir korelasyon matrisi grafiği oluşturacağız. psych’den corPlot() kullanılarak da grafik oluşturualbilir.Ölçekteki birkaç maddenin (mavi/mor renkli kutulara bakınız) diğer maddelerle negatif korelasyona sahip olduğunu görüyoruz. Bunlar NFC Ölçeğindeki (R) işaretli maddelerdir (yani, negatif olarak ifade edilmiş maddeler). Tüm maddeleri aynı yöne koymak için bu maddelere verilen yanıtları ters kodlayacağız (yani, 1=tamamen katılıyorum ile 7=tamamen katılmıyorum). Bu işlem için psych’reverse.code() fonksiyonunu kullanacağız.","code":"\nmatris <- dplyr::select(nfc, starts_with(\"nfc\"))\n\nhead(matris)\ncormat <- psych::polychoric(x = matris)$rho\n\ncormat %>% kbl(digits = 2) %>%\nkable_styling(bootstrap_options = c(\"striped\", \"condensed\"), font_size =\n11)\nggcorrplot::ggcorrplot(\n  corr = cormat, # korelasyon matirisi\n type = \"lower\", # alt kösegen\n show.diag = TRUE, # kosegen\n lab = TRUE, # degerleri ekleme\n lab_size = 3) #\n# ters kodlacak maddeler -1 ile belirtilmiştir.\n\nnfc_key <- c(1,1,1,-1,1,-1,-1,-1,-1,-1,-1,-1,1,1,-1,-1)\n\nters_matris <- psych::reverse.code(\n keys = nfc_key, # ters kodlanacak maddeler\n items = matris, # veri\n mini = 1, # minumum deger\n maxi = 7) # maksimum deger\ncor_ters_matris <-\n psych::polychoric(ters_matris)$rho\n ggcorrplot::ggcorrplot(\n corr = cor_ters_matris,\n type = \"lower\",\n show.diag = TRUE,\n lab = TRUE,\n lab_size = 3) \n# yeniden adlandırma\n colnames(ters_matris) <- colnames(matris)\n ters_matris <- as.data.frame(ters_matris)\n head(ters_matris)\nlibrary(\"OpenMx\")\n means_cor <-\n mean(vechs(cor_ters_matris))\n library(qgraph)\n qgraph(cor_ters_matris,\n cut=0, layout=\"spring\",\n title=paste(\"Korelasyon matrisi,\n ortalama korelasyon = \",\n round(means_cor, digits=2),\n sep=\" \"))\nlibrary(EGAnet); library(psychTools)\n\n# Perform Unique Variable Analysis\nEGA(matris)## Model: GLASSO (EBIC with gamma = 0.5)\n## Correlations: auto\n## Lambda: 0.0753057457698569 (n = 100, ratio = 0.1)\n## \n## Number of nodes: 16\n## Number of edges: 75\n## Edge density: 0.625\n## \n## Non-zero edge weights: \n##      M    SD    Min   Max\n##  0.049 0.119 -0.153 0.626\n## \n## ----\n## \n## Algorithm:  Walktrap\n## \n## Number of communities:  3\n## \n## nfc01 nfc02 nfc03 nfc04 nfc05 nfc06 nfc07 nfc08 nfc09 nfc10 nfc11 nfc12 nfc13 \n##     1     1     1     2     1     2     2     2     2     2     2     2     1 \n## nfc14 nfc15 nfc16 \n##     1     3     3 \n## \n## ----\n## \n## Unidimensional Method: Louvain\n## Unidimensional: No\n## \n## ----\n## \n## TEFI: -10.355"},{"path":"klasik-test-teorisi.html","id":"madde-analizi","chapter":"Bölüm 16 Klasik Test Teorisi","heading":"16.3 Madde analizi","text":"bir madde için betimleyici istatistikler (örn. ortalama, standart sapma, minimum ve maksimum), madde düzeyinde istatistikler (örn. güçlük ve ayırt edicilik) ve bunların ölçek düzeyinde istatistiklerle (örn. güvenilirlik) ilişkileri R’de, ikili (yani, 0 veya 1) ve sıralı (örneğin, Likert ölçeği maddeleri) maddeler üzerinde madde analizi yapmak için çeşitli paketler bulunmaktadır.","code":"\nitemanalysis_ctt <- CTT::itemAnalysis(items = ters_matris, pBisFlag = .2,\n bisFlag = .2)\n itemanalysis_ctt$itemReport %>% kbl(digits = 2) "},{"path":"klasik-test-teorisi.html","id":"psych-revelle-2021-alpha","chapter":"Bölüm 16 Klasik Test Teorisi","heading":"16.3.1 psych (Revelle 2021): alpha()","text":"","code":"\nitemanalysis_psych <- psych::alpha(x = ters_matris)\n itemanalysis_psych## \n## Reliability analysis   \n## Call: psych::alpha(x = ters_matris)\n## \n##   raw_alpha std.alpha G6(smc) average_r S/N    ase mean   sd median_r\n##       0.87      0.87    0.88       0.3 6.8 0.0054    5 0.82     0.29\n## \n##     95% confidence boundaries \n##          lower alpha upper\n## Feldt     0.86  0.87  0.88\n## Duhachek  0.86  0.87  0.88\n## \n##  Reliability if an item is dropped:\n##       raw_alpha std.alpha G6(smc) average_r S/N alpha se  var.r med.r\n## nfc01      0.86      0.86    0.87      0.29 6.2   0.0059 0.0098  0.27\n## nfc02      0.86      0.86    0.87      0.29 6.2   0.0059 0.0091  0.28\n## nfc03      0.86      0.86    0.88      0.30 6.4   0.0058 0.0094  0.29\n## nfc04      0.87      0.87    0.88      0.31 6.6   0.0056 0.0098  0.30\n## nfc05      0.86      0.87    0.88      0.30 6.5   0.0057 0.0100  0.30\n## nfc06      0.87      0.87    0.89      0.31 6.9   0.0054 0.0084  0.31\n## nfc07      0.86      0.86    0.87      0.29 6.0   0.0060 0.0092  0.27\n## nfc08      0.86      0.86    0.88      0.29 6.3   0.0059 0.0098  0.28\n## nfc09      0.86      0.87    0.88      0.30 6.4   0.0057 0.0097  0.30\n## nfc10      0.86      0.87    0.88      0.30 6.4   0.0058 0.0099  0.29\n## nfc11      0.86      0.86    0.87      0.29 6.2   0.0059 0.0096  0.28\n## nfc12      0.86      0.87    0.88      0.30 6.4   0.0058 0.0098  0.29\n## nfc13      0.86      0.86    0.87      0.30 6.3   0.0058 0.0091  0.29\n## nfc14      0.87      0.87    0.88      0.30 6.5   0.0057 0.0088  0.29\n## nfc15      0.86      0.87    0.87      0.30 6.5   0.0057 0.0084  0.30\n## nfc16      0.87      0.87    0.87      0.30 6.5   0.0057 0.0083  0.30\n## \n##  Item statistics \n##          n raw.r std.r r.cor r.drop mean  sd\n## nfc01 1209  0.64  0.65  0.62   0.58  5.5 1.2\n## nfc02 1209  0.66  0.67  0.65   0.60  4.9 1.4\n## nfc03 1209  0.59  0.59  0.56   0.51  4.4 1.4\n## nfc04 1209  0.52  0.51  0.46   0.43  5.5 1.5\n## nfc05 1209  0.54  0.55  0.50   0.47  5.8 1.2\n## nfc06 1209  0.42  0.41  0.34   0.32  4.3 1.5\n## nfc07 1209  0.72  0.72  0.70   0.66  5.3 1.3\n## nfc08 1209  0.65  0.64  0.61   0.57  4.7 1.6\n## nfc09 1209  0.58  0.57  0.53   0.49  5.5 1.5\n## nfc10 1209  0.59  0.58  0.54   0.50  4.8 1.5\n## nfc11 1209  0.65  0.64  0.62   0.58  5.3 1.4\n## nfc12 1209  0.58  0.58  0.54   0.51  5.6 1.4\n## nfc13 1209  0.61  0.61  0.59   0.54  4.1 1.4\n## nfc14 1209  0.54  0.54  0.51   0.46  3.6 1.5\n## nfc15 1209  0.55  0.55  0.53   0.47  5.8 1.3\n## nfc16 1209  0.54  0.54  0.53   0.46  5.5 1.4\n## \n## Non missing response frequency for each item\n##          1    2    3    4    5    6    7 miss\n## nfc01 0.01 0.02 0.05 0.07 0.25 0.43 0.18    0\n## nfc02 0.01 0.05 0.10 0.18 0.27 0.26 0.12    0\n## nfc03 0.02 0.08 0.15 0.22 0.29 0.19 0.05    0\n## nfc04 0.01 0.05 0.06 0.08 0.15 0.37 0.28    0\n## nfc05 0.01 0.02 0.03 0.06 0.21 0.33 0.34    0\n## nfc06 0.04 0.11 0.14 0.27 0.21 0.19 0.05    0\n## nfc07 0.01 0.03 0.07 0.14 0.24 0.35 0.17    0\n## nfc08 0.02 0.08 0.13 0.18 0.24 0.23 0.11    0\n## nfc09 0.02 0.03 0.07 0.11 0.15 0.28 0.34    0\n## nfc10 0.03 0.06 0.12 0.15 0.25 0.28 0.12    0\n## nfc11 0.01 0.04 0.09 0.13 0.22 0.30 0.21    0\n## nfc12 0.01 0.02 0.09 0.09 0.18 0.32 0.30    0\n## nfc13 0.04 0.11 0.19 0.25 0.25 0.13 0.04    0\n## nfc14 0.09 0.16 0.21 0.29 0.15 0.07 0.03    0\n## nfc15 0.01 0.02 0.05 0.07 0.17 0.32 0.36    0\n## nfc16 0.01 0.03 0.06 0.08 0.22 0.31 0.28    0"},{"path":"klasik-test-teorisi.html","id":"shinyitemanalysis","chapter":"Bölüm 16 Klasik Test Teorisi","heading":"16.3.2 ShinyItemAnalysis ( ):","text":"","code":"\nitemanalysis_shiny <- ShinyItemAnalysis::ItemAnalysis(Data = ters_matris)\n\n itemanalysis_shiny %>% kbl(digits = 2)\nShinyItemAnalysis::DDplot(Data = ters_matris, discrim = \"RIR\")"},{"path":"klasik-test-teorisi.html","id":"güvenirlik","chapter":"Bölüm 16 Klasik Test Teorisi","heading":"16.4 Güvenirlik","text":"psych paketindeki splitHalf() fonksiyonu ile bu işlem çok daha kolaydır. Bu fonksiyon, belirli bir veri kümesi için tüm (ya da en azından çok sayıda) olası split-half güvenilirlik değerlerini hesaplar. Bu fonksiyonu kullanmak için sadece analiz edilecek veri setini belirtmek yeterlidir.","code":"\npsych::splitHalf(r = ters_matris)## Split half reliabilities  \n## Call: psych::splitHalf(r = ters_matris)\n## \n## Maximum split half reliability (lambda 4) =  0.92\n## Guttman lambda 6                          =  0.88\n## Average split half reliability            =  0.87\n## Guttman lambda 3 (alpha)                  =  0.87\n## Guttman lambda 2                          =  0.88\n## Minimum split half reliability  (beta)    =  0.78\n## Average interitem r =  0.3  with median =  0.29\n sp_rel <- psych::splitHalf(r = ters_matris, raw = TRUE)\n hist(x = sp_rel$raw,\n breaks = 101,\n xlab = \"İki yarı güvenirliği\",\n main = \"Tum iki yarı guvenirlikleri\")\n abline(v = mean(sp_rel$raw), col = \"red\", lwd = 2, lty = 2)"},{"path":"klasik-test-teorisi.html","id":"iç-tuttarlık","chapter":"Bölüm 16 Klasik Test Teorisi","heading":"16.4.1 İç tuttarlık","text":"İç tutarlılık, bir ölçüm aracındaki maddeler arasındaki homojenlik derecesidir.Benzer şekilde, psych içinde alpha() fonksiyonunu kullanarak madde analizi yaptığımızda, iç tutarlılık sonuçlarını da elde ettik. Tekrar itemanalysis_psych yazdırdığımızda aşağıdaki sonuçları görebiliriz:İç tuttarlıkraw_alpha: Maddeler arasındaki kovaryanslara dayalı alfa katsayısı (≥ 0,7 değerleri “kabul edilebilir” güvenilirliği gösterir)raw_alpha: Maddeler arasındaki kovaryanslara dayalı alfa katsayısı (≥ 0,7 değerleri “kabul edilebilir” güvenilirliği gösterir)std.alpha: Maddeler arasındaki korelasyonlara dayalı standartlaştırılmış alfa katsayısıstd.alpha: Maddeler arasındaki korelasyonlara dayalı standartlaştırılmış alfa katsayısıG6: Guttman’ın Lambda 6 güvenilirliğiG6: Guttman’ın Lambda 6 güvenilirliğiaverage_r: Ortalama maddeler arası korelasyonlaraverage_r: Ortalama maddeler arası korelasyonlarS/N: Sinyal/Gürültü oranı, burada s/n = nr/(1 − r)S/N: Sinyal/Gürültü oranı, burada s/n = nr/(1 − r)ase: Alfa katsayısının standart hatasıase: Alfa katsayısının standart hatasıOrtalama: Maddelerin ortalaması alınarak veya toplanarak oluşturulan ölçek ortalamasıOrtalama: Maddelerin ortalaması alınarak veya toplanarak oluşturulan ölçek ortalamasısd: Toplam puanın standart sapmasısd: Toplam puanın standart sapmasımedian_r: Medyan öğeler arası korelasyonlarmedian_r: Medyan öğeler arası korelasyonlarBu değerler arasında, iç tutarlılığı yorumlamak için raw_alpha değerini kullanırız. NFC Ölçeği için yüksek iç tutarlılığa işaret etmektedir. Çıktının “Bir madde çıkarılırsa güvenilirlik” başlığı altındaki ikinci kısmı, bir madde araçtan çıkarıldıktan sonra iç tutarlılığın nasıl değiştiğini göstermektedir. Örneğimizde, ham_alfa sütunu iç tutarlılığın ya aynı kaldığını ya da 0,86’ya düştüğünü göstermektedir, bu da maddelerin hiçbirini çıkarmanın güvenilirliği artırmamıza yardımcı olmayacağını ve bu nedenle orijinal ölçeği kullanmamız gerektiğini göstermektedir.İç tuttarlık NFC Ölçeği için iç tutarlılığı hesaplamak üzere QME paketini (Brown et al., 2016) kullanacağız. Alfa katsayısı ve Guttman’ın lambda güvenilirlik istatistiklerine ek olarak, QME paketi Feldt-Gilmer ve Feldt-Brennan güvenilirlik istatistiklerini de hesaplar.Spearman-Brown formülü İlk olarak, NFC ölçeğinin uzunluğunu 0,5 kat kısaltmanın güvenirliği nasıl değiştirileceğini inceleyeceğiz (yani, uzunluğu 16 maddeden 8 maddeye düşürmek)Çıktı, NFC Ölçeğinin uzunluğunu 16 maddeden 8 maddeye düşürmek zorunda kalsaydık, iç tutarlılığın kabaca 0,77 olacağını göstermektedir.iç tutarlılığı 0.87’den (mevcut değer) 0.90’(hedef değer) çıkarmak için kaç maddeye daha ihtiyacımız olacağını göreceğiz.Yukarıdaki sonuç, 0,90’lık iç tutarlılık düzeyine ulaşmak için 22 maddeye (yani orijinal NFC maddeleriyle benzer özelliklere sahip 6 ek maddeye) ihtiyacımız olduğunu göstermektedir.","code":"\nitemanalysis_ctt## \n##  Number of Items \n##  16 \n## \n##  Number of Examinees \n##  1209 \n## \n##  Coefficient Alpha \n##  0.87\nitemanalysis_psych\n## Reliability analysis   \n## Call: psych::alpha(x = ters_matris)\n## \n##   raw_alpha std.alpha G6(smc) average_r S/N    ase mean   sd median_r\n##       0.87      0.87    0.88       0.3 6.8 0.0054    5 0.82     0.29\nreliability_qme <- QME::analyze(test = ters_matris, id = FALSE, na_to_0 = FALSE)## Adding id column.\n reliability_qme$test_level## $descriptives\n##                          Value\n## Minimum Score       21.0000000\n## Maximum Score      112.0000000\n## Mean Score          80.6228288\n## Median Score        82.0000000\n## Standard Deviation  13.1904670\n## IQR                 17.0000000\n## Skewness (G1)       -0.6471103\n## Kurtosis (G2)        0.7557418\n## \n## $reliability\n##                    Estimate    95% LL    95% UL      SEM\n## Guttman's L2      0.8731550 0.8624677 0.8833207 4.697826\n## Guttman's L4      0.8932339 0.8842384 0.9017905 4.309996\n## Feldt-Gilmer      0.8717610 0.8609563 0.8820384 4.723569\n## Feldt-Brennan     0.8712988 0.8604551 0.8816133 4.732074\n## Coefficient Alpha 0.8704009 0.8594817 0.8807874 4.748551\nCTT::spearman.brown(r.xx = 0.87, input = 0.5, n.or.r = \"n\")## $r.new\n## [1] 0.7699115\nn <- CTT::spearman.brown(r.xx = 0.87, input = 0.90, n.or.r = \"r\")\nround(n$n.new * 16, digits = 0)## [1] 22"},{"path":"klasik-test-teorisi.html","id":"ölçüt-bağlantılı-geçerlik","chapter":"Bölüm 16 Klasik Test Teorisi","heading":"16.4.2 Ölçüt bağlantılı geçerlik","text":"Ölçüt bağıntılı geçerlik, bir ölçme aracının aynı yapıyı (veya benzer yapıyı) ölçen başka bir aracın sonucunu ne kadar iyi tahmin ettiğini gösterir.Eşzamanlı geçerlikEşzamanlı geçerlikYordama geçerlikYordama geçerlikÖz-Kontrol Ölçeği’nin kısa formundan alınan öz-kontrol puanları (Bertrams & Dickhäuser, 2009), Yetişkin Mizaç Anketi, Çabalı Kontrol Ölçeğinden alınan çabalı kontrol puanları ve Eylem Kontrol Ölçeğinden alınan eylem yönelimi puanları.Önceki araştırmaların bulgularına dayanarak, NFC ile diğer üç yapı (öz kontrol, çaba gerektiren kontrol ve eylem kontrolü) arasında pozitif, küçük ila orta düzeyde ilişkiler bulmayı bekliyoruzİlk olarak, NFC Ölçeği için 1 ila 7 arasındaki madde puanlarını -3 ila +3 olarak yeniden kodlama car paketindeki (Fox & Weisberg, 2019) recode() fonkisyonu ile yapılabilir.Ölçüt bağlantılı geçerlikNFC Ölçeği puanlarını diğer ölçeklerden gelen puanlarla tek bir veri kümesinde birleştirebiliriz.korelasyon matrisi grafiği, NFC Ölçeği puanları ile diğer ölçeklerden alınan puanlar arasında gerçekten de pozitif, küçük ila orta düzeyde bir korelasyon olduğunu göstermektedir. Bunların sadece ölçek puanları arasındaki ham korelasyonlar olduğunu unutmayın. Yani, bir ölçekte yer alan ölçüm hatasından kaynaklanan zayıflama için düzeltilmemiştir.Zayıflatılmış korelasyonları elde etmek için psych paketinden correct.cor() fonksiyonunu kullanacağız. Bu fonksiyonu kullanmak için, ölçek puanlarının ham korelasyon matrisini ve güvenilirlik (yani iç tutarlılık) tahminlerinin bir vektörünü listelememiz gerekir. NFC Ölçeği için güvenilirlik tahmini 0.87’dir ve üç kriter ölçümü için güvenilirlik tahminleri ( ) şeklindedir: Eylem Kontrol Ölçeği: 0.791 Özdenetim Ölçeği: 0.817 Çabalı Kontrol Ölçeği: 0.783Bu bilgiyi kullanarak, zayıflatılmış korelasyonları aşağıdaki gibi hesaplayabiliriz:yeni korelasyon matrisinde, üst köşegen kısmı zayıflama için düzeltilmiş dört ölçek puanı arasındaki korelasyonları, köşegen kısmı dört ölçek için güvenilirlik tahminlerini ve alt köşegen kısmı dört ölçek puanı arasındaki orijinal (yani ham) korelasyonları göstermektedir. Zayıflama için düzeltme uygulandıktan sonra, yeni korelasyon değerleri ham değerlerinden daha yüksek hale gelmiştir. Örneğin, NFC ölçeğinden alınan puanlar Çabalı Kontrol Ölçeğinden alınan puanlarla korelasyona sahipken, iki ölçek arasındaki düzeltilmiş korelasyon ’tir.","code":"\nrecode_nfc <- function(x) {\ncar::recode(x, \"1=-3; 2=-2; 3=-1; 4=0; 5=1; 6=2; 7=3\")\n }\n ters_matris <- apply(ters_matris,\n 2, # her bir sutuna uygulanir\n recode_nfc)\n nfc_score <- rowSums(ters_matris)\n summary(nfc_score)##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##  -43.00    9.00   18.00   16.62   26.00   48.00\nhist(nfc_score,\n xlab = \"NFC Toplam Puan\",\n main = \"NFC Puan Dağılımı\")\n scores <- cbind(nfc_score, nfc[, c(\"action_orientation\",\n\"self_control\", \"effortful_control\")])\ncormat_scores <- \ncor(scores, use = \"pairwise.complete.obs\")\n\nggcorrplot::ggcorrplot(corr = cormat_scores,\ntype = \"lower\", \nshow.diag = TRUE,\nlab = TRUE, \nlab_size = 3) \npsych::correct.cor(x = cormat_scores, \n                   y = c(0.87, 0.791, 0.817, 0.783)) %>%\n  round(., 2) %>%\n  kbl() %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"condensed\"), font_size = 13)"},{"path":"klasik-test-teorisi.html","id":"madde-geçerlik-indeksi","chapter":"Bölüm 16 Klasik Test Teorisi","heading":"16.4.3 Madde Geçerlik İndeksi","text":"NFC Ölçeğinden alınan toplam puanlar ile ölçüt ölçümleri arasındaki ilişkiye ek olarak, NFC Ölçeğindeki bir madde ile ölçüt ölçümlerinden alınan puanlar arasındaki ilişkiyi kontrol etmek için madde geçerlilik indeksini (IVI) de hesaplayabiliriz. IVI -0,5 ile 0,5 arasında değişebilir ve büyük değerler (mutlak büyüklük olarak) daha yüksek geçerliliğe işaret eder. ivi() fonksiyonu orijinal olarak paketinden gelmektedir","code":"\nivi <- function(item, criterion) {\ns_i <- sd(item, na.rm = TRUE)\nr <- cor(item, criterion, use = \"complete.obs\")\nindex <- s_i * r\nreturn(index)\n}\n\nnfc_ivi <- apply(ters_matris,  2, \n                 function(x) ivi(item = x,\n                                 criterion = nfc$action_orientation))\n\nnfc_ivi <- as.data.frame(nfc_ivi)\nprint(nfc_ivi)##          nfc_ivi\n## nfc01 0.37297915\n## nfc02 0.21153487\n## nfc03 0.19981987\n## nfc04 0.14540417\n## nfc05 0.06209198\n## nfc06 0.20228579\n## nfc07 0.26048244\n## nfc08 0.25950684\n## nfc09 0.25584111\n## nfc10 0.44981819\n## nfc11 0.27994998\n## nfc12 0.24413937\n## nfc13 0.29590845\n## nfc14 0.29309729\n## nfc15 0.03979380\n## nfc16 0.10474004"},{"path":"klasik-test-teorisi.html","id":"madde-analizi-1","chapter":"Bölüm 16 Klasik Test Teorisi","heading":"16.5 Madde Analizi","text":"Kullanılacak veri seti, 651 üniversite öğrencisinin Homeostasis Concept Inventory (HCI) çoktan seçmeli testine verdiği yanıtlardan oluşmaktadır. Bu veri kümesi orijinal olarak ShinyItemAnalysis paketinden yer almaktadır (bkz. ?ShinyItemAnalysis??HCItest ). Veriitem1 item20: Answers multiple-choice items (, B, C, D, E)item1 item20: Answers multiple-choice items (, B, C, D, E)gender: “F” female “M” malegender: “F” female “M” maleeng_first_lang: “yes” English student’s first language, otherwise “”eng_first_lang: “yes” English student’s first language, otherwise “”study_year: student’s year study universitystudy_year: student’s year study universitymajor: öğrenci yaşam bilimlerinde ana dal yapmayı planlıyorsa 1, aksi takdirde 0major: öğrenci yaşam bilimlerinde ana dal yapmayı planlıyorsa 1, aksi takdirde 0","code":"\nhci <- read.csv(\"import/hci.csv\", header = TRUE)\nhead(hci)\nstr(hci)## 'data.frame':    651 obs. of  24 variables:\n##  $ item1         : chr  \"D\" \"D\" \"D\" \"D\" ...\n##  $ item2         : chr  \"B\" \"B\" \"B\" \"B\" ...\n##  $ item3         : chr  \"A\" \"A\" \"A\" \"A\" ...\n##  $ item4         : chr  \"D\" \"D\" \"D\" \"D\" ...\n##  $ item5         : chr  \"B\" \"B\" \"C\" \"B\" ...\n##  $ item6         : chr  \"B\" \"C\" \"C\" \"C\" ...\n##  $ item7         : chr  \"B\" \"B\" \"B\" \"C\" ...\n##  $ item8         : chr  \"C\" \"C\" \"C\" \"C\" ...\n##  $ item9         : chr  \"D\" \"D\" \"D\" \"D\" ...\n##  $ item10        : chr  \"A\" \"A\" \"A\" \"A\" ...\n##  $ item11        : chr  \"A\" \"A\" \"A\" \"A\" ...\n##  $ item12        : chr  \"D\" \"D\" \"D\" \"D\" ...\n##  $ item13        : chr  \"A\" \"A\" \"A\" \"A\" ...\n##  $ item14        : chr  \"A\" \"A\" \"A\" \"A\" ...\n##  $ item15        : chr  \"D\" \"C\" \"A\" \"C\" ...\n##  $ item16        : chr  \"A\" \"A\" \"A\" \"A\" ...\n##  $ item17        : chr  \"D\" \"C\" \"C\" \"C\" ...\n##  $ item18        : chr  \"C\" \"C\" \"C\" \"C\" ...\n##  $ item19        : chr  \"C\" \"C\" \"C\" \"C\" ...\n##  $ item20        : chr  \"D\" \"D\" \"D\" \"D\" ...\n##  $ gender        : chr  \"F\" \"F\" \"M\" \"M\" ...\n##  $ eng_first_lang: chr  \"yes\" \"yes\" \"yes\" \"yes\" ...\n##  $ study_year    : int  4 4 4 4 4 4 4 4 4 3 ...\n##  $ major         : int  1 1 1 1 1 1 1 1 1 1 ...\nDataExplorer::plot_bar(data = hci, nrow = 6, ncol = 4)\nDataExplorer::plot_histogram(data = hci[, c(\"study_year\")])\nkey <- read.csv(\"import/hci_key.csv\", header = TRUE)"},{"path":"klasik-test-teorisi.html","id":"çeldirici-analiz","chapter":"Bölüm 16 Klasik Test Teorisi","heading":"16.6 Çeldirici Analiz","text":"Bir çeldirici aşağıdaki gibi çeşitli nedenlerden dolayı iyi çalışmayabilir: çoğunlukla yeterli içerik bilgisine sahip öğrencilerin çeldiriciyi seçmesi neredeyse hiçbir öğrenci çeldiriciyi seçmemesi çoğu öğrenci (yeterli içerik bilgisine sahip olanlar da dahil) doğru seçenek yerine çeldiriciyi seçmesiPuanlama","code":"\nhci_items <- dplyr::select(hci, \n                           starts_with(\"item\")) \nhead(hci_items)\nceldirici <- CTT::distractorAnalysis(items = hci_items, key = key)\nceldirici$item1 %>% kbl(digits = 2)\nkey3 <- as.vector(key$key)\nShinyItemAnalysis::plotDistractorAnalysis(Data = hci_items,       key = key3,\n      num.groups = 3, \n      item = 1)## $item1\nhci_scored <- CTT::score(items = hci_items,\n     key = key3, \n     output.scored = TRUE, \n    rel = TRUE) ## You will find additional options and better formatting using itemAnalysis().\nstr(hci_scored)## List of 3\n##  $ score      : Named num [1:651] 16 19 17 20 19 20 20 14 18 17 ...\n##   ..- attr(*, \"names\")= chr [1:651] \"P1\" \"P2\" \"P3\" \"P4\" ...\n##  $ reliability:List of 9\n##   ..$ nItem         : int 20\n##   ..$ nPerson       : int 651\n##   ..$ alpha         : num 0.715\n##   ..$ scaleMean     : num 12.2\n##   ..$ scaleSD       : num 3.64\n##   ..$ alphaIfDeleted: num [1:20(1d)] 0.704 0.71 0.701 0.715 0.705 ...\n##   ..$ pBis          : num [1:20(1d)] 0.288 0.221 0.35 0.173 0.277 ...\n##   ..$ bis           : num [1:20(1d)] 0.37 0.295 0.525 0.218 0.344 ...\n##   ..$ itemMean      : Named num [1:20] 0.699 0.753 0.848 0.404 0.442 ...\n##   .. ..- attr(*, \"names\")= chr [1:20] \"item1\" \"item2\" \"item3\" \"item4\" ...\n##   ..- attr(*, \"class\")= chr \"reliability\"\n##  $ scored     : num [1:651, 1:20] 1 1 1 1 1 1 1 0 1 1 ...\n##   ..- attr(*, \"dimnames\")=List of 2\n##   .. ..$ : NULL\n##   .. ..$ : chr [1:20] \"item1\" \"item2\" \"item3\" \"item4\" ...\nscores <- hci_scored$score\nsummary(scores)\nhist(x = scores, \n     xlab = \"Toplam Puan\", \n     main = \"Toplam Puan Dağılımı\", \n     col = \"lightblue\", \n     breaks = 15, \n     xlim = c(0, 20)) \nabline(v = mean(scores), col = \"red\", lwd = 2, lty = 2)##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##    3.00   10.00   12.00   12.21   15.00   20.00\nhci_scored$reliability## \n##  Number of Items \n##  20 \n## \n##  Number of Examinees \n##  651 \n## \n##  Coefficient Alpha \n##  0.715"},{"path":"klasik-test-teorisi.html","id":"puanlama--dönüşüm","chapter":"Bölüm 16 Klasik Test Teorisi","heading":"16.7 Puanlama -Dönüşüm","text":"Toplam puanları (20 üzerinden) 50 ortalama ve 10 standart sapmaya sahip olacak şekilde yeniden ölçeklendirmek istediğimizi varsayalım (tıpkı T puanları gibi). Bu tür bir dönüşümü gerçekleştirmek için CTT paketindeki score.transform() kullanabilirizMadde analizleri İlk olarak, psych paketinden tetrachoric() fonksiyonunu kullanarak maddeler arasındaki korelasyonları kontrol edilir ve ardından ggcorrplot() kullanarak korelasyonları görselleştireceğiz.Korelasyon matrisi grafiği, veri kümesinde 7. ve 17. maddeler gibi birkaç sorunlu madde olduğunu göstermektedirGüncellenen madde analizi sonuçları,\nhci testinin iç tutarlılığının 0.73’e yükseldiğini göstermektedirHer ne kadar 4. ve 9. maddeler düşük nokta-çiftserili korelasyon gösterdikleri için işaretlenmiş olsalar da, çiftserili korelasyon değerleri çok düşük değildir.","code":"\nscores_scaled <- CTT::score.transform(scores = scores, \n                  mu.new = 50, \n                  sd.new = 15) \nhist(x = scores_scaled$new.scores,\n     xlab = \"Toplam Puan\", \n     main = \"Toplam Puan Dağılımı\",  \n     col = \"lightblue\", \n     xlim = c(0, 100))\n\nabline(v = mean(scores_scaled$new.scores), col = \"red\", lwd = 2, lty = 2)\ncormat_hci <- psych::tetrachoric(x = hci_scored$scored)$rho\nggcorrplot::ggcorrplot(corr = cormat_hci,\n                       type = \"lower\", \n                       show.diag = TRUE,\n                       lab = TRUE, \n                       lab_size = 3) \nhci_items_scored <- hci_scored$scored \nhci_itemanalysis <- CTT::itemAnalysis(items = hci_items_scored,\n                                      pBisFlag = .2, bisFlag = .2)\nhci_itemanalysis$itemReport %>% \n  kbl(digits = 2)\nhci_itemanalysis2 <- CTT::itemAnalysis(items =\n    hci_items_scored[, -c(7, 17)], \n      pBisFlag = .2, \n      bisFlag = .2)\nhci_itemanalysis2## \n##  Number of Items \n##  18 \n## \n##  Number of Examinees \n##  651 \n## \n##  Coefficient Alpha \n##  0.733\nhci_itemanalysis2$itemReport %>% \n  kbl(digits = 2)"},{"path":"klasik-test-teorisi.html","id":"ölçmenin-standart-hatası","chapter":"Bölüm 16 Klasik Test Teorisi","heading":"16.8 Ölçmenin Standart hatası","text":"Test düzeyinde önemli bir istatistik, aşağıdaki şekilde hesaplanabilen ölçmenin standart ölçüm hatasıdır (SEM):\\[SEM = σ (1 − r_{xx})\\]Burada test puanlarının standart sapması ve testin güvenilirliğidir. SEM ve güven aralıklarını hesaplamak için, madde verilerini girdi olarak alan ve toplam puan için SEM ve güven aralıklarını hesaplayan özel bir fonksiyon oluşturma","code":"\nsem.ctt <- function(x, ci.level = 0.95) {\n  require(\"CTT\")\n  rxx <- CTT::itemAnalysis(items = x)$alpha\n  scores <- rowSums(x, na.rm = TRUE)\n  sigma <- sd(scores, na.rm = TRUE)\n  sem <- sigma*sqrt((1-rxx))\n  z <- qnorm(1-(1-ci.level)/2)\n  output <- data.frame(lower_CI = scores - (sem*z),\n                       observed = scores,\n                       upper_CI = scores + (sem*z))\n  return(output)\n}\n\nsem_hci <- sem.ctt(x = hci_items_scored, ci.level = 0.95)\nhead(sem_hci)"},{"path":"klasik-test-teorisi.html","id":"dif","chapter":"Bölüm 16 Klasik Test Teorisi","heading":"16.9 DIF","text":"DIF madde düzeyindeki yanlılığı tespit etmek için kullanılır. difR paketi (Magis et al., 2010) , DIF gösteren iki kategorili maddeleri tespit etmek için çeşitli yöntemler sağlar.Aşağıdaki örnekte, puanlanan hci maddelerini DIF açısından analiz etmek için Mantel-Haenszel (MH) ve lojistik regresyon yöntemlerini kullanacağız.Cinsiyet veya ana dil olarak İngilizce konuşulmasına bağlı olarak DIF sergileyen hci maddelerini belirlemek için grup değişkenleri olarak “sex” ve “eng_first_lang” kullanacağız.Çıktı iki bölümden oluşmaktadır.İlk bölümde maddeler için MH ki-kare istatistikleri ve bunlara karşılık gelen p değerleri gösterilmektedir.İki maddenin (madde 1 ve 19) p değerleri .05’ten küçük olduğu için kız ve erkek öğrenciler arasında DIF gösterdiği gerekçesiyle * ile işaretlendiğini görüyoruz. Bu maddeler ayrıca “DIF maddesi olarak tespit edilen maddeler” altında listelenmiştir.Çıktının ikinci kısmı, ETS delta sınıflandırması kullanılarak etki büyüklüğünü göstermektedir. İki madde (madde 1 ve 19) “B: Orta Derecede DIF” olarak sınıflandırılırken, geri kalan maddeler “: İhmal Edilebilir DIF” olarak sınıflandırılmıştır. “C: Büyük DIF” işaretine sahip hiçbir madde yoktur.Grafik ayrıca MH ki-kare testine göre işaretlenmiş iki maddeyi de göstermektedir. Bu maddeler eşik ki-kare değeri için yatay çizginin üzerinde görünmektedir ( anlamlılık düzeyi için ).Sonuçlar, üç maddenin (madde 3, 16 ve 18) dile dayalı DIF içerdiği için işaretlendiğini göstermektedir. ETS delta sınıflandırması kullanılarak elde edilen etki büyüklüğü, madde 3’ün “B: Orta DIF” olarak sınıflandırıldığını, madde 16 ve 18’ise “C: Büyük DIF” olarak sınıflandırıldığını göstermektedir. Bu maddelere ek olarak, 6. ve 20. maddeler “B: Orta DIF” olarak sınıflandırılmıştır.Dolayısıyla, bu maddelerin içeriğinin diğer işaretli maddelerle birlikte incelenmesi ve dile dayalı DIF’neden ortaya çıktığının belirlenmesi faydalı olacaktır.difMH() fonksiyonundan elde edilen çıktıya benzer şekilde,difLogistic()` fonksiyonundan elde edilen çıktı da iki bölümden oluşur. Çıktının üst kısmı, öğeler için olabilirlik oranı test istatistiklerini ve karşılık gelen p değerlerini gösterir.LR yöntemi, 1. ve 19. maddelere ek olarak, anlamlılık düzeyinde 12. ve 20. maddeler olmak üzere iki DIF’li madde daha tespit etmiştir. Çıktının ikinci kısmı, sözde R-kare farkları kullanılarak hesaplanan etki büyüklüklerini göstermektedir. Sonuçlar, iki etki büyüklüğü ölçütüne (ZT ve JG) dayalı olarak tüm maddeler için etki büyüklüğünün “: İhmal Edilebilir DIF” olduğunu göstermektedir. Grafikte, dört DIF maddesinin (madde 1, 12, 19 ve 20) eşik olabilirlik oranı istatistiği ( anlamlılık düzeyi için 5.9915) için yatay çizginin üzerinde olduğunu görüyoruz.Aynı fonksiyonu, olabilirlik oranı istatistiğine dayalı olarak işaretlenmiş maddeler için ayrı grafikler oluşturmak için de kullanılabilir. Çizim, x ekseninin toplam test puanları olduğu ve y ekseninin doğru cevap olasılığını (yani 0 üzerinden 1 plot(gender_LR) plot captured! α = .05 α = .05 plot() 1 alma) gösterdiği ayrı madde karakteristik eğrileri oluşturur. Bu grafik, DIF türünün tek tip mi yoksa tek tip olmayan mı olduğunu ve iki gruptan hangisinin (yani referans ve odak) diğer gruba göre avantajlı olduğunu gösterebilir. Aşağıdaki örnekte, 1. ve 19. maddeler için madde karakteristik eğrileri oluşturacağız.LR yöntemi, dil temelli DIF içeren altı madde tespit etmiştir: 1, 10, 13, 16, 18 ve 19. maddeler. Ancak bu maddelerin tümü, iki etki büyüklüğü ölçütüne (ZT ve JG) göre “: İhmal Edilebilir DIF” etki büyüklüğüne sahiptir. Son olarak, DIF içerdiği için işaretlenen maddelerden ikisine bir göz atalım. Şekillerde, 16. maddenin odak grup lehine tekdüze bir DIF’e sahip olduğunu, 10. maddenin ise tekdüze olmayan bir DIF’e sahip olduğunu görebiliriz (yani hangi grubun tercih edildiği testteki toplam puana bağlıdır)","code":"\nhci_scored <- read.csv(\"import/hci_scored.csv\", header = TRUE)\nhead(hci_scored)\ntable(hci_scored$gender)\ntable(hci_scored$eng_first_lang)## \n##   F   M \n## 405 246 \n## \n##  no yes \n## 143 508\nhci_items <- dplyr::select(hci_scored, starts_with(\"item\"))\ngender <- hci_scored$gender\nlanguage <- hci_scored$eng_first_lang\ngender_MH <- difR::difMH(Data = hci_items,\n                         group = gender,\n                         focal.name = \"F\",\n                         match = \"score\",\n                         purify = TRUE)\nprint(gender_MH)## \n## Detection of Differential Item Functioning using Mantel-Haenszel method \n## with continuity correction and with item purification\n## \n## Results based on asymptotic inference \n##  \n## Convergence reached after 2 iterations\n## \n## Matching variable: test score \n##  \n## No set of anchor items was provided \n##  \n## No p-value adjustment for multiple comparisons \n##  \n## Mantel-Haenszel Chi-square statistic: \n##  \n##        Stat.  P-value  \n## item1  5.1837 0.0228  *\n## item2  0.1790 0.6722   \n## item3  0.0524 0.8189   \n## item4  3.0679 0.0799  .\n## item5  0.4067 0.5237   \n## item6  1.3774 0.2405   \n## item7  0.2183 0.6403   \n## item8  0.2457 0.6201   \n## item9  1.6002 0.2059   \n## item10 0.3804 0.5374   \n## item11 0.0826 0.7738   \n## item12 3.4527 0.0631  .\n## item13 0.0000 0.9948   \n## item14 0.0000 0.9986   \n## item15 0.2856 0.5931   \n## item16 0.6194 0.4313   \n## item17 0.0035 0.9529   \n## item18 0.0081 0.9283   \n## item19 5.1109 0.0238  *\n## item20 0.0161 0.8990   \n## \n## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1  \n## \n## Detection threshold: 3.8415 (significance level: 0.05)\n## \n## Items detected as DIF items: \n##        \n##  item1 \n##  item19\n## \n##  \n## Effect size (ETS Delta scale): \n##  \n## Effect size code: \n##  'A': negligible effect \n##  'B': moderate effect \n##  'C': large effect \n##  \n##        alphaMH deltaMH  \n## item1   0.6308  1.0827 B\n## item2   1.1173 -0.2606 A\n## item3   0.9044  0.2361 A\n## item4   0.7122  0.7975 A\n## item5   1.1387 -0.3053 A\n## item6   1.2749 -0.5708 A\n## item7   1.1015 -0.2272 A\n## item8   1.1325 -0.2924 A\n## item9   1.2767 -0.5741 A\n## item10  1.1484 -0.3252 A\n## item11  0.9152  0.2082 A\n## item12  0.6904  0.8706 A\n## item13  1.0213 -0.0496 A\n## item14  0.9757  0.0578 A\n## item15  0.8905  0.2725 A\n## item16  0.8404  0.4087 A\n## item17  1.0064 -0.0149 A\n## item18  0.9906  0.0223 A\n## item19  0.5729  1.3091 B\n## item20  1.0515 -0.1181 A\n## \n## Effect size codes: 0 'A' 1.0 'B' 1.5 'C' \n##  (for absolute values of 'deltaMH') \n##  \n## Output was not captured!\nplot(gender_MH)## The plot was not captured!\nlang_MH <- difR::difMH(Data = hci_items,\n                       group = language,\n                       focal.name = \"no\",\n                       match = \"score\",\n                       purify = TRUE)\nprint(lang_MH)\nplot(lang_MH)## \n## Detection of Differential Item Functioning using Mantel-Haenszel method \n## with continuity correction and with item purification\n## \n## Results based on asymptotic inference \n##  \n## Convergence reached after 2 iterations\n## \n## Matching variable: test score \n##  \n## No set of anchor items was provided \n##  \n## No p-value adjustment for multiple comparisons \n##  \n## Mantel-Haenszel Chi-square statistic: \n##  \n##        Stat.  P-value   \n## item1  1.5933 0.2069    \n## item2  1.6164 0.2036    \n## item3  4.3557 0.0369  * \n## item4  0.0003 0.9870    \n## item5  0.3458 0.5565    \n## item6  2.8791 0.0897  . \n## item7  0.0841 0.7718    \n## item8  0.0191 0.8900    \n## item9  0.0410 0.8396    \n## item10 2.0092 0.1563    \n## item11 0.0039 0.9499    \n## item12 0.0091 0.9241    \n## item13 0.2976 0.5854    \n## item14 0.4777 0.4895    \n## item15 0.0000 0.9980    \n## item16 7.9690 0.0048  **\n## item17 0.2822 0.5953    \n## item18 8.4877 0.0036  **\n## item19 1.1926 0.2748    \n## item20 3.2762 0.0703  . \n## \n## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1  \n## \n## Detection threshold: 3.8415 (significance level: 0.05)\n## \n## Items detected as DIF items: \n##        \n##  item3 \n##  item16\n##  item18\n## \n##  \n## Effect size (ETS Delta scale): \n##  \n## Effect size code: \n##  'A': negligible effect \n##  'B': moderate effect \n##  'C': large effect \n##  \n##        alphaMH deltaMH  \n## item1   0.7214  0.7676 A\n## item2   1.3642 -0.7298 A\n## item3   1.8628 -1.4619 B\n## item4   1.0290 -0.0671 A\n## item5   1.1615 -0.3518 A\n## item6   0.6357  1.0647 B\n## item7   1.0840 -0.1895 A\n## item8   0.9476  0.1264 A\n## item9   1.0698 -0.1585 A\n## item10  0.7198  0.7728 A\n## item11  1.0441 -0.1014 A\n## item12  1.0030 -0.0070 A\n## item13  1.1516 -0.3317 A\n## item14  1.2147 -0.4570 A\n## item15  1.0260 -0.0603 A\n## item16  0.5058  1.6018 C\n## item17  0.8636  0.3447 A\n## item18  0.4185  2.0468 C\n## item19  0.7499  0.6764 A\n## item20  1.5553 -1.0380 B\n## \n## Effect size codes: 0 'A' 1.0 'B' 1.5 'C' \n##  (for absolute values of 'deltaMH') \n##  \n## Output was not captured! \n## The plot was not captured!\ngender_LR <- difR::difLogistic(Data = hci_items,\n                               group = gender,\n                               focal.name = \"F\",\n                               match = \"score\",\n                               type = \"both\",\n                               purify = TRUE)\nprint(gender_LR)## \n## Detection of both types of Differential Item Functioning\n## using Logistic regression method, with item purification\n## and with LRT DIF statistic\n## \n## Convergence reached after 1 iteration\n## \n## Matching variable: test score \n##  \n## No set of anchor items was provided \n##  \n## No p-value adjustment for multiple comparisons \n##  \n## Logistic regression DIF statistic: \n##  \n##        Stat.   P-value   \n## item1   7.9458  0.0188 * \n## item2   0.0069  0.9966   \n## item3   0.7535  0.6861   \n## item4   5.5434  0.0626 . \n## item5   0.2458  0.8844   \n## item6   1.8683  0.3929   \n## item7   0.2159  0.8977   \n## item8   1.2364  0.5389   \n## item9   4.0294  0.1334   \n## item10  2.2201  0.3295   \n## item11  4.7836  0.0915 . \n## item12  6.7575  0.0341 * \n## item13  1.9140  0.3840   \n## item14  0.0040  0.9980   \n## item15  0.8848  0.6425   \n## item16  1.2484  0.5357   \n## item17  0.3616  0.8346   \n## item18  0.6338  0.7284   \n## item19 11.3500  0.0034 **\n## item20  6.2415  0.0441 * \n## \n## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1  \n## \n## Detection threshold: 5.9915 (significance level: 0.05)\n## \n## Items detected as DIF items:\n##        \n##  item1 \n##  item12\n##  item19\n##  item20\n## \n##  \n## Effect size (Nagelkerke's R^2): \n##  \n## Effect size code: \n##  'A': negligible effect \n##  'B': moderate effect \n##  'C': large effect \n##  \n##        R^2    ZT JG\n## item1  0.0144 A  A \n## item2  0.0000 A  A \n## item3  0.0016 A  A \n## item4  0.0102 A  A \n## item5  0.0004 A  A \n## item6  0.0031 A  A \n## item7  0.0004 A  A \n## item8  0.0022 A  A \n## item9  0.0073 A  A \n## item10 0.0040 A  A \n## item11 0.0095 A  A \n## item12 0.0112 A  A \n## item13 0.0030 A  A \n## item14 0.0000 A  A \n## item15 0.0015 A  A \n## item16 0.0020 A  A \n## item17 0.0008 A  A \n## item18 0.0011 A  A \n## item19 0.0209 A  A \n## item20 0.0109 A  A \n## \n## Effect size codes: \n##  Zumbo & Thomas (ZT): 0 'A' 0.13 'B' 0.26 'C' 1 \n##  Jodoin & Gierl (JG): 0 'A' 0.035 'B' 0.07 'C' 1 \n## \n##  Output was not captured!\nplot(gender_LR)## The plot was not captured!\nplot(gender_LR, item = 1, plot = \"itemCurve\")## The plot was not captured!\nplot(gender_LR, item = 19, plot = \"itemCurve\")## The plot was not captured!\nlang_LR <- difR::difLogistic(Data = hci_items,\n                             group = language,\n                             focal.name = \"no\",\n                             match = \"score\",\n                             type = \"both\",\n                             purify = TRUE)\n\nprint(lang_LR)\n\nplot(lang_LR)## \n## Detection of both types of Differential Item Functioning\n## using Logistic regression method, with item purification\n## and with LRT DIF statistic\n## \n## Convergence reached after 4 iterations\n## \n## Matching variable: test score \n##  \n## No set of anchor items was provided \n##  \n## No p-value adjustment for multiple comparisons \n##  \n## Logistic regression DIF statistic: \n##  \n##        Stat.   P-value    \n## item1   6.8336  0.0328 *  \n## item2   1.3503  0.5091    \n## item3   3.0770  0.2147    \n## item4   0.9306  0.6279    \n## item5   2.2886  0.3184    \n## item6   4.7808  0.0916 .  \n## item7   3.5067  0.1732    \n## item8   0.7884  0.6742    \n## item9   5.3922  0.0675 .  \n## item10  7.5287  0.0232 *  \n## item11  0.0262  0.9870    \n## item12  0.8611  0.6501    \n## item13  7.1926  0.0274 *  \n## item14  0.6589  0.7193    \n## item15  0.0142  0.9929    \n## item16 14.0757  0.0009 ***\n## item17  2.3535  0.3083    \n## item18 13.1093  0.0014 ** \n## item19  8.1858  0.0167 *  \n## item20  2.1369  0.3435    \n## \n## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1  \n## \n## Detection threshold: 5.9915 (significance level: 0.05)\n## \n## Items detected as DIF items:\n##        \n##  item1 \n##  item10\n##  item13\n##  item16\n##  item18\n##  item19\n## \n##  \n## Effect size (Nagelkerke's R^2): \n##  \n## Effect size code: \n##  'A': negligible effect \n##  'B': moderate effect \n##  'C': large effect \n##  \n##        R^2    ZT JG\n## item1  0.0121 A  A \n## item2  0.0027 A  A \n## item3  0.0067 A  A \n## item4  0.0016 A  A \n## item5  0.0039 A  A \n## item6  0.0079 A  A \n## item7  0.0065 A  A \n## item8  0.0014 A  A \n## item9  0.0094 A  A \n## item10 0.0134 A  A \n## item11 0.0001 A  A \n## item12 0.0014 A  A \n## item13 0.0115 A  A \n## item14 0.0012 A  A \n## item15 0.0000 A  A \n## item16 0.0219 A  A \n## item17 0.0049 A  A \n## item18 0.0243 A  A \n## item19 0.0152 A  A \n## item20 0.0037 A  A \n## \n## Effect size codes: \n##  Zumbo & Thomas (ZT): 0 'A' 0.13 'B' 0.26 'C' 1 \n##  Jodoin & Gierl (JG): 0 'A' 0.035 'B' 0.07 'C' 1 \n## \n##  Output was not captured! \n## The plot was not captured!\nplot(lang_LR, item = 10, plot = \"itemCurve\")\nplot(lang_LR, item = 16, plot = \"itemCurve\")## The plot was not captured!\n## The plot was not captured!"},{"path":"klasik-test-teorisi.html","id":"kaynaklar-6","chapter":"Bölüm 16 Klasik Test Teorisi","heading":"16.10 Kaynaklar","text":"Cacioppo, John T, Richard E Petty. (1982). Need Cognition. Journal Personality Social Psychology 42(1), 116.Chiesi, Francesca, Kinga Morsanyi, Maria Anna Donati, Caterina Primi. (2018). Applying Item Response Theory Develop Shortened Version Need Cognition Scale. Advances Cognitive Psychology 14(3), 75.Grass, Julia, Florian Krieger, Philipp Paulus, Samuel Greiff, Anja Strobel, Alexander Strobel. (2019). Thinking Action: Need Cognition Predicts SelfControl Together Action Orientation. PLOS ONE 14(8): 1–20.","code":""},{"path":"mtk.html","id":"mtk","chapter":"Bölüm 17 MTK","heading":"Bölüm 17 MTK","text":"Klasik gerçek puan modelinde birey özellikleri ile test özelliklerini birbirinden ayırmak güçtür, biri diğerinin bağlamında yorumlanır.Psikometride ilgilenilen birey özelliği testle ölçülen yetenektir.KTK çerçevesinde yetenek kavramı gerçek puanla ifade edilir ve gerçek puan testte gözlenen performansın beklenen değeri olarak tanımlanır.KTK çerçevesinde bir bireyin yeteneği sadece belli bir teste göre tanımlanır. Bireylerin yeteneği test maddelerinin zor veya kolay olmasına bağlıdır.Test zor bir testse, birey düşük yeteneğe sahip gibi görünecektir, test kolay bir testse, birey daha yüksek yeteneğe sahip gibi görünecektir.KTK çerçevesinde bir test maddesinin güçlüğü testi alan bir birey grubunda maddeyi doğru yanıtlayan birey oranıdır.Bir maddenin kolay veya zor olması ölçülen bir grup bireyin yeteneğine bağlıdır.Klasik test kuramı çerçevesinde madde ve test güçlüğünün yanı sıra madde ayırt ediciliği ve test puanlarının güvenirliği de belli bir grup bireye göre tanımlanır.Birey özellikleri test bağlamı değiştikçe değişir, madde ve test özellikleri de birey bağlamı değiştikçe değişir.Bu nedenle farklı testleri alan bireylerin ve özellikleri farklı birey grubundan elde edilen maddelerin karşılaştırılması oldukça zordur.Teste bağlı birey puanları, farklı testleri alan bireyleri karşılaştırırken, sınırlı kullanıma sahiptir.Gruba bağlı madde indeksleri, madde indekslerinin elde edildiği birey grubundan farklı birey grupları için testler geliştirirken, sınırlı kullanıma sahiptir.KTK çerçevesinde ele alınan güvenirlik tanımı ve kavramsal olarak güvenirlik kavramının zıttı olarak düşünülen ölçmenin standart hatası kavramı belli problemleri beraberinde getirmektedir.KTK çerçevesinde güvenirlik kavramı bir testin paralel (eşdeğer) formlarından elde edilen puanlar arasındaki korelasyon olarak tanımlanır. Uygulamada paralel test tanımını sağlamak oldukça zor, hatta imkansızdır.Güvenirliğin alt sınır kestirimlerini sağlayan veya bilinmeyen yanlılıklara sahip güvenirlik kestirimleri veren çeşitli güvenirlik katsayıları bulunmaktadır.Test puanlarının güvenirliğinin ve varyansının bir fonksiyonu olan ölçmenin standart hatasının testi alan bütün bireyler için aynı olduğu varsayılır. Ancak farklı yeteneklerdeki bireyler için elde edilen test puanları farklı miktarlarda hatalar içermektedir.KTK madde odaklı değil test odaklıdır. Klasik gerçek puan modeli bireylerin bir maddeyi nasıl yanıtladığını ele almaz.KTK bir bireyin veya bir grup bireyin belli bir test maddesinde nasıl bir performans göstereceği hakkında tahminlerde bulunulmasına izin vermez.Halbuki bir bireyin belli bir maddeyi doğru yanıtlama olasılığı gibi bir bilgi, belli birey grupları için belli özelliklerde testler tasarlarken önemlidir.Ayrıca KTK ile testlerin geliştirlmesinde, yanlı maddelerin belirlenmesi, uyarlamalı testlerin yapılandırılması, test puanlarının eşitlenmesi gibi birçok test geliştirme probleminde çok kesin çözümler sunmamaktadır.KTK sınırlılıklarından dolayı psikometrisyenler KTK'ya alternatif ölçme kuramlarının arayışı içine girmiştir. Alternatif bir ölçme kuramı aşağıdakileri içermelidir.\nGrup bağımlı olmayan madde istatistikleri\nTest bağımlı olmayan birey yeterliliğini tanımlayan puanlar\nGüvenirlik kestiriminde tamamen paralel testler gerektirmeyen bir model\nyetenek puanı için bir ölçme kesinliği sağlayan bir model\nTest düzeyinden ziyade madde düzeyinde kurulan bir model\nKTK sınırlılıklarından dolayı psikometrisyenler KTK'ya alternatif ölçme kuramlarının arayışı içine girmiştir. Alternatif bir ölçme kuramı aşağıdakileri içermelidir.Grup bağımlı olmayan madde istatistikleriTest bağımlı olmayan birey yeterliliğini tanımlayan puanlarGüvenirlik kestiriminde tamamen paralel testler gerektirmeyen bir modelHer yetenek puanı için bir ölçme kesinliği sağlayan bir modelTest düzeyinden ziyade madde düzeyinde kurulan bir modelBu özellikler madde tepki kuramı veya gizil özellik kuramı olarak bilinen alternatif ölçme kuramının çerçevesinde elde edilebilir.Bu özellikler madde tepki kuramı veya gizil özellik kuramı olarak bilinen alternatif ölçme kuramının çerçevesinde elde edilebilir.","code":""},{"path":"mtk.html","id":"madde-tepki-kuramı","chapter":"Bölüm 17 MTK","heading":"17.1 Madde Tepki Kuramı","text":"MTK'da veya gizil özellik kuramında bir testteki maddelere verilen yanıtların test maddelerinden daha az sayıdaki gizil özellikler tarafından açıklanacağı varsayılmaktadır.Kuramın çoğu uygulamasında bir testteki maddelere verilen yanıtların tek bir gizil özellik tarafından açıklanacağı varsayılır.MTK gizil özelliğin farklı düzeylerindeki bireylerin maddeyi nasıl yanıtlayacağını matematiksel olarak gösterir.Bu matematiksel model farklı testleri alan bireylerin performanslarının karşılaştırılmasına izin verir.Bu model madde analizinin madde analizlerinde kullanılan gruptan farklı yetenek düzeylerindeki gruplara uygulanmasına izin verir.MTK iki temel varsayıma dayanır.\nBir bireyin bir test maddesindeki performansı özellik(ler), gizil özellik(ler) veya yetenek(ler) olarak adlandırılan faktör(ler) tarafından yordanabilir (veya açıklanabilir). \nBireylerin madde performansı ve madde performansının altında yatan bir grup özellik arasındaki ilişki madde karakteristik fonksiyonu (MKF) veya madde karakteristik eğrisi (MKE) olarak adlandırılan ve monotonik olarak artan bir fonksiyonla tanımlanır.\nMTK iki temel varsayıma dayanır.Bir bireyin bir test maddesindeki performansı özellik(ler), gizil özellik(ler) veya yetenek(ler) olarak adlandırılan faktör(ler) tarafından yordanabilir (veya açıklanabilir). Bir bireyin bir test maddesindeki performansı özellik(ler), gizil özellik(ler) veya yetenek(ler) olarak adlandırılan faktör(ler) tarafından yordanabilir (veya açıklanabilir). Bireylerin madde performansı ve madde performansının altında yatan bir grup özellik arasındaki ilişki madde karakteristik fonksiyonu (MKF) veya madde karakteristik eğrisi (MKE) olarak adlandırılan ve monotonik olarak artan bir fonksiyonla tanımlanır.Bireylerin madde performansı ve madde performansının altında yatan bir grup özellik arasındaki ilişki madde karakteristik fonksiyonu (MKF) veya madde karakteristik eğrisi (MKE) olarak adlandırılan ve monotonik olarak artan bir fonksiyonla tanımlanır.","code":""},{"path":"mtk.html","id":"madde-karakteristik-eğrisi-mke","chapter":"Bölüm 17 MTK","heading":"17.2 Madde Karakteristik Eğrisi (MKE)","text":"MKE testteki bir maddeyi doğru yanıtlama olasılığını testteki maddelerdeki performansın altında yatan gizil özelliğin bir fonksiyonunu gösteren bir eğridir.MKE madde performansı altında yatan tek bir gizil özellik (yetenek) olduğu durumdaki madde karakteristik fonksiyonunu gösterir.Grup üyeliğinden bağımsız olarak, gizil özelliğin yüksek değerlerine sahip bireylerin maddeyi doğru yanıtlama olasılığı gizil özelliğin düşük değerlerine sahip bireylerin maddeyi doğru yanıtlama olasılığından daha yüksektir.","code":""},{"path":"mtk.html","id":"madde-tepki-kuramı-sayıltıları","chapter":"Bölüm 17 MTK","heading":"17.3 Madde Tepki Kuramı Sayıltıları","text":"MTK modelleri modelin uygulandığı veri hakkında bir takım sayıltılar gerektirir.Sayıltıların uygulanabilirliği doğrudan belirlenemez, ancak dolaylı bazı kanıtlar toplanabilir ve değerlendirilebilir. Ayrıca modelin veriye genel uyumu da değerlendirilebilir.Yaygın olarak kullanılan MTK modellerinin sayıltılarından biri testi oluşturan maddeler tarafından sadece bir yeteneğin ölçüldüğüdür. Bu sayıltı tek boyutluluk sayıltısı olarak adlandırılır.Tek boyutlulukla ilgili bir kavram yerel bağımsızlık kavramıdır.","code":""},{"path":"mtk.html","id":"tek-boyutluluk-ve-yerel-bağımsızlık","chapter":"Bölüm 17 MTK","heading":"17.4 Tek Boyutluluk ve Yerel Bağımsızlık","text":"KTK'da iki değişken arasındaki ilişkiden söz edilirken genellikle korelasyon kavramından yararlanılır.MTK'da iki değişken arasındaki ilişkiden bahsedilirken daha genel bir kavram olan istatistiksel bağımsızlık kavramından yaralanılır. İki tane iki kategorili madde için aşağıdaki dört eşitlik karşılanıyorsa istatistiksel bağımsızlıktan söz edilir:\\(P_i(+)\\) maddesini doğru yanıtlama olasılığı\\(P_i(-)\\) maddesini yanlış yanıtlama olasılığı\\(P_j(+)\\) j maddesini doğru yanıtlama olasılığı\\(Pj_(+)\\) j maddesini yanlış yanıtlama olasılığı\\(P(+,+) = P_i(+)P_j(+)\\)\n\\(P(+,-) = P_i(+)P_j(-)\\)\n\\(P(-,+) = P_i(-)P_j(+)\\)\n\\(P(-,-) = P_i(-)P_j(-)\\)Tek boyutluluk maddeler arasındaki istatistiksel bağımlılık terimiyle tanımlanır.Yerel bağımsızlık gizil özelliğe göre homojen olan herhangi bir alt evren için maddelerin istatistiksel bağımsız olması anlamına gelir.Tek boyutluluk ve yerel bağımlılık eşdeğer kavramlar değildir.Örneğin, testteki madde çiftleri için yerel bağımsız olacak şekilde iki gizil özellik bulunuyorsa, test iki boyutludur. Genel olarak bir testin boyutu yerel bağımsızlığı sağlamak için gerekli gizil özellik sayısına eşittir.","code":""},{"path":"mtk.html","id":"madde-tepki-kuramı-modelleri","chapter":"Bölüm 17 MTK","heading":"17.5 Madde Tepki Kuramı Modelleri","text":"Sonsuz sayıda MTK modeli tasarlamak mümkün olmakla birlikte, az sayıda model uygulamada kullanılmaktadır.En popüler tek boyutlu MTK modelleri arasındaki temel ayrım, maddeleri tanımlamak için kullanılan parametrelerin sayısındadır. En popüler üç tek boyutlu MTK modeli\nbir-parametreli lojistik (1-PL)\niki-parametreli lojistik (2-PL)\nüç-parametreli lojistik (3-PL) modellerdir.\nbir-parametreli lojistik (1-PL)bir-parametreli lojistik (1-PL)iki-parametreli lojistik (2-PL)iki-parametreli lojistik (2-PL)üç-parametreli lojistik (3-PL) modellerdir.üç-parametreli lojistik (3-PL) modellerdir.Bu modeller iki kategorili madde yanıt verisi için uygundur.","code":""},{"path":"mtk.html","id":"bir-parametreli-lojistik-1-pl-model","chapter":"Bölüm 17 MTK","heading":"17.6 Bir-Parametreli Lojistik (1-PL) Model","text":"1PL model yaygın olarak kullanılan MTK modellerindendir. 1PL model için madde karakteristik eğrileri aşağıdaki eşitlikle elde edilir:\\[P_i(\\theta) = \\frac{exp(\\theta-b_i)}{1+exp(\\theta-b_i)} = \\frac{1}{1+exp[-(\\theta-b_i)]}\\]\n\\[ln(\\frac{P_i(\\theta)}{1-P_i(\\theta)})=\\theta - b_{}\\]Burada,\\(P_i(θ)\\) : θ yetenek düzeyindeki bir bireyin maddesini doğru yanıtlama olasılığı\\(P_i(θ)\\) : θ yetenek düzeyindeki bir bireyin maddesini doğru yanıtlama olasılığı\\(b_i\\): maddesinin güçlük parametresi\\(b_i\\): maddesinin güçlük parametresiBir madde için \\(b_i\\) parametresi yetenek ölçeğinde maddeyi doğru yanıtlama olasılığının 0.5 olduğu noktadır.Bir madde için \\(b_i\\) parametresi yetenek ölçeğinde maddeyi doğru yanıtlama olasılığının 0.5 olduğu noktadır.Bu parametre yer parametresi olup yetenek ölçeğiyle ilişkili olarak madde karakteristik eğrisinin pozisyonunu belirtir.Bu parametre yer parametresi olup yetenek ölçeğiyle ilişkili olarak madde karakteristik eğrisinin pozisyonunu belirtir.\\(b_i\\) parametresinin daha büyük değerleri, bir bireyin maddeyi doğru yanıtlamak için %50 şansa sahip olması için daha büyük yetenek düzeyine sahip olmasını gerektirir. Diğer bir ifadeyle \\(b_i\\) parametresinin daha büyük değerleri, daha zor maddeyi ifade eder.Zor maddeler yetenek ölçeğinin sağında veya daha yüksek ucundadır.Kolay maddeler yetenek ölçeğinin solunda veya daha düşük ucundadır.Bir grubun yetenek düzeyleri ortalaması 0 ve standart sapması 1 olacak şekilde ölçeklendiğinde, \\(b_i\\) değerleri genel olarak -2.0 ile +2.0 arasında değişir.\\(b_i\\) değerleri -2.0’ye yakın olan maddeler bireyler için oldukça kolay,*\\(b_i\\) değerleri -2.0’ye yakın olan maddeler bireyler için oldukça kolay,*\\(b_i\\) değerleri +2.0’ye yakın olan maddeler bireyler için oldukça zor maddelerdir.\\(b_i\\) değerleri +2.0’ye yakın olan maddeler bireyler için oldukça zor maddelerdir.\\(b_i\\) yetenek düzeyiyle aynı ölçektedir.\\(b_i\\) yetenek düzeyiyle aynı ölçektedir.\\(b_i\\) ve \\(\\theta\\) düzeyi arasındaki fark logit ölçeğindedir. logit bir olasılık değerinin bir dönüşümüdür.\\(logit(p)= ln(\\frac{p}{1-p})\\)Örneğin\\(logit(0.01)=ln(\\frac{0.01}{0.99})=-4.595\\)\\(logit(0.01)=ln(\\frac{0.01}{0.99})=-4.595\\)\\(logit(0.1)=ln(\\frac{0.1}{0.9})=-2.197\\)\\(logit(0.1)=ln(\\frac{0.1}{0.9})=-2.197\\)\\(logit(0.6)=ln(\\frac{0.6}{0.4})=0.405\\)\\(logit(0.6)=ln(\\frac{0.6}{0.4})=0.405\\)\\(logit(0.99)=ln(\\frac{0.99}{0.01})=4.595\\)\\(logit(0.99)=ln(\\frac{0.99}{0.01})=4.595\\)\\(logit(0.9)=ln(\\frac{0.9}{0.1})=2.197\\)\\(logit(0.9)=ln(\\frac{0.9}{0.1})=2.197\\)\\(logit(0.4)=ln(\\frac{0.4}{0.6})=-0.405\\)\\(logit(0.4)=ln(\\frac{0.4}{0.6})=-0.405\\)\\(logit(0.5)=ln(\\frac{0.5}{0.5})=0\\)Olasılık değerleri tek biçimli (uniformly) dağıldıysa,\nlogit değerlerinin dağılımı standart normal dağılıma oldukça yakındır.50000 tek biçimli değişkenlogit değerleri","code":"\nlog(0.5/0.5)\n\nlog(0.1/0.9)\n\nlog(0.9/0.1)## [1] 0\n## [1] -2.197225\n## [1] 2.197225\ntekbicimli <- runif(5000,0,1)\nlogs <- log(tekbicimli/(1-tekbicimli))\nhist(tekbicimli)\nhist(logs)"},{"path":"mtk.html","id":"pl---mke","chapter":"Bölüm 17 MTK","heading":"17.7 1PL - MKE","text":"Elimizde 1PL modelde uygun dört maddelik bir testte yer alan madde parametreleri bulunsun.Madde 1 için \\(b_1 =  1.0\\)Madde 1 için \\(b_1 =  1.0\\)Madde 2 için \\(b_2 =  2.0\\)Madde 2 için \\(b_2 =  2.0\\)Madde 3 için \\(b_3 = -1.0\\)Madde 3 için \\(b_3 = -1.0\\)Madde 4 için \\(b_4 =  0.0\\)Madde 4 için \\(b_4 =  0.0\\)\\[P_i(\\theta) = \\frac{1}{1+exp[-(\\theta-b_i)]}\\]Eğriler yetenek ölçeğinde sadece yerleri bakımından farklılık gösterir.1-PL modelinde birey performansını etkileyen tek madde özelliği madde güçlüğüdür. 1-PL modelinde KTK madde ayırt edicilik indeksine karşılık gelen bir madde parametresi yoktur.Bu bütün maddelerin eşit ayırt ediciliğe sahip olduğunu varsaymaya eşdeğerdir.1-PL modelinde madde karakteristik eğrilerinin alt asimptotu sıfırdır.Bu çok düşük yetenek düzeyine sahip bireylerin maddeyi doğru yanıtlama olasılığının sıfır olduğunu belirtir.Bu çok düşük yetenek düzeyine sahip bireylerin maddeyi doğru yanıtlama olasılığının sıfır olduğunu belirtir.Böylece çoktan seçmeli maddelerde düşük yetenek düzeyine sahip bireylerin tahmin olasılığına izin verilmez. Tahmin olmaması sayıltısı çoktan-seçmeli maddeleri içeren bir testin çok kolay olduğu durumlarda karşılanabilir.Böylece çoktan seçmeli maddelerde düşük yetenek düzeyine sahip bireylerin tahmin olasılığına izin verilmez. Tahmin olmaması sayıltısı çoktan-seçmeli maddeleri içeren bir testin çok kolay olduğu durumlarda karşılanabilir.","code":""},{"path":"mtk.html","id":"iki-parametreli-lojistik-2-pl-model","chapter":"Bölüm 17 MTK","heading":"17.8 İki-Parametreli Lojistik (2-PL) Model","text":"2-PL model yaygın olarak kullanılan MTK modellerindendir.2-PL model için madde karakteristik eğrileri aşağıdaki eşitlikle elde edilir:\\[P_i(\\theta) = \\frac{exp[a_i(\\theta-b_i)]}{1+exp[a_i(\\theta-b_i)]}=\\frac{1}{1+exp(-[a_i(\\theta-b_i)])}\\]\\[ln(\\frac{P_i(\\theta)}{1-P_i(\\theta)})=a_i(\\theta - b_{})\\]Burada,\\(P_i(\\theta)\\): θ yetenek düzeyindeki bir bireyin maddesini doğru yanıtlama olasılığı\\(P_i(\\theta)\\): θ yetenek düzeyindeki bir bireyin maddesini doğru yanıtlama olasılığı\\(b_i\\): maddesinin güçlük parametresi\\(b_i\\): maddesinin güçlük parametresi\\(a_i\\): maddesinin ayırt edicilik parametresi\\(a_i\\): maddesinin ayırt edicilik parametresiÇoğu durumda ai(θ - bi), D = 1.7 normalleştirme sabitiyle çarpılır.Çoğu durumda ai(θ - bi), D = 1.7 normalleştirme sabitiyle çarpılır.Tarihsel olarak MTK modeli kümülatif normal model (normal ogive model) olarak geliştirilmiştir. Ancak zamanla kümülatif normal model yerine, matematiksel olarak daha kolay ele alındığından, kümülatif lojistik model kullanılmaya başlamıştır.Eğer \\(a_i(θ - b_i)\\) 1.7 normalleştirme sabitiyle çarpılırsa, iki model arasındaki fark neredeyse ihmal edilir düzeyde olacaktır. Yetenek düzeyinin bütün değerleri için iki modelle elde edilen olasılık değerleri arasındaki fark 0.01’den küçük olacaktır.BILOG ve MULTILOG gibi özelleşmiş çoğu MTK yazılımı sadece lojistik modeli kullanır.D sabitinin kullanılıp kullanılmaması tercihe kalmıştır.Bir madde için \\(a_i\\) parametresi yetenek ölçeğinde \\(b_i\\) noktasında madde karakteristik eğrisinin eğimiyle orantılıdır.Daha dik eğimli maddeler farklı yetenek düzeylerindeki bireyleri ayırmada daha az eğimli maddelere göre daha kullanışlıdır.Bir maddenin bir θ yetenek düzeyinin yakınındaki bireyler arasındaki ayırt ediciliğiBir maddenin bir θ yetenek düzeyinin yakınındaki bireyler arasındaki ayırt ediciliği(θ düzeyine eşit veya daha düşük yetenek düzeyine sahip bireyleri θ düzeyinden yüksek yetenek düzeyine sahip bireylerden ayırma gücü)\nθ değerindeki madde karakteristik eğrisinin eğimiyle belirlenir.(θ düzeyine eşit veya daha düşük yetenek düzeyine sahip bireyleri θ düzeyinden yüksek yetenek düzeyine sahip bireylerden ayırma gücü)\nθ değerindeki madde karakteristik eğrisinin eğimiyle belirlenir.\\(a_i\\) değerleri kuramsal olarak (-∞, +∞) ölçeğindedir.\\(a_i\\) değerleri kuramsal olarak (-∞, +∞) ölçeğindedir.Başarı testlerinde eksi yönde ayırt ediciliğe sahip maddeler, testten çıkarılır.Başarı testlerinde eksi yönde ayırt ediciliğe sahip maddeler, testten çıkarılır.Çünkü yetenek düzeyi arttıkça maddenin doğru yanıtlanma olasılığının düşmesi maddeyle ilgili bir probleme (yanlış anahtarlama gibi) işaret eder.Çünkü yetenek düzeyi arttıkça maddenin doğru yanıtlanma olasılığının düşmesi maddeyle ilgili bir probleme (yanlış anahtarlama gibi) işaret eder.Ayrıca uygulamada genellikle 2.0’den büyük ayırt edicilik değerlerine rastlanmaz. Bu nedenle \\(a_i\\) parametresi için olağan aralık (0, 2)’dir.Ayrıca uygulamada genellikle 2.0’den büyük ayırt edicilik değerlerine rastlanmaz. Bu nedenle \\(a_i\\) parametresi için olağan aralık (0, 2)’dir.","code":""},{"path":"mtk.html","id":"pl---mke-1","chapter":"Bölüm 17 MTK","heading":"17.9 2PL - MKE","text":"Elimizde 2PL modelde uygun dört maddelik bir testte yer alan madde parametreleri bulunsun.Madde 1 için \\(b_1\\) = 1.0 ve \\(a_1\\) = 1.0Madde 1 için \\(b_1\\) = 1.0 ve \\(a_1\\) = 1.0Madde 2 için \\(b_2\\) = 2.0 ve \\(a_2\\) = 0.5Madde 2 için \\(b_2\\) = 2.0 ve \\(a_2\\) = 0.5Madde 3 için \\(b_3\\) = -1.0 ve \\(a_3\\) = 1.5Madde 3 için \\(b_3\\) = -1.0 ve \\(a_3\\) = 1.5Madde 4 için \\(b_4\\) = 0.0 ve \\(a_4\\) = 1.2Madde 4 için \\(b_4\\) = 0.0 ve \\(a_4\\) = 1.2Eğriler 1-PL modelinde olduğu gibi paralel değildir. eğrinin eğimi farklılık gösterir. Bu da madde ayırt edicilik parametrelerinin farklı olduğunu yansıtır.2-PL modelinde birey performansını etkileyen madde özellikleri madde güçlüğü ve madde ayırt ediciliğidir. 2-PL modelinde 1-PL modelinde olduğu gibi madde karakteristik eğrilerinin alt asimptotu sıfırdır. Bu çok düşük yetenek düzeyine sahip bireylerin maddeyi doğru yanıtlama olasılığının sıfır olduğunu belirtir. Böylece çoktan seçmeli maddelerde düşük yetenek düzeyine sahip bireylerin tahmin olasılığına izin verilmez.Tahmin olmaması sayıltısı çoktan-seçmeli maddeleri içeren bir testin çok zor olmadığı durumlarda karşılanabilir.","code":""},{"path":"mtk.html","id":"pl-model","chapter":"Bölüm 17 MTK","heading":"17.10 3-PL Model","text":"3-PL model için madde karakteristik eğrileri aşağıdaki eşitlikle elde edilir:\\[P_i(\\theta) = c_i + (1- ci)* \\frac{exp[a_i(\\theta-b_i)]}{1+exp[a_i(\\theta-b_i)]}=c_i +\\frac{1-c_i}{1+exp(-[a_i(\\theta-b_i)])}\\]\n\\(P_i(θ):\\) θ yetenek düzeyindeki bir bireyin maddesini doğru yanıtlama olasılığı\\(b_i\\) : maddesinin güçlük parametresi\\(b_i\\) : maddesinin güçlük parametresi\\(a_i\\) : maddesinin ayırt edicilik parametresi\\(a_i\\) : maddesinin ayırt edicilik parametresi\\(c_i\\) : maddesinin sahte-tahmin parametresi\\(c_i\\) : maddesinin sahte-tahmin parametresiTahmin yerine sahte-tahmin denmesinin nedeni, parametrenin tahminden fazlasını içermesidir. Örneğin, madde yazarları çekici ancak yanlış seçenekler geliştirebilir.Seçmeli-yanıtlı (çoktan-seçmeli gibi) maddeler gibi tahmin yoluyla doğru yanıtlara izin veren madde formatlarından elde edilen verilere 1-PL ve 2-PL modellerin uygulanmasında problemle karşılaşılabilir.1-PL ve 2-PL modellerinde maddeyi doğru yanıtlama olasılığı yetenek düzeyi düştükçe sıfıra yaklaşır. Ancak çok düşük yetenek düzeyindeki bireyler için bile maddeyi doğru yanıtlama olasılığı, bireyler doğru yanıtı tahmin edebileceklerinden sıfırdan büyüktür. 3-PL modelinde yer alan \\(c_i\\) parametresi, seçmeli-yanıtlı test maddelerindeki performansta tahminin bir etken olduğu durumlarda, yetenek ölçeğinin düşük ucundaki performansı hesaba katar.Sıfırdan farklı \\(c_i\\) parametresi, testi alan herhangi bir bireyin maddeyi doğru yanıtlama olasılığının sıfırdan farklı olduğunu yansıtır.Yetenek düzeyinin çok düşük değerleri için bile bireylerin en az %20’si maddeyi doğru yanıtlayacaktır.","code":""},{"path":"mtk.html","id":"pl---mke-2","chapter":"Bölüm 17 MTK","heading":"17.11 3-PL - MKE","text":"Elimizde 3PL modelde uygun altı maddelik bir testte yer alan madde parametreleri bulunsun.Madde 1 için \\(b_1\\) = 1.0 ve \\(a_1\\) = 1.8 ve \\(c_1\\) = 0Madde 2 için \\(b_2\\) = 1.0 ve \\(a_2\\) = 0.8 ve \\(c_2\\) = 0Madde 3 için \\(b_3\\) = 1.0 ve \\(a_3\\) = 1.8 ve \\(c_3\\) = 0.25Madde 4 için \\(b_4\\) = -1.5 ve \\(a_4\\) = 1.8 ve \\(c_4\\) = 0Madde 5 için \\(b_5\\) = -0.5 ve \\(a_5\\) = 1.2 ve \\(c_5\\) = 0.10Madde 6 için \\(b_6\\) = 0.5 ve \\(a_6\\) = 0.4 ve \\(c_6\\) = 0.15Madde 1 ve Madde 4 arasındaki karşılaştırma, b parametresinin MKE şeklindeki rolünü vurgulamaktadır.Madde 1 ve Madde 2 arasındaki karşılaştırma, parametresinin MKE dikliğindeki rolünü vurgulamaktadır.Madde 1 ve Madde 3 arasındaki karşılaştırma, c parametresinin MKE şeklindeki rolünü vurgulamaktadır.6 maddeden hangi madde θ = -1.0 değerinde en kolay maddedir?Yandaki 6 maddeden hangi madde θ = 0.0 değerinde en zor maddedir?Yandaki 6 maddeden hangi iki madde θ = -1.0 değerinde eşit güçlükteki maddelerdir?Yandaki 6 maddeden hangi madde θ = 3.0 değerinde en ayırt edici maddedir?","code":"## NULL## NULL"},{"path":"mtk.html","id":"madde-bilgi-fonksiyonu","chapter":"Bölüm 17 MTK","heading":"17.12 Madde Bilgi Fonksiyonu","text":"Teknik olarak, bilgi bir parametre kestiriminin standart hatasının tersiyle ilişkili bir değerdir.Yüksek bilgi değeri parametre kestirimi hakkında daha fazla bilgiye sahip olunduğunu belirtir.MTK'da bilgi birey yeteneğini kestirmek için kullanılan maddelerin toplamından elde edilen bilgiyi ifade eder.Bilginin miktarı yetenek değerine bağlıdır, bu nedenle test bilgi fonksiyonu olarak adlandırılır.Bilgi miktarı uygulamada test düzeyinde değerlendirilir. Ancak bilgi madde düzeyinde elde edilir ve test bilgi fonksiyonu \\(I_T(θ)\\) madde bilgi fonksiyonlarının \\(I_i(θ)\\) toplamıdır.\\(I_T(θ)= \\sum{I_i(θ)}\\)maddesi için belli bir yetenek düzeyinde (θ değerinde) bilgi miktarı için farklı MTK modellerinde kullanılan eşitlikler aşağıdaki gibidir:1PL\\(I_i(θ)=P_i(θ)*Q_i(θ)\\)\n\\(Q_i(θ)=1-P_i(θ)\\)\n\\(Q_i(θ)=1-P_i(θ)\\)2PL\\(I_i(θ)=a_i^2P_i(θ)*Q_i(θ)\\)3PL\\(I_i(θ)=a_i^2 \\frac{Q_i(θ)}{P_i(θ)}[\\frac{P_i(θ) - c_i}{1- c_i}]^2\\)","code":""},{"path":"mtk.html","id":"pl-modeli-için-madde-bilgi-fonksiyonu","chapter":"Bölüm 17 MTK","heading":"17.12.1 1-PL Modeli için Madde Bilgi Fonksiyonu","text":"1-PL (= 1.0, c = 0.0, D = 1.7 sabiti yok)b = 1.2 madde güçlüğü ile θ = 1.0 yetenek düzeyindeki bir birey için\\[P_i(\\theta) = \\frac{1}{1+exp[-(\\theta-b_i)]}\\]\n\\[P_i(1) = \\frac{1}{1+exp[-(1-1.2)]} = 0.45\\]\n\\(I_i(θ)= 0.45 * (1-0.45) =2.48\\)","code":"\np <- 1/(1+exp(-(1-1.2)))\np * (1-p)## [1] 0.2475166\nb <- c(1.2)\ntheta <- seq(-4,4,0.01)\n\nprob <- c()\n  for(j in 1:length(theta)){\n    dir <- 1/(1 + exp(-(theta[j] - b)))\n    prob[j] <- dir\n    j=j+1\n  }\nbilgi =  prob * (1- prob)\n\np <- data.frame(prob,bilgi)\nMBF <- ggplot(p, aes(theta, bilgi)) +\n  geom_line()\nMBF"},{"path":"mtk.html","id":"pl-model-madde-bilgi-fonksiyonu","chapter":"Bölüm 17 MTK","heading":"17.12.2 2-PL Model Madde Bilgi Fonksiyonu","text":"2-PL (= 0.8, c = 0.0, D = 1.7 sabiti yok)b = 1.2 madde güçlüğü ile θ = 1.0 yetenek düzeyindeki bir birey için","code":"\nb <- 1.2\na <- 0.8\ntheta <- seq(-4,4,0.01)\np <- 1/(1+exp(-(0.8*(1-1.2))))\na^2 * p * (1-p)## [1] 0.1589804\nprob <- c()\n  for(j in 1:length(theta)){\n    dir <- 1/(1 + exp(-(a*(theta[j] - b))))\n    prob[j] <- dir\n    j=j+1\n  }\nbilgi =  a*a * prob * (1- prob)\n\np <- data.frame(prob,bilgi)\nMBF2 <- ggplot(p, aes(theta, bilgi)) +  geom_line()\nMBF2"},{"path":"mtk.html","id":"test-bilgi-fonksiyonu","chapter":"Bölüm 17 MTK","heading":"17.13 Test Bilgi Fonksiyonu","text":"Bireysel maddelerin teste katkısının miktarı testteki diğer maddelerin bilgisi olmadan belirlenebilir.Bu klasik test kuramında mümkün değildir.Bu klasik test kuramında mümkün değildir.Örneğin, güvenirlik veya nokta-çift serili korelasyon testteki maddelerin geri kalanından bağımsız olarak belirlenemez.Örneğin, güvenirlik veya nokta-çift serili korelasyon testteki maddelerin geri kalanından bağımsız olarak belirlenemez.Testteki madde sayısı daha fazlaysa, daha yüksek test bilgi fonksiyonu elde edilir.Testteki madde sayısı daha fazlaysa, daha yüksek test bilgi fonksiyonu elde edilir.Lord (1977) tarafından önerilen test geliştirme yöntemi:Beklenen test bilgi fonksiyonunun şekli belirlenir:\nHedef bilgi fonksiyonu\nÖrneğin,Maddeler seçilir ve test bilgi fonksiyonu hesaplanır ve hedef bilgi fonksiyonuyla karşılaştırılır.Bir önceki basamak beklenen sonuçlar elde edilene kadar tekrar edilir.","code":""},{"path":"mtk.html","id":"maksimum-bilgi","chapter":"Bölüm 17 MTK","heading":"17.14 Maksimum Bilgi","text":"maddesi için maksimum bilgi farklı MTK modellerinde aşağıdaki yetenek düzeylerinde (θ değerinde) elde edilir:1-PL\\(\\theta=b_i\\)1-PL (= 1.0, b = 1.2, c = 0.0)\\(\\theta=b_i=1.2\\)2-PL\\(\\theta=b_i\\)2-PL (= 0.8, b = 1.2, c = 0.0)\\(\\theta=b_i=1.2\\)3-PL\\(\\theta=b_i + \\frac{1}{Da_i}[ln\\frac{1 + \\sqrt{1+8c_i}}{2}]^2\\)3-PL (= 0.8, b = 1.2, c = 0.2, D =1.7 sabiti yok)\\(\\theta=b_i=1.53\\)","code":""},{"path":"mtk.html","id":"madde-tepki-kuramı-1","chapter":"Bölüm 17 MTK","heading":"17.15 Madde Tepki Kuramı","text":"","code":""},{"path":"mtk.html","id":"kaynaklar-7","chapter":"Bölüm 17 MTK","heading":"17.16 Kaynaklar","text":"","code":""},{"path":"mtk-ile-madde-analizi-uygulaması.html","id":"mtk-ile-madde-analizi-uygulaması","chapter":"Bölüm 18 MTK ile Madde Analizi Uygulaması","heading":"Bölüm 18 MTK ile Madde Analizi Uygulaması","text":"iki kategorili (doğru-yanlış) MTK modelleriiki kategorili (doğru-yanlış) MTK modellerimadde ve yetenek parametresi kestirimimadde ve yetenek parametresi kestirimimadde karakteristik eğrisi çizimi ve yorumlanmasımadde karakteristik eğrisi çizimi ve yorumlanmasımodel-veri uyumunun incelenmesimodel-veri uyumunun incelenmesimadde ve test bilgi fonksiyonumadde ve test bilgi fonksiyonukullanılacak veriler\n: Sunu veri\n: Ödev Veri\nkullanılacak veriler: Sunu veri: Sunu veri: Ödev Veri: Ödev Verikodlar\n: Kodlar\nkodlar: Kodlar","code":""},{"path":"mtk-ile-madde-analizi-uygulaması.html","id":"iki-kategorili-doğru-yanlış-mtk-modelleri","chapter":"Bölüm 18 MTK ile Madde Analizi Uygulaması","heading":"18.1 İki kategorili (doğru-yanlış) MTK modelleri","text":"En popüler üç tek boyutlu iki kategorili madde yanıt verisi MTK modelleribir-parametreli lojistik (1-PL)\\[P_i(\\theta) = \\frac{exp(\\theta-b_i)}{1+exp(\\theta-b_i)} = \\frac{1}{1+exp[-(\\theta-b_i)]}\\]iki-parametreli lojistik (2-PL)\\[P_i(\\theta) = \\frac{exp[a_i(\\theta-b_i)]}{1+exp[a_i(\\theta-b_i)]}=\\frac{1}{1+exp(-[a_i(\\theta-b_i)])}\\]üç-parametreli lojistik (3-PL)\\[P_i(\\theta) = c_i + (1- ci)* \\frac{exp[a_i(\\theta-b_i)]}{1+exp[a_i(\\theta-b_i)]}=c_i +\\frac{1-c_i}{1+exp(-[a_i(\\theta-b_i)])}\\]","code":""},{"path":"mtk-ile-madde-analizi-uygulaması.html","id":"mirt-paketi-yüklenmesi","chapter":"Bölüm 18 MTK ile Madde Analizi Uygulaması","heading":"18.2 mirt paketi yüklenmesi","text":"Analizler mirt paketinde yapılacaktır. Paketin yüklenmesi ve aktivite edilmesi aşağıdaki kodlarla sağlanır.MTK analizlerinin yapılacağı paketlere ltm Rizopoulos (2006) ve irtoys Partchev vd. (2017) örnek verilebilir. Choi ve Asilkalkan (2019) makalesinde 45 farklı MTK paketine ilişkin açıklamalar bulunmaktadır.1PL modelin hazırlanmasıİlk olarak test edilecek model hazırlanmalıdır.Kodun ilk satırı, tek bir gizil özelliğin (F'nin) veri setindeki 1 ile 15 arasındaki sütunlardaki maddeler tarafından ölçüldüğünü göstermektedirCONSTRAIN ile başlayan ikinci satır ise 1'den 15'e kadar olan sütunlardaki maddeleri aynı madde ayırt ediciliğine (a1) sahip olacak şekilde sınırlar.Sadece ilk 10 maddede madde ayırt ediciliğini aynı olacak şekilde sınırlamak isterseniz modeli aşağıdaki gibi düzenleyebilirsiniz.Veri aktarımı : Veriyi açılan linkten farklı kaydet ile alabilirsiniz.Veriyi 1-0 olarak puanlamak için key2binary()\nfonksiyonunu kullanabilirsiniz.","code":"\n# install.packages(\"mirt\")\nlibrary(\"mirt\")\nbirpl_model <- \"F = 1-15\n                CONSTRAIN = (1-15, a1)\"\nbirpl_model_v1 <- \"F = 1-15\n                CONSTRAIN = (1-10, a1)\"\nlibrary(readr)\nikikategorili <- read_csv(\"import/dichotomous.csv\")[,-1]\nhead(ikikategorili[,1:5])\nDataExplorer::plot_bar(ikikategorili)\nveri <- read_csv(\"import/veri.csv\")## Rows: 262 Columns: 13\n## ── Column specification ────────────────────────────────────────────────────────\n## Delimiter: \",\"\n## dbl (13): Subject, Rot1_2, Rot1_3, Rot1_4, Rot1_5, Rot2_2, Rot2_3, Rot2_4, R...\n## \n## ℹ Use `spec()` to retrieve the full column specification for this data.\n## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nlibrary(mirt)\ndat1 <- key2binary(veri[,-1],\n    key = c(2,3,4,5,2,3,4,5,2,3,4,5))\nhead(veri[,1:5])\nhead(dat1)##      Rot1_2 Rot1_3 Rot1_4 Rot1_5 Rot2_2 Rot2_3 Rot2_4 Rot2_5 Rot3_2 Rot3_3\n## [1,]      0      0      0      0      0      0      0      0      0      0\n## [2,]      0      0      0      0      0      0      0      0      0      0\n## [3,]      0      0      0      0      0      0      0      0      0      0\n## [4,]      0      0      0      0      0      0      0      0      0      0\n## [5,]      0      0      0      0      0      0      0      0      0      0\n## [6,]      0      0      0      0      0      0      0      0      0      0\n##      Rot3_4 Rot3_5\n## [1,]      0      0\n## [2,]      0      0\n## [3,]      0      0\n## [4,]      0      0\n## [5,]      0      0\n## [6,]      0      0"},{"path":"mtk-ile-madde-analizi-uygulaması.html","id":"madde-istatistikleri","chapter":"Bölüm 18 MTK ile Madde Analizi Uygulaması","heading":"18.2.1 Madde Istatistikleri","text":"","code":"\nitemstats(ikikategorili)## $overall\n##     N mean_total.score sd_total.score ave.r sd.r alpha\n##  1000            6.682          2.698 0.114 0.11 0.688\n## \n## $itemstats\n##        N  mean    sd total.r total.r_if_rm alpha_if_rm\n## V1  1000 0.182 0.386   0.626         0.526       0.645\n## V2  1000 0.074 0.262  -0.169        -0.261       0.717\n## V3  1000 0.175 0.380   0.382         0.253       0.678\n## V4  1000 0.164 0.370   0.438         0.317       0.671\n## V5  1000 0.280 0.449   0.427         0.277       0.676\n## V6  1000 0.566 0.496   0.501         0.344       0.666\n## V7  1000 0.440 0.497   0.536         0.384       0.660\n## V8  1000 0.479 0.500   0.532         0.379       0.661\n## V9  1000 0.435 0.496   0.525         0.372       0.662\n## V10 1000 0.915 0.279   0.291         0.193       0.684\n## V11 1000 0.123 0.329   0.375         0.263       0.677\n## V12 1000 0.760 0.427   0.414         0.270       0.676\n## V13 1000 0.936 0.245   0.277         0.190       0.684\n## V14 1000 0.612 0.488   0.517         0.366       0.663\n## V15 1000 0.541 0.499   0.522         0.368       0.663\n## \n## $proportions\n##         0     1\n## V1  0.818 0.182\n## V2  0.926 0.074\n## V3  0.825 0.175\n## V4  0.836 0.164\n## V5  0.720 0.280\n## V6  0.434 0.566\n## V7  0.560 0.440\n## V8  0.521 0.479\n## V9  0.565 0.435\n## V10 0.085 0.915\n## V11 0.877 0.123\n## V12 0.240 0.760\n## V13 0.064 0.936\n## V14 0.388 0.612\n## V15 0.459 0.541"},{"path":"mtk-ile-madde-analizi-uygulaması.html","id":"parametre-kestirimleri","chapter":"Bölüm 18 MTK ile Madde Analizi Uygulaması","heading":"18.2.2 Parametre Kestirimleri","text":"mirt paketinin mirt() fonksiyonu temel olarak data ve model olarak iki argümanla çalışır.mirt paketinin mirt() fonksiyonu temel olarak data ve model olarak iki argümanla çalışır.ikikategorili veri setinin birpl_model modeli için testi aşağıdaki gibi yapılabilir.ikikategorili veri setinin birpl_model modeli için testi aşağıdaki gibi yapılabilir.birpl_uyum nesnesiparametre kestirimlerinigizil özelliğin ortalamasınıgizil özelliğin varyans-kovaryans matrisinikestirim sürecine ilişkin ek bilgileri içerir.","code":"\nbirpl_model <- \"F = 1-15\n                CONSTRAIN = (1-15, a1)\"\nbirpl_uyum <- mirt(data = ikikategorili, model = birpl_model,SE=TRUE,\n                   verbose=FALSE)"},{"path":"mtk-ile-madde-analizi-uygulaması.html","id":"varsayımlar-1","chapter":"Bölüm 18 MTK ile Madde Analizi Uygulaması","heading":"18.2.3 Varsayımlar","text":"Tek boyutluluk tek boyutlu MTK modelleri, tüm maddelerin tek bir sürekli gizli değişkeni ölçtüğünü varsayar.Tek boyutluluk varsayımını test etmenin farklı yolları vardır. Örneğin, kavramsal olarak genel bir faktör tarafından hesaplanan ölçek puanlarındaki varyans yüzdesini yansıtan McDonald's hiyerarşik Omega'sını değerlendirebiliriz.Madde çiftlerinin yerel bağımsızlığını kontrol etmek için ise Yen'Q3 istatistiği kullanılabilir.Madde çiftlerinin yerel bağımsızlığını kontrol etmek için ise Yen'Q3 istatistiği kullanılabilir.ve j. maddelerinden elde edilen artıklar arasındaki korelasyon matrisi\nve j. maddelerinden elde edilen artıklar arasındaki korelasyon matrisiYen .20'den yüksek korelasyonlara problemli olarak yaklaşmayı tavsiye etmiştir.","code":"\nlibrary(psych)\nsummary(omega(ikikategorili, plot = F))## Omega \n## omega(m = ikikategorili, plot = F)\n## Alpha:                 0.72 \n## G.6:                   0.71 \n## Omega Hierarchical:    0.58 \n## Omega H asymptotic:    0.78 \n## Omega Total            0.74 \n## \n## With eigenvalues of:\n##    g  F1*  F2*  F3* \n## 1.86 0.69 0.20 0.28 \n## The degrees of freedom for the model is 63  and the fit was  0.05 \n## The number of observations was  1000  with Chi Square =  52.23  with prob <  0.83 \n## \n## The root mean square of the residuals is  0.02 \n## The df corrected root mean square of the residuals is  0.03 \n## \n## RMSEA and the  0.9 confidence intervals are  0 0 0.012\n## BIC =  -382.96Explained Common Variance of the general factor =  0.61 \n## \n##  Total, General and Subset omega for each subset\n##                                                  g  F1*  F2*  F3*\n## Omega total for total scores and subscales    0.74 0.60 0.53 0.39\n## Omega general for total scores and subscales  0.58 0.36 0.43 0.26\n## Omega group for total scores and subscales    0.09 0.25 0.09 0.14\nbirpl_uyum <- mirt(data = ikikategorili, model = birpl_model,SE=TRUE,\n                    verbose=FALSE)\n Q3 <- residuals(birpl_uyum, type = 'Q3', method = 'ML')## Q3 summary statistics:\n##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##  -0.183  -0.099  -0.064  -0.069  -0.040   0.027 \n## \n##         V1     V2     V3     V4     V5     V6     V7     V8     V9    V10\n## V1   1.000 -0.183 -0.127  0.016 -0.142 -0.089 -0.049 -0.054  0.026 -0.053\n## V2  -0.183  1.000  0.027 -0.040 -0.034 -0.083 -0.062 -0.056 -0.057 -0.014\n## V3  -0.127  0.027  1.000 -0.134 -0.049 -0.031 -0.100 -0.068 -0.091 -0.009\n## V4   0.016 -0.040 -0.134  1.000 -0.099 -0.056 -0.019 -0.102 -0.098 -0.016\n## V5  -0.142 -0.034 -0.049 -0.099  1.000 -0.117 -0.064 -0.062 -0.082  0.003\n## V6  -0.089 -0.083 -0.031 -0.056 -0.117  1.000 -0.106 -0.143 -0.114 -0.109\n## V7  -0.049 -0.062 -0.100 -0.019 -0.064 -0.106  1.000 -0.155 -0.128  0.007\n## V8  -0.054 -0.056 -0.068 -0.102 -0.062 -0.143 -0.155  1.000 -0.089 -0.046\n## V9   0.026 -0.057 -0.091 -0.098 -0.082 -0.114 -0.128 -0.089  1.000 -0.094\n## V10 -0.053 -0.014 -0.009 -0.016  0.003 -0.109  0.007 -0.046 -0.094  1.000\n## V11 -0.005 -0.020 -0.167 -0.120 -0.076 -0.036 -0.056 -0.072 -0.009 -0.050\n## V12 -0.081 -0.096 -0.041 -0.061 -0.068 -0.090 -0.111 -0.055 -0.104 -0.117\n## V13  0.006 -0.016 -0.039 -0.019 -0.040 -0.062 -0.052 -0.036 -0.053  0.001\n## V14 -0.048 -0.059 -0.067 -0.042 -0.095 -0.083 -0.078 -0.082 -0.130 -0.106\n## V15 -0.018 -0.086 -0.074 -0.070 -0.169 -0.060 -0.127 -0.114 -0.102 -0.063\n##        V11    V12    V13    V14    V15\n## V1  -0.005 -0.081  0.006 -0.048 -0.018\n## V2  -0.020 -0.096 -0.016 -0.059 -0.086\n## V3  -0.167 -0.041 -0.039 -0.067 -0.074\n## V4  -0.120 -0.061 -0.019 -0.042 -0.070\n## V5  -0.076 -0.068 -0.040 -0.095 -0.169\n## V6  -0.036 -0.090 -0.062 -0.083 -0.060\n## V7  -0.056 -0.111 -0.052 -0.078 -0.127\n## V8  -0.072 -0.055 -0.036 -0.082 -0.114\n## V9  -0.009 -0.104 -0.053 -0.130 -0.102\n## V10 -0.050 -0.117  0.001 -0.106 -0.063\n## V11  1.000 -0.017 -0.035 -0.054 -0.093\n## V12 -0.017  1.000 -0.076 -0.116 -0.032\n## V13 -0.035 -0.076  1.000 -0.106 -0.055\n## V14 -0.054 -0.116 -0.106  1.000 -0.087\n## V15 -0.093 -0.032 -0.055 -0.087  1.000\nQ3[lower.tri(Q3,diag = TRUE)] <- NA\nsum(abs(Q3) >0.2,na.rm=TRUE)## [1] 0"},{"path":"mtk-ile-madde-analizi-uygulaması.html","id":"model-uyumu","chapter":"Bölüm 18 MTK ile Madde Analizi Uygulaması","heading":"18.2.4 Model Uyumu","text":"Elde edilenElde edilenRMSEA değeri = 0.0648 (%95 CI[0.0594, 0.0702]) veRMSEA değeri = 0.0648 (%95 CI[0.0594, 0.0702]) veSRMSR değeri = 0.0929, önerilen eşik değerleri olan RMSEA <= .06SRMSR değeri = 0.0929, önerilen eşik değerleri olan RMSEA <= .06SRMSR <= .08 kullanılarak verilerin modelin iyi uyum sağlamadığını göstermektedir.SRMSR <= .08 kullanılarak verilerin modelin iyi uyum sağlamadığını göstermektedir.Madde uyumlarına baktığımızda özellikle V1, V2 maddelerinde yüksek ki-kare ve ve RMSEA değerleri gözlenmektedir.","code":"\n M2(birpl_uyum)\nlibrary(dplyr)\nitemfit(birpl_uyum) %>% kable(digits=2)"},{"path":"mtk-ile-madde-analizi-uygulaması.html","id":"parametre-kestirimleri-1","chapter":"Bölüm 18 MTK ile Madde Analizi Uygulaması","heading":"18.2.5 Parametre Kestirimleri","text":"Kestirim süreci birpl_uyum nesnesine atandıktan sonra, parametreleri inceleme için coef() fonksiyonunun kullanabilir.Kestirim süreci birpl_uyum nesnesine atandıktan sonra, parametreleri inceleme için coef() fonksiyonunun kullanabilir.Çok boyutlu MTK'da yer alan, eğim ve kesişim parametrelerini geleneksel MTK parametrelerine dönüştürmek için IRTpars argümanı TRUE değeri ile kullanılır.Çok boyutlu MTK'da yer alan, eğim ve kesişim parametrelerini geleneksel MTK parametrelerine dönüştürmek için IRTpars argümanı TRUE değeri ile kullanılır.simplify argümanı TRUE değeri ile kullanıldığında parametreler liste yapısı yerine veri seti olarak elde edilir.simplify argümanı TRUE değeri ile kullanıldığında parametreler liste yapısı yerine veri seti olarak elde edilir.parametre kestirimlerini olusturulan birpl_par nesnesinin items bileşeninden alabiliriz.satır, madde adıyla başlar.satır, madde adıyla başlar.Sütunlar ise sırasıyla\nilk sütun madde ayırtedicliği\nikinci sütun b madde güçlüğü\nüçüncü sütun g alt asimptot (yani tahmin)\nson sütun u üst asimptottur.\n1PL modeli alt ve üst asimptot parametrelerini içermediğinden, sırasıyla zaman 0 ve 1 dir.\nSütunlar ise sırasıylailk sütun madde ayırtedicliğiilk sütun madde ayırtedicliğiikinci sütun b madde güçlüğüikinci sütun b madde güçlüğüüçüncü sütun g alt asimptot (yani tahmin)üçüncü sütun g alt asimptot (yani tahmin)son sütun u üst asimptottur.son sütun u üst asimptottur.1PL modeli alt ve üst asimptot parametrelerini içermediğinden, sırasıyla zaman 0 ve 1 dir.1PL modeli alt ve üst asimptot parametrelerini içermediğinden, sırasıyla zaman 0 ve 1 dir.İlk sütun, 1.01 tahmini ile madde ayırt ayırtedicliği parametresini göstermektedir.İlk sütun, 1.01 tahmini ile madde ayırt ayırtedicliği parametresini göstermektedir.ikinci sütun, madde güçlük parametrelerini göstermektedir.ikinci sütun, madde güçlük parametrelerini göstermektedir.Peki en kolay madde hangisidir?Peki en kolay madde hangisidir?En zor madde hangisidir?En zor madde hangisidir?","code":"\nbirpl_model <- \"F = 1-15\n                CONSTRAIN = (1-15, a1)\"\nbirpl_uyum <- mirt(data = ikikategorili, model = birpl_model,\n                    verbose=FALSE)\nbirpl_par <- coef(birpl_uyum, \n                  IRTpars = TRUE, \n                  simplify = TRUE)\nbirpl_par$items##            a           b g u\n## V1  1.013626  1.76949298 0 1\n## V2  1.013626  2.89739255 0 1\n## V3  1.013626  1.82367304 0 1\n## V4  1.013626  1.91203231 0 1\n## V5  1.013626  1.12434465 0 1\n## V6  1.013626 -0.32009940 0 1\n## V7  1.013626  0.28823807 0 1\n## V8  1.013626  0.09959949 0 1\n## V9  1.013626  0.31260843 0 1\n## V10 1.013626 -2.73110850 0 1\n## V11 1.013626  2.28648733 0 1\n## V12 1.013626 -1.36726150 0 1\n## V13 1.013626 -3.05783719 0 1\n## V14 1.013626 -0.54748073 0 1\n## V15 1.013626 -0.19875398 0 1\nbirpl_par <- coef(birpl_uyum, \n                  IRTpars = TRUE, \n                  simplify = TRUE)\nbirpl_par$items##            a           b g u\n## V1  1.013626  1.76949298 0 1\n## V2  1.013626  2.89739255 0 1\n## V3  1.013626  1.82367304 0 1\n## V4  1.013626  1.91203231 0 1\n## V5  1.013626  1.12434465 0 1\n## V6  1.013626 -0.32009940 0 1\n## V7  1.013626  0.28823807 0 1\n## V8  1.013626  0.09959949 0 1\n## V9  1.013626  0.31260843 0 1\n## V10 1.013626 -2.73110850 0 1\n## V11 1.013626  2.28648733 0 1\n## V12 1.013626 -1.36726150 0 1\n## V13 1.013626 -3.05783719 0 1\n## V14 1.013626 -0.54748073 0 1\n## V15 1.013626 -0.19875398 0 1"},{"path":"mtk-ile-madde-analizi-uygulaması.html","id":"madde-karakteristik-eğrisi-mke-1","chapter":"Bölüm 18 MTK ile Madde Analizi Uygulaması","heading":"18.2.6 Madde Karakteristik Eğrisi (MKE)","text":"plot() fonksiyonu ile oluşturulan nesne içindeki maddeler için tek tek ya da istenilen maddeler için MKE çizdirilebilir.mirt paketi grafik çiziminde lattice paketini kullanmaktadır. lattice paketi özellikleri ile grafiklerinizi özelleştirebilirsiniz.mirt paketi grafik çiziminde lattice paketini kullanmaktadır. lattice paketi özellikleri ile grafiklerinizi özelleştirebilirsiniz.Panelin oluşum şekli layout argümanı ile x ekseni limitlerini ise theta_lim argümanı ile değiştirilebilir.Panelin oluşum şekli layout argümanı ile x ekseni limitlerini ise theta_lim argümanı ile değiştirilebilir.Böylece çoktan seçmeli maddelerde düşük yetenek düzeyine sahip bireylerin tahmin olasılığına izin verilmez. Tahmin olmaması sayıltısı çoktan-seçmeli maddeleri içeren bir testin çok kolay olduğu durumlarda karşılanabilir.Böylece çoktan seçmeli maddelerde düşük yetenek düzeyine sahip bireylerin tahmin olasılığına izin verilmez. Tahmin olmaması sayıltısı çoktan-seçmeli maddeleri içeren bir testin çok kolay olduğu durumlarda karşılanabilir.facet_items argümanının FALSE değeri ile tüm maddelerin MKE tek bir grafikte elde edilebilir.facet_items argümanının FALSE değeri ile tüm maddelerin MKE tek bir grafikte elde edilebilir.","code":"\nplot(birpl_uyum,type = \"trace\", which.items = 1:15)\nplot(birpl_uyum, type = \"trace\", which.items = 1:15,\n     layout=c(5, 3),theta_lim = c(-4, 4))\nplot(birpl_uyum,\n     type = \"trace\", \nwhich.items = 1:15, \nlayout=c(5, 3),\npanel=function(x, y){\npanel.grid(h=-1, v=-1)\npanel.xyplot(x, y)\npanel.abline(h=0.5, lwd=1,\n        lty=1)})\nplot(birpl_uyum, type = \"trace\", which.items = 1:15,\nfacet_items = FALSE)"},{"path":"mtk-ile-madde-analizi-uygulaması.html","id":"pl-model-1","chapter":"Bölüm 18 MTK ile Madde Analizi Uygulaması","heading":"18.3 2-PL Model","text":"Modelin hazırlanmasıModelin testi2-PL Model için Model Uyum2-PL Model için Madde Uyum2-PL Model Parametrelerin incelenmesiMadde parametreleri oluşturulan nesnenin items bileşeninde yer almaktadır.2-PL Model MKE","code":"\nikipl_model <- \"F = 1 - 15\"\nikipl_uyum <- mirt(data = ikikategorili, model = ikipl_model,\nitemtype = \"2PL\", SE=TRUE,  verbose=FALSE)\nM2(ikipl_uyum)\nitemfit(ikipl_uyum)\nikipl_par <- coef(ikipl_uyum, IRTpars = TRUE, simplify = TRUE)\nikipl_par$items##              a           b g u\n## V1   4.9770527  0.97389708 0 1\n## V2  -1.5064231 -2.23536051 0 1\n## V3   0.8270586  2.12124033 0 1\n## V4   1.2474614  1.66057442 0 1\n## V5   0.8174703  1.31802216 0 1\n## V6   1.0167249 -0.31516639 0 1\n## V7   1.1407667  0.27023173 0 1\n## V8   1.1035449  0.09815291 0 1\n## V9   1.1595573  0.28974905 0 1\n## V10  0.8961434 -3.00368157 0 1\n## V11  1.1407616  2.10056256 0 1\n## V12  0.9224835 -1.46118722 0 1\n## V13  1.0481447 -2.98989657 0 1\n## V14  1.1180121 -0.50818301 0 1\n## V15  1.1598398 -0.17723738 0 1\nplot(ikipl_uyum, type = \"trace\", which.items = 1:15)\nplot(ikipl_uyum, type = \"trace\", which.items = 1:15,facet_items = FALSE,\n     abline=c(h=0.5))"},{"path":"mtk-ile-madde-analizi-uygulaması.html","id":"pl-model-2","chapter":"Bölüm 18 MTK ile Madde Analizi Uygulaması","heading":"18.4 3-PL Model","text":"Modelin hazırlanmasıModelin testiParametrelerin incelenmesi3-PL Model için Model Uyum3-PL Model için Madde Uyum3-PL Model Madde Parametreleri3-PL Model Madde ParametreleriMadde parametreleri oluşturulan nesnenin items bileşeninde yer almaktadır.Madde parametreleri oluşturulan nesnenin items bileşeninde yer almaktadır.3-PL Model MKE","code":"\nucpl_model <- \"F = 1 - 15\"\nucpl_uyum <- mirt(data = ikikategorili, model = ucpl_model,\nitemtype = \"3PL\", verbose=FALSE)\nucpl_par <- coef(ucpl_uyum, IRTpars = TRUE, simplify = TRUE)\nM2(ucpl_uyum)\nitemfit(ucpl_uyum)\nucpl_par$items##              a          b            g u\n## V1   5.0095769  0.9730634 6.856953e-05 1\n## V2  -1.7864777 -2.1254780 7.449526e-03 1\n## V3   0.8261103  2.1244227 2.190968e-04 1\n## V4   1.5065681  1.6127171 2.276560e-02 1\n## V5   0.8321204  1.3033160 4.390669e-04 1\n## V6   1.0127359 -0.3120958 9.971312e-04 1\n## V7   1.1433362  0.2749052 1.172248e-03 1\n## V8   1.1136806  0.1036166 1.632577e-03 1\n## V9   1.3997565  0.4684585 8.285908e-02 1\n## V10  0.8859144 -2.9635666 5.056955e-02 1\n## V11  1.2099583  2.0555836 4.698548e-03 1\n## V12  0.9253188 -1.4495526 4.689105e-03 1\n## V13  5.9251510 -0.1267528 8.569785e-01 1\n## V14  1.1340456 -0.4838188 9.595944e-03 1\n## V15  1.1625190 -0.1728392 8.848252e-04 1\nplot(ucpl_uyum, type = \"trace\", which.items = 1:15)\nplot(ucpl_uyum, type = \"trace\", which.items = 1:15,facet_items = FALSE,\n     abline=c(h=0.5))"},{"path":"mtk-ile-madde-analizi-uygulaması.html","id":"yetenek-parametresi-kestirimi","chapter":"Bölüm 18 MTK ile Madde Analizi Uygulaması","heading":"18.5 Yetenek Parametresi Kestirimi","text":"MTK modellerinde başlıca üç yolla puanlama yapılır:Maksimum Likelihood (ML)Maksimum Likelihood (ML)Maksimum Posteriori (MAP)Maksimum Posteriori (MAP)Expected/estimated Posteriori (EAP)Expected/estimated Posteriori (EAP)Bireylerin faktör puanları veya gizil özellik düzeyi kestirimleri fscores() fonksiyonuyla hesaplanabilir.Bireylerin faktör puanları veya gizil özellik düzeyi kestirimleri fscores() fonksiyonuyla hesaplanabilir.fscores() fonksiyonunun birinci argümanı object olup bu argümanın değeri mirt() fonksiyonunun çıktısı olarak kaydedilen nesnelerdir. Kestirim yönteminin türü method argümanıyla maksimum olabilirlik (ML) olarak belirlenmiştir.fscores() fonksiyonunun birinci argümanı object olup bu argümanın değeri mirt() fonksiyonunun çıktısı olarak kaydedilen nesnelerdir. Kestirim yönteminin türü method argümanıyla maksimum olabilirlik (ML) olarak belirlenmiştir.full.scores.SE argümanı için de TRUE değeri seçilerek kestirimlerin standart hataları istenebilir.full.scores.SE argümanı için de TRUE değeri seçilerek kestirimlerin standart hataları istenebilir.","code":"\nML   <- fscores(ikipl_uyum, method=\"ML\",full.scores.SE=TRUE)## Warning: The following factor score estimates failed to converge successfully:\n##     112,568,796,959\nMAP  <- fscores(ikipl_uyum, method=\"MAP\", full.scores.SE=TRUE)\nEAP  <- fscores(ikipl_uyum, method=\"EAP\",full.scores.SE=TRUE)\nhead(ML)##                F      SE_F\n## [1,]  0.73603270 0.3806593\n## [2,]  0.53590413 0.4571045\n## [3,]  0.89771900 0.3458166\n## [4,] -0.50361328 0.6321820\n## [5,]  2.33978577 0.8193420\n## [6,] -0.03367516 0.6027560\nhead(MAP)##               F      SE_F\n## [1,]  0.6355854 0.3844652\n## [2,]  0.4365773 0.4451435\n## [3,]  0.7980747 0.3415016\n## [4,] -0.3610353 0.5297980\n## [5,]  1.5724578 0.4910050\n## [6,] -0.0247113 0.5156826\nhead(EAP)##                F      SE_F\n## [1,]  0.55522250 0.4072993\n## [2,]  0.34833436 0.4382801\n## [3,]  0.74927202 0.3834750\n## [4,] -0.38920524 0.5196820\n## [5,]  1.70157621 0.4909653\n## [6,] -0.07368355 0.4928855\nyetenek <- data.frame(ML= ML[,1],MAP=MAP[,1],EAP=EAP[,1])\n\napply(yetenek,2,summary)##                  ML         MAP           EAP\n## Min.           -Inf -2.52282408 -2.566836e+00\n## 1st Qu. -0.91649165 -0.64567907 -6.672408e-01\n## Median  -0.06447746 -0.04720803 -9.426944e-02\n## Mean           -Inf  0.02283950 -5.416872e-05\n## 3rd Qu.  0.70642942  0.60541014  5.217741e-01\n## Max.    19.99988027  2.20150199  2.295843e+00\nyetenek_v1 <- yetenek[!is.infinite(yetenek$ML),]\n\napply(yetenek_v1,2,summary)##                  ML         MAP          EAP\n## Min.    -3.88806981 -2.19596246 -2.228596152\n## 1st Qu. -0.91529147 -0.64486819 -0.666439513\n## Median  -0.06368468 -0.04662918 -0.093739792\n## Mean     0.01367254  0.02538771  0.002515182\n## 3rd Qu.  0.70642987  0.60541034  0.521774267\n## Max.    19.99988027  2.20150199  2.295843371\ncor(yetenek_v1)##            ML       MAP       EAP\n## ML  1.0000000 0.8166070 0.8172591\n## MAP 0.8166070 1.0000000 0.9982609\n## EAP 0.8172591 0.9982609 1.0000000\npairs(yetenek_v1)\nanova(birpl_uyum,ikipl_uyum)\nanova(ikipl_uyum,ucpl_uyum)"},{"path":"mtk-ile-madde-analizi-uygulaması.html","id":"madde-bilgi-fonksiyonu-1","chapter":"Bölüm 18 MTK ile Madde Analizi Uygulaması","heading":"18.6 Madde Bilgi Fonksiyonu","text":"Teknik olarak, bilgi bir parametre kestiriminin standart hatasının tersiyle ilişkili bir değerdir.\nYüksek bilgi değeri parametre kestirimi hakkında daha fazla bilgiye sahip olunduğunu belirtir.\nTeknik olarak, bilgi bir parametre kestiriminin standart hatasının tersiyle ilişkili bir değerdir.Yüksek bilgi değeri parametre kestirimi hakkında daha fazla bilgiye sahip olunduğunu belirtir.MTK'da bilgi birey yeteneğini kestirmek için kullanılan maddelerin toplamından elde edilen bilgiyi ifade eder.MTK'da bilgi birey yeteneğini kestirmek için kullanılan maddelerin toplamından elde edilen bilgiyi ifade eder.","code":"\nplot(birpl_uyum, \ntype = \"infotrace\", \nwhich.items = 5)\nplot(ikipl_uyum, \ntype = \"infotrace\", \nwhich.items = 5)\nplot(ucpl_uyum, \ntype = \"infotrace\", \nwhich.items = 5)\nplot(ikipl_uyum, \ntype = \"infotrace\", \nwhich.items = 1:15, layout=c(5, 3))\nplot(ikipl_uyum, \ntype = \"infotrace\", \nwhich.items = 2:15, layout=c(5, 3))\nmadde1 <- extract.item(ikipl_uyum, 1)\nTheta <- matrix(seq(-6,6, by = .1))\ninfo.1 <- iteminfo(madde1, Theta)\nplot(Theta, info.1, type = 'l', main = 'Item information')\ntinfo <- testinfo(ikipl_uyum, \nTheta,which.items = 1:5)\nplot(Theta, tinfo, type = 'l')\ntinfo <- testinfo(ikipl_uyum, \nTheta,which.items = 1:10)\nplot(Theta, tinfo, type = 'l')\ntinfo <- testinfo(ikipl_uyum, \nTheta,which.items = 1:15)\nplot(Theta, tinfo, type = 'l')\ntinfo <- testinfo(ikipl_uyum, Theta,which.items = c(1,3:5,7:10,11))\nplot(Theta, tinfo, type = 'l')\nplot(ikipl_uyum, type='infoSE')"},{"path":"mtk-ile-madde-analizi-uygulaması.html","id":"sıra-sizde-3","chapter":"Bölüm 18 MTK ile Madde Analizi Uygulaması","heading":"18.7 Sıra Sizde","text":"1.: Veriyi açılan linkten farklı kaydet ile alabilirsiniz.MTK varsayamlarını test ediniz.MTK varsayamlarını test ediniz.Verinin hangi MTK modeline daha iyi uyum sağladığını inceleyiniz.Verinin hangi MTK modeline daha iyi uyum sağladığını inceleyiniz.Madde parametrelerini ve madde karakteristik eğrileri ile birlikte raporlayınız.Madde parametrelerini ve madde karakteristik eğrileri ile birlikte raporlayınız.Yetenek paramterelerini kestirinizYetenek paramterelerini kestirinizTest bilgi fonskiyonun grafiğini çiziniz.Test bilgi fonskiyonun grafiğini çiziniz.","code":""},{"path":"mtk-ile-madde-analizi-uygulaması.html","id":"kaynaklar-8","chapter":"Bölüm 18 MTK ile Madde Analizi Uygulaması","heading":"18.8 Kaynaklar","text":"Atar, B., Atalay Kabasakal, K, Unsal Ozberk, E. B., Ozberk, E. H. & Kibrislioglu Uysal, N. (2020). R ile Veri Analizi ve Psikometri Uygulamaları, Pegem Akademi, Ankara.Atar, B., Atalay Kabasakal, K, Unsal Ozberk, E. B., Ozberk, E. H. & Kibrislioglu Uysal, N. (2020). R ile Veri Analizi ve Psikometri Uygulamaları, Pegem Akademi, Ankara.Chalmers, R. P. (2012). mirt: multidimensional item response theory package R environment. Journal Statistical Software, 48(6), 1-29.Chalmers, R. P. (2012). mirt: multidimensional item response theory package R environment. Journal Statistical Software, 48(6), 1-29.Desjardins, C.D., & Bulut, O. (2017). Handbook Educational Measurement Psychometrics Using R (1st ed.). Chapman Hall/CRC. https://doi.org/10.1201/b20498Desjardins, C.D., & Bulut, O. (2017). Handbook Educational Measurement Psychometrics Using R (1st ed.). Chapman Hall/CRC. https://doi.org/10.1201/b20498","code":""},{"path":"veri-üretimi.html","id":"veri-üretimi","chapter":"Bölüm 19 Veri Üretimi","heading":"Bölüm 19 Veri Üretimi","text":"İstatistiğin en önemli konularından birisi olasılık dağılımlarıdır.R’da veri üretimi yaparken çıktıların ne olduklarını bilmek yerine çıktıların olma olasılıkları üzerinden veri üretmek gerekebilir.Örneğin, bir sınıftaki öğrencilerin madeni para atışında, paranın yazı ya da tura gelme olasılığı üzerine veri üretimi yapılırken,yazı gelme olasılığının 0.5; tura gelme olasılığının 0.5 olduğu bu durumda Bernoulli dağılımı yardımıyla yüzlerce ya da binlerce para atışı için veri üretmek mümkündür.Paranın iki kere hava atılmasıYY (1/4)YY (1/4)TT (1/4)TT (1/4)TY (2/4)TY (2/4)Paranın dört kere hava atılmasıYYYY (1/16)YYYY (1/16)TTTT (1/16)TTTT (1/16)YTTT (4/16)YTTT (4/16)TYYY (4/16)TYYY (4/16)YYTT (6/16)YYTT (6/16)Paranın otuz kere hava atılması","code":"\nx <- 0:2\ny <- dbinom(x,size=2,p=0.5)\ny## [1] 0.25 0.50 0.25\nplot(x, y ,type=\"h\",col=\"red\", lwd=10,\nmain=\"bozuk parayi iki kere havaya atma\")\nx <- 0:4\ny <- dbinom(x,size=4,p=0.5)\ny## [1] 0.0625 0.2500 0.3750 0.2500 0.0625\nplot(x, y ,type=\"h\",col=\"red\", lwd=10,\nmain=\"bozuk parayi dört kere havaya atma\")\nx <- 0:30\ny <- dbinom(x,size=30,p=0.5)\ny##  [1] 9.31e-10 2.79e-08 4.05e-07 3.78e-06 2.55e-05 1.33e-04 5.53e-04 1.90e-03\n##  [9] 5.45e-03 1.33e-02 2.80e-02 5.09e-02 8.06e-02 1.12e-01 1.35e-01 1.44e-01\n## [17] 1.35e-01 1.12e-01 8.06e-02 5.09e-02 2.80e-02 1.33e-02 5.45e-03 1.90e-03\n## [25] 5.53e-04 1.33e-04 2.55e-05 3.78e-06 4.05e-07 2.79e-08 9.31e-10\nplot(x, y ,type=\"h\",col=\"red\", lwd=10,\nmain=\"bozuk parayi otuz kere havaya atma\")"},{"path":"veri-üretimi.html","id":"dağılımlar","chapter":"Bölüm 19 Veri Üretimi","heading":"19.1 Dağılımlar","text":"Normal, log-normal, ki-kare, binom, poisson, uniform, gamma, beta vb. gibi farklı dağılımlar mevcuttur.p, olasılık (probability) kümülatif dağılım fonksiyonuna ilişkin bilgilerip, olasılık (probability) kümülatif dağılım fonksiyonuna ilişkin bilgileriq, çeyreklik (quantile) kümülatif dağılım fonksiyonunun tersine ilişkin bilgileriq, çeyreklik (quantile) kümülatif dağılım fonksiyonunun tersine ilişkin bilgilerid, yoğunluk (density) yoğunluk fonksiyonuna ilişkin bilgilerid, yoğunluk (density) yoğunluk fonksiyonuna ilişkin bilgilerir, rastgele (random) belirlenen dağılımdaki rastgele veriyir, rastgele (random) belirlenen dağılımdaki rastgele veriyiNormal dağılama uygun veri üretmek için rnorm()Tek biçimli (uniform) dağılıma ilişkin bir veri üretmek için runif()","code":"\nn=50\nnd1 <- rnorm(n=n, mean=50, sd=10)\nmean(nd1)\nsd(nd1)## [1] 49.7\n## [1] 8.86\nhist(nd1)\nnd2 <- runif(n=n, min=50, max=150)\nmin(nd2)\nsd(nd2)## [1] 50.8\n## [1] 30\nhist(nd2)"},{"path":"veri-üretimi.html","id":"iterasyon","chapter":"Bölüm 19 Veri Üretimi","heading":"19.2 İterasyon","text":"Veri üretimlerinde tek bir örneklemin elde edilmesi güvenilir olmayabilir.Örneğin, ortalaması 100, standart sapması 20 olan normal dağılıma ilişkin veri üretildiğinde, elde edilen ortalama değer bir örneklem için örnekleme hatasından dolayı100 değerinden göreceli olarak farklı çıkabilir.veri üretme çalışmalarında tekrarlamaların yapılması önemlidir.İterasyon, veri üretiminin fonksiyonlar ve döngüler kullanılarak genişletilmesi ve genellenebilir sonuçlar elde edilmesi olarak tanımlanabilir.","code":"\nset.seed(41)\nx <- rnorm(2, mean=100, sd=20)\nmean(x)## [1] 94\nn_k <- 10                 # Küçük örneklem\nn_b <- 50                 # Büyük örneklem\n\ntekrar <- 10000              # Tekrar sayısı\nkucuk_orn <- numeric(tekrar) # Küçük örneklem ort.\nbuyuk_orn <- numeric(tekrar) # Büyük örneklem ort.\n\norneklem.normal <- rnorm(n = 1000, mean = 35, sd = 15)#Sekil\n\nfor (i in 1:tekrar) {\n  kucuk_orn[i] <- mean(rnorm(n = n_k,mean =  35, sd = 15)  ) \n  buyuk_orn[i] <- mean(rnorm(n = n_b,mean =  35, sd = 15)  ) \n}\npar(mfrow = c(3,1))\nhist(orneklem.normal, breaks = 50, \nmain = \"Dağılımı\", xlab = \"\",col = \"steelblue\")\nhist(kucuk_orn, breaks = 50,\nmain = \"Küçük Örneklemlerin \\n Ortalama Dağılımı\", \nxlab = \"Ortalama\",col = \"steelblue\")\nhist(buyuk_orn, breaks = 50,\nmain = \"Büyük Örneklemlerin \\n Ortalama Dağılımı\", \nxlab = \"Ortalama\",col = \"steelblue\")"},{"path":"veri-üretimi.html","id":"iterasyonların-kaydedilmesi","chapter":"Bölüm 19 Veri Üretimi","heading":"19.3 İterasyonların Kaydedilmesi","text":"Özellikle büyük verilerle çalışırken, iterasyonlar uzun zamanlar alabilir. seferinde iterasyonların tekrarlanması yerine iterasyon sonuçlarının kaydedilip yeniden okutularak analizlere devam edilmesi gerekebilir.kucuk_orn ve buyuk_orn veri setlerini iki ayrı klasöre yazdırnız.Daha önce oluşturduğunuz kucuk_orn ve buyuk_orn veri setlerini iki ayrı klasörden okutup R nesnesi olarak yazdırınız.","code":"\ndir.create(\"Simulasyon_k\")\ndir.create(\"Simulasyon_b\")\n\nfor (i in 1:5) {\n  write.table(rnorm(n = n_k,mean =  35, sd = 15),\nfile=paste(\"Simulasyon_k/simulasyon_\",i,\".txt\", sep=\"\"))\n   \n  write.table(rnorm(n = n_b,mean =  35, sd = 15),\nfile=paste(\"Simulasyon_b/simulasyon_\",i,\".txt\", sep=\"\"))\n}\nkucuk_orn <- list()\nbuyuk_orn <- list()\nfor(i in 1:5){\nkucuk_orn[[i]] <-  \nread.table(file=paste(\"Simulasyon_k/simulasyon_\",i,\".txt\",\nsep=\"\"))\nbuyuk_orn[[i]] <-\nread.table(file=paste(\"Simulasyon_b/simulasyon_\",i,\".txt\",\nsep=\"\"))\n}"},{"path":"veri-üretimi.html","id":"psikometri-alanında-veri-üretimi","chapter":"Bölüm 19 Veri Üretimi","heading":"19.4 Psikometri Alanında Veri Üretimi","text":"Ölçme ve değerlendirme alanında gerçekleştirilen bazı çalışmalarda, çalışmanın amacı doğrultusunda, veri setlerinin üretilmesi gerekebilir.Bu çalışmalarda veri setleri çoğunlukla Monte Carlo (MC) teknikleri kullanılarak üretilir.MC yaklaşımında matematiksel bir model kullanılarak bilgisayar yazılımı aracılığıyla rastgele örneklemler elde edilebilir. MC çalışmaları ile parametre değerlerini belirlemek, çalışmada bazı faktörleri (madde sayısı gibi) sabit tutup bazı faktörleri (örneklem büyüklüğü gibi) manipüle ederek değişkenlerin etkilerini incelemek mümkündür.Böylece belli özellikleri önceden bilinen veri setleri, ele alınan koşullar altında, yöntemlerin veya modellerin değerlendirilmesine ve karşılatırılmasına olanak sağlar.Ancak sonuçların kullanışlılığı için MC çalışmalarında modellenen koşulların gerçek uygulamalara ne kadar yakın olduğuna, replikasyon sayısına, vb. dikkat edilmesi gerekir (Harwell & Others, 1996).Revelle (2019) tarafından üretilen psych ile YEM, MTK, ve KTK ya uygun veriler üretilebilir.Revelle (2019) tarafından üretilen psych ile YEM, MTK, ve KTK ya uygun veriler üretilebilir.Partchev (2017) tarafından yazılan irtoys paketinde bulunan 1, 2 ve 3 parametreli lojistik modele uygun veriler üretilebilir.Partchev (2017) tarafından yazılan irtoys paketinde bulunan 1, 2 ve 3 parametreli lojistik modele uygun veriler üretilebilir.Chalmers (2019) tarafından hazırlanan mirt paketiyle hem tamamlayıcı hem de tamamlayıcı olmayan ÇBMTK verisi üretilebilir.Chalmers (2019) tarafından hazırlanan mirt paketiyle hem tamamlayıcı hem de tamamlayıcı olmayan ÇBMTK verisi üretilebilir.** ...**** ...**","code":""},{"path":"veri-üretimi.html","id":"r-paketleri-ile-veri-üretimi","chapter":"Bölüm 19 Veri Üretimi","heading":"19.5 R Paketleri ile Veri Üretimi","text":"hangi model?hangi model?kaç madde?kaç madde?madde ve yetenek parametreleri ne olacak?madde ve yetenek parametreleri ne olacak?Aşama 1 3PL modele dayali 8 maddelik veri veri üretilmesi\nİlk aşama madde parametrelerinin belirlenmesiAşama 2\nİkinci aşama yetenek parametrelerinin belirlenmesi1000 kişilik normal dağılıma dayalı veri üretimiAşama 3 irtoys paketi sim fonksiyonu ile veri üretilmesiirtoys paketi sim fonksiyonu ile veri üretilmesiAşama 4Üretilen verinin parametrelerinin kestirimiVeri üretimini tekrarlamak için fonksiyon yazmamız lazım.Veri üretimini tekrarlamak için fonksiyon yazmamız lazım.Fonksiyon1\nmadde sayısı ve birey sayısına bağlı olarak\nmadde parametresi üretsin\nyetenek parametresi üretsin\nmadde cevapları üretsin\nçıktıda madde\nparametrelerini, yetenek parametrelerini\nve cevap matrisini tutsun\n\nFonksiyon1madde sayısı ve birey sayısına bağlı olarak\nmadde parametresi üretsin\nyetenek parametresi üretsin\nmadde cevapları üretsin\nçıktıda madde\nparametrelerini, yetenek parametrelerini\nve cevap matrisini tutsun\nmadde sayısı ve birey sayısına bağlı olarakmadde parametresi üretsinmadde parametresi üretsinyetenek parametresi üretsinyetenek parametresi üretsinmadde cevapları üretsinmadde cevapları üretsinçıktıda madde\nparametrelerini, yetenek parametrelerini\nve cevap matrisini tutsunçıktıda madde\nparametrelerini, yetenek parametrelerini\nve cevap matrisini tutsun","code":"\nset.seed(41)\nmadde <- 8\nmaddepar <- cbind(\nrnorm(madde, mean = 0, sd = 0.75)*1.702,    #a\nrnorm(madde, mean = 0.30, sd = 0.51)*1.702, #b\nrnorm(madde, mean = 0.16, sd = 0.05))       #c \nmaddepar##        [,1]      [,2]  [,3]\n## [1,] -1.014  1.379159 0.193\n## [2,]  0.252  2.409834 0.204\n## [3,]  1.279 -0.539118 0.170\n## [4,]  1.645  0.000801 0.274\n## [5,]  1.156  1.427334 0.115\n## [6,]  0.630  0.235798 0.267\n## [7,]  0.765  0.463257 0.102\n## [8,] -2.016  0.796831 0.158\nset.seed(41)\nbirey <- 1000\nyetenek <- rnorm(birey, mean = 0, sd = 1)\nyetenek[1:10]##  [1] -0.794  0.197  1.002  1.289  0.906  0.494  0.599 -1.580  1.001  2.188\nveri <- irtoys::sim(ip = maddepar, x = yetenek)\n  colnames(veri) <- paste0(\"madde\", 1:madde)\n  head(veri)##      madde1 madde2 madde3 madde4 madde5 madde6 madde7 madde8\n## [1,]      0      1      1      0      0      0      1      1\n## [2,]      1      0      1      1      0      1      0      0\n## [3,]      1      1      1      1      0      1      0      1\n## [4,]      1      1      0      1      0      1      1      0\n## [5,]      1      1      0      1      0      1      1      1\n## [6,]      1      0      1      1      0      1      0      0\nlibrary(irtoys)\nip = maddepar\nx = yetenek\nsim## function (ip, x = NULL) \n## {\n##     if (is.list(ip)) \n##         ip = ip$est\n##     i = irf(ip = ip, x = x)\n##     d = dim(i$f)\n##     u = runif(d[1] * d[2])\n##     dim(u) = d\n##     return(ifelse(i$f > u, 1, 0))\n## }\n## <bytecode: 0x000001d15e380f28>\n## <environment: namespace:irtoys>\nlibrary(mirt)\nmodel3PL <- mirt(veri, # cevap matrisi\n                 1,  # tek boyutlu model\n                 itemtype = \"3PL\", # 3PL\n                 verbose = FALSE, \n                 technical = list(NCYCLES = 1000,\n                 message = FALSE))\n\nmirt::coef(model3PL, IRTpars = TRUE, simplify = TRUE)$items##             a      b       g u\n## madde1 -1.096  1.541 0.00484 1\n## madde2  0.308  2.155 0.21580 1\n## madde3  1.093 -0.932 0.02929 1\n## madde4  1.353  0.071 0.24129 1\n## madde5  0.975  1.547 0.08119 1\n## madde6  1.007  1.079 0.47165 1\n## madde7  0.697  0.711 0.08023 1\n## madde8 -1.890  0.970 0.00211 1\nveri_uretimi <- function(madde, birey ){\n  .....\n}\nveri_uretimi <- function(maddesay, bireysay, seed) {\n  # seed ayaralanır\n  set.seed(seed)\n  # madde parametreleri üretilir.\n  maddepar <- cbind(\n    rnorm(maddesay, mean = 1.13, sd = 0.25)*1.702, #a\n    rnorm(maddesay, mean = 0.21, sd = 0.51)*1.702, #b\n    rnorm(maddesay, mean = 0.16, sd = 0.05)) #c\n  # yetenek parametreleri üretilir\n  yetenek <- rnorm(bireysay, mean = 0, sd = 1)\n  # 3PL modele göre veri uretimi\n  cevaplar <- irtoys::sim(ip = maddepar, x = yetenek)\n  colnames(cevaplar) <- paste0(\"madde\", 1:maddesay)\n  # Parametrelerin ve ciktinin nesnede toplanması\n  veri <- list(maddepar = maddepar,\n               yetenek = yetenek,\n               seed = seed,\n               cevaplar = cevaplar)\n  # Cikti\n  return(veri)\n}\nveri_1 <- veri_uretimi(madde = 8, birey = 1000, seed = 666)\nhead(veri_1$yetenek)## [1]  0.0306 -1.4823 -1.1266 -1.7638 -1.0626 -1.3430\nhead(veri_1$maddepar,3)##      [,1]   [,2]  [,3]\n## [1,] 2.24 -1.198 0.203\n## [2,] 2.78  0.321 0.177\n## [3,] 1.77  2.224 0.131\nhead(veri_1$cevaplar,3)##      madde1 madde2 madde3 madde4 madde5 madde6 madde7 madde8\n## [1,]      1      1      0      1      1      1      0      0\n## [2,]      0      0      0      0      1      0      1      0\n## [3,]      1      0      0      1      0      1      0      1"},{"path":"veri-üretimi.html","id":"paramtere-kestirimi","chapter":"Bölüm 19 Veri Üretimi","heading":"19.6 Paramtere kestirimi","text":"Fonksiyon2veri_uretimi fonksiyonu ile üretilen veri girdi olsunhangi modele göre kestirim yapacağı argüman olsun. (2PL ya da 3PL )çıktı olarak kestirilen parametre matrisi verilsin","code":"\nkestirilen_par <- function(veri, par=3){\n  \n  ....\n}\nkestirilen_par <- function(veri, par=3){\n\n  if(par==3){\n    model <- mirt::mirt(veri, # cevap matrisi\n                         1,  # tek boyutlu model\n                         itemtype = \"3PL\", # 3PL\n                         verbose = FALSE, \n                         technical = list(NCYCLES = 1000,\n                                          message = FALSE))\n  }else {\n        model <- mirt::mirt(veri, # cevap matrisi\n                         1,  # tek boyutlu model\n                         itemtype = \"2PL\", # 2pl\n                         verbose = FALSE, \n                         technical = list(NCYCLES = 1000,\n                                          message = FALSE))\n  }\n# Madde parametreleri\nkestirim <- as.data.frame(mirt::coef(model, IRTpars = TRUE, \nsimplify = TRUE)$item[,1:3])\nkestirim\n}\n\nkestirim <- kestirilen_par(veri_1$cevaplar)\nhead(kestirim)"},{"path":"veri-üretimi.html","id":"kestirilen-değerler-ve-gerçek-değerler","chapter":"Bölüm 19 Veri Üretimi","heading":"19.7 Kestirilen Değerler ve Gerçek Değerler","text":"RMSE bir madde için bir replikasyonda kestirilen parametre değeri ile gerçek parametre değeri arasındaki farkın karesinin ortalamasının kareköküdür\\[RMSE(\\tau) = \\sqrt\\frac{\\sum_{r}^{R} (\\hat{\\tau}- \\tau)^2}{R})\\]BIAS kestirime ilişkin sistematik hatayı ifade eden yanlılık bir madde için bir replikasyonda kestirilen parametre değerinin ortalaması ile gerçek parametre değeri arasındaki farktır ve aşağıdaki formül ile hesaplanır:\\[BIAS(\\tau) = \\frac{\\sum_{r}^{R}\\hat{\\tau}}{R} - \\tau\\]SE kestirime ilişkin rastgele hatayı ifade eden standart hata bir madde için bir replikasyonda kestirilen parametre değeri ile ortalama parametre kestirimi arasındaki farkın karesinin ortalamasının kareköküdür. Diğer bir ifadeyle replikasyonlarda kestirilen parametre değerlerinin standart sapmasıdır ve aşağıdaki formül ile hesaplanır:\\[SE(\\tau) = \\sqrt\\frac{\\sum_{r}^{R} (\\hat{\\tau}- \\overline{\\hat{\\tau}})^2}{R})\\]Yanlılığın karesi ile standart hatanın karesinin toplamı RMSE’nin karesinin toplamına eşittir. RMSE, yanlılık ve standart hata arasındaki ilişki aşağıdaki eşitlik ile gösterilebilir:\\[RMSE^2= Bias^2 +SE^2\\]","code":"\nhata <- function(kestirim, gercek) {\n  \n}\nkestirim =  kestirim\ngercek = veri_1$maddepa\nhata <- function(kestirim, gercek) {\nresult <- data.frame(parametreler = c(\"a\", \"b\", \"c\"),\n\nbias = sapply(1L:3L, function(i) mean((kestirim[, i] - gercek[,i]))),\n\nrmse = sapply(1L:3L, function(i) sqrt(mean((kestirim[, i] - gercek[,i])^2))),\n\nkorelasyon = sapply(1L:3L, function(i) cor(kestirim[, i], gercek[,i])))\n\nreturn(result)\n}\nhata(kestirim,veri_1$maddepar)"},{"path":"veri-üretimi.html","id":"r-paketleri-ile-veri-üretimi-1","chapter":"Bölüm 19 Veri Üretimi","heading":"19.8 R Paketleri ile Veri Üretimi","text":"Fonksiyon yazarken nelere dikkat etmeliyiz?","code":"\ntemp2 <- veri_uretimi(maddesay = 10, bireysay = 1000)## Error in veri_uretimi(maddesay = 10, bireysay = 1000): argument \"seed\" is missing, with no default\nveri_uretimi <- function(maddesay, bireysay, seed = NULL){\n  if(!is.null(seed)) {\n    set.seed(seed)}\n  else {\n    seed <- sample.int(10000, 1)\n    set.seed(seed)\n    cat(\"atanan seed = \", seed, \"\\n\")\n  }\n# madde parametreleri üretilir.\n  print(\"Madde parametresi uretme\")\n  \nmaddepar <- cbind(\n  rnorm(maddesay, mean = 1.13, sd = 0.25)*1.702, #a\n  rnorm(maddesay, mean = 0.21, sd = 0.51)*1.702, #b\n  rnorm(maddesay, mean = 0.16, sd = 0.05)) #c\n\n# yetenek parametreleri üretilir\nyetenek <- rnorm(bireysay, mean = 0, sd = 1)\n# 3PL modele göre veri uretimi\nprint(\"Üretilen veri\")\ncevaplar <- irtoys::sim(ip = maddepar, x = yetenek)\ncolnames(cevaplar) <- paste0(\"madde\", 1:maddesay)\n# Parametrelerin ve ciktinin nesnede toplanması\nprint(\"Cıktıların birleştirilmesi\")\nveri <- list(maddepar = maddepar,\n             yetenek = yetenek,\n             seed = seed,\n             cevaplar = cevaplar)\n# Cikti\nreturn(veri)\n}\n\n temp2 <- veri_uretimi(maddesay = 10, bireysay = 1000)## atanan seed =  5593 \n## [1] \"Madde parametresi uretme\"\n## [1] \"Üretilen veri\"\n## [1] \"Cıktıların birleştirilmesi\""},{"path":"veri-üretimi.html","id":"veri-üretiminde-tekrar","chapter":"Bölüm 19 Veri Üretimi","heading":"19.9 Veri Üretiminde Tekrar","text":"Tekrar etmek amacıyla döngülerden ya da apply fonksiyonlarından yararlanalılabilir.replicate fonksiyonu kullanıldığında oluşan çıktı liste biçiminde olacaktır.Oluşan nesnenin sadece maddepar bileşenin almak için\nçıktıların liste biçimindedirÇıktıların liste olmaması için sapply de kullanılabilir.","code":"replicate(tekrar sayisi, fonksiyon)\ntekrarsayisi=5L\nx <- replicate(tekrarsayisi, veri_uretimi(maddesay = 10, bireysay = 1000))## atanan seed =  7116 \n## [1] \"Madde parametresi uretme\"\n## [1] \"Üretilen veri\"\n## [1] \"Cıktıların birleştirilmesi\"\n## atanan seed =  727 \n## [1] \"Madde parametresi uretme\"\n## [1] \"Üretilen veri\"\n## [1] \"Cıktıların birleştirilmesi\"\n## atanan seed =  6970 \n## [1] \"Madde parametresi uretme\"\n## [1] \"Üretilen veri\"\n## [1] \"Cıktıların birleştirilmesi\"\n## atanan seed =  4875 \n## [1] \"Madde parametresi uretme\"\n## [1] \"Üretilen veri\"\n## [1] \"Cıktıların birleştirilmesi\"\n## atanan seed =  789 \n## [1] \"Madde parametresi uretme\"\n## [1] \"Üretilen veri\"\n## [1] \"Cıktıların birleştirilmesi\"\nlapply(1L:tekrarsayisi, function(i) x[,i][1])## [[1]]\n## [[1]]$maddepar\n##       [,1]   [,2]   [,3]\n##  [1,] 2.63 -0.570 0.0752\n##  [2,] 1.53  0.065 0.1859\n##  [3,] 1.27  1.798 0.0994\n##  [4,] 1.93  2.325 0.1950\n##  [5,] 2.36  0.461 0.1757\n##  [6,] 1.81  0.827 0.1840\n##  [7,] 2.26  1.668 0.1773\n##  [8,] 2.21  0.170 0.1471\n##  [9,] 2.46  0.392 0.1278\n## [10,] 2.23  0.370 0.1622\n## \n## \n## [[2]]\n## [[2]]$maddepar\n##       [,1]   [,2]   [,3]\n##  [1,] 2.45  0.946 0.2168\n##  [2,] 1.92 -0.918 0.1914\n##  [3,] 1.81  1.793 0.1693\n##  [4,] 2.44 -0.037 0.1583\n##  [5,] 2.21  0.938 0.1930\n##  [6,] 1.77  0.582 0.1354\n##  [7,] 2.70  0.729 0.1620\n##  [8,] 2.20  0.657 0.1847\n##  [9,] 1.37 -0.646 0.0643\n## [10,] 2.32  0.275 0.2355\n## \n## \n## [[3]]\n## [[3]]$maddepar\n##        [,1]    [,2]   [,3]\n##  [1,] 0.953 -0.9018 0.1527\n##  [2,] 1.629  1.1330 0.1238\n##  [3,] 1.983  0.6882 0.2082\n##  [4,] 2.341 -0.0603 0.1029\n##  [5,] 1.816 -0.1821 0.0628\n##  [6,] 0.877  0.2849 0.1136\n##  [7,] 2.068  0.6827 0.1639\n##  [8,] 2.132  1.7466 0.1687\n##  [9,] 1.958  0.5841 0.1750\n## [10,] 1.622 -0.8964 0.0769\n## \n## \n## [[4]]\n## [[4]]$maddepar\n##       [,1]     [,2]   [,3]\n##  [1,] 1.66  0.53978 0.2016\n##  [2,] 2.06 -0.10367 0.1652\n##  [3,] 1.91 -0.00871 0.1806\n##  [4,] 1.73  1.60843 0.1435\n##  [5,] 2.06 -0.50558 0.0348\n##  [6,] 1.18 -0.59864 0.1434\n##  [7,] 2.25  2.52695 0.0724\n##  [8,] 2.12  2.02581 0.1501\n##  [9,] 2.16  0.15750 0.1643\n## [10,] 1.90  0.06026 0.2402\n## \n## \n## [[5]]\n## [[5]]$maddepar\n##        [,1]     [,2]   [,3]\n##  [1,] 2.146  0.00822 0.1249\n##  [2,] 0.961 -0.51301 0.1942\n##  [3,] 1.915  0.20316 0.1171\n##  [4,] 2.001 -0.06609 0.1784\n##  [5,] 1.770  1.16286 0.0885\n##  [6,] 1.717 -0.31480 0.1344\n##  [7,] 1.640  0.72448 0.1466\n##  [8,] 1.849 -0.16944 0.1500\n##  [9,] 1.493  0.53916 0.2028\n## [10,] 2.238 -0.31732 0.1517\nsapply(1L:tekrarsayisi, function(i) x[,i][1])## $maddepar\n##       [,1]   [,2]   [,3]\n##  [1,] 2.63 -0.570 0.0752\n##  [2,] 1.53  0.065 0.1859\n##  [3,] 1.27  1.798 0.0994\n##  [4,] 1.93  2.325 0.1950\n##  [5,] 2.36  0.461 0.1757\n##  [6,] 1.81  0.827 0.1840\n##  [7,] 2.26  1.668 0.1773\n##  [8,] 2.21  0.170 0.1471\n##  [9,] 2.46  0.392 0.1278\n## [10,] 2.23  0.370 0.1622\n## \n## $maddepar\n##       [,1]   [,2]   [,3]\n##  [1,] 2.45  0.946 0.2168\n##  [2,] 1.92 -0.918 0.1914\n##  [3,] 1.81  1.793 0.1693\n##  [4,] 2.44 -0.037 0.1583\n##  [5,] 2.21  0.938 0.1930\n##  [6,] 1.77  0.582 0.1354\n##  [7,] 2.70  0.729 0.1620\n##  [8,] 2.20  0.657 0.1847\n##  [9,] 1.37 -0.646 0.0643\n## [10,] 2.32  0.275 0.2355\n## \n## $maddepar\n##        [,1]    [,2]   [,3]\n##  [1,] 0.953 -0.9018 0.1527\n##  [2,] 1.629  1.1330 0.1238\n##  [3,] 1.983  0.6882 0.2082\n##  [4,] 2.341 -0.0603 0.1029\n##  [5,] 1.816 -0.1821 0.0628\n##  [6,] 0.877  0.2849 0.1136\n##  [7,] 2.068  0.6827 0.1639\n##  [8,] 2.132  1.7466 0.1687\n##  [9,] 1.958  0.5841 0.1750\n## [10,] 1.622 -0.8964 0.0769\n## \n## $maddepar\n##       [,1]     [,2]   [,3]\n##  [1,] 1.66  0.53978 0.2016\n##  [2,] 2.06 -0.10367 0.1652\n##  [3,] 1.91 -0.00871 0.1806\n##  [4,] 1.73  1.60843 0.1435\n##  [5,] 2.06 -0.50558 0.0348\n##  [6,] 1.18 -0.59864 0.1434\n##  [7,] 2.25  2.52695 0.0724\n##  [8,] 2.12  2.02581 0.1501\n##  [9,] 2.16  0.15750 0.1643\n## [10,] 1.90  0.06026 0.2402\n## \n## $maddepar\n##        [,1]     [,2]   [,3]\n##  [1,] 2.146  0.00822 0.1249\n##  [2,] 0.961 -0.51301 0.1942\n##  [3,] 1.915  0.20316 0.1171\n##  [4,] 2.001 -0.06609 0.1784\n##  [5,] 1.770  1.16286 0.0885\n##  [6,] 1.717 -0.31480 0.1344\n##  [7,] 1.640  0.72448 0.1466\n##  [8,] 1.849 -0.16944 0.1500\n##  [9,] 1.493  0.53916 0.2028\n## [10,] 2.238 -0.31732 0.1517"},{"path":"veri-üretimi.html","id":"doparallel","chapter":"Bölüm 19 Veri Üretimi","heading":"19.10 doParallel","text":"","code":"\ntekrar = 4 \nseed = sample.int(10000, 100)\nmaddesay = 10 # 10, 15, 20, or 25\nbireysay = 1000 # 250, 500, 750, or 1000\nlibrary(doParallel)\ndetectCores()\ncl <- makeCluster(4) # en fazla n-2 \nregisterDoParallel(cl)\n# burada kod\nstopCluster(cl)"},{"path":"veri-üretimi.html","id":"foreach","chapter":"Bölüm 19 Veri Üretimi","heading":"19.10.1 foreach","text":"Döngüler yavas olabilir, apply ailesi çıktıları kullanışlı olmayabilir.Cikti düzenleme","code":"\nlibrary(doParallel)## Loading required package: foreach## \n## Attaching package: 'foreach'## The following objects are masked from 'package:purrr':\n## \n##     accumulate, when## Loading required package: iterators## Loading required package: parallel\nforeach(i=1:4) %do% sqrt(i)## [[1]]\n## [1] 1\n## \n## [[2]]\n## [1] 1.41\n## \n## [[3]]\n## [1] 1.73\n## \n## [[4]]\n## [1] 2\n#coklu arguman\nforeach(i=1:4, j=1:4) %do%\n    sqrt(i+j)## [[1]]\n## [1] 1.41\n## \n## [[2]]\n## [1] 2\n## \n## [[3]]\n## [1] 2.45\n## \n## [[4]]\n## [1] 2.83\nfor(i in 1:5) {\n    sum(rnorm(1e6))\n} \nlibrary(doParallel)\ncl <- makeCluster(4) # en fazla n-2 \nregisterDoParallel(cl)\n foreach(i=1:5) %dopar% {\n    sum(rnorm(1e6))\n }   \nstopCluster(cl) # cekirdek atama işini bitirir.## [[1]]\n## [1] -984\n## \n## [[2]]\n## [1] 1140\n## \n## [[3]]\n## [1] -845\n## \n## [[4]]\n## [1] -1721\n## \n## [[5]]\n## [1] 1800\ncl <- makeCluster(4) \nregisterDoParallel(cl)\n\ntekrar = 4 \nseed = sample.int(10000, 100)\nmaddesay = 10 # 10, 15, 20, or 25\nbireysay = 1000 # 250, 500, 750, or 1000\n\nsimulasyon <- foreach(i=1:4,\n             .packages = c(\"mirt\", \"doParallel\"),\n             .combine = rbind) %dopar% {\n             # Adım 1 madde parametrelerini ve veri setini üretme\n             adim1 <- veri_uretimi(maddesay =maddesay, \n                      bireysay =bireysay, seed=seed[i])\n             # Adım 2 üretilen veri seti üzerinden ketsirim yapma\n             adim2 <- kestirilen_par(adim1$cevaplar)\n             # adim 3 raporlama\n             hata(adim2, adim1$maddepar)\n            }\nsimulasyon\nlibrary(tidyverse)\nsimulasyon_v1 <- simulasyon %>%\n  group_by(parametreler) %>%\n  summarise(bias = round(mean(bias),3),\n            rmse = round(mean(rmse),3),\n            korelasyon = round(mean(korelasyon),3)) %>%\n  mutate(maddesay = maddesay,\n         bireysay = bireysay) %>%\n  as.data.frame()\nsimulasyon_v1\ntekrar = 1;seed = sample.int(10000, 100)\nmaddesay = c(10, 20 ,40)\nbireysay = c(250, 500, 1000)\n\n# kumeler \ncl <- makeCluster(6);registerDoParallel(cl)\n\n# İc ice foreachler\nsonuc <- foreach(i=1:tekrar, \n                      .packages = c(\"mirt\", \"doParallel\", \"dplyr\"),\n                      .combine = rbind) %:%\n  foreach(j=maddesay, \n          .packages = c(\"mirt\", \"doParallel\", \"dplyr\"),\n          .combine = rbind)  %:%\n  foreach(k=bireysay, \n          .packages = c(\"mirt\", \"doParallel\", \"dplyr\"),\n          .combine = rbind)    %dopar% {\n            adim1 <- veri_uretimi(maddesay=j, bireysay=k, seed=seed[i])\n            adim2 <- kestirilen_par(adim1$cevaplar)\n            adim3 <- hata(adim2, adim1$maddepar)\n            adim3 %>%\n              group_by(parametreler) %>%\n              summarise(bias = round(mean(bias),3),\n                        rmse = round(mean(rmse),3),\n                        korelasyon = round(mean(korelasyon),3)) %>%\n              mutate(maddesay = j, bireysay = k,\n              ) %>%              as.data.frame()\n          }\n\nstopCluster(cl)\n write.table(adim3, \"results.csv\", \n                        sep = \",\", \n                        col.names = FALSE, \n                        row.names = FALSE, \n                        append = TRUE) # sonuçların eklenmesi için dosyayı \n                                         # açık tutacaktır\niterations = 4; seed = sample.int(10000, 100)\nmaddesay = 10 ;bireysay = 1000 #250, 500, 750, or 1000\nlibrary(\"doSNOW\")\ncl <- makeCluster(4);registerDoSNOW(cl)\n\npb <- txtProgressBar(max = iterations, style = 3) # Progres bar\nprogress <- function(n) {setTxtProgressBar(pb, n)}\nopts <- list(progress = progress)\nsonuc <- foreach(i=1:iterations,\n                      .packages = c(\"mirt\", \"doSNOW\"),\n                      .options.snow = opts, #\n                      .combine = rbind) %dopar% {\n                        # Generate item parameters and data\n                        adim1 <- veri_uretimi(maddesay  , bireysay, seed=seed[i])\n                        # Estimate item parameters\n                        adim2 <- kestirilen_par(adim1$cevaplar)\n                        # Summarize results\n                        hata(adim2, adim1$maddepar)\n                      }\nclose(pb) # kapat progress bar\nstopCluster(cl)## \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |==================                                                    |  25%\n  |                                                                            \n  |===================================                                   |  50%\n  |                                                                            \n  |====================================================                  |  75%\n  |                                                                            \n  |======================================================================| 100%"},{"path":"pl-verisinin-üretimi.html","id":"pl-verisinin-üretimi","chapter":"Bölüm 20 2pl Verisinin Üretimi","heading":"Bölüm 20 2pl Verisinin Üretimi","text":"İki Kategorili Madde Puanları üretimi Rasch modele görep <- 1/(1+exp(-(theta-bb))İki Kategorili Madde Puanları üretimi 2pl modele görep <- 1/(1+exp(-((aa)*(theta-bb))))","code":"\nb <- rnorm(20, 0, 1)\ntheta <- rnorm(1000, 0, 1)\nmadde_sayisi <- length(b)\nkisi_sayisi <- length(theta)\nreplikasyon <- 10\nb.mat <- matrix(b, kisi_sayisi, madde_sayisi, byrow=T)\nhead(b.mat)##           [,1]       [,2]       [,3]       [,4]     [,5]      [,6]      [,7]\n## [1,] 0.5155049 -0.4432878 -0.2412438 -0.8347979 1.671411 0.5068067 -1.583434\n## [2,] 0.5155049 -0.4432878 -0.2412438 -0.8347979 1.671411 0.5068067 -1.583434\n## [3,] 0.5155049 -0.4432878 -0.2412438 -0.8347979 1.671411 0.5068067 -1.583434\n## [4,] 0.5155049 -0.4432878 -0.2412438 -0.8347979 1.671411 0.5068067 -1.583434\n## [5,] 0.5155049 -0.4432878 -0.2412438 -0.8347979 1.671411 0.5068067 -1.583434\n## [6,] 0.5155049 -0.4432878 -0.2412438 -0.8347979 1.671411 0.5068067 -1.583434\n##           [,8]       [,9]      [,10]     [,11]      [,12]    [,13]     [,14]\n## [1,] -1.295396 -0.2259059 -0.4563871 0.1515573 -0.9796441 0.926898 0.4341016\n## [2,] -1.295396 -0.2259059 -0.4563871 0.1515573 -0.9796441 0.926898 0.4341016\n## [3,] -1.295396 -0.2259059 -0.4563871 0.1515573 -0.9796441 0.926898 0.4341016\n## [4,] -1.295396 -0.2259059 -0.4563871 0.1515573 -0.9796441 0.926898 0.4341016\n## [5,] -1.295396 -0.2259059 -0.4563871 0.1515573 -0.9796441 0.926898 0.4341016\n## [6,] -1.295396 -0.2259059 -0.4563871 0.1515573 -0.9796441 0.926898 0.4341016\n##          [,15]     [,16]     [,17]    [,18]      [,19]    [,20]\n## [1,] 0.6198547 -0.158973 0.3318957 1.078609 -0.3191135 1.400262\n## [2,] 0.6198547 -0.158973 0.3318957 1.078609 -0.3191135 1.400262\n## [3,] 0.6198547 -0.158973 0.3318957 1.078609 -0.3191135 1.400262\n## [4,] 0.6198547 -0.158973 0.3318957 1.078609 -0.3191135 1.400262\n## [5,] 0.6198547 -0.158973 0.3318957 1.078609 -0.3191135 1.400262\n## [6,] 0.6198547 -0.158973 0.3318957 1.078609 -0.3191135 1.400262\ntheta.mat <- matrix(theta, kisi_sayisi, madde_sayisi)\nhead(theta.mat)##            [,1]       [,2]       [,3]       [,4]       [,5]       [,6]\n## [1,]  0.3253951  0.3253951  0.3253951  0.3253951  0.3253951  0.3253951\n## [2,] -0.9508433 -0.9508433 -0.9508433 -0.9508433 -0.9508433 -0.9508433\n## [3,] -1.3800811 -1.3800811 -1.3800811 -1.3800811 -1.3800811 -1.3800811\n## [4,] -0.7764768 -0.7764768 -0.7764768 -0.7764768 -0.7764768 -0.7764768\n## [5,] -0.8268484 -0.8268484 -0.8268484 -0.8268484 -0.8268484 -0.8268484\n## [6,]  0.4029838  0.4029838  0.4029838  0.4029838  0.4029838  0.4029838\n##            [,7]       [,8]       [,9]      [,10]      [,11]      [,12]\n## [1,]  0.3253951  0.3253951  0.3253951  0.3253951  0.3253951  0.3253951\n## [2,] -0.9508433 -0.9508433 -0.9508433 -0.9508433 -0.9508433 -0.9508433\n## [3,] -1.3800811 -1.3800811 -1.3800811 -1.3800811 -1.3800811 -1.3800811\n## [4,] -0.7764768 -0.7764768 -0.7764768 -0.7764768 -0.7764768 -0.7764768\n## [5,] -0.8268484 -0.8268484 -0.8268484 -0.8268484 -0.8268484 -0.8268484\n## [6,]  0.4029838  0.4029838  0.4029838  0.4029838  0.4029838  0.4029838\n##           [,13]      [,14]      [,15]      [,16]      [,17]      [,18]\n## [1,]  0.3253951  0.3253951  0.3253951  0.3253951  0.3253951  0.3253951\n## [2,] -0.9508433 -0.9508433 -0.9508433 -0.9508433 -0.9508433 -0.9508433\n## [3,] -1.3800811 -1.3800811 -1.3800811 -1.3800811 -1.3800811 -1.3800811\n## [4,] -0.7764768 -0.7764768 -0.7764768 -0.7764768 -0.7764768 -0.7764768\n## [5,] -0.8268484 -0.8268484 -0.8268484 -0.8268484 -0.8268484 -0.8268484\n## [6,]  0.4029838  0.4029838  0.4029838  0.4029838  0.4029838  0.4029838\n##           [,19]      [,20]\n## [1,]  0.3253951  0.3253951\n## [2,] -0.9508433 -0.9508433\n## [3,] -1.3800811 -1.3800811\n## [4,] -0.7764768 -0.7764768\n## [5,] -0.8268484 -0.8268484\n## [6,]  0.4029838  0.4029838\ndir.create(\"Rasch\")## Warning in dir.create(\"Rasch\"): 'Rasch' already exists\nfor (r in 1:replikasyon){\n  logit <- (theta.mat-b.mat)\n  P <- 1/(1+exp(-logit))\n  head(P)\n  rand <- matrix(runif(kisi_sayisi*madde_sayisi), kisi_sayisi, madde_sayisi)\n  res <- ifelse(P>rand, 1, 0)\n  write.table(res, file=paste(\"Rasch/Rasch_rep\",r,\".txt\",sep=\"\"), sep=\",\", \n              row.names=F, col.names=F, na=\" \", quote=F)\n}\nset.seed(21)\na <- round(rlnorm(20, meanlog=0.000, sdlog=0.200), 3)\nb <- round(rnorm(20, mean=0.000, sd=1.000), 3)\nk <- length(b)\n\nset.seed(41)\nbirey <- rnorm(400, mean=0.500, sd=0.750)\nn <- length(birey)\ntheta <- rep(birey, k)\naa <- rep(a, each=n)\nbb <- rep(b, each=n)\np <- 1/(1+exp(-((aa)*(theta-bb))))\nhead(round(p, 3))## [1] 0.361 0.574 0.732 0.779 0.715 0.636\nrr <- runif(n*k, 0, 1)\nhead(round(rr, 3))## [1] 0.339 0.154 0.363 0.315 0.627 0.177\npuan <- ifelse(p>rr, 1, 0)\npuan <- matrix(puan, ncol=k)\nmadde2PL <- matrix(scan(\"import/madde2PL.dat\"), byrow=TRUE, ncol=3)\nset.seed(41)\nbirey <- rnorm(400)\npuan2PL <- function(madde, birey){\n  a <- madde[, 1]\n  b <- madde[, 2]\n  k <- length(b)\n  n <- length(birey)\n  theta <- rep(birey, k)\n  aa <- rep(a, each=n)\n  bb <- rep(b, each=n)\n  p <- 1/(1+exp(-((aa)*(theta-bb))))\n  rr <- runif(n*k, 0, 1)\n  puan <- ifelse(p>rr, 1, 0)\n  puan <- matrix(puan, ncol=k)\n  return(puan)\n}"},{"path":"pl-verisinin-üretimi.html","id":"çok-kategorili-madde-puanları-verisinin-üretimi","chapter":"Bölüm 20 2pl Verisinin Üretimi","heading":"20.1 Çok Kategorili Madde Puanları Verisinin Üretimi","text":"madde ve birey parametrelerinin değerlerinin belirlenmesimadde ve birey parametrelerinin değerlerinin belirlenmesiAşamalı tepki modeli (ATM) için, bir bireyin maddesini x kategorisinde veya x kategorisinin üstünde yanıtlama olasılığı p hesaplanır.Aşamalı tepki modeli (ATM) için, bir bireyin maddesini x kategorisinde veya x kategorisinin üstünde yanıtlama olasılığı p hesaplanır.Daha sonra hesaplanan olasılık değerleriyle karşılaştırmak üzere 0 ile 1 aralığında tek biçimli (uniform) rastgele değerler (u) üretilir.Daha sonra hesaplanan olasılık değerleriyle karşılaştırmak üzere 0 ile 1 aralığında tek biçimli (uniform) rastgele değerler (u) üretilir.Üretilen bir değer ilgili olasılık değeriyle karşılaştırılır.Üretilen bir değer ilgili olasılık değeriyle karşılaştırılır.Rastgele değer, x kategorisinde hesaplanan olasılık değerinden küçük ancak x+1 kategorisinde hesaplanan olasılık değerinden büyük ise madde puanı olarak x-1 değeri atanır.Rastgele değer, x kategorisinde hesaplanan olasılık değerinden küçük ancak x+1 kategorisinde hesaplanan olasılık değerinden büyük ise madde puanı olarak x-1 değeri atanır.parametresia parametresib1 parametresidiger b parametreleriMadde sayısının nesneye atanması\\[P^*_{ix}(\\theta) = \\frac{exp[a_i(\\theta-b_{im})]}{1+exp[a_i(\\theta-b_{im})]} = \\frac{1}{1+exp{-[a_i(\\theta-b_{im})]}}\\]\n- \\(P^*_{ix}\\): \\(θ\\) yetenek düzeyinde bir birey için \\(\\) maddesini \\(x\\) kategorisinde veya \\(x\\) kategorisinin üstünde yanıtlama olasılığıdır.\\(a_i\\), \\(\\) maddesi \\(\\) parametresidir.\\(a_i\\), \\(\\) maddesi \\(\\) parametresidir.\\(b_im\\) \\(\\) maddesi için \\(m\\) (m=x-1) kategori eşiği ile ilişkili kategori eşik parametresidir.\\(b_im\\) \\(\\) maddesi için \\(m\\) (m=x-1) kategori eşiği ile ilişkili kategori eşik parametresidir.Formüle karşılık gelen bir kategori için olasılık değerlerine ilişkin R komutları aşağıdaki gibidir:Formüle karşılık gelen bir kategori için olasılık değerlerine ilişkin R komutları aşağıdaki gibidir:p1 <- 1/(1+exp(-((aa)*(theta-bb1))))p1 <- 1/(1+exp(-((aa)*(theta-bb1))))p2 <- 1/(1+exp(-((aa)*(theta-bb2))))p2 <- 1/(1+exp(-((aa)*(theta-bb2))))p3 <- 1/(1+exp(-((aa)*(theta-bb3))))p3 <- 1/(1+exp(-((aa)*(theta-bb3))))p4 <- 1/(1+exp(-((aa)*(theta-bb4))))p4 <- 1/(1+exp(-((aa)*(theta-bb4))))bir bireyin bir maddeye ilişkin belirli bir kategorinin üstünde yanıt verme olasılıklarını (p1, p2, p3 ve p4) hesaplamak için birey parametresinin madde sayısı kadar tekrar etmesi gerekmektedir.bir bireyin bir maddeye ilişkin belirli bir kategorinin üstünde yanıt verme olasılıklarını (p1, p2, p3 ve p4) hesaplamak için birey parametresinin madde sayısı kadar tekrar etmesi gerekmektedir.Yetenek bireyin tekrarlanmasıYetenek bireyin tekrarlanmasıMadde parametrelerinin tekrarlanmasıMadde Puanlarının Atanması\"puan\" matrisinin ilk 2 satırının seçilmesi","code":"\nset.seed(26)\na <- round(rlnorm(8, meanlog=0.000, sdlog=0.200), 3)\na## [1] 0.653 1.258 0.907 1.180 0.921 1.030 1.026 1.201\nb1 <- seq(from=-2.500, to=-0.750, by=0.250)\nb2 <- b1+1.250\nb3 <- b2+1.250\nb4 <- b3+1.250\ncbind(b1,b2,b3,b4)##         b1    b2   b3   b4\n## [1,] -2.50 -1.25 0.00 1.25\n## [2,] -2.25 -1.00 0.25 1.50\n## [3,] -2.00 -0.75 0.50 1.75\n## [4,] -1.75 -0.50 0.75 2.00\n## [5,] -1.50 -0.25 1.00 2.25\n## [6,] -1.25  0.00 1.25 2.50\n## [7,] -1.00  0.25 1.50 2.75\n## [8,] -0.75  0.50 1.75 3.00\nk <- length(a)\nk## [1] 8\nset.seed(46)\nbirey <- rnorm(400)\nn <- length(birey)\nn## [1] 400\ntheta <- rep(birey, k)\naa  <- rep(a, each=n)\nbb1 <- rep(b1, each=n)\nbb2 <- rep(b2, each=n)\nbb3 <- rep(b3, each=n)\nbb4 <- rep(b4, each=n)\np1 <- 1/(1+exp(-((aa)*(theta-bb1))))\np2 <- 1/(1+exp(-((aa)*(theta-bb2))))\np3 <- 1/(1+exp(-((aa)*(theta-bb3))))\np4 <- 1/(1+exp(-((aa)*(theta-bb4))))\npar <- cbind(p1,p2,p3,p4)\nhead(par)##             p1        p2        p3        p4\n## [1,] 0.7399113 0.5570647 0.3573252 0.1973021\n## [2,] 0.8545847 0.7220738 0.5345751 0.3367685\n## [3,] 0.7607382 0.5843073 0.3832516 0.2155112\n## [4,] 0.9197751 0.8352146 0.6914261 0.4976362\n## [5,] 0.9165028 0.8291341 0.6820595 0.4867537\n## [6,] 0.7731207 0.6010321 0.3997558 0.2274559\nrr <- runif(n*k, 0, 1)\nhead(par)##             p1        p2        p3        p4\n## [1,] 0.7399113 0.5570647 0.3573252 0.1973021\n## [2,] 0.8545847 0.7220738 0.5345751 0.3367685\n## [3,] 0.7607382 0.5843073 0.3832516 0.2155112\n## [4,] 0.9197751 0.8352146 0.6914261 0.4976362\n## [5,] 0.9165028 0.8291341 0.6820595 0.4867537\n## [6,] 0.7731207 0.6010321 0.3997558 0.2274559\nhead(rr, 6)## [1] 0.3757090 0.4476721 0.7699587 0.7494361 0.9873121 0.9012236##      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8]\n## [1,]    2    1    3    0    0    2    0    0\n## [2,]    3    4    3    3    2    2    1    4\n## [3,]    0    2    2    1    1    2    1    1\n## [4,]    2    3    2    4    3    3    1    2\n## [5,]    0    4    1    2    0    0    1    2\n## [6,]    0    2    1    1    2    2    1    2\npuan <- 0\nfor (j in 1:(k*n)){\n  if((rr[j]>p1[j]))puan[j] <- 0 \n  else if((rr[j]<p1[j]&rr[j]>p2[j]))puan[j] <- 1 \n  else if((rr[j]<p2[j]&rr[j]>p3[j]))puan[j] <- 2 \n  else if((rr[j]<p3[j]&rr[j]>p4[j]))puan[j] <- 3 \n  else puan[j] <- 4 \n}\n\npuan <- matrix(puan, ncol=k)\npuan[1:2,]\nid <- matrix(1:n, ncol=1)\n\ndata <- cbind(id, puan)##      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8]\n## [1,]    2    1    3    0    0    2    0    0\n## [2,]    3    4    3    3    2    2    1    4\nmaddeAT <- cbind(a,b1,b2,b3,b4)\nbirey <- rnorm(400)\nlibrary(mirt)## Loading required package: stats4## Loading required package: lattice\na <- matrix(rlnorm(20,.2,.3))\ndiffs <- t(apply(matrix(runif(20*4, .3, 1), 20), 1, cumsum))\ndiffs <- -(diffs - rowMeans(diffs))\nd <- diffs + rnorm(20)\ndat <- simdata(a, d, 500, itemtype = 'graded')\nhead(dat)##      Item_1 Item_2 Item_3 Item_4 Item_5 Item_6 Item_7 Item_8 Item_9 Item_10\n## [1,]      4      2      4      0      1      4      0      4      4       3\n## [2,]      1      0      3      2      0      3      0      4      3       1\n## [3,]      0      0      4      0      0      4      0      4      1       1\n## [4,]      3      0      2      1      1      4      4      2      0       0\n## [5,]      3      0      4      0      3      4      0      2      1       0\n## [6,]      4      4      4      4      4      4      0      4      4       4\n##      Item_11 Item_12 Item_13 Item_14 Item_15 Item_16 Item_17 Item_18 Item_19\n## [1,]       4       4       2       4       4       4       3       3       4\n## [2,]       2       2       3       4       0       0       2       0       0\n## [3,]       0       4       2       2       0       0       0       0       2\n## [4,]       0       1       0       0       0       0       0       0       0\n## [5,]       0       4       3       2       0       1       0       0       2\n## [6,]       4       4       4       4       4       4       4       4       4\n##      Item_20\n## [1,]       3\n## [2,]       2\n## [3,]       0\n## [4,]       3\n## [5,]       0\n## [6,]       2"}]
