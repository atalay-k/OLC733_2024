# Çoklu Regresyon

- Çok değişkenli analiz, bir çalışmadaki bireylerden veya 
nesnelerden elde edilen çoklu ölçümlerin aynı anda 
analizidir. Dolayısıyla **ikiden fazla değişkenin** aynı anda 
analizi çok değişkenli analiz olarak düşünülebilir.


- Çoklu regresyon, basit regresyonun tek bir bağımlı değişkenin 
**iki veya daha fazla yordayıcısına** izin veren uzantısıdır. Diğer bir 
ifadeyle, çoklu regresyon tek bir bağımlı değişken ile **iki veya daha 
fazla bağımsız (yordayıcı)** değişken arasındaki ilişkinin analiz 
edilmesi için kullanılan istatistiksel bir yöntemdir. 

- Çoklu regresyonun amacı değerleri bilinen **bağımsız değişkenleri 
kullanarak bağımlı değişkenin değerini** yordamaktır. 

- Regresyon yöntemiyle **bağımsız değişkenlerden en fazla yordamayı 
sağlamak üzere her bağımsız değişken**  ağırlıklandırılır. 


- Ağırlıklar bağımsız değişkenin **yordamaya bağıl katkısını** ifade eder 
ve her bir  değişkenin yordamadaki etkisine ilişkin yorumlamayı kolaylaştırır. 

- Çoklu regresyon, hem bağımlı değişken hem de bağımsız 
değişkenler **en az eşit aralıklı ölçek düzeyinde** ölçüldüğünde 
kullanılmalıdır. 

- Ancak bağımsız değişkenler **sınıflama veya sıralama ölçeğinde** ölçüldüğünde ilgili değişkenler **belli koşullar**
altında analize dahil edilebilir.

- Çoklu regresyon her bir bağımsız değişkendeki değişikliklerin 
**bağımlı değişkendeki değişikliklerle ne ölçüde** ilişkili olduğunu 
kestirir. 

- Ancak **bağımsız değişkenler arasındaki korelasyon**
yordama sürecini zorlaştırır.


## Bağımsız değişkenler arasındaki ilişki
ceteris paribus



Örneğin, $X_1$ ve $Y$ arasındaki  korelasyon katsayısı **0.40**, $X_2$ ve $Y$
arasındaki korelasyon katsayısı **0.60**, $X_1$ ve $X_2$ arasındaki korelasyon 
katsayısı sıfır ise, $Y$’nin  varyansının iki değişken tarafından 
açıklanan toplam oranı iki  değişkenin $Y$ ile korelasyonlarının 
kareleri toplamından elde edilebilir: 

$0.40^2 + 0.50^2 = 0.16 + 0.25 = 0.41$


<img src="images/CR_1.PNG" width="75%" style="display: block; margin: auto;" />



- Ancak, uygulamada çoğunlukla $X_1$ ve $X_2$ birlikte değişim gösterirler 
ve iki değişkenin  $Y$ ile korelasyonlarının kareleri toplamı 
çok yüksek bir oran verir. 

- Bunun nedeni, iki bağımsız  değişkenin aralarındaki  korelasyondan dolayı
her bir  bağımsız değişken tarafından  açıklanan $Y$ varyansının bir  kısmının üst üste gelmesidir. 

- Çoklu regresyonun en önemli  özelliği modele eklenen bağımsız 
değişkenler arasındaki ilişkileri kontrol altına almasıdır. 



<img src="images/CR_2.PNG" width="75%" style="display: block; margin: auto;" />






- Modeldeki bağımsız değişkenler arasındaki ilişkilerin kontrol altına alınması, modeldeki bir değişkenin bağımlı değişken üzerindeki etkisini incelerken, modeldeki diğer bütün değişkenlerin sabit tutulmasıdır.**ceteris paribus**

 - Örneğin, bir çalışmada kahve tüketiminin ölüm oranını nasıl etkilediği çalışılmıştır. Başta, sonuçlar daha yüksek kahve tuketiminin daha yüksek ölüm riskiyle ilişkili olduğunu göstermiştir. Ancak kahve içen çoğu kişisigara da içmektedir. Araştırmacılar modellerine sigara icme aliskanliklari icin bir değişken eklediklerinde, sigara içmenin ölüm riskini artırırken, kahve tüketiminin ölüm riskini azalttığını bulmuşlardır.

- Bu durumda modele bütün önemli değişkenlerin eklenmesi gerekmektedir. Önemli değişkenlerin modelin dışında bırakılması, katsayılara ilişkin kestirimlerin **yanlı** olmasına neden olabilmektedir.



## Çoklu Regresyon Uygulama

- Öğrencilerin matematikteki **performans düzeylerini, motivasyon ve 
kaygı düzeylerinden yordamak** ile ilgilendiğimizi düşünelim.

- Bu araştırma sorusuna cevap vermek için çoklu regresyon uygun bir 
istatistiksel analiz yöntemdir.

$$Y_{\text{performans_i}} = b_0 + b_1 X_{\text{motivasyon_i}} +  b_2 X_{\text{kaygi_i}} + e_i$$

- Burada, $b_1$ ve $b_2$ motivasyon ve kaygı yordayıcıları için ağırlıklardır. Diğer bir ifadeyle regresyon katsayılarıdır veya eğimlerdir. $b_0$ ise kesişimdir.

- veri seti  🔗[Performans.sav ](import/Performans.sav)

- **Performans:** Öğrencilerin matematik  performans düzeyleri olup eşit aralık 
ölçeğinde ölçülen sürekli bir değişkendir.
- **Motivasyon:** Öğrencilerin motivasyon 
düzeyleri olup eşit aralık ölçeğinde 
ölçülen sürekli bir değişkendir.
- **Kaygı:** Öğrencilerin kaygı düzeyleri olup 
eşit aralık ölçeğinde ölçülen sürekli bir 
değişkendir.
- **Güven:** Öğrencilerin matematiğe karşı 
güven düzeyleri olup eşit aralık ölçeğinde 
ölçülen sürekli bir değişkendir.

- Analize başlamadan önce değişkenlerin betimsel istatistikleri ve değişkenler arası korelasyonlar incelenmelidir.

Betimsel İstatistikler

```r
library(haven)
library(dplyr)
library(knitr)
performans <- read_sav("import/Performans.sav")
psych::describe(performans) %>% kable(digit=2)
```



|           | vars|  n|  mean|    sd| median| trimmed|   mad|   min|   max| range|  skew| kurtosis|   se|
|:----------|----:|--:|-----:|-----:|------:|-------:|-----:|-----:|-----:|-----:|-----:|--------:|----:|
|Performans |    1| 15| 18.18|  7.83|  18.04|   17.93|  9.21|  4.11| 35.50| 31.39|  0.28|    -0.38| 2.02|
|Motivasyon |    2| 15| 39.93| 10.02|  40.00|   40.15| 10.38| 22.00| 55.00| 33.00| -0.18|    -1.17| 2.59|
|Kaygi      |    3| 15| 18.07|  4.77|  18.30|   17.86|  2.25| 10.72| 28.17| 17.45|  0.59|    -0.08| 1.23|
|Guven      |    4| 15| 21.63|  7.37|  22.00|   21.31|  5.71|  8.75| 38.70| 29.95|  0.30|    -0.10| 1.90|





- Korelasyon değerleri ve anlamlılığı


```r
library(broom)
cor_1 <- cor.test(~ Performans + Motivasyon , data = performans)
tidy(cor_1)  %>% kable(digit=2)
```



| estimate| statistic| p.value| parameter| conf.low| conf.high|method                               |alternative |
|--------:|---------:|-------:|---------:|--------:|---------:|:------------------------------------|:-----------|
|     0.82|      5.25|       0|        13|     0.54|      0.94|Pearson's product-moment correlation |two.sided   |



```r
cor_2 <- cor.test(~ Performans + Kaygi , data = performans)
tidy(cor_2)[,c(1,3)]  %>% kable(digit=2)
```



| estimate| p.value|
|--------:|-------:|
|    -0.24|    0.39|


```r
cor_3 <- cor.test(~ Motivasyon + Kaygi , data = performans)
tidy(cor_3)[,c(1,3)] %>% kable(digit=2)
```



| estimate| p.value|
|--------:|-------:|
|     0.15|     0.6|

- İlişki Grafiği 


```r
library(GGally)
ggpairs(performans[,1:3])
```

<img src="04-CR_files/figure-html/unnamed-chunk-7-1.png" width="100%" style="display: block; margin: auto;" />
- 3D grafik


```r
library(scatterplot3d)
scatterplot3d(performans[,1:3],pch = 16, color="steelblue", angle=75)
```

<img src="04-CR_files/figure-html/unnamed-chunk-8-1.png" width="100%" style="display: block; margin: auto;" />

- 3D grafik


```r
scatterplot3d(performans[,1:3],pch = 16, color="steelblue",angle=75,box = FALSE,type = "h")
```

```
## Warning: Unknown or uninitialised column: `color`.
```

<img src="04-CR_files/figure-html/unnamed-chunk-9-1.png" width="100%" style="display: block; margin: auto;" />

- 3D grafik



```r
library(rgl)
plot3d(performans$Performans, performans$Motivasyon, performans$Kaygi,
xlab = "Performans", ylab = "Motivasyon", zlab = "Kaygi", type = "s",size = 1.5,col = "red")
rglwidget() 
```

<div class="figure" style="text-align: center">

```{=html}
<div id="rgl92193" style="width:672px;height:480px;" class="rglWebGL html-widget" role="img" aria-labelledby="rgl92193-aria"></div>
<script type="application/json" data-for="rgl92193">{"x":{"material":{"color":"#000000","alpha":1,"lit":true,"ambient":"#000000","specular":"#FFFFFF","emission":"#000000","shininess":50,"smooth":true,"front":"filled","back":"filled","size":3,"lwd":1,"fog":true,"point_antialias":false,"line_antialias":false,"texture":null,"textype":"rgb","texmode":"modulate","texmipmap":false,"texminfilter":"linear","texmagfilter":"linear","texenvmap":false,"depth_mask":true,"depth_test":"less","isTransparent":false,"polygon_offset":[0,0],"margin":"","floating":false,"tag":"","blend":["src_alpha","one_minus_src_alpha"]},"rootSubscene":7,"objects":{"13":{"id":13,"type":"spheres","material":{},"vertices":"0","colors":"1","radii":[[0.7039732933044434]],"centers":"2","ignoreExtent":false,"fastTransparency":true,"flags":32771},"15":{"id":15,"type":"text","material":{"lit":false,"margin":0,"floating":true,"edge":[0,1,1]},"vertices":"3","colors":"4","texts":[["Performans"]],"cex":[[1]],"adj":[[0.5,0.5,0.5]],"centers":"5","family":[["sans"]],"font":[[1]],"ignoreExtent":true,"flags":33808},"16":{"id":16,"type":"text","material":{"lit":false,"margin":1,"floating":true,"edge":[1,1,1]},"vertices":"6","colors":"7","texts":[["Motivasyon"]],"cex":[[1]],"adj":[[0.5,0.5,0.5]],"centers":"8","family":[["sans"]],"font":[[1]],"ignoreExtent":true,"flags":33808},"17":{"id":17,"type":"text","material":{"lit":false,"margin":2,"floating":true,"edge":[1,1,1]},"vertices":"9","colors":"10","texts":[["Kaygi"]],"cex":[[1]],"adj":[[0.5,0.5,0.5]],"centers":"11","family":[["sans"]],"font":[[1]],"ignoreExtent":true,"flags":33808},"11":{"id":11,"type":"light","vertices":[[0,0,1]],"colors":[[1,1,1,1],[1,1,1,1],[1,1,1,1]],"viewpoint":true,"finite":false},"10":{"id":10,"type":"background","material":{},"colors":"12","centers":"13","sphere":false,"fogtype":"none","fogscale":1,"flags":32768},"12":{"id":12,"type":"background","material":{"lit":false,"back":"lines"},"colors":"14","centers":"15","sphere":false,"fogtype":"none","fogscale":1,"flags":32768},"14":{"id":14,"type":"bboxdeco","material":{"front":"lines","back":"lines"},"vertices":"16","colors":"17","axes":{"mode":["pretty","pretty","pretty"],"step":[5,5,5],"nticks":[5,5,5],"marklen":[15,15,15],"expand":[1.029999971389771,1.029999971389771,1.029999971389771]},"draw_front":true,"flags":32769},"7":{"id":7,"type":"subscene","par3d":{"antialias":8,"FOV":30,"ignoreExtent":false,"listeners":7,"mouseMode":{"none":"none","left":"trackball","right":"zoom","middle":"fov","wheel":"pull"},"observer":[0,0,125.3147583007812],"modelMatrix":[[0.8970806002616882,0,0,-17.76793670654297],[0,0.2918461263179779,1.51644504070282,-40.72311401367188],[0,-0.8018406629562378,0.5519408583641052,-105.1763000488281],[0,0,0,1]],"projMatrix":[[3.732050895690918,0,0,0],[0,3.732050895690918,0,0],[0,0,-3.863703727722168,-451.7452392578125],[0,0,-1,0]],"skipRedraw":false,"userMatrix":[[1,0,0,0],[0,0.3420201433256682,0.9396926207859085,0],[0,-0.9396926207859085,0.3420201433256682,0],[0,0,0,1]],"userProjection":[[1,0,0,0],[0,1,0,0],[0,0,1,0],[0,0,0,1]],"scale":[0.8970806002616882,0.8533009886741638,1.613767147064209],"viewport":{"x":0,"y":0,"width":1,"height":1},"zoom":1,"bbox":[3.32689905166626,36.2859001159668,21.17499923706055,55.82500076293945,10.28402137756348,28.60566902160645],"windowRect":[60,83,316,339],"family":"sans","font":1,"cex":1,"useFreeType":false,"fontname":"TT Arial","maxClipPlanes":8,"glVersion":4.6,"activeSubscene":0},"embeddings":{"viewport":"replace","projection":"replace","model":"replace","mouse":"replace"},"objects":[12,14,13,15,16,17,11],"subscenes":[],"flags":34067}},"crosstalk":{"key":[],"group":[],"id":[],"options":[]},"width":672,"height":480,"buffer":{"accessors":[{"bufferView":0,"componentType":5126,"count":15,"type":"VEC3"},{"bufferView":1,"componentType":5121,"count":1,"type":"VEC4"},{"bufferView":2,"componentType":5126,"count":15,"type":"VEC3"},{"bufferView":3,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":4,"componentType":5121,"count":1,"type":"VEC4"},{"bufferView":5,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":6,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":7,"componentType":5121,"count":1,"type":"VEC4"},{"bufferView":8,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":9,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":10,"componentType":5121,"count":1,"type":"VEC4"},{"bufferView":11,"componentType":5126,"count":1,"type":"VEC3"},{"bufferView":12,"componentType":5126,"count":1,"type":"VEC4"},{"bufferView":13,"componentType":5121,"count":1,"type":"VEC3"},{"bufferView":14,"componentType":5121,"count":1,"type":"VEC4"},{"bufferView":15,"componentType":5121,"count":1,"type":"VEC3"},{"bufferView":16,"componentType":5126,"count":17,"type":"VEC3"},{"bufferView":17,"componentType":5121,"count":1,"type":"VEC4"}],"bufferViews":[{"buffer":0,"byteLength":180,"byteOffset":0},{"buffer":0,"byteLength":4,"byteOffset":180},{"buffer":0,"byteLength":180,"byteOffset":184},{"buffer":0,"byteLength":12,"byteOffset":364},{"buffer":0,"byteLength":4,"byteOffset":376},{"buffer":0,"byteLength":12,"byteOffset":380},{"buffer":0,"byteLength":12,"byteOffset":392},{"buffer":0,"byteLength":4,"byteOffset":404},{"buffer":0,"byteLength":12,"byteOffset":408},{"buffer":0,"byteLength":12,"byteOffset":420},{"buffer":0,"byteLength":4,"byteOffset":432},{"buffer":0,"byteLength":12,"byteOffset":436},{"buffer":0,"byteLength":16,"byteOffset":448},{"buffer":0,"byteLength":3,"byteOffset":464},{"buffer":0,"byteLength":4,"byteOffset":467},{"buffer":0,"byteLength":3,"byteOffset":471},{"buffer":0,"byteLength":204,"byteOffset":476},{"buffer":0,"byteLength":4,"byteOffset":680}],"buffers":[{"byteLength":684,"bytes":"Ne5FQQAAsEG5LndBiJKDQAAAyEHygp5BXgOtQQAASEJj+pRB4F7HQQAAPEIUlZFB6rPQQQAA\nOEImhitBAJyNQQAAIEKqojJBgVkkQQAA+EEDT5NByy+XQQAAXEIDW+FBGpmZQQAAFEJdiZhB\nzgGOQQAAIEJTUpNBMQEOQgAAWEJuYpJB/lOQQQAAGEJKLGNBV7s1QQAAFEIVF9lBkAzCQQAA\nPEKHPHpBiq0oQQAA8EENGo5BAQAAATXuRUEAALBBuS53QYiSg0AAAMhB8oKeQV4DrUEAAEhC\nY/qUQeBex0EAADxCFJWRQeqz0EEAADhCJoYrQQCcjUEAACBCqqIyQYFZJEEAAPhBA0+TQcsv\nl0EAAFxCA1vhQRqZmUEAABRCXYmYQc4BjkEAACBCU1KTQTEBDkIAAFhCbmKSQf5TkEEAABhC\nSixjQVe7NUEAABRCFRfZQZAMwkEAADxChzx6QYqtKEEAAPBBDRqOQQAAwH8AAIBAAACAPwAA\nAAEAAMB/AACAQAAAgD8AAMB/AACAQAAAgD8AAAABAADAfwAAgEAAAIA/AADAfwAAgEAAAIA/\nAAAAAQAAwH8AAIBAAACAP5mYmD6ZmJg+mZiYPgAAgD8AAAABAQEBAAAAAAAAAKBAAADAfwAA\nwH8AACBBAADAfwAAwH8AAHBBAADAfwAAwH8AAKBBAADAfwAAwH8AAMhBAADAfwAAwH8AAPBB\nAADAfwAAwH8AAAxCAADAfwAAwH8AAMB/AADIQQAAwH8AAMB/AADwQQAAwH8AAMB/AAAMQgAA\nwH8AAMB/AAAgQgAAwH8AAMB/AAA0QgAAwH8AAMB/AABIQgAAwH8AAMB/AABcQgAAwH8AAMB/\nAADAfwAAcEEAAMB/AADAfwAAoEEAAMB/AADAfwAAyEEAAAAB"}]},"context":{"shiny":false,"rmarkdown":null},"vertexShader":"#line 2 1\n// File 1 is the vertex shader\n#ifdef GL_ES\n#ifdef GL_FRAGMENT_PRECISION_HIGH\nprecision highp float;\n#else\nprecision mediump float;\n#endif\n#endif\n\nattribute vec3 aPos;\nattribute vec4 aCol;\nuniform mat4 mvMatrix;\nuniform mat4 prMatrix;\nvarying vec4 vCol;\nvarying vec4 vPosition;\n\n#ifdef NEEDS_VNORMAL\nattribute vec3 aNorm;\nuniform mat4 normMatrix;\nvarying vec4 vNormal;\n#endif\n\n#if defined(HAS_TEXTURE) || defined (IS_TEXT)\nattribute vec2 aTexcoord;\nvarying vec2 vTexcoord;\n#endif\n\n#ifdef FIXED_SIZE\nuniform vec3 textScale;\n#endif\n\n#ifdef FIXED_QUADS\nattribute vec3 aOfs;\n#endif\n\n#ifdef IS_TWOSIDED\n#ifdef HAS_NORMALS\nvarying float normz;\nuniform mat4 invPrMatrix;\n#else\nattribute vec3 aPos1;\nattribute vec3 aPos2;\nvarying float normz;\n#endif\n#endif // IS_TWOSIDED\n\n#ifdef FAT_LINES\nattribute vec3 aNext;\nattribute vec2 aPoint;\nvarying vec2 vPoint;\nvarying float vLength;\nuniform float uAspect;\nuniform float uLwd;\n#endif\n\n#ifdef USE_ENVMAP\nvarying vec3 vReflection;\n#endif\n\nvoid main(void) {\n  \n#ifndef IS_BRUSH\n#if defined(NCLIPPLANES) || !defined(FIXED_QUADS) || defined(HAS_FOG) || defined(USE_ENVMAP)\n  vPosition = mvMatrix * vec4(aPos, 1.);\n#endif\n  \n#ifndef FIXED_QUADS\n  gl_Position = prMatrix * vPosition;\n#endif\n#endif // !IS_BRUSH\n  \n#ifdef IS_POINTS\n  gl_PointSize = POINTSIZE;\n#endif\n  \n  vCol = aCol;\n  \n// USE_ENVMAP implies NEEDS_VNORMAL\n\n#ifdef NEEDS_VNORMAL\n  vNormal = normMatrix * vec4(-aNorm, dot(aNorm, aPos));\n#endif\n\n#ifdef USE_ENVMAP\n  vReflection = normalize(reflect(vPosition.xyz/vPosition.w, \n                        normalize(vNormal.xyz/vNormal.w)));\n#endif\n  \n#ifdef IS_TWOSIDED\n#ifdef HAS_NORMALS\n  /* normz should be calculated *after* projection */\n  normz = (invPrMatrix*vNormal).z;\n#else\n  vec4 pos1 = prMatrix*(mvMatrix*vec4(aPos1, 1.));\n  pos1 = pos1/pos1.w - gl_Position/gl_Position.w;\n  vec4 pos2 = prMatrix*(mvMatrix*vec4(aPos2, 1.));\n  pos2 = pos2/pos2.w - gl_Position/gl_Position.w;\n  normz = pos1.x*pos2.y - pos1.y*pos2.x;\n#endif\n#endif // IS_TWOSIDED\n  \n#ifdef NEEDS_VNORMAL\n  vNormal = vec4(normalize(vNormal.xyz/vNormal.w), 1);\n#endif\n  \n#if defined(HAS_TEXTURE) || defined(IS_TEXT)\n  vTexcoord = aTexcoord;\n#endif\n  \n#if defined(FIXED_SIZE) && !defined(ROTATING)\n  vec4 pos = prMatrix * mvMatrix * vec4(aPos, 1.);\n  pos = pos/pos.w;\n  gl_Position = pos + vec4(aOfs*textScale, 0.);\n#endif\n  \n#if defined(IS_SPRITES) && !defined(FIXED_SIZE)\n  vec4 pos = mvMatrix * vec4(aPos, 1.);\n  pos = pos/pos.w + vec4(aOfs,  0.);\n  gl_Position = prMatrix*pos;\n#endif\n  \n#ifdef FAT_LINES\n  /* This code was inspired by Matt Deslauriers' code in \n   https://mattdesl.svbtle.com/drawing-lines-is-hard */\n  vec2 aspectVec = vec2(uAspect, 1.0);\n  mat4 projViewModel = prMatrix * mvMatrix;\n  vec4 currentProjected = projViewModel * vec4(aPos, 1.0);\n  currentProjected = currentProjected/currentProjected.w;\n  vec4 nextProjected = projViewModel * vec4(aNext, 1.0);\n  vec2 currentScreen = currentProjected.xy * aspectVec;\n  vec2 nextScreen = (nextProjected.xy / nextProjected.w) * aspectVec;\n  float len = uLwd;\n  vec2 dir = vec2(1.0, 0.0);\n  vPoint = aPoint;\n  vLength = length(nextScreen - currentScreen)/2.0;\n  vLength = vLength/(vLength + len);\n  if (vLength > 0.0) {\n    dir = normalize(nextScreen - currentScreen);\n  }\n  vec2 normal = vec2(-dir.y, dir.x);\n  dir.x /= uAspect;\n  normal.x /= uAspect;\n  vec4 offset = vec4(len*(normal*aPoint.x*aPoint.y - dir), 0.0, 0.0);\n  gl_Position = currentProjected + offset;\n#endif\n  \n#ifdef IS_BRUSH\n  gl_Position = vec4(aPos, 1.);\n#endif\n}","fragmentShader":"#line 2 2\n// File 2 is the fragment shader\n#ifdef GL_ES\n#ifdef GL_FRAGMENT_PRECISION_HIGH\nprecision highp float;\n#else\nprecision mediump float;\n#endif\n#endif\nvarying vec4 vCol; // carries alpha\nvarying vec4 vPosition;\n#if defined(HAS_TEXTURE) || defined (IS_TEXT)\nvarying vec2 vTexcoord;\nuniform sampler2D uSampler;\n#endif\n\n#ifdef HAS_FOG\nuniform int uFogMode;\nuniform vec3 uFogColor;\nuniform vec4 uFogParms;\n#endif\n\n#if defined(IS_LIT) && !defined(FIXED_QUADS)\nvarying vec4 vNormal;\n#endif\n\n#if NCLIPPLANES > 0\nuniform vec4 vClipplane[NCLIPPLANES];\n#endif\n\n#if NLIGHTS > 0\nuniform mat4 mvMatrix;\n#endif\n\n#ifdef IS_LIT\nuniform vec3 emission;\nuniform float shininess;\n#if NLIGHTS > 0\nuniform vec3 ambient[NLIGHTS];\nuniform vec3 specular[NLIGHTS]; // light*material\nuniform vec3 diffuse[NLIGHTS];\nuniform vec3 lightDir[NLIGHTS];\nuniform bool viewpoint[NLIGHTS];\nuniform bool finite[NLIGHTS];\n#endif\n#endif // IS_LIT\n\n#ifdef IS_TWOSIDED\nuniform bool front;\nvarying float normz;\n#endif\n\n#ifdef FAT_LINES\nvarying vec2 vPoint;\nvarying float vLength;\n#endif\n\n#ifdef USE_ENVMAP\nvarying vec3 vReflection;\n#endif\n\nvoid main(void) {\n  vec4 fragColor;\n#ifdef FAT_LINES\n  vec2 point = vPoint;\n  bool neg = point.y < 0.0;\n  point.y = neg ? (point.y + vLength)/(1.0 - vLength) :\n                 -(point.y - vLength)/(1.0 - vLength);\n#if defined(IS_TRANSPARENT) && defined(IS_LINESTRIP)\n  if (neg && length(point) <= 1.0) discard;\n#endif\n  point.y = min(point.y, 0.0);\n  if (length(point) > 1.0) discard;\n#endif // FAT_LINES\n  \n#ifdef ROUND_POINTS\n  vec2 coord = gl_PointCoord - vec2(0.5);\n  if (length(coord) > 0.5) discard;\n#endif\n  \n#if NCLIPPLANES > 0\n  for (int i = 0; i < NCLIPPLANES; i++)\n    if (dot(vPosition, vClipplane[i]) < 0.0) discard;\n#endif\n    \n#ifdef FIXED_QUADS\n    vec3 n = vec3(0., 0., 1.);\n#elif defined(IS_LIT)\n    vec3 n = normalize(vNormal.xyz);\n#endif\n    \n#ifdef IS_TWOSIDED\n    if ((normz <= 0.) != front) discard;\n#endif\n\n#ifdef IS_LIT\n    vec3 eye = normalize(-vPosition.xyz/vPosition.w);\n    vec3 lightdir;\n    vec4 colDiff;\n    vec3 halfVec;\n    vec4 lighteffect = vec4(emission, 0.);\n    vec3 col;\n    float nDotL;\n#ifdef FIXED_QUADS\n    n = -faceforward(n, n, eye);\n#endif\n    \n#if NLIGHTS > 0\n    for (int i=0;i<NLIGHTS;i++) {\n      colDiff = vec4(vCol.rgb * diffuse[i], vCol.a);\n      lightdir = lightDir[i];\n      if (!viewpoint[i])\n        lightdir = (mvMatrix * vec4(lightdir, 1.)).xyz;\n      if (!finite[i]) {\n        halfVec = normalize(lightdir + eye);\n      } else {\n        lightdir = normalize(lightdir - vPosition.xyz/vPosition.w);\n        halfVec = normalize(lightdir + eye);\n      }\n      col = ambient[i];\n      nDotL = dot(n, lightdir);\n      col = col + max(nDotL, 0.) * colDiff.rgb;\n      col = col + pow(max(dot(halfVec, n), 0.), shininess) * specular[i];\n      lighteffect = lighteffect + vec4(col, colDiff.a);\n    }\n#endif\n    \n#else // not IS_LIT\n    vec4 colDiff = vCol;\n    vec4 lighteffect = colDiff;\n#endif\n    \n#ifdef IS_TEXT\n    vec4 textureColor = lighteffect*texture2D(uSampler, vTexcoord);\n#endif\n    \n#ifdef HAS_TEXTURE\n\n// These calculations use the definitions from \n// https://docs.gl/gl3/glTexEnv\n\n#ifdef USE_ENVMAP\n    float m = 2.0 * sqrt(dot(vReflection, vReflection) + 2.0*vReflection.z + 1.0);\n    vec4 textureColor = texture2D(uSampler, vReflection.xy / m + vec2(0.5, 0.5));\n#else\n    vec4 textureColor = texture2D(uSampler, vTexcoord);\n#endif\n\n#ifdef TEXTURE_rgb\n\n#if defined(TEXMODE_replace) || defined(TEXMODE_decal)\n    textureColor = vec4(textureColor.rgb, lighteffect.a);\n#endif \n\n#ifdef TEXMODE_modulate\n    textureColor = lighteffect*vec4(textureColor.rgb, 1.);\n#endif\n\n#ifdef TEXMODE_blend\n    textureColor = vec4((1. - textureColor.rgb) * lighteffect.rgb, lighteffect.a);\n#endif\n\n#ifdef TEXMODE_add\n    textureColor = vec4(lighteffect.rgb + textureColor.rgb, lighteffect.a);\n#endif\n\n#endif //TEXTURE_rgb\n        \n#ifdef TEXTURE_rgba\n\n#ifdef TEXMODE_replace\n// already done\n#endif \n\n#ifdef TEXMODE_modulate\n    textureColor = lighteffect*textureColor;\n#endif\n\n#ifdef TEXMODE_decal\n    textureColor = vec4((1. - textureColor.a)*lighteffect.rgb) +\n                     textureColor.a*textureColor.rgb, \n                     lighteffect.a);\n#endif\n\n#ifdef TEXMODE_blend\n    textureColor = vec4((1. - textureColor.rgb) * lighteffect.rgb,\n                    lighteffect.a*textureColor.a);\n#endif\n\n#ifdef TEXMODE_add\n    textureColor = vec4(lighteffect.rgb + textureColor.rgb,\n                    lighteffect.a*textureColor.a);\n#endif\n    \n#endif //TEXTURE_rgba\n    \n#ifdef TEXTURE_alpha\n#if defined(TEXMODE_replace) || defined(TEXMODE_decal)\n    textureColor = vec4(lighteffect.rgb, textureColor.a);\n#endif \n\n#if defined(TEXMODE_modulate) || defined(TEXMODE_blend) || defined(TEXMODE_add)\n    textureColor = vec4(lighteffect.rgb, lighteffect.a*textureColor.a);\n#endif\n \n#endif\n    \n// The TEXTURE_luminance values are not from that reference    \n#ifdef TEXTURE_luminance\n    float luminance = dot(vec3(1.,1.,1.),textureColor.rgb)/3.;\n\n#if defined(TEXMODE_replace) || defined(TEXMODE_decal)\n    textureColor = vec4(luminance, luminance, luminance, lighteffect.a);\n#endif \n\n#ifdef TEXMODE_modulate\n    textureColor = vec4(luminance*lighteffect.rgb, lighteffect.a);\n#endif\n\n#ifdef TEXMODE_blend\n    textureColor = vec4((1. - luminance)*lighteffect.rgb,\n                        lighteffect.a);\n#endif\n\n#ifdef TEXMODE_add\n    textureColor = vec4(luminance + lighteffect.rgb, lighteffect.a);\n#endif\n\n#endif // TEXTURE_luminance\n \n    \n#ifdef TEXTURE_luminance_alpha\n    float luminance = dot(vec3(1.,1.,1.),textureColor.rgb)/3.;\n\n#if defined(TEXMODE_replace) || defined(TEXMODE_decal)\n    textureColor = vec4(luminance, luminance, luminance, textureColor.a);\n#endif \n\n#ifdef TEXMODE_modulate\n    textureColor = vec4(luminance*lighteffect.rgb, \n                        textureColor.a*lighteffect.a);\n#endif\n\n#ifdef TEXMODE_blend\n    textureColor = vec4((1. - luminance)*lighteffect.rgb,\n                        textureColor.a*lighteffect.a);\n#endif\n\n#ifdef TEXMODE_add\n    textureColor = vec4(luminance + lighteffect.rgb, \n                        textureColor.a*lighteffect.a);\n\n#endif\n\n#endif // TEXTURE_luminance_alpha\n    \n    fragColor = textureColor;\n\n#elif defined(IS_TEXT)\n    if (textureColor.a < 0.1)\n      discard;\n    else\n      fragColor = textureColor;\n#else\n    fragColor = lighteffect;\n#endif // HAS_TEXTURE\n    \n#ifdef HAS_FOG\n    // uFogParms elements: x = near, y = far, z = fogscale, w = (1-sin(FOV/2))/(1+sin(FOV/2))\n    // In Exp and Exp2: use density = density/far\n    // fogF will be the proportion of fog\n    // Initialize it to the linear value\n    float fogF;\n    if (uFogMode > 0) {\n      fogF = (uFogParms.y - vPosition.z/vPosition.w)/(uFogParms.y - uFogParms.x);\n      if (uFogMode > 1)\n        fogF = mix(uFogParms.w, 1.0, fogF);\n      fogF = fogF*uFogParms.z;\n      if (uFogMode == 2)\n        fogF = 1.0 - exp(-fogF);\n      // Docs are wrong: use (density*c)^2, not density*c^2\n      // https://gitlab.freedesktop.org/mesa/mesa/-/blob/master/src/mesa/swrast/s_fog.c#L58\n      else if (uFogMode == 3)\n        fogF = 1.0 - exp(-fogF*fogF);\n      fogF = clamp(fogF, 0.0, 1.0);\n      gl_FragColor = vec4(mix(fragColor.rgb, uFogColor, fogF), fragColor.a);\n    } else gl_FragColor = fragColor;\n#else\n    gl_FragColor = fragColor;\n#endif // HAS_FOG\n    \n}","players":[],"webGLoptions":{"preserveDrawingBuffer":true}},"evals":[],"jsHooks":[]}</script>
```

<p id="rgl92193-aria" hidden></p>
</div>




- Regresyonda amaç hata puanlarının (artıkların) kareleri toplamının küçüleceği, 
diğer bir ifade ile $Y$ ve yordanan $Y'$ arasındaki korelasyonun 
büyüyeceği, $b_0$, $b_1$ ve $b_2$ değerleri için tek bir çözüm kümesi 
bulmaktır.

- Grafiğin sadeleştirilmesi için bir bağımsız değişken kullanılmıştır. Tek bir çözüm bulmak için  kullanılan yöntem Sıradan **En 
Küçük Kareler Yöntemi**  (Ordinary Least Squares  Procedure) olarak adlandırılır. 


<img src="images/CR_3.PNG" width="75%" style="display: block; margin: auto;" />


- $R^2$ değeri *çoklu korelasyon katsayısı* (multiple correlation 
coefficient) olup bağımlı değişkenin gözlenen değerleri ile bağımsız 
değişkenlerin *en iyi doğrusal kombinasyonu* arasındaki 
korelasyondur. 

- **En iyi doğrusal kombinasyon**, bağımlı değişkenin 
bağımsız değişkenlerden yordanmasında, daha iyi bir iş yapacak 
regresyon katsayıları kümesi olmadığı anlamına gelir.


Çoklu Korelasyon

```r
model <- lm(Performans ~ Motivasyon + Kaygi,data=performans)
sqrt(glance(model)[,1]) #r.squareddeğerinin karekoku alınır
```

<div class="kable-table">

| r.squared|
|---------:|
| 0.9019952|

</div>

-  R değeri bağımlı değişkenin **gözlenen** ve **yordanan** değerleri arasındaki **korelasyondur**.

- Bağımlı değişkenin **yordanan değerinin** bağımlı değişkenin 
**gözlenen değerine** mümkün olduğunca yakın olmasını 
gerektiren **en küçük kareler kriterinden** dolayı bağımlı 
değişkenin **gözlenen ve yordanan değerleri arasındaki korelasyon eksi 
değerler** alamaz. Dolayısıyla çoklu korelasyon katsayısı 0 ile 1 
arasında değişir



**Çoklu Korelasyon Formulu **
$$R_{Y_{12}}= \sqrt{\frac{r^2_{Y_1}+r^2_{Y_2}-2r^2_{Y_1}r^2_{Y_2}r_{12}}{1-r_{12}}}$$
$$R_{Y_{12}}=\sqrt{\frac{(0.824)^2+(-0.241)^2-2*(0.824)(-0.241)(0.147)}{1-(0.147)^2}}) = 0.902$$

```r
model_s <- augment(model,data=performans)
cor(model_s[,1], model_s[,5]) # Y ve Y' arası korelasyon
```

```
##              .fitted
## Performans 0.9019952
```

öğrencilerin **gözlenen performans puanları** ve **yoradan performans puanları** arasındaki korelasyon katsayısı nokta **0.902** eşittir


- Çoklu korelasyon katsayısının kestirimi hem örneklem büyüklüğüne 
$(n)$ hem de bağımsız değişkenlerin sayısına $(k)$ bağlıdır. 

- Bağımlı değişken ile bağımsız değişkenler arasında hiç ilişki yoksa, 
$R$ değerinin sıfıra yakın olması beklenir ancak $R$’nin beklenen değeri 
rastgele bir veri için $k/(n-1)$’dir. 

  - Örneğin, örneklem büyüklüğünün **50**, bağımsız değişken sayısının **2** olduğu bir  durumda, bağımlı değişken ile bağımsız değişkenler arasında hiç ilişki yoksa, R değeri **0.04** olacaktır, **0** değil.

- Bu nedenle büyük örnekleme sahip olmak önemlidir. Her bağımsız 
değişken için **en az 10** gözlem önerilmektedir. Bir başka öneri de 
örneklem büyüklüğünün **bağımsız değişken sayısından en az 50 
fazla olması** yönündedir.

- Bir çalışmada, tek bir bağımsız değişken bulunduğunda, **0.80** güce sahip olmak için **0.30** evren korelasyonunun **124** birey gerektireceği belirtilmiştir. **Beş bağımsız** değişken bulunduğundaysa, örneklem büyüklüğünün **187** olması gerekmektedir.


### belirlilik katsayısı 



```r
model <- lm(Performans ~ Motivasyon + Kaygi,data=performans)
glance(model)[,1]
```

<div class="kable-table">

| r.squared|
|---------:|
| 0.8135954|

</div>

$R^2$ değeri **belirlilik katsayısı** (coefficient of determination) olup 
bağımlı değişkenin gözlenen ve yordanan değerleri arasındaki 
korelasyonun karesi alınarak hesaplanır. Bu değer bağımlı 
değişkendeki varyansın model tarafından açıklanan oranını ifade 
eder. Diğer bir ifadeyle **bağımlı değişkenin varyansının bağımsız 
değişkenlerin en iyi doğrusal kombinasyonu** ile paylaşılan oranını 
ifade eder. 
 **Performans puanlarındaki varyansın yaklaşık %81’i öğrencilerin motivasyon ve kaygı puanları** tarafından açıklanabilir. 

- Modele yeni bir bağımsız değişken eklendiğinde, $R^2$ değeri artar, 
sadece **şans eseri olsa bile**. Böylece daha fazla bağımsız değişken 
içeren model sadece daha fazla bağımsız değişken içerdiği için 
veriye daha iyi uyum sağlıyor gibi gözükebilir. 

- Bu etkiyi gidermek için  $adj R^2$ değeri hesaplanabilir.

-  $\text{adj}{R^2}$ değeri, $R^2$ değerinin modeldeki bağımsız değişken sayısı için modifiye edilmiş  versiyonudur.  $\text{adj}{R^2}$  değeri, yeni eklenen bağımsız
değişken modeli şans eseri beklenenden daha fazla geliştirirse artar, 
daha az geliştirirse azalır. 

-  $\text{adj}{R^2}$  değeri, eksi değerler alabilir ancak genellikle artı değerler alır. Her zaman $R^2$ değerinden daha düşüktür.



- $R^2$ değeri, $n$ gözlemlerin sayısı, $k$ bağımsız değişkenlerin  sayısı olmak üzere, aşağıdaki eşitlikle hesaplanabilir.
$$R^2_{adj}= R^2 - \frac{k-(1-R^2)}{n-k-1}$$
$$R^2_{adj}= 0.814 - \frac{2-(1-0.814)}{15-2-1} =0.783$$



```r
glance(model)[,2]
```

<div class="kable-table">

| adj.r.squared|
|-------------:|
|     0.7825279|

</div>
$adj R^2$ evrende gerçek korelasyonun karesinin daha az yanlı kestirimi olsa da, çoğunlukla $R^2$ değeri rapor edilir.


## Kestirimin standart hatası

- **Kestirimin standart hatası**  (standard error of the estimation), modeldeki  artıkların karelerinin toplamının, $n-p$ ( $n$ örneklem büyüklüğü ve $p$ modeldeki parametrelerin sayısı) ile bölünmesiyle elde  edilen bölümün kareköküdür.



```r
res <- model$residuals


sqrt(sum((res - mean(res)) ^ 2 / (length(res)-3)))
```

```
## [1] 3.650458
```



```r
glance(model)[,3]
```

<div class="kable-table">

|    sigma|
|--------:|
| 3.650457|

</div>



## Model veri uyumu

- Modelin veriye iyi uyup uymadığının test edilmesinde kullanılacak **F** değeri varyans analizi sonucunda elde edilir.

- Regresyonun anlamlılığının test edildiği varyans analizinde, birlikte ele alınan bir grup bağımsız değişkenin (motivasyon ve kaygı gibi)  en iyi doğrusal kombinasyonu ile bağımlı değişken (performans gibi)  arasında **korelasyon yoktur sıfır hipotezi** test edilir. İstatistiksel olarak  **anlamlı etki**, **evrende çoklu korelasyon katsayısının sıfırdan farklı  olduğu anlamına **gelir.



```r
glance(model)[,4:6] %>% kable(digit=2)
```



| statistic| p.value| df|
|---------:|-------:|--:|
|     26.19|       0|  2|

- F istatistiği 26.2 değerine eşittir ve istatistiğe ilişkin p < 0.001. Bu olasılık 0.05’ten küçük olduğundan, sıfır hipotezi reddedilir. 

- Bu sonuç **motivasyon ve kaygı değişkenlerinin ikisi birlikte kullanıldığında, çoklu korelasyon katsayısının anlamlı olarak sıfırdan büyük olduğunu** ifade etmektedir. Diğer bir ifadeyle, motivasyon ve kaygı değişkenleri  performansı istatistiksel olarak anlamlı bir şekilde yordamaktadır. 
- **Regresyon modeli veriye iyi uyum sağlamaktadır.**

- Model sonuçları


```r
library(knitr)
tidy(model) %>% kable(digit=2)
```



|term        | estimate| std.error| statistic| p.value|
|:-----------|--------:|---------:|---------:|-------:|
|(Intercept) |     1.74|      5.10|      0.34|    0.74|
|Motivasyon  |     0.69|      0.10|      6.97|    0.00|
|Kaygi       |    -0.61|      0.21|     -2.94|    0.01|

Performans puanlarındaki farklılıkların **bir kısmı motivasyon puanlarındaki farklılıklardan**, **bir kısmı ise kaygı puanlarındaki farklılıklardan** kaynaklanmaktadır


## Kaygının sabit tutulması

- **Performansın** sadece **kaygıdan yordandığı basit regresyon analizi**  gerçekleştirilirse, yordanan puanlar ve gözlenen puanlar arasındaki fark **(artıkPER1)**, **performansın kaygıdan yordanamayan kısmı** olacaktır. 


```r
artıkPER1 <- lm(Performans ~  Kaygi,data=performans)$residuals
```

- **Motivasyonun** sadece **kaygıdan yordandığı basit regresyon analizi**  gerçekleştirilirse, yordanan puanlar ve gözlenen puanlar arasındaki fark  **(artıkMOT)**, **motivasyonun kaygıdan yordanamayan kısmı** olacaktır.


```r
artıkMOT <- lm(Motivasyon  ~  Kaygi,data=performans)$residuals
```

- Böylece **artıkPER1** ve **artıkMOT** olarak adlandırılan artık puanlar kaygıdan bağımsız olacaktır. 


-  Diğer bir ifadeyle, **kaygı ilişkilerinde** herhangi bir rol oynamayacaktır. **artıkPER1** puanları **artıkMOT** puanlarından yordanırsa, **artıkMOT** puanlarına  ilişkin eğim katsayısı **0.686** olarak kestirilecektir. Bu değer, **öğrencilerin kaygı düzeyleri kontrol altına** alındıktan sonra, **motivasyon düzeylerindeki bir birimlik** artışın matematikteki **performans düzeylerini 0.686** birim artırmaya eğilimli  olduğunu önermektedir


```r
lm(artıkPER1  ~  artıkMOT,
   data=data.frame(artıkPER1,artıkMOT))$coefficients %>% kable(digit=3)
```



|            |     x|
|:-----------|-----:|
|(Intercept) | 0.000|
|artıkMOT    | 0.686|


- $$B_{Y_{12}} = \frac{r_{Y1}-r_{Y2}r_{12}}{1-r^2_{12}}\frac{sd_Y}{sd_1}$$

- $$B_{Y_{12}} = \frac{(0.824)-(-0.241)(0.147)}{1-(0.022)}\frac{7.827}{10.025} = 0.879 * 0.780 =0.686$$

- Bu değer, **kaygı puanı kontrol altına alındıktan sonra**, **motivasyon** puanlarındaki
**bir birimlik artışın** öğrencilerin **matematik performansından 0.686** birim artmaya eğilimi olduğunu önermektedir.


```r
((cor(performans)[2,1] - cor(performans)[3,1]*cor(performans)[2,3])/
   (1-cor(performans)[2,3]^2))*(sd(performans$Performans)/sd(performans$Motivasyon))
```

```
## [1] 0.6862988
```


## Motivasyonun sabit tutulması

- **Performansın** sadece **motivasyondan** yordandığı basit regresyon analizi 
gerçekleştirilirse, yordanan puanlar ve gözlenen puanlar arasındaki fark 
**(artıkPER2)**, **performansın motivasyondan** yordanamayan kısmı olacaktır. 


```r
artıkPER2 <- lm(Performans ~  Motivasyon ,data=performans)$residuals
```

- **Kaygının** sadece **motivasyondan** yordandığı basit regresyon analizi  
gerçekleştirilirse, yordanan puanlar ve gözlenen puanlar arasındaki 
fark **(artıkKAY)**, **kaygının motivasyondan** yordanamayan kısmı olacaktır. 


```r
artıkKAY <- lm(Kaygi ~  Motivasyon ,data=performans)$residuals
```


- Böylece **artıkPER2** ve **artıkKAY** olarak adlandırılan artık puanlar motivasyondan bağımsız olacaktır. Diğer bir ifadeyle, **motivasyon ilişkilerinde herhangi bir rol** oynamayacaktır. 

- **artıkPER2** puanları **artıkKAY** puanlarından yordanırsa, **artıkKAY** 
puanlarına ilişkin eğim katsayısı **-0.607** olarak kestirilecektir. Bu değer,
**öğrencilerin motivasyon düzeyleri kontrol altına alındıktan sonra**, kaygı 
düzeylerindeki **bir birimlik** artışın matematikteki performans düzeylerini **0.607** birim azaltmaya eğilimli olduğunu önermektedir


```r
lm(artıkPER2  ~  artıkKAY,
   data=data.frame(artıkPER2,artıkKAY))$coefficients %>% kable(digit=3)
```



|            |      x|
|:-----------|------:|
|(Intercept) |  0.000|
|artıkKAY    | -0.607|



$$B_{Y_{21}} = \frac{r_{Y2}-r_{Y1}r_{12}}{1-r^2_{12}}\frac{sd_Y}{sd_2}$$

$$B_{Y_{12}} = \frac{(-0.241)-(0.824)(0.147)}{1-(0.022)}\frac{7.827}{4.769}=(-0.370)*(1.641) =-0.607$$

Bu değer, **motivasyon puanı kontrol altına alındıktan sonra**,  kaygı puanlarındaki **bir birimlik** artışın öğrencilerin matematik performansından **0.607** birim azaltmaya eğilimli olduğunu önermektedir.


```r
((cor(performans)[3,1] - cor(performans)[2,1]*cor(performans)[2,3])/
   (1-cor(performans)[2,3]^2))*(sd(performans$Performans)/sd(performans$Kaygi))
```

```
## [1] -0.6072857
```

## Regresyon Sabiti

$$B_0 = M_Y - B_{Y12}*M_1 -B_{Y21}*M_2$$
$$B_0 = 18.176  - (0.686)*(39.933) -(-0.607)*(18.701) = 1.744$$


```r
mean(performans$Performans)-
  model$coefficients[2]*mean(performans$Motivasyon)-
  model$coefficients[3]*mean(performans$Kaygi)
```

```
## Motivasyon 
##   1.744129
```

Bu değer hem motivasyon puanı hem de kaygı puanı 0'a eşit olduğunda yordanan performans puanıdır.



- Böylece yordanan performans puanı 

$$Y_{performans_i} = 1.744 + 0.686 X_{motivasyon_i} -  0.607 X_{kaygi_i}$$


## Standart puanlar ile regresyon



```r
library(QuantPsyc)
lm.beta(model) %>% kable(digit=3)
```



|           |      x|
|:----------|------:|
|Motivasyon |  0.879|
|Kaygi      | -0.370|

- Çoklu regresyon eşitliğini elde etmeden önce değişkenlerin her biri 
**standartlaştırılırsa** (değişkenlerin her birinin ortalaması 0, standart sapması 1  olacak şekilde ayarlanırsa), sonuçlar **standart sapma** birimlerince ifade edilir.

- Böylece örnekte standartlaştırılmış değişkenler kullanıldığında, yordanan 
standartlaştırılmış performans düzeyleri aşağıdaki eşitlikle hesaplanabilir:

$$Y_{Zperformans_i} = 0.879 X_{Zmotivasyon_i} + -0.370 X_{Zkaygi_i}$$
- Değişkenler standartlaştırıldığında, **kesişim katsayısı 0** olacaktır ve eşitlikte gösterilmeyecektir.


- Motivasyon için **standartlaştırılmış eğim katsayısı** $\beta_{motivasyon}$ **0.879** değerine eşittir. Bu değer, **kaygı puanı kontrol altına alındıktan** sonra, **motivasyon** 
puanındaki **bir standart sapmalık artışın** öğrencilerin matematikteki 
performans puanlarını **0.879 standart sapma** artırmaya eğilimli olduğunu 
önermektedir.

- Benzer şekilde, **kaygı için standartlaştırılmamış eğim katsayısı** $\beta_{motivasyon}$ **-0.370** değerine eşittir. Bu değer, **motivasyon puanı kontrol altına** alındıktan sonra, kaygı puanındaki **bir standart sapmalık artışın** öğrencilerin matematikteki performans puanlarını **0.370 standart sapma** azaltmaya eğilimli olduğunu 
önermektedir.


- Motivasyonun standartlaştırılmış eğim katsayısının mutlak değeri, 
kaygının standartlaştırılmış eğim katsayının mutlak değerinden daha büyük olduğundan, 
motivasyonun öğrencilerin matematikteki performanslarını yordamada kaygıya 
göre daha önemli bir yordayıcı olduğu söylenebilir.


**|0.879| > |-0.307|**
    
    
- Standartlaştırılmış eğim katsayılarının bağıl büyüklükleri "önemin" en iyi 
göstergeleri olmasa da, yorumlanmaları kolaydır ve regresyon analizlerinin 
yürütülmesinde yararlanılan bilgisayar programlarının çoğu tarafından yazdırılır.

- Ancak bağımsız değişkenlerin **standartlaştırılmamış eğim katsayılarını karşılaştırmak uygun değildir.** 

- NOT: Bağımsız değişkenler arasında korelasyon olduğunda, **standartlaştırılmış ğim katsayısı** bağımlı değişken ile bağımsız değişken arasındaki **korelasyon katsayısı değildir.**



## Yordanan ve Artık Değerler


```r
model$fitted.values
```

```
##         1         2         3         4         5         6         7         8 
##  7.460803  6.868878 24.750038 22.948914 26.803619 22.415911 11.837088 22.383666 
##         9        10        11        12        13        14        15 
## 15.558025 18.012795 27.692114 19.201051 10.657716 24.502360 11.546048 
## attr(,"format.spss")
## [1] "F8.2"
## attr(,"display_width")
## [1] 9
```


```r
model$residuals
```

```
##          1          2          3          4          5          6          7 
##  4.9098531 -2.7572412 -3.1233932  1.9724107 -0.7157694 -4.7147384 -1.5652365 
##          8          9         10         11         12         13         14 
## -3.4853296  3.6417319 -0.2619138  7.8090497 -1.1600390  0.7005214 -0.2462261 
##         15 
## -1.0036796 
## attr(,"format.spss")
## [1] "F8.2"
## attr(,"display_width")
## [1] 9
```

- Öğrencilerin **standratlaştırılmamış yordanan matematik performans düzeyleri** ve **standartlaştırılmamış artıkları** modelden çekilebilir. 

- Örneğin, ilk öğrenci için standratlastırılmamış yordanan değer yaklaşık **7.46**, artık ise yaklaşık **4.910**’tir.


## Yordanan ve Artık Değerlerin Standart Puanları


```r
library(outliers)
model$fitted.values %>% scores(type = "z")
```

```
##           1           2           3           4           5           6 
## -1.51756652 -1.60139987  0.93107934  0.67598917  1.22192462  0.60050077 
##           7           8           9          10          11          12 
## -0.89776046  0.59593408 -0.37077032 -0.02310523  1.34776075  0.14518552 
##          13          14          15 
## -1.06479299  0.89600114 -0.93898001 
## attr(,"format.spss")
## [1] "F8.2"
## attr(,"display_width")
## [1] 9
```



```r
model$residuals %>% scores(type = "z")
```

```
##           1           2           3           4           5           6 
##  1.45276239 -0.81583220 -0.92417187  0.58361096 -0.21178695 -1.39503047 
##           7           8           9          10          11          12 
## -0.46313334 -1.03126421  1.07754165 -0.07749693  2.31059738 -0.34324063 
##          13          14          15 
##  0.20727527 -0.07285515 -0.29697589 
## attr(,"format.spss")
## [1] "F8.2"
## attr(,"display_width")
## [1] 9
```

- Öğrencilerin **standratlaştırılmış yordanan matematik performans düzeyleri** ve **standartlaştırılmış artıkları** modelden çekilebilir.

## Çoklu Regresyon

- Regresyon katsayılarından her birinin istatistiksel olarak sıfırdan 
farklı olup olmadığı test edilebilir. Bu durumda regresyon 
katsayılarına ilişkin test edilecek sıfır hipotezleri aşağıdaki gibidir:

$H_0: \beta_1 = 0$
 - Kaygı düzeyleri eşit olan öğrenciler için 
motivasyon düzeylerindeki farklılıklar 
performans düzeylerinde farklılığa yol açar mı?

$H_0: \beta_2 = 0$
- Motivasyon düzeyleri eşit olan öğrenciler için 
kaygı düzeylerindeki farklılıklar performans 
düzeylerinde farklılığa yol açar mı?


## anlamlılık değerleri



Hipotez testlerine ilişkin **t istatistiği**, standartlaştırılmamış regresyon 
katsayılarının standart hatalarına bölünmesi ile hesaplanır. 

```r
tidy(model) %>% kable()
```



|term        |   estimate| std.error| statistic|   p.value|
|:-----------|----------:|---------:|---------:|---------:|
|(Intercept) |  1.7441290| 5.0963498|  0.342231| 0.7380964|
|Motivasyon  |  0.6862988| 0.0983943|  6.974987| 0.0000149|
|Kaygi       | -0.6072857| 0.2068317| -2.936134| 0.0124612|




```r
0.686 /0.0984
```

```
## [1] 6.971545
```


- Motivasyona ilişkin eğim için testin, olasılık değeri (p ˂ 0.001) 
0.05’ten daha küçük olduğundan, anlamlı olarak sıfırdan farklı 
olduğu görülmektedir.


- Hipotez testlerine ilişkin t istatistiği standartlaştırılmamış regresyon 
katsayılarının standart hatalarına bölünmesi ile hesaplanır. 

- Kaygıya ilişkin eğim de anlamlıdır  **(t = -2.936, p = 0.012)**, öğrencilerin 
motivasyon düzeylerindeki farklılıklar  kontrol altına alınsa bile, öğrencilerin 
kaygı düzeyleri performans  düzeylerinde fark yapmaktadır ve  kaygı düzeyi negatif bir etkiye 
sahiptir.


- Hipotez testlerine ilişkin t istatistiği **standartlaştırılmamış regresyon 
katsayılarının standart hatalarına** bölünmesi ile hesaplanır. 

- Regresyon katsayısının **standart hatası tekrarlanan örneklemlerde 
istatistiğin değişkenliğini** belirtir. 

- İki regresyon katsayısı ile ilgili **p** değerleri 0.05 alfa düzeyinden daha 
küçüktür, bu nedenle her iki bağımsız değişken de öğrencilerin matematikteki 
performanslarını yordamada **istatistiksel olarak anlamlıdır.**


## Yol Şeması

- Çoklu regresyon modelini bir **yol şeması** ile sunmak oldukça kullanışlıdır.


```r
# path model
library(lavaan)
```

```
## This is lavaan 0.6-17
## lavaan is FREE software! Please report any bugs.
```

```r
library(lavaanPlot)
model_1 <- 'Performans ~  Motivasyon + Kaygi'
fit1 <- sem(model_1, data = performans)
coef(fit1)
```

```
##  Performans~Motivasyon       Performans~Kaygi Performans~~Performans 
##                  0.686                 -0.607                 10.661
```


- Standart çözüm

```r
lavaanPlot(model = fit1, coefs = TRUE, stand = TRUE, sig = 0.05) 
```

```{=html}
<div class="grViz html-widget html-fill-item" id="htmlwidget-75b0c94530af8e9725db" style="width:30%;height:480px;"></div>
<script type="application/json" data-for="htmlwidget-75b0c94530af8e9725db">{"x":{"diagram":" digraph plot { \n graph [ overlap = true, fontsize = 10 ] \n node [ shape = box ] \n node [shape = box] \n Motivasyon; Kaygi; Performans \n node [shape = oval] \n  \n \n edge [ color = black ] \n Motivasyon->Performans [label = \"0.88\"] Kaygi->Performans [label = \"-0.37\"]  \n}","config":{"engine":"dot","options":null}},"evals":[],"jsHooks":[]}</script>
```


- Standart olmayan çözüm:

Not: Araştırmacılar özellikle ortalamaların yapısı ile ilgilenmedikleri sürece yol şemasında $b_0$ gösterilmez.


```r
lavaanPlot(model = fit1, coefs = TRUE, stand = FALSE, sig = 0.05) 
```

```{=html}
<div class="grViz html-widget html-fill-item" id="htmlwidget-a5ed9f8259f2a6d37f7b" style="width:30%;height:480px;"></div>
<script type="application/json" data-for="htmlwidget-a5ed9f8259f2a6d37f7b">{"x":{"diagram":" digraph plot { \n graph [ overlap = true, fontsize = 10 ] \n node [ shape = box ] \n node [shape = box] \n Motivasyon; Kaygi; Performans \n node [shape = oval] \n  \n \n edge [ color = black ] \n Motivasyon->Performans [label = \"0.69\"] Kaygi->Performans [label = \"-0.61\"]  \n}","config":{"engine":"dot","options":null}},"evals":[],"jsHooks":[]}</script>
```




```r
m <- matrix(c("Motivasyon", NA, "NA",  NA,   NA,
                NA, NA, NA,  NA, "Performans",
              "Kaygi",    NA, NA,  NA,   NA), byrow = TRUE, 3, 5)
library(semptools)
library(semPlot)

yol<- semPaths( fit1,  whatLabels = "std",
           sizeMan = 10,
           edge.label.cex = 1.15,
           style = "ram",
           nCharNodes = 0, nCharEdges = 0,
           layout = m)
```

<img src="04-CR_files/figure-html/unnamed-chunk-39-1.png" width="100%" style="display: block; margin: auto;" />

```r
yol <- mark_sig(yol, fit1)

plot(yol)
```

<img src="04-CR_files/figure-html/unnamed-chunk-39-2.png" width="100%" style="display: block; margin: auto;" />


- Öğrencilerin matematik performanslarının düzeyini motivasyon 
ve kaygı düzeylerinden yordamak için çoklu regresyon analizi 
gerçekleştirilmiştir. Genel regresyon istatistiksel olarak anlamlıdır 
$F_{[2, 12]} = 26.188, p < .001$ ve $R^2 = 0.814$ Öğrencilerin hem 
motivasyonlarının düzeyi ( $b_1 = 0.686$) hem kaygılarının düzeyi( $b_2 = -0.607$) matematik performanslarının düzeyinin istatistiksel  olarak anlamlı yordayıcılarıdır, 
$t = 6.975; p < .001, t = -2.936; p = .012$


## Regresyon Eşitliğinin Oluşturulması
**Aşamalı (Stepwise) Regresyon**

- Bir regresyon modeline dahil edilebilecek çok sayıda değişken 
bulunduğunda, bu değişkenlerden **en uygun** regresyon eşitliğinin 
oluşturulması için değişken seçiminde çeşitli yöntemler vardır. Bu 
yöntemlerden birisi aşamalı **stepwise** regresyondur.

- Aşamalı regresyon yöntemi **her bağımsız değişkenin regresyon 
modeline** katkısının incelenmesini sağlar. 

- Bu yönteme göre önce **bağımlı değişkenle en yüksek korelasyona** 
sahip bağımsız değişken seçilerek basit regresyon modeli kurulur. 


- Birinci regresyon eşitliğinden kalan **hata varyansının istatistiksel olarak anlamlı kısmını en çok açıklayan bağımsız değişkeni** bulmak 
için **kısmi korelasyon** katsayıları incelenir ve en yüksek **kısmi korelasyon katsayısına** sahip bağımsız değişken modele eklenir.

- İki bağımsız değişken ile regresyon eşitliği yeniden hesaplanır ve 
**eklenen değişkenin modele anlamlı katkısı olup olmadığı** test edilir. 
Bu işlem modele anlamlı katkı sağlayacak değişken kalmayana 
kadar devam eder. 




```r
sadece_kesisim  <- lm(Performans ~ Motivasyon, data=performans)
glance(sadece_kesisim) %>%  kable(digit=3)
```



| r.squared| adj.r.squared| sigma| statistic| p.value| df|  logLik|    AIC|    BIC| deviance| df.residual| nobs|
|---------:|-------------:|-----:|---------:|-------:|--:|-------:|------:|------:|--------:|-----------:|----:|
|      0.68|         0.655| 4.598|    27.585|       0|  1| -43.094| 92.188| 94.312|  274.791|          13|   15|


```r
tum  <- lm(Performans ~  Motivasyon + Kaygi, data=performans)
glance(tum) %>%  kable(digit=3)
```



| r.squared| adj.r.squared| sigma| statistic| p.value| df|  logLik|    AIC|    BIC| deviance| df.residual| nobs|
|---------:|-------------:|-----:|---------:|-------:|--:|-------:|------:|------:|--------:|-----------:|----:|
|     0.814|         0.783|  3.65|    26.188|       0|  2| -39.033| 86.067| 88.899|   159.91|          12|   15|


- Birinci modelde **motivasyon tek yordayıcıdır** ve performans ile korelasyonu **0.824’tür**  $R = 0.824$ . Motivasyon tek başına performans puanlarındaki 
varyansın yaklaşık **%68’ini** $R^2 = 0.680$ açıklamaktadır. 

- Modele **kaygının yordayıcı olarak eklenmesiyle** korelasyon **0.902**’ye $R = 0.902$  yükselmiştir. Motivasyon ve kaygı birlikte performans puanlarındaki 
varyansın yaklaşık **%81**’ini $R^2 = 0.814$  açıklamaktadır. 

- Modele kaygının eklenmesiyle $R^2$ değişimi (R Square Change) 0.134’tür. $R^2$ değerindeki bu değişim kaygının eklenmesiyle açıklanan varyans oranında 
**%13**’lük bir artış olduğu anlamındadır. $R^2$ değişimi F testi (F Change) ile test edilmiştir ve F değerindeki değişim istatistiksel olarak anlamlıdır $p = 0.012$ Dolayısıyla modele eklenen kaygı değişkeni yordamayı anlamlı olarak 
geliştirmiştir. 


```r
asamali <- step(sadece_kesisim, direction='forward', scope=formula(tum), trace=0)
tidy(anova(tum,sadece_kesisim))
```

<div class="kable-table">

|term                            | df.residual|      rss| df|     sumsq| statistic|   p.value|
|:-------------------------------|-----------:|--------:|--:|---------:|---------:|---------:|
|Performans ~ Motivasyon + Kaygi |          12| 159.9101| NA|        NA|        NA|        NA|
|Performans ~ Motivasyon         |          13| 274.7906| -1| -114.8805|  8.620882| 0.0124612|

</div>



- Modelde tek bir yordayıcı (motivasyon) varken, korelasyon **0.824**’tür ve sıfır  hipotezi doğruysa bu kadar yüksek bir korelasyon elde etme olasılığı p < 0.001. 
Bu olasılık 0.05’ten küçük olduğundan, korelasyonun anlamlı olarak sıfırdan 
büyük olduğu söylenebilir. 

- Modele motivasyon değişkeninin yanı sıra kaygi değişkeni de yordayıcı olarak 
eklendiğinde, çoklu korelasyon **0.902**’dir ve sıfır hipotezi doğruysa bu kadar  yüksek bir korelasyon elde etme olasılığı p < 0.001. Bu olasılık 0.05’ten küçük  olduğundan, çoklu korelasyonun anlamlı olarak sıfırdan büyük olduğu söylenebilir.


- Birinci modelde motivasyon tek yordayıcıdır. Bu modelde motivasyona ilişkin 
standartlaştırılmamış eğim katsayısı **0.644** olarak kestirilmiş olup kestirimin standart hatası **0.123**’tür. Bu katsayı p ˂ .05’te anlamlıdır. Standartlaştırılmış eğim  katsayısı 0.824 olarak kestirilmiştir ve bu değer motivasyon ile performansarasındaki korelasyondur. 

- İkinci modelde **motivasyon ve kaygı** yordayıcılardır. Bu modelde motivasyona ilişkin standartlaştırılmamış eğim katsayısı **0.686** olarak kestirilmiş olup kestirimin  standart hatası **0.098**’dir.


- Öğrencilerin kaygı düzeyi kontrol altına alındığında, 
artan motivasyon düzeyi daha yüksek performans puanları ile ilişkilidir. Bu katsayı p ˂ .05’te anlamlıdır. Standartlaştırılmış eğim katsayısı **0.879** olarak kestirilmiştir. Kaygıya ilişkin standartlaştırılmamış eğim katsayısı **-0.607** olarak kestirilmiş olup  kestirimin standart hatası **0.207**’dir. Öğrencilerin motivasyon düzeyi kontrol altına  alındığında, artan kaygı düzeyi daha düşük performans puanları ile ilişkilidir. 

- Kaygının modele eklenmesi korelasyonu çok fazla artırmasa da istatistiksel olarak anlamlı bir yordayıcıdır. Standartlaştırılmış eğim katsayısı -0.370 olarak kestirilmiştir. 


## Etkili Gözlemlerin Belirlenmesi

- Etkili gözlemler (influential observations) regresyon sonuçları 
üzerinde **orantısız etkisi** olan bütün gözlemleri içerir. 

- Bu **aşırı değerler regresyon doğrusunu kendilerine doğru çekerek** modelin 
katsayıları üzerinde anlamlı etkileri olan değerlerdir. 

- Bu gözlemlerin belirlenmesinde kullanılan bazı istatistikler şunlardır: 
- **Distance (Uzaklık)**
- **Leverage (hi)**
- **Influence (Etki)**
- **Cook’s D**


### **Distance (Uzaklık):**

- **Bağımlı değişkenlerdeki potansiyel uç değerlerin** 
belirlenmesinde kullanışlı bir istatistiktir. 

- **Uzaklık için en yaygın ölçüm artıktır**. 

- Artık herhangi **bir nokta ve regresyon eğrisi arasındaki dikey uzaklığı** ölçer. Bu noktalar **rastgele hatayı temsil edebilir**, veri yanlış kodlanmış olabilir veya veri setine ait  olmayan olağan dışı durumları yansıtabilir. 


## **Leverage (hi):** 
 
 - **Bağımsız değişkenlerdeki potansiyel uç değerlerin belirlenmesinde **
kullanışlı bir istatistiktir. 

- Levarage bir gözlemin bir bağımsız değişkene, $X_j$, göre **olağan dışı olma derecesini** ölçer. 

- Leverage için olası değerler, N gözlemlerin sayısı olmak üzere, **1/N** ile **1.0** arasında değişir. 

- Ortalama leverage puanı, **p** bağımsız değişken sayısı ve **N** gözlem sayısı olmak üzere, **(p +1)/N** eşitliği ile hesaplanabilir. 

- **Yüksek leverage değerine** sahip gözlemler ortalama değerden 2  veya 3 kat daha yüksek leverage puanlarına sahip olacaktır. 


## **Influence (Etki):**

- Etkili bir gözlem **uzaklık ve/veya leverage için yüksek değere** 
sahip olan ve **modelin kesişim ve eğim katsayılarını anlamlı** olarak etkileyen bir 
gözlemdir. 

- Bu gözlemin varlığı veya yokluğu regresyon yüzeyinin yerini önemli 
ölçüde değiştirecektir. 

- Uzaklık ve/veya leverage için yüksek değere sahip gözlemlerin regresyon 
üzerinde önemli bir etkisi olmayabilir. Bir gözlemin etkide yüksek olması için 
**hem uzaklık hem de leverage için yüksek değerlere** sahip olması gerekir.


## **Cook’s D** 

- Etkinin en yaygın ölçümü **Cook’s D** olarak bilinir. 

- Cook’s D **i** gözlemi veriden çıkarılıp analiz yeniden gerçekleştirilirse, $b_j$ katsayısındaki  değişikliğin karesinin toplamının bir fonksiyonudur. 

- Her gözlem için hesaplanabilir. Her gözlem için bu değer, **N** gözlemlerin sayısı olmak üzere **4/N** ile karşılaştırılabilir. **4/N** üzerindeki değerler problem olabilecek gözlemlere işaret eder.

- **Cook’s D** etkinin genel bir ölçümü olarak düşünülebilir. Gözlemin 
eklenmesiyle her katsayının nasıl değiştiğini ölçen daha spesifik bir 
ölçüm ele alınabilir. Bu ölçüm **DFBETA** olarak adlandırılır ve her 
gözlem için hesaplanabilir. (kritik değer $2/\sqrt{n}$



**Cook’s D**

```r
library(olsrr)
```

```
## 
## Attaching package: 'olsrr'
```

```
## The following object is masked from 'package:MASS':
## 
##     cement
```

```
## The following object is masked from 'package:datasets':
## 
##     rivers
```

```r
ols_plot_cooksd_bar(model)
```

<img src="04-CR_files/figure-html/unnamed-chunk-43-1.png" width="100%" style="display: block; margin: auto;" />


**DFBETA**


```r
ols_plot_dfbetas(model)
```

<img src="04-CR_files/figure-html/unnamed-chunk-44-1.png" width="100%" style="display: block; margin: auto;" />



```r
ols_plot_dffits(model)
```

<img src="04-CR_files/figure-html/unnamed-chunk-45-1.png" width="100%" style="display: block; margin: auto;" />



```r
ols_plot_resid_lev(model)
```

<img src="04-CR_files/figure-html/unnamed-chunk-46-1.png" width="100%" style="display: block; margin: auto;" />



## Etkili Gözlemlerin Belirlenmesi

<img src="images/CR_4.PNG" width="80%" style="display: block; margin: auto;" />



- Regresyon analizinin sonuçları ve sonuçların genellenebilirliği 
**birkaç gözlemle değişebilir.** Dolayısıyla bu gözlemlerin etkilerinin 
değerlendirilmesi için belirlenmesi gerekir. 

- Etkili gözlem, gözlemlerdeki veya veri girişindeki bir hatadan 
kaynaklanabilir. Bu durumda birey analizden çıkarılabilir veya veri 
düzeltilebilir. 

- Sıradışı bir durumla açıklanabilen, ender karşılaşılan geçerli bir 
gözlem analizden çıkarılabilir. Halbuki olası bir açıklaması olmayan, 
ender karşılaşılan bir gözlemi bir neden olmadan çıkarmak 
problemlidir ancak gözlemin analize dahil edilmesi de 
savunulamayabilir. **Bu durumda analizlerin gözlem dahil edilerek ve 
dahil edilmeyerek tekrarlanması önerilir.**


Cook's D için kesme noktası 4/15= 0.267, 8. ve 11. gözlemler bu sınırı asıyor

```r
influence.measures(model, infl = influence(model))
```

```
## Influence measures of
## 	 lm(formula = Performans ~ Motivasyon + Kaygi, data = performans) :
## 
##      dfb.1_  dfb.Mtvs dfb.Kayg   dffit cov.r   cook.d    hat inf
## 1   0.95795 -0.960377 -0.16108  1.1422 0.896 0.372039 0.3012    
## 2  -0.25252  0.415588 -0.15745 -0.4984 1.422 0.084595 0.2501    
## 3   0.14949 -0.263213  0.00861 -0.3676 1.209 0.045656 0.1388    
## 4  -0.04850  0.110703 -0.01220  0.1872 1.332 0.012398 0.1026    
## 5  -0.05212 -0.059328  0.11625 -0.1413 1.796 0.007232 0.2869   *
## 6  -0.50564 -0.103904  0.68481 -0.8203 0.924 0.201071 0.2200    
## 7  -0.09262  0.115511 -0.02600 -0.1686 1.409 0.010150 0.1264    
## 8   1.12071 -0.626060 -0.99660 -1.3623 1.570 0.574244 0.4905   *
## 9   0.07075 -0.094818  0.07387  0.3019 1.061 0.030173 0.0774    
## 10 -0.00254  0.000079 -0.00142 -0.0191 1.390 0.000132 0.0670    
## 11 -0.76153  1.357765 -0.15466  1.6459 0.228 0.510106 0.2092   *
## 12 -0.07535  0.006834  0.07308 -0.1166 1.424 0.004897 0.1142    
## 13 -0.06170 -0.043739  0.14852  0.1670 1.965 0.010089 0.3487   *
## 14 -0.00051 -0.015642  0.01231 -0.0267 1.490 0.000260 0.1297    
## 15 -0.07231  0.081208 -0.00672 -0.1135 1.472 0.004648 0.1373
```



DFBETA için kesme noktası ise 2/(15^1/2) = 0.516
hat değerleri ise levarge a karşılık geliyor


```r
influence.measures(model, infl = influence(model))
```

```
## Influence measures of
## 	 lm(formula = Performans ~ Motivasyon + Kaygi, data = performans) :
## 
##      dfb.1_  dfb.Mtvs dfb.Kayg   dffit cov.r   cook.d    hat inf
## 1   0.95795 -0.960377 -0.16108  1.1422 0.896 0.372039 0.3012    
## 2  -0.25252  0.415588 -0.15745 -0.4984 1.422 0.084595 0.2501    
## 3   0.14949 -0.263213  0.00861 -0.3676 1.209 0.045656 0.1388    
## 4  -0.04850  0.110703 -0.01220  0.1872 1.332 0.012398 0.1026    
## 5  -0.05212 -0.059328  0.11625 -0.1413 1.796 0.007232 0.2869   *
## 6  -0.50564 -0.103904  0.68481 -0.8203 0.924 0.201071 0.2200    
## 7  -0.09262  0.115511 -0.02600 -0.1686 1.409 0.010150 0.1264    
## 8   1.12071 -0.626060 -0.99660 -1.3623 1.570 0.574244 0.4905   *
## 9   0.07075 -0.094818  0.07387  0.3019 1.061 0.030173 0.0774    
## 10 -0.00254  0.000079 -0.00142 -0.0191 1.390 0.000132 0.0670    
## 11 -0.76153  1.357765 -0.15466  1.6459 0.228 0.510106 0.2092   *
## 12 -0.07535  0.006834  0.07308 -0.1166 1.424 0.004897 0.1142    
## 13 -0.06170 -0.043739  0.14852  0.1670 1.965 0.010089 0.3487   *
## 14 -0.00051 -0.015642  0.01231 -0.0267 1.490 0.000260 0.1297    
## 15 -0.07231  0.081208 -0.00672 -0.1135 1.472 0.004648 0.1373
```




## Kategorik Bağımsız bir Değişken ile Çoklu Regresyon

- Regresyon modellerinde bagimsiz bir değişkensurekli 
veya kategorik olabilir.

- Bir regresyon analizine kategorik bir degiskeni dahil 
ederken, regresyon modelinin degiskenin duzeylerindeki 
farkliliklari dogru olarak kestirmesini saglamak icin,
degiskenin duzeylerinin **yeniden kodlanmasi **
gerekmektedir. 

- Kategorik degiskenleri kodlamanın en basit yöntemi **dummy 
(yapay)** kodlamadir. 

- Dummy kodlama ile kategorik degiskenin 
duzeylerine sayısal değerler atanarak dummy degisken(ler) 
olusturulur.

-Dummy değişkenkategorik bir degiskenin duzeylerinin sayisal 
gosterimidir.


- Bir bireyin **k** tane duzeye sahip kategorik bagimsiz bir degiskenin 
belli bir duzeyine iliskin uyeligini temsil eden **k-1** tane dummy 
değişkenolusturulur. 
- Eger bir birey kategorik degiskenin birinci duzeyindeyse birinci dummy 
degiskene 1 değeri verilir, birey degiskenin baska bir duzeyindeyse 
birinci dummy degiskene 0 değeri verilir.
- Eger ayni birey kategorik degiskenin ikinci duzeyindeyse ikinci dummy 
degiskene 1 değeri verilir, birey degiskenin baska bir duzeyindeyse ikinci 
dummy degiskene 0 değeri verilir.
- Eger ayni birey kategorik degiskenin (k-1). duzeyindeyse (k-1). dummy 
degiskene 1 değeri verilir, birey degiskenin baska bir duzeyindeyse (k-1). dummy degiskene 0 değeri verilir.
- Boyle bir kodlama ile olusturulan her bir dummy değişkeniki duzeye 
sahiptir: 1 ve 0


- Bir kategorik değişken icin olusturulan dummy degiskenlerle 
gerceklestirilen bir regresyon analizinde regresyon katsayilarinin 
yorumlanmasi asagidaki gibidir:
- **Birinci dummy degiskene iliskin katsayi**, diger butun degiskenler kontrol 
altina alindiginda, **kategorik degiskenin birinci duzeyi ve kategorik degiskenin son duzeyi** arasindaki bagimli degiskenin yordanan değerinin 
farkidir. 

- **Ikinci dummy degiskene iliskin katsayi**, diger butun degiskenler kontrol 
altina alindiginda, **kategorik degiskenin ikinci duzeyi** ve **kategorik degiskenin son duzeyi** arasindaki bagimli degiskenin yordanan değerinin 
farkidir. 
- **j. dummy degiskene iliskin katsayi**, diger butun degiskenler kontrol altina alindiginda, **kategorik degiskenin j. duzeyi** ve **kategorik degiskenin son duzeyi** arasindaki bagimli degiskenin yordanan değerinin farkidir.


## Dummy Değişkenlerin Oluşturulması Örnek: Performansın Yordanması

- Uc duzeyi (evil, bekar ve diger) bulunan medeni durum degiskeni 
icin biri “Evli”, digeri “Bekar” olarak adlandirilan iki dummy değişken 
(ornegin, D1 ve D2) olusturulabilir.

| Medeni Durum | D1 (Evli) | D2 (Bekar) | D3 (Diger)|
|::|::|::|::|::|::|
|Evli |1 |0 |0|
|Bekar|0 |1 |0|
|Diger|0 |0 |1|
- Referans Grup: Diger
- Kategorik degiskenin **uc duzeyini** gostermek icin uc gosterge  degiskenine ihtiyac yoktur. Degiskenin duzeyleri sadece **iki  gostergeyle tanimlanmistir.**
- D1 degiskeni icin 0 değerine, D2 degiskeni icin 0 değerine sahip bir birey diger kategorisine aittir.


## Dummy Değişkenlerin Oluşturulması Örnek: Performansın Yordanması

- D1 ve D2 bagimsiz degiskenleri ile gerceklestirilen bir regresyon 
analizinde kestirilen $b_1$ egim katsayisi evliler ve digerleri arasındaki 
yordanan matematik performansi farkini, $b_2$ egim katsayisi ise 
bekarlar ve digerleri arasındaki yordanan matematik performansi 
farkini belirtir.

- Evliler ve bekarlar arasindaki yordanan matematik performansi farki, 
birinci ve ikinci medeni durum katsayilari arasindaki farktir: $b_1 - b_2$


## Dummy Değişkenlerin Oluşturulması Örnek: Performansın Yordanması


```r
library(haven)
Performansd1 <- read_sav("import/Performansd1.sav")
summary(Performansd1)
```

```
##    Performans       Motivasyon        Kaygi           Guven      
##  Min.   : 4.112   Min.   :22.00   Min.   :10.72   Min.   : 8.75  
##  1st Qu.:11.864   1st Qu.:34.00   1st Qu.:15.54   1st Qu.:17.12  
##  Median :18.041   Median :40.00   Median :18.30   Median :22.00  
##  Mean   :18.176   Mean   :39.93   Mean   :18.07   Mean   :21.63  
##  3rd Qu.:22.941   3rd Qu.:47.00   3rd Qu.:18.84   3rd Qu.:25.60  
##  Max.   :35.501   Max.   :55.00   Max.   :28.17   Max.   :38.70  
##     Medeni         
##  Length:15         
##  Class :character  
##  Mode  :character  
##                    
##                    
## 
```


## Dummy Değişkenlerin Oluşturulması Örnek: Performansın Yordanması

```r
library(fastDummies)
```

```
## Thank you for using fastDummies!
```

```
## To acknowledge our work, please cite the package:
```

```
## Kaplan, J. & Schlegel, B. (2023). fastDummies: Fast Creation of Dummy (Binary) Columns and Rows from Categorical Variables. Version 1.7.1. URL: https://github.com/jacobkap/fastDummies, https://jacobkap.github.io/fastDummies/.
```

```r
# Performansd1$D1 <- ifelse(Performansd1$Medeni  == "Evli", 1, 0)
# Performansd1$D2<- ifelse(Performansd1$Medeni  == "Bekar", 1, 0)
dataf <- dummy_cols(Performansd1, select_columns = 'Medeni')
summary(dataf)
```

```
##    Performans       Motivasyon        Kaygi           Guven      
##  Min.   : 4.112   Min.   :22.00   Min.   :10.72   Min.   : 8.75  
##  1st Qu.:11.864   1st Qu.:34.00   1st Qu.:15.54   1st Qu.:17.12  
##  Median :18.041   Median :40.00   Median :18.30   Median :22.00  
##  Mean   :18.176   Mean   :39.93   Mean   :18.07   Mean   :21.63  
##  3rd Qu.:22.941   3rd Qu.:47.00   3rd Qu.:18.84   3rd Qu.:25.60  
##  Max.   :35.501   Max.   :55.00   Max.   :28.17   Max.   :38.70  
##     Medeni             Medeni_1         Medeni_2         Medeni_3     
##  Length:15          Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  
##  Class :character   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000  
##  Mode  :character   Median :0.0000   Median :0.0000   Median :0.0000  
##                     Mean   :0.2667   Mean   :0.4667   Mean   :0.2667  
##                     3rd Qu.:0.5000   3rd Qu.:1.0000   3rd Qu.:0.5000  
##                     Max.   :1.0000   Max.   :1.0000   Max.   :1.0000
```


## Dummy Değişkenlerin Oluşturulması Örnek: Performansın Yordanması




```r
model_dummy <- lm(Performans ~ Medeni_1 + Medeni_2 , 
                  data=dataf)
model_dummy
```

```
## 
## Call:
## lm(formula = Performans ~ Medeni_1 + Medeni_2, data = dataf)
## 
## Coefficients:
## (Intercept)     Medeni_1     Medeni_2  
##     19.6442      -6.6234       0.6386
```



- Kesişim katsayısı $b_0$  19.644 matematik değerine eşittir. Bu değer, medeni 
durumu diger olan ogrencilerin yordanan performans puanıdır. 
- Evli için standartlaştırılmamış eğim katsayısı $b_1$ -6.623 değerine eşittir. Bu değer, **evliler ve digerleri arasindaki** yordanan matematik performans 
puanları farkinin -6.623 birim olduğunu önerir.
- $19.644 – 6.623 = 13.021$ medeni durumu evli  olan ogrencilerin yordanan matematik performans puanidir.



## Dummy Değişkenlerin Oluşturulması Örnek: Performansın Yordanması

```r
model_dummy
```

```
## 
## Call:
## lm(formula = Performans ~ Medeni_1 + Medeni_2, data = dataf)
## 
## Coefficients:
## (Intercept)     Medeni_1     Medeni_2  
##     19.6442      -6.6234       0.6386
```

- benzer şekilde, Bekar için standartlaştırılmamış eğim katsayısı $b_21$ 0.639 
değerine eşittir. Bu değer, **bekarlar ve digerleri arasindaki** yordanan 
matematik performans puanları farkinin 0.639 birim olduğunu önerir.

- $19.644 + 0.639 = 20.283$ medeni durumu bekar olan ogrencilerin yordanan matematik 
performans puanidir.


## Coklu Regresyonda Iki-Yonlu Etkilesim Etkisi

- Eger bir coklu regresyon modelinde bir bağımsız değişken ile
bagimli değişken arasindaki iliskinin buyuklugu diger bir bağımsız
degiskenin duzeyine gore degisirse, etkilesim gozlenir.

- Etkilesim etkisi, düzenleyici (moderator) etki olarak da bilinmektedir. 

<!--   - Örneğin, klinik calismalarla test edilen kolesterol dusurucu bir ilacin dozunun -->
<!-- $X_1$ ve ilaci kullanan bireylerin cinsiyetinin $X_2$  kolesterol dusurme miktari $Y$  -->
<!-- uzerindeki etkisini gosteren grafikler asagidaki gibi olabilir -->



## Coklu Regresyonda Iki-Yonlu Etkilesim Etkisi

- Etkileşim terimi $X_1$ değişkeninin değerlerinin aracı $X_2$ değişkeninin 
değerleriyle çarpılmasıyla oluşan bileşik bir değişkendir.

- Regresyon eşitliği aşağıdaki gibidir:

$$Y= a + b_1x_{1i} +  b_2x_{2i} + b_3x_{1i}x_{2i}$$

- Burada, $b_3$ katsayısı aracı etki olup $X_2$ değişkenin değeri değişirken $X_1$
değişkeninin etkisindeki birim değişimi belirtir.



## Coklu Regresyonda Iki-Yonlu Etkilesim Etkisi

$$Y= a + b_1x_{1i} +  b_2x_{2i} + b_3x_{1i}x_{2i}$$

- $b_1$ katsayısı  $X_2$ değişkenine ilişkin  değer sıfırken $X_1$ değişkeninin etkisini,

- $b_2$ katsayısı $X_1$ değişkenine ilişkin değer sıfırken $X_2$ değişkeninin etkisini belirtir (Etkileşim etkisinin bulunmadığı modelde, $b_1$ katsayısı $X_2$ değişkeninin bütün düzeylerinde $X_1$ değişkeninin etkisini, $b_2$ katsayısı $X_1$ değişkeninin bütün düzeylerinde $X_2$ değişkeninin etkisini temsil eder). 


## ## Coklu Regresyonda Iki-Yonlu Etkilesim Etkisi

- Bağımsız değişkenin toplam etkisini belirlemek için değişkenin ayrı ve aracı etkisi bir araya getirilmelidir. 

- $X_1$  değişkeninin $X_2$  değişkeninin herhangi bir değerindeki  toplam etkisi aşağıdaki eşitlikle hesaplanabilir:


$$ b_{toplam} = b_1+b_3X_2$$


## Coklu Regresyonda Iki-Yonlu Etkilesim Etkisi

-Sunumdaki ornek Wagner, Compas ve Howell (1988)’in calismasindan 
gelmektedir. 

- Wagner ve digerleri calismalarinda **daha fazla strese maruz kalan bireylerin psikolojik belirtileri daha yuksek duzeyde gosterecegini**
onermistir. 

- Ancak bir birey stresiyle basa cikmasina yardimci olacak yuksek 
duzeyde **sosyal destege sahipse**, belirtilerin stres arttikca daha yavas 
artmasinin beklenecegini, daha az sosyal destege sahip bireyler icinse, 
semptomlarin stres arttikca daha hizli artmasinin beklenecegini belirttiler.

- Wagner, B. M., Compas, B. E., & Howell, D. C. (1988). Daily and major life events: A test  of an integrative model of psychosocial stress. American Journal of Community Psychology, 16 (2), 189-205. 



## Coklu Regresyonda Iki-Yonlu Etkilesim Etkisi

“Hassles.sav” SPSS veri dosyasi bir ID degiskeni ve ID degiskeni 
disinda dort değişken ve 56 universite birinci sinif ogrencisini 
icermektedir. Veri setine asagidaki web adresinden ulasilabilir:

- https://www.uvm.edu/~dhowell/methods8/DataFiles/DataSets.html


```r
library(haven)
zorluklar <- read_sav("import/Hassles.sav")[,c(1,2,4,5)]
colnames(zorluklar)  <- c("id","sorun","destek","belirtiler")
```


## Coklu Regresyonda Iki-Yonlu Etkilesim Etkisi
İlk olarak değişkenler arasındaki ilişkilere bakılır.


```r
ggpairs(zorluklar[,-1])
```

<img src="04-CR_files/figure-html/unnamed-chunk-55-1.png" width="40%" style="display: block; margin: auto;" />


## Coklu Regresyonda Iki-Yonlu Etkilesim Etkisi

- Destek, sorun veya belirtiler ile iliskili olmamasina ragmen, beklendigi
gibi, Zorluklar ve Belirtiler arasinda istatistiksel olarak bir iliski vardir (r = 0, 
577).

- Ancak bu bulgular sorun ve belirtiler arasindaki iliskinin destek
duzeyine bagli olup olmadigi sorusuna cevap vermemektedir



## Coklu Regresyonda Iki-Yonlu Etkilesim Etkisi

- Sorun ve Destek etkilesimini test etmek icin sorun değerleri ile 
destek değerlerinin carpimiyla yeni bir değişken olusturulur.

- Ancak bu iki degiskene iliskin değerlerin carpilmasiyla olusan degiskenin 
analize dahil edilmesinde iki problem ortaya cikacaktir.

  - Sorun veya Destek degiskenlerinden biri veya ikisi, carpimlariyla olusan 
değişken ile yuksek duzeyde korelasyona sahip olacaktir ki bu da veride **coklu baglanti problemine** neden olacaktir. 


## Coklu Regresyonda Iki-Yonlu Etkilesim Etkisi

-   Regresyon analizinde Sorun veya Destek degiskeninin herhangi bir etkisi
diger degiskenin değerinin 0 oldugu durumda değerlendirilecektir. 

 - Diger bir ifadeyle, Sorun uzerindeki test hic sosyal destegi olmayan bir katilimci icin  Sorunların belirtilerle iliskili olup olmadigi testi olacaktir. 
- Benzer sekilde, destek uzerindeki test hic Sorunları olmayan katilimcilar icin değerlendirilecektir. 

- Hem **coklu baglanti problemi**, hem de **ana etkilerden birinin digerana etkinin uc değerinde değerlendirilmesi** problemi istenmeyen 
durumlardir.



## Coklu Regresyonda Iki-Yonlu Etkilesim Etkisi

- Bahsedilen problemlerle basa cikmak icin **sorun degiskeni ve destek 
degiskeni** merkezlenebilir. 

- Bunun icin her bir degiskene iliskin bireysel gozlemlerden ilgili 
degiskenin ortalamasi cikarilarak sapma puanlari hesaplanacaktir. 


```r
zorluklar$csorun <- zorluklar$sorun -mean(zorluklar$sorun)
zorluklar$cdestek <- zorluklar$destek -mean(zorluklar$destek)
zorluklar$cross  <- zorluklar$sorun*zorluklar$destek
zorluklar$cross_m  <- zorluklar$csorun*zorluklar$cdestek
```



## Coklu Regresyonda Iki-Yonlu Etkilesim Etkisi

- Degiskenler merkezlendikten sonra merkezlenen sorun 
degiskeni icin 0 değeri sorun degiskeninin ortalama duzeyindeki 
katilimcilari temsil ederken,  merkezlenen destek degiskeni icin 0 değeri 
destek degiskeninin ortalama duzeyindeki katilimcilari 
temsil eder. 

- Boylece ana etkiler diger degiskenin uygun duzeyinde değerlendirilir. 


## Coklu Regresyonda Iki-Yonlu Etkilesim Etkisi

- Degiskenlerin merkezlenmesiyle sorun ve destek degiskenleri 
arasindaki **coklu baglanti** da önemli olcude dusecektir. 

- Merkezlenen sorun, Merkezlenen destek, Merkezlenen sorun 
degiskeninin değerleri ile Merkezlenen Destek degiskeninin değerlerinin 
carpilmasiyla elde edilen etkilesim terimi ve Belirtiler arasindaki 
korelasyon matrisi incelenir.




.pull-left[

```r
ggpairs(zorluklar[,c(2:4,7)])
```

<img src="04-CR_files/figure-html/unnamed-chunk-57-1.png" width="70%" style="display: block; margin: auto;" />




```r
ggpairs(zorluklar[,c(5,6,4,8)])
```

<img src="04-CR_files/figure-html/unnamed-chunk-58-1.png" width="70%" style="display: block; margin: auto;" />


## Coklu Regresyonda Iki-Yonlu Etkilesim Etkisi

- Belirtilerin bagimli degişken, merkezlenen sorunların ve merkezlenen
Destegin bağımsız değişken olarak modellendigi regresyonda, iki
bağımsız degiskenin etkilesimini incelemek uzere etkilesim terimi de 
regresyon modeline eklenir.


```r
cross_model <- lm(belirtiler  ~ csorun  + cdestek + cross_m ,data=zorluklar)
glance(cross_model)
tidy(cross_model)
```

<div class="kable-table">

| r.squared| adj.r.squared|    sigma| statistic|  p.value| df|    logLik|      AIC|      BIC| deviance| df.residual| nobs|
|---------:|-------------:|--------:|---------:|--------:|--:|---------:|--------:|--------:|--------:|-----------:|----:|
| 0.3884955|     0.3532164| 16.89323|  11.01206| 1.05e-05|  3| -235.6926| 481.3853| 491.5121| 14839.82|          52|   56|

</div><div class="kable-table">

|term        |   estimate| std.error|  statistic|   p.value|
|:-----------|----------:|---------:|----------:|---------:|
|(Intercept) | 89.5849395| 2.2915032| 39.0943989| 0.0000000|
|csorun      |  0.0859416| 0.0192129|  4.4731132| 0.0000422|
|cdestek     |  0.1463575| 0.3052438|  0.4794774| 0.6336095|
|cross_m     | -0.0050649| 0.0023629| -2.1435460| 0.0367670|

</div>

- $R^2$ değeri yaklasik 0.39 olup belirtilerdeki varyansin yaklasik
%39’unun dogrusal regresyon modeli tarafindan aciklandigi
anlamina gelmektedir. 


## Coklu Regresyonda Iki-Yonlu Etkilesim Etkisi


```r
tidy(cross_model)
```

<div class="kable-table">

|term        |   estimate| std.error|  statistic|   p.value|
|:-----------|----------:|---------:|----------:|---------:|
|(Intercept) | 89.5849395| 2.2915032| 39.0943989| 0.0000000|
|csorun      |  0.0859416| 0.0192129|  4.4731132| 0.0000422|
|cdestek     |  0.1463575| 0.3052438|  0.4794774| 0.6336095|
|cross_m     | -0.0050649| 0.0023629| -2.1435460| 0.0367670|

</div>

- Hem merkezlenen sorun hem de etkileşim terimi istatistiksel olarak 
anlamlıdır (sırasıyla p ˂ 0.001 ve p = 0.037). Ancak merkezlenen Destek 
istatistiksel olarak anlamlı değildir (p = 0.634). Destek değişkeni 
etkileşim teriminin hesaplanmasında yer aldığından, regresyon 
modelinde kalabilir. 


- Etkilesim etkisinin anlamini yorumlamak icin degiskenler arasindaki 
iliskilerin grafik ile gosterimi yardimci olabilir. En basit çözüm sosyal 
destegin sabit duzeyleri icin zorluklar ve psikolojik belirtiler 
arasindaki iliskiye bakmaktir. 




## Coklu Regresyonda Iki-Yonlu Etkilesim Etkisi

- Merkezlenen sosyal destek değişkeninin değerileri -21 ile +19 arasında 
değişmektedir. Bu değişken icin dusuk, orta ve yuksek değerleri temsil etmek 
üzere sirasiyla -15, 0 ve +15 değerleri secilebilir.


```r
library(dplyr)
zorluklar <- zorluklar %>% mutate(
  cdestek_kat = case_when(
  cdestek <= -15 ~ "dusuk",
  cdestek >-15 &    cdestek <15~ "orta",
  cdestek >=15 ~ "yuksek",
  )
)
zorluklar <- zorluklar %>%  arrange(csorun)
```




## Coklu Regresyonda Iki-Yonlu Etkilesim Etkisi



```r
library(plotly)
```

```
## 
## Attaching package: 'plotly'
```

```
## The following object is masked from 'package:MASS':
## 
##     select
```

```
## The following object is masked from 'package:ggplot2':
## 
##     last_plot
```

```
## The following object is masked from 'package:stats':
## 
##     filter
```

```
## The following object is masked from 'package:graphics':
## 
##     layout
```

```r
p <- ggplot(data=zorluklar, aes(x=sorun, y=belirtiler))+
    geom_line(aes(color=cdestek_kat))


ggplotly(p)
```

```{=html}
<div class="plotly html-widget html-fill-item" id="htmlwidget-547bf2756b4531a6045c" style="width:100%;height:480px;"></div>
<script type="application/json" data-for="htmlwidget-547bf2756b4531a6045c">{"x":{"data":[{"x":[176,185],"y":[73,125],"text":["sorun: 176<br />belirtiler:  73<br />cdestek_kat: dusuk","sorun: 185<br />belirtiler: 125<br />cdestek_kat: dusuk"],"type":"scatter","mode":"lines","line":{"width":1.8897637795275593,"color":"rgba(248,118,109,1)","dash":"solid"},"hoveron":"points","name":"dusuk","legendgroup":"dusuk","showlegend":true,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[16,27,42,45,49,54,54,62,64,65,67,68,68,75,75,88,89,95,96,112,118,131,139,143,144,153,153,156,158,161,164,171,172,193,193,201,202,202,203,214,217,219,229,229,260,277,290,298,342,380,525,717],"y":[80,64,77,78,62,86,74,58,66,86,63,106,88,109,78,81,90,62,111,87,80,80,82,81,70,73,84,74,74,109,99,74,88,79,100,91,102,102,88,93,97,93,127,99,131,101,96,111,75,107,177,117],"text":["sorun:  16<br />belirtiler:  80<br />cdestek_kat: orta","sorun:  27<br />belirtiler:  64<br />cdestek_kat: orta","sorun:  42<br />belirtiler:  77<br />cdestek_kat: orta","sorun:  45<br />belirtiler:  78<br />cdestek_kat: orta","sorun:  49<br />belirtiler:  62<br />cdestek_kat: orta","sorun:  54<br />belirtiler:  86<br />cdestek_kat: orta","sorun:  54<br />belirtiler:  74<br />cdestek_kat: orta","sorun:  62<br />belirtiler:  58<br />cdestek_kat: orta","sorun:  64<br />belirtiler:  66<br />cdestek_kat: orta","sorun:  65<br />belirtiler:  86<br />cdestek_kat: orta","sorun:  67<br />belirtiler:  63<br />cdestek_kat: orta","sorun:  68<br />belirtiler: 106<br />cdestek_kat: orta","sorun:  68<br />belirtiler:  88<br />cdestek_kat: orta","sorun:  75<br />belirtiler: 109<br />cdestek_kat: orta","sorun:  75<br />belirtiler:  78<br />cdestek_kat: orta","sorun:  88<br />belirtiler:  81<br />cdestek_kat: orta","sorun:  89<br />belirtiler:  90<br />cdestek_kat: orta","sorun:  95<br />belirtiler:  62<br />cdestek_kat: orta","sorun:  96<br />belirtiler: 111<br />cdestek_kat: orta","sorun: 112<br />belirtiler:  87<br />cdestek_kat: orta","sorun: 118<br />belirtiler:  80<br />cdestek_kat: orta","sorun: 131<br />belirtiler:  80<br />cdestek_kat: orta","sorun: 139<br />belirtiler:  82<br />cdestek_kat: orta","sorun: 143<br />belirtiler:  81<br />cdestek_kat: orta","sorun: 144<br />belirtiler:  70<br />cdestek_kat: orta","sorun: 153<br />belirtiler:  73<br />cdestek_kat: orta","sorun: 153<br />belirtiler:  84<br />cdestek_kat: orta","sorun: 156<br />belirtiler:  74<br />cdestek_kat: orta","sorun: 158<br />belirtiler:  74<br />cdestek_kat: orta","sorun: 161<br />belirtiler: 109<br />cdestek_kat: orta","sorun: 164<br />belirtiler:  99<br />cdestek_kat: orta","sorun: 171<br />belirtiler:  74<br />cdestek_kat: orta","sorun: 172<br />belirtiler:  88<br />cdestek_kat: orta","sorun: 193<br />belirtiler:  79<br />cdestek_kat: orta","sorun: 193<br />belirtiler: 100<br />cdestek_kat: orta","sorun: 201<br />belirtiler:  91<br />cdestek_kat: orta","sorun: 202<br />belirtiler: 102<br />cdestek_kat: orta","sorun: 202<br />belirtiler: 102<br />cdestek_kat: orta","sorun: 203<br />belirtiler:  88<br />cdestek_kat: orta","sorun: 214<br />belirtiler:  93<br />cdestek_kat: orta","sorun: 217<br />belirtiler:  97<br />cdestek_kat: orta","sorun: 219<br />belirtiler:  93<br />cdestek_kat: orta","sorun: 229<br />belirtiler: 127<br />cdestek_kat: orta","sorun: 229<br />belirtiler:  99<br />cdestek_kat: orta","sorun: 260<br />belirtiler: 131<br />cdestek_kat: orta","sorun: 277<br />belirtiler: 101<br />cdestek_kat: orta","sorun: 290<br />belirtiler:  96<br />cdestek_kat: orta","sorun: 298<br />belirtiler: 111<br />cdestek_kat: orta","sorun: 342<br />belirtiler:  75<br />cdestek_kat: orta","sorun: 380<br />belirtiler: 107<br />cdestek_kat: orta","sorun: 525<br />belirtiler: 177<br />cdestek_kat: orta","sorun: 717<br />belirtiler: 117<br />cdestek_kat: orta"],"type":"scatter","mode":"lines","line":{"width":1.8897637795275593,"color":"rgba(0,186,56,1)","dash":"solid"},"hoveron":"points","name":"orta","legendgroup":"orta","showlegend":true,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[126,379],"y":[118,88],"text":["sorun: 126<br />belirtiler: 118<br />cdestek_kat: yuksek","sorun: 379<br />belirtiler:  88<br />cdestek_kat: yuksek"],"type":"scatter","mode":"lines","line":{"width":1.8897637795275593,"color":"rgba(97,156,255,1)","dash":"solid"},"hoveron":"points","name":"yuksek","legendgroup":"yuksek","showlegend":true,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null}],"layout":{"margin":{"t":26.228310502283104,"r":7.3059360730593621,"b":40.182648401826491,"l":43.105022831050235},"plot_bgcolor":"rgba(255,255,255,1)","paper_bgcolor":"rgba(255,255,255,1)","font":{"color":"rgba(0,0,0,1)","family":"","size":14.611872146118724},"xaxis":{"domain":[0,1],"automargin":true,"type":"linear","autorange":false,"range":[-19.050000000000004,752.04999999999995],"tickmode":"array","ticktext":["0","200","400","600"],"tickvals":[0,200,400,600],"categoryorder":"array","categoryarray":["0","200","400","600"],"nticks":null,"ticks":"outside","tickcolor":"rgba(51,51,51,1)","ticklen":3.6529680365296811,"tickwidth":0.66417600664176002,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":11.68949771689498},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"gridcolor":"rgba(235,235,235,1)","gridwidth":0.66417600664176002,"zeroline":false,"anchor":"y","title":{"text":"sorun","font":{"color":"rgba(0,0,0,1)","family":"","size":14.611872146118724}},"hoverformat":".2f"},"yaxis":{"domain":[0,1],"automargin":true,"type":"linear","autorange":false,"range":[52.049999999999997,182.94999999999999],"tickmode":"array","ticktext":["60","90","120","150","180"],"tickvals":[60,90,120,150,180],"categoryorder":"array","categoryarray":["60","90","120","150","180"],"nticks":null,"ticks":"outside","tickcolor":"rgba(51,51,51,1)","ticklen":3.6529680365296811,"tickwidth":0.66417600664176002,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":11.68949771689498},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"gridcolor":"rgba(235,235,235,1)","gridwidth":0.66417600664176002,"zeroline":false,"anchor":"x","title":{"text":"belirtiler","font":{"color":"rgba(0,0,0,1)","family":"","size":14.611872146118724}},"hoverformat":".2f"},"shapes":[{"type":"rect","fillcolor":"transparent","line":{"color":"rgba(51,51,51,1)","width":0.66417600664176002,"linetype":"solid"},"yref":"paper","xref":"paper","x0":0,"x1":1,"y0":0,"y1":1}],"showlegend":true,"legend":{"bgcolor":"rgba(255,255,255,1)","bordercolor":"transparent","borderwidth":1.8897637795275593,"font":{"color":"rgba(0,0,0,1)","family":"","size":11.68949771689498},"title":{"text":"cdestek_kat","font":{"color":"rgba(0,0,0,1)","family":"","size":14.611872146118724}}},"hovermode":"closest","barmode":"relative"},"config":{"doubleClick":"reset","modeBarButtonsToAdd":["hoverclosest","hovercompare"],"showSendToCloud":false},"source":"A","attrs":{"49b07eb56aca":{"x":{},"y":{},"colour":{},"type":"scatter"}},"cur_data":"49b07eb56aca","visdat":{"49b07eb56aca":["function (y) ","x"]},"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.20000000000000001,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot","plotly_sunburstclick"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script>
```





```{=html}
<div class="plotly html-widget html-fill-item" id="htmlwidget-7164135e51fcc8d0eecc" style="width:100%;height:480px;"></div>
<script type="application/json" data-for="htmlwidget-7164135e51fcc8d0eecc">{"x":{"data":[{"x":[-200,-193.22033898305085,-186.4406779661017,-179.66101694915255,-172.88135593220341,-166.10169491525426,-159.32203389830508,-152.54237288135593,-145.76271186440678,-138.98305084745763,-132.20338983050848,-125.42372881355932,-118.64406779661017,-111.86440677966102,-105.08474576271186,-98.305084745762713,-91.525423728813564,-84.745762711864415,-77.966101694915267,-71.186440677966118,-64.406779661016969,-57.627118644067792,-50.847457627118644,-44.067796610169495,-37.288135593220346,-30.508474576271198,-23.728813559322049,-16.9491525423729,-10.169491525423723,-3.3898305084745743,3.3898305084745743,10.169491525423723,16.949152542372872,23.72881355932202,30.508474576271169,37.288135593220318,44.067796610169466,50.847457627118644,57.627118644067764,64.406779661016913,71.186440677966061,77.966101694915267,84.745762711864415,91.525423728813564,98.305084745762713,105.08474576271186,111.86440677966101,118.64406779661016,125.42372881355931,132.20338983050846,138.9830508474576,145.76271186440675,152.5423728813559,159.32203389830505,166.1016949152542,172.88135593220335,179.66101694915255,186.4406779661017,193.22033898305085,200],"y":[55.006551593285131,56.104281267401738,57.202010941518353,58.299740615634946,59.397470289751553,60.49519996386816,61.592929637984774,62.690659312101381,63.788388986217996,64.886118660334589,65.983848334451196,67.081578008567803,68.179307682684424,69.277037356801031,70.374767030917624,71.472496705034231,72.570226379150839,73.667956053267446,74.765685727384053,75.86341540150066,76.961145075617267,78.058874749733874,79.156604423850482,80.254334097967089,81.352063772083682,82.449793446200303,83.54752312031691,84.645252794433517,85.742982468550125,86.840712142666732,87.938441816783339,89.036171490899946,90.133901165016553,91.23163083913316,92.329360513249767,93.42709018736636,94.524819861482968,95.622549535599589,96.720279209716196,97.818008883832789,98.915738557949396,100.01346823206602,101.11119790618262,102.20892758029923,103.30665725441584,104.40438692853245,105.50211660264904,106.59984627676565,107.69757595088227,108.79530562499887,109.89303529911548,110.99076497323207,112.08849464734868,113.18622432146529,114.28395399558191,115.3816836696985,116.47941334381512,117.57714301793172,118.67487269204833,119.77260236616495],"text":["csorun: -200.000000<br />belirtiler:  55.00655<br />destek: dusuk","csorun: -193.220339<br />belirtiler:  56.10428<br />destek: dusuk","csorun: -186.440678<br />belirtiler:  57.20201<br />destek: dusuk","csorun: -179.661017<br />belirtiler:  58.29974<br />destek: dusuk","csorun: -172.881356<br />belirtiler:  59.39747<br />destek: dusuk","csorun: -166.101695<br />belirtiler:  60.49520<br />destek: dusuk","csorun: -159.322034<br />belirtiler:  61.59293<br />destek: dusuk","csorun: -152.542373<br />belirtiler:  62.69066<br />destek: dusuk","csorun: -145.762712<br />belirtiler:  63.78839<br />destek: dusuk","csorun: -138.983051<br />belirtiler:  64.88612<br />destek: dusuk","csorun: -132.203390<br />belirtiler:  65.98385<br />destek: dusuk","csorun: -125.423729<br />belirtiler:  67.08158<br />destek: dusuk","csorun: -118.644068<br />belirtiler:  68.17931<br />destek: dusuk","csorun: -111.864407<br />belirtiler:  69.27704<br />destek: dusuk","csorun: -105.084746<br />belirtiler:  70.37477<br />destek: dusuk","csorun:  -98.305085<br />belirtiler:  71.47250<br />destek: dusuk","csorun:  -91.525424<br />belirtiler:  72.57023<br />destek: dusuk","csorun:  -84.745763<br />belirtiler:  73.66796<br />destek: dusuk","csorun:  -77.966102<br />belirtiler:  74.76569<br />destek: dusuk","csorun:  -71.186441<br />belirtiler:  75.86342<br />destek: dusuk","csorun:  -64.406780<br />belirtiler:  76.96115<br />destek: dusuk","csorun:  -57.627119<br />belirtiler:  78.05887<br />destek: dusuk","csorun:  -50.847458<br />belirtiler:  79.15660<br />destek: dusuk","csorun:  -44.067797<br />belirtiler:  80.25433<br />destek: dusuk","csorun:  -37.288136<br />belirtiler:  81.35206<br />destek: dusuk","csorun:  -30.508475<br />belirtiler:  82.44979<br />destek: dusuk","csorun:  -23.728814<br />belirtiler:  83.54752<br />destek: dusuk","csorun:  -16.949153<br />belirtiler:  84.64525<br />destek: dusuk","csorun:  -10.169492<br />belirtiler:  85.74298<br />destek: dusuk","csorun:   -3.389831<br />belirtiler:  86.84071<br />destek: dusuk","csorun:    3.389831<br />belirtiler:  87.93844<br />destek: dusuk","csorun:   10.169492<br />belirtiler:  89.03617<br />destek: dusuk","csorun:   16.949153<br />belirtiler:  90.13390<br />destek: dusuk","csorun:   23.728814<br />belirtiler:  91.23163<br />destek: dusuk","csorun:   30.508475<br />belirtiler:  92.32936<br />destek: dusuk","csorun:   37.288136<br />belirtiler:  93.42709<br />destek: dusuk","csorun:   44.067797<br />belirtiler:  94.52482<br />destek: dusuk","csorun:   50.847458<br />belirtiler:  95.62255<br />destek: dusuk","csorun:   57.627119<br />belirtiler:  96.72028<br />destek: dusuk","csorun:   64.406780<br />belirtiler:  97.81801<br />destek: dusuk","csorun:   71.186441<br />belirtiler:  98.91574<br />destek: dusuk","csorun:   77.966102<br />belirtiler: 100.01347<br />destek: dusuk","csorun:   84.745763<br />belirtiler: 101.11120<br />destek: dusuk","csorun:   91.525424<br />belirtiler: 102.20893<br />destek: dusuk","csorun:   98.305085<br />belirtiler: 103.30666<br />destek: dusuk","csorun:  105.084746<br />belirtiler: 104.40439<br />destek: dusuk","csorun:  111.864407<br />belirtiler: 105.50212<br />destek: dusuk","csorun:  118.644068<br />belirtiler: 106.59985<br />destek: dusuk","csorun:  125.423729<br />belirtiler: 107.69758<br />destek: dusuk","csorun:  132.203390<br />belirtiler: 108.79531<br />destek: dusuk","csorun:  138.983051<br />belirtiler: 109.89304<br />destek: dusuk","csorun:  145.762712<br />belirtiler: 110.99076<br />destek: dusuk","csorun:  152.542373<br />belirtiler: 112.08849<br />destek: dusuk","csorun:  159.322034<br />belirtiler: 113.18622<br />destek: dusuk","csorun:  166.101695<br />belirtiler: 114.28395<br />destek: dusuk","csorun:  172.881356<br />belirtiler: 115.38168<br />destek: dusuk","csorun:  179.661017<br />belirtiler: 116.47941<br />destek: dusuk","csorun:  186.440678<br />belirtiler: 117.57714<br />destek: dusuk","csorun:  193.220339<br />belirtiler: 118.67487<br />destek: dusuk","csorun:  200.000000<br />belirtiler: 119.77260<br />destek: dusuk"],"type":"scatter","mode":"lines","line":{"width":1.8897637795275593,"color":"rgba(248,118,109,1)","dash":"solid"},"hoveron":"points","name":"dusuk","legendgroup":"dusuk","showlegend":true,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[-200,-193.22033898305085,-186.4406779661017,-179.66101694915255,-172.88135593220341,-166.10169491525426,-159.32203389830508,-152.54237288135593,-145.76271186440678,-138.98305084745763,-132.20338983050848,-125.42372881355932,-118.64406779661017,-111.86440677966102,-105.08474576271186,-98.305084745762713,-91.525423728813564,-84.745762711864415,-77.966101694915267,-71.186440677966118,-64.406779661016969,-57.627118644067792,-50.847457627118644,-44.067796610169495,-37.288135593220346,-30.508474576271198,-23.728813559322049,-16.9491525423729,-10.169491525423723,-3.3898305084745743,3.3898305084745743,10.169491525423723,16.949152542372872,23.72881355932202,30.508474576271169,37.288135593220318,44.067796610169466,50.847457627118644,57.627118644067764,64.406779661016913,71.186440677966061,77.966101694915267,84.745762711864415,91.525423728813564,98.305084745762713,105.08474576271186,111.86440677966101,118.64406779661016,125.42372881355931,132.20338983050846,138.9830508474576,145.76271186440675,152.5423728813559,159.32203389830505,166.1016949152542,172.88135593220335,179.66101694915255,186.4406779661017,193.22033898305085,200],"y":[72.396610497096916,72.979265718704909,73.561920940312902,74.144576161920881,74.727231383528874,75.309886605136867,75.892541826744861,76.475197048352854,77.057852269960847,77.640507491568826,78.223162713176819,78.805817934784812,79.388473156392806,79.971128378000799,80.553783599608778,81.136438821216771,81.719094042824764,82.301749264432758,82.884404486040751,83.46705970764873,84.049714929256723,84.632370150864716,85.215025372472709,85.797680594080703,86.380335815688682,86.962991037296675,87.545646258904668,88.128301480512661,88.710956702120654,89.293611923728648,89.876267145336627,90.45892236694462,91.041577588552613,91.624232810160606,92.206888031768599,92.789543253376578,93.372198474984572,93.954853696592565,94.537508918200558,95.120164139808537,95.70281936141653,96.285474583024524,96.868129804632517,97.45078502624051,98.033440247848503,98.616095469456496,99.198750691064475,99.781405912672469,100.36406113428046,100.94671635588846,101.52937157749645,102.11202679910443,102.69468202071242,103.27733724232041,103.85999246392841,104.44264768553639,105.02530290714439,105.60795812875237,106.19061335036037,106.77326857196836],"text":["csorun: -200.000000<br />belirtiler:  72.39661<br />destek: orta","csorun: -193.220339<br />belirtiler:  72.97927<br />destek: orta","csorun: -186.440678<br />belirtiler:  73.56192<br />destek: orta","csorun: -179.661017<br />belirtiler:  74.14458<br />destek: orta","csorun: -172.881356<br />belirtiler:  74.72723<br />destek: orta","csorun: -166.101695<br />belirtiler:  75.30989<br />destek: orta","csorun: -159.322034<br />belirtiler:  75.89254<br />destek: orta","csorun: -152.542373<br />belirtiler:  76.47520<br />destek: orta","csorun: -145.762712<br />belirtiler:  77.05785<br />destek: orta","csorun: -138.983051<br />belirtiler:  77.64051<br />destek: orta","csorun: -132.203390<br />belirtiler:  78.22316<br />destek: orta","csorun: -125.423729<br />belirtiler:  78.80582<br />destek: orta","csorun: -118.644068<br />belirtiler:  79.38847<br />destek: orta","csorun: -111.864407<br />belirtiler:  79.97113<br />destek: orta","csorun: -105.084746<br />belirtiler:  80.55378<br />destek: orta","csorun:  -98.305085<br />belirtiler:  81.13644<br />destek: orta","csorun:  -91.525424<br />belirtiler:  81.71909<br />destek: orta","csorun:  -84.745763<br />belirtiler:  82.30175<br />destek: orta","csorun:  -77.966102<br />belirtiler:  82.88440<br />destek: orta","csorun:  -71.186441<br />belirtiler:  83.46706<br />destek: orta","csorun:  -64.406780<br />belirtiler:  84.04971<br />destek: orta","csorun:  -57.627119<br />belirtiler:  84.63237<br />destek: orta","csorun:  -50.847458<br />belirtiler:  85.21503<br />destek: orta","csorun:  -44.067797<br />belirtiler:  85.79768<br />destek: orta","csorun:  -37.288136<br />belirtiler:  86.38034<br />destek: orta","csorun:  -30.508475<br />belirtiler:  86.96299<br />destek: orta","csorun:  -23.728814<br />belirtiler:  87.54565<br />destek: orta","csorun:  -16.949153<br />belirtiler:  88.12830<br />destek: orta","csorun:  -10.169492<br />belirtiler:  88.71096<br />destek: orta","csorun:   -3.389831<br />belirtiler:  89.29361<br />destek: orta","csorun:    3.389831<br />belirtiler:  89.87627<br />destek: orta","csorun:   10.169492<br />belirtiler:  90.45892<br />destek: orta","csorun:   16.949153<br />belirtiler:  91.04158<br />destek: orta","csorun:   23.728814<br />belirtiler:  91.62423<br />destek: orta","csorun:   30.508475<br />belirtiler:  92.20689<br />destek: orta","csorun:   37.288136<br />belirtiler:  92.78954<br />destek: orta","csorun:   44.067797<br />belirtiler:  93.37220<br />destek: orta","csorun:   50.847458<br />belirtiler:  93.95485<br />destek: orta","csorun:   57.627119<br />belirtiler:  94.53751<br />destek: orta","csorun:   64.406780<br />belirtiler:  95.12016<br />destek: orta","csorun:   71.186441<br />belirtiler:  95.70282<br />destek: orta","csorun:   77.966102<br />belirtiler:  96.28547<br />destek: orta","csorun:   84.745763<br />belirtiler:  96.86813<br />destek: orta","csorun:   91.525424<br />belirtiler:  97.45079<br />destek: orta","csorun:   98.305085<br />belirtiler:  98.03344<br />destek: orta","csorun:  105.084746<br />belirtiler:  98.61610<br />destek: orta","csorun:  111.864407<br />belirtiler:  99.19875<br />destek: orta","csorun:  118.644068<br />belirtiler:  99.78141<br />destek: orta","csorun:  125.423729<br />belirtiler: 100.36406<br />destek: orta","csorun:  132.203390<br />belirtiler: 100.94672<br />destek: orta","csorun:  138.983051<br />belirtiler: 101.52937<br />destek: orta","csorun:  145.762712<br />belirtiler: 102.11203<br />destek: orta","csorun:  152.542373<br />belirtiler: 102.69468<br />destek: orta","csorun:  159.322034<br />belirtiler: 103.27734<br />destek: orta","csorun:  166.101695<br />belirtiler: 103.85999<br />destek: orta","csorun:  172.881356<br />belirtiler: 104.44265<br />destek: orta","csorun:  179.661017<br />belirtiler: 105.02530<br />destek: orta","csorun:  186.440678<br />belirtiler: 105.60796<br />destek: orta","csorun:  193.220339<br />belirtiler: 106.19061<br />destek: orta","csorun:  200.000000<br />belirtiler: 106.77327<br />destek: orta"],"type":"scatter","mode":"lines","line":{"width":1.8897637795275593,"color":"rgba(0,186,56,1)","dash":"solid"},"hoveron":"points","name":"orta","legendgroup":"orta","showlegend":true,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[-200,-193.22033898305085,-186.4406779661017,-179.66101694915255,-172.88135593220341,-166.10169491525426,-159.32203389830508,-152.54237288135593,-145.76271186440678,-138.98305084745763,-132.20338983050848,-125.42372881355932,-118.64406779661017,-111.86440677966102,-105.08474576271186,-98.305084745762713,-91.525423728813564,-84.745762711864415,-77.966101694915267,-71.186440677966118,-64.406779661016969,-57.627118644067792,-50.847457627118644,-44.067796610169495,-37.288135593220346,-30.508474576271198,-23.728813559322049,-16.9491525423729,-10.169491525423723,-3.3898305084745743,3.3898305084745743,10.169491525423723,16.949152542372872,23.72881355932202,30.508474576271169,37.288135593220318,44.067796610169466,50.847457627118644,57.627118644067764,64.406779661016913,71.186440677966061,77.966101694915267,84.745762711864415,91.525423728813564,98.305084745762713,105.08474576271186,111.86440677966101,118.64406779661016,125.42372881355931,132.20338983050846,138.9830508474576,145.76271186440675,152.5423728813559,159.32203389830505,166.1016949152542,172.88135593220335,179.66101694915255,186.4406779661017,193.22033898305085,200],"y":[89.786669400908707,89.854250170008072,89.921830939107451,89.989411708206816,90.056992477306196,90.124573246405575,90.19215401550494,90.259734784604319,90.327315553703698,90.394896322803064,90.462477091902443,90.530057861001822,90.597638630101187,90.665219399200566,90.732800168299931,90.800380937399311,90.86796170649869,90.935542475598069,91.003123244697449,91.070704013796799,91.138284782896179,91.205865551995558,91.273446321094937,91.341027090194316,91.408607859293681,91.476188628393047,91.543769397492426,91.611350166591805,91.678930935691184,91.746511704790564,91.814092473889914,91.881673242989294,91.949254012088673,92.016834781188052,92.084415550287432,92.151996319386797,92.219577088486176,92.287157857585541,92.35473862668492,92.422319395784285,92.489900164883665,92.55748093398303,92.625061703082409,92.692642472181788,92.760223241281167,92.827804010380547,92.895384779479912,92.962965548579291,93.030546317678656,93.098127086778035,93.165707855877415,93.23328862497678,93.300869394076159,93.368450163175538,93.436030932274903,93.503611701374268,93.571192470473662,93.638773239573027,93.706354008672406,93.773934777771771],"text":["csorun: -200.000000<br />belirtiler:  89.78667<br />destek: yuksek","csorun: -193.220339<br />belirtiler:  89.85425<br />destek: yuksek","csorun: -186.440678<br />belirtiler:  89.92183<br />destek: yuksek","csorun: -179.661017<br />belirtiler:  89.98941<br />destek: yuksek","csorun: -172.881356<br />belirtiler:  90.05699<br />destek: yuksek","csorun: -166.101695<br />belirtiler:  90.12457<br />destek: yuksek","csorun: -159.322034<br />belirtiler:  90.19215<br />destek: yuksek","csorun: -152.542373<br />belirtiler:  90.25973<br />destek: yuksek","csorun: -145.762712<br />belirtiler:  90.32732<br />destek: yuksek","csorun: -138.983051<br />belirtiler:  90.39490<br />destek: yuksek","csorun: -132.203390<br />belirtiler:  90.46248<br />destek: yuksek","csorun: -125.423729<br />belirtiler:  90.53006<br />destek: yuksek","csorun: -118.644068<br />belirtiler:  90.59764<br />destek: yuksek","csorun: -111.864407<br />belirtiler:  90.66522<br />destek: yuksek","csorun: -105.084746<br />belirtiler:  90.73280<br />destek: yuksek","csorun:  -98.305085<br />belirtiler:  90.80038<br />destek: yuksek","csorun:  -91.525424<br />belirtiler:  90.86796<br />destek: yuksek","csorun:  -84.745763<br />belirtiler:  90.93554<br />destek: yuksek","csorun:  -77.966102<br />belirtiler:  91.00312<br />destek: yuksek","csorun:  -71.186441<br />belirtiler:  91.07070<br />destek: yuksek","csorun:  -64.406780<br />belirtiler:  91.13828<br />destek: yuksek","csorun:  -57.627119<br />belirtiler:  91.20587<br />destek: yuksek","csorun:  -50.847458<br />belirtiler:  91.27345<br />destek: yuksek","csorun:  -44.067797<br />belirtiler:  91.34103<br />destek: yuksek","csorun:  -37.288136<br />belirtiler:  91.40861<br />destek: yuksek","csorun:  -30.508475<br />belirtiler:  91.47619<br />destek: yuksek","csorun:  -23.728814<br />belirtiler:  91.54377<br />destek: yuksek","csorun:  -16.949153<br />belirtiler:  91.61135<br />destek: yuksek","csorun:  -10.169492<br />belirtiler:  91.67893<br />destek: yuksek","csorun:   -3.389831<br />belirtiler:  91.74651<br />destek: yuksek","csorun:    3.389831<br />belirtiler:  91.81409<br />destek: yuksek","csorun:   10.169492<br />belirtiler:  91.88167<br />destek: yuksek","csorun:   16.949153<br />belirtiler:  91.94925<br />destek: yuksek","csorun:   23.728814<br />belirtiler:  92.01683<br />destek: yuksek","csorun:   30.508475<br />belirtiler:  92.08442<br />destek: yuksek","csorun:   37.288136<br />belirtiler:  92.15200<br />destek: yuksek","csorun:   44.067797<br />belirtiler:  92.21958<br />destek: yuksek","csorun:   50.847458<br />belirtiler:  92.28716<br />destek: yuksek","csorun:   57.627119<br />belirtiler:  92.35474<br />destek: yuksek","csorun:   64.406780<br />belirtiler:  92.42232<br />destek: yuksek","csorun:   71.186441<br />belirtiler:  92.48990<br />destek: yuksek","csorun:   77.966102<br />belirtiler:  92.55748<br />destek: yuksek","csorun:   84.745763<br />belirtiler:  92.62506<br />destek: yuksek","csorun:   91.525424<br />belirtiler:  92.69264<br />destek: yuksek","csorun:   98.305085<br />belirtiler:  92.76022<br />destek: yuksek","csorun:  105.084746<br />belirtiler:  92.82780<br />destek: yuksek","csorun:  111.864407<br />belirtiler:  92.89538<br />destek: yuksek","csorun:  118.644068<br />belirtiler:  92.96297<br />destek: yuksek","csorun:  125.423729<br />belirtiler:  93.03055<br />destek: yuksek","csorun:  132.203390<br />belirtiler:  93.09813<br />destek: yuksek","csorun:  138.983051<br />belirtiler:  93.16571<br />destek: yuksek","csorun:  145.762712<br />belirtiler:  93.23329<br />destek: yuksek","csorun:  152.542373<br />belirtiler:  93.30087<br />destek: yuksek","csorun:  159.322034<br />belirtiler:  93.36845<br />destek: yuksek","csorun:  166.101695<br />belirtiler:  93.43603<br />destek: yuksek","csorun:  172.881356<br />belirtiler:  93.50361<br />destek: yuksek","csorun:  179.661017<br />belirtiler:  93.57119<br />destek: yuksek","csorun:  186.440678<br />belirtiler:  93.63877<br />destek: yuksek","csorun:  193.220339<br />belirtiler:  93.70635<br />destek: yuksek","csorun:  200.000000<br />belirtiler:  93.77393<br />destek: yuksek"],"type":"scatter","mode":"lines","line":{"width":1.8897637795275593,"color":"rgba(97,156,255,1)","dash":"solid"},"hoveron":"points","name":"yuksek","legendgroup":"yuksek","showlegend":true,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null}],"layout":{"margin":{"t":26.228310502283104,"r":7.3059360730593621,"b":40.182648401826491,"l":43.105022831050235},"plot_bgcolor":"rgba(255,255,255,1)","paper_bgcolor":"rgba(255,255,255,1)","font":{"color":"rgba(0,0,0,1)","family":"","size":14.611872146118724},"xaxis":{"domain":[0,1],"automargin":true,"type":"linear","autorange":false,"range":[-220,220],"tickmode":"array","ticktext":["-200","-100","0","100","200"],"tickvals":[-200,-100.00000000000001,0,100,200],"categoryorder":"array","categoryarray":["-200","-100","0","100","200"],"nticks":null,"ticks":"outside","tickcolor":"rgba(51,51,51,1)","ticklen":3.6529680365296811,"tickwidth":0.66417600664176002,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":11.68949771689498},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"gridcolor":"rgba(235,235,235,1)","gridwidth":0.66417600664176002,"zeroline":false,"anchor":"y","title":{"text":"csorun","font":{"color":"rgba(0,0,0,1)","family":"","size":14.611872146118724}},"hoverformat":".2f"},"yaxis":{"domain":[0,1],"automargin":true,"type":"linear","autorange":false,"range":[51.768249054641139,123.01090490480894],"tickmode":"array","ticktext":["60","80","100","120"],"tickvals":[60,80,100,120],"categoryorder":"array","categoryarray":["60","80","100","120"],"nticks":null,"ticks":"outside","tickcolor":"rgba(51,51,51,1)","ticklen":3.6529680365296811,"tickwidth":0.66417600664176002,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":11.68949771689498},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"gridcolor":"rgba(235,235,235,1)","gridwidth":0.66417600664176002,"zeroline":false,"anchor":"x","title":{"text":"belirtiler","font":{"color":"rgba(0,0,0,1)","family":"","size":14.611872146118724}},"hoverformat":".2f"},"shapes":[{"type":"rect","fillcolor":"transparent","line":{"color":"rgba(51,51,51,1)","width":0.66417600664176002,"linetype":"solid"},"yref":"paper","xref":"paper","x0":0,"x1":1,"y0":0,"y1":1}],"showlegend":true,"legend":{"bgcolor":"rgba(255,255,255,1)","bordercolor":"transparent","borderwidth":1.8897637795275593,"font":{"color":"rgba(0,0,0,1)","family":"","size":11.68949771689498},"title":{"text":"destek","font":{"color":"rgba(0,0,0,1)","family":"","size":14.611872146118724}}},"hovermode":"closest","barmode":"relative"},"config":{"doubleClick":"reset","modeBarButtonsToAdd":["hoverclosest","hovercompare"],"showSendToCloud":false},"source":"A","attrs":{"49b02ed367f1":{"x":{},"y":{},"colour":{},"type":"scatter"}},"cur_data":"49b02ed367f1","visdat":{"49b02ed367f1":["function (y) ","x"]},"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.20000000000000001,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot","plotly_sunburstclick"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script>
```




## Coklu Regresyonda Iki-Yonlu Etkilesim Etkisi


- Yuksek duzeyde sosyal destek ile sorunlardaki artislar psikolojik belirtilerde kucuk artislarla iliskilendirilirler. 

- Orta duzeyde sosyal destek ile sorunlardaki artislar psikolojik belirtilerde
daha buyuk artislarla iliskilendirilir.

- Dusuk duzeyde sosyal destek ile sorunlardaki artislar psikolojik belirtilerde
dramatik artislarla iliskilendirilir.





```r
ggplotly(p)
```

```{=html}
<div class="plotly html-widget html-fill-item" id="htmlwidget-649108b707d6b9a5295a" style="width:100%;height:480px;"></div>
<script type="application/json" data-for="htmlwidget-649108b707d6b9a5295a">{"x":{"data":[{"x":[-200,-193.22033898305085,-186.4406779661017,-179.66101694915255,-172.88135593220341,-166.10169491525426,-159.32203389830508,-152.54237288135593,-145.76271186440678,-138.98305084745763,-132.20338983050848,-125.42372881355932,-118.64406779661017,-111.86440677966102,-105.08474576271186,-98.305084745762713,-91.525423728813564,-84.745762711864415,-77.966101694915267,-71.186440677966118,-64.406779661016969,-57.627118644067792,-50.847457627118644,-44.067796610169495,-37.288135593220346,-30.508474576271198,-23.728813559322049,-16.9491525423729,-10.169491525423723,-3.3898305084745743,3.3898305084745743,10.169491525423723,16.949152542372872,23.72881355932202,30.508474576271169,37.288135593220318,44.067796610169466,50.847457627118644,57.627118644067764,64.406779661016913,71.186440677966061,77.966101694915267,84.745762711864415,91.525423728813564,98.305084745762713,105.08474576271186,111.86440677966101,118.64406779661016,125.42372881355931,132.20338983050846,138.9830508474576,145.76271186440675,152.5423728813559,159.32203389830505,166.1016949152542,172.88135593220335,179.66101694915255,186.4406779661017,193.22033898305085,200],"y":[55.006551593285131,56.104281267401738,57.202010941518353,58.299740615634946,59.397470289751553,60.49519996386816,61.592929637984774,62.690659312101381,63.788388986217996,64.886118660334589,65.983848334451196,67.081578008567803,68.179307682684424,69.277037356801031,70.374767030917624,71.472496705034231,72.570226379150839,73.667956053267446,74.765685727384053,75.86341540150066,76.961145075617267,78.058874749733874,79.156604423850482,80.254334097967089,81.352063772083682,82.449793446200303,83.54752312031691,84.645252794433517,85.742982468550125,86.840712142666732,87.938441816783339,89.036171490899946,90.133901165016553,91.23163083913316,92.329360513249767,93.42709018736636,94.524819861482968,95.622549535599589,96.720279209716196,97.818008883832789,98.915738557949396,100.01346823206602,101.11119790618262,102.20892758029923,103.30665725441584,104.40438692853245,105.50211660264904,106.59984627676565,107.69757595088227,108.79530562499887,109.89303529911548,110.99076497323207,112.08849464734868,113.18622432146529,114.28395399558191,115.3816836696985,116.47941334381512,117.57714301793172,118.67487269204833,119.77260236616495],"text":["csorun: -200.000000<br />belirtiler:  55.00655<br />destek: dusuk","csorun: -193.220339<br />belirtiler:  56.10428<br />destek: dusuk","csorun: -186.440678<br />belirtiler:  57.20201<br />destek: dusuk","csorun: -179.661017<br />belirtiler:  58.29974<br />destek: dusuk","csorun: -172.881356<br />belirtiler:  59.39747<br />destek: dusuk","csorun: -166.101695<br />belirtiler:  60.49520<br />destek: dusuk","csorun: -159.322034<br />belirtiler:  61.59293<br />destek: dusuk","csorun: -152.542373<br />belirtiler:  62.69066<br />destek: dusuk","csorun: -145.762712<br />belirtiler:  63.78839<br />destek: dusuk","csorun: -138.983051<br />belirtiler:  64.88612<br />destek: dusuk","csorun: -132.203390<br />belirtiler:  65.98385<br />destek: dusuk","csorun: -125.423729<br />belirtiler:  67.08158<br />destek: dusuk","csorun: -118.644068<br />belirtiler:  68.17931<br />destek: dusuk","csorun: -111.864407<br />belirtiler:  69.27704<br />destek: dusuk","csorun: -105.084746<br />belirtiler:  70.37477<br />destek: dusuk","csorun:  -98.305085<br />belirtiler:  71.47250<br />destek: dusuk","csorun:  -91.525424<br />belirtiler:  72.57023<br />destek: dusuk","csorun:  -84.745763<br />belirtiler:  73.66796<br />destek: dusuk","csorun:  -77.966102<br />belirtiler:  74.76569<br />destek: dusuk","csorun:  -71.186441<br />belirtiler:  75.86342<br />destek: dusuk","csorun:  -64.406780<br />belirtiler:  76.96115<br />destek: dusuk","csorun:  -57.627119<br />belirtiler:  78.05887<br />destek: dusuk","csorun:  -50.847458<br />belirtiler:  79.15660<br />destek: dusuk","csorun:  -44.067797<br />belirtiler:  80.25433<br />destek: dusuk","csorun:  -37.288136<br />belirtiler:  81.35206<br />destek: dusuk","csorun:  -30.508475<br />belirtiler:  82.44979<br />destek: dusuk","csorun:  -23.728814<br />belirtiler:  83.54752<br />destek: dusuk","csorun:  -16.949153<br />belirtiler:  84.64525<br />destek: dusuk","csorun:  -10.169492<br />belirtiler:  85.74298<br />destek: dusuk","csorun:   -3.389831<br />belirtiler:  86.84071<br />destek: dusuk","csorun:    3.389831<br />belirtiler:  87.93844<br />destek: dusuk","csorun:   10.169492<br />belirtiler:  89.03617<br />destek: dusuk","csorun:   16.949153<br />belirtiler:  90.13390<br />destek: dusuk","csorun:   23.728814<br />belirtiler:  91.23163<br />destek: dusuk","csorun:   30.508475<br />belirtiler:  92.32936<br />destek: dusuk","csorun:   37.288136<br />belirtiler:  93.42709<br />destek: dusuk","csorun:   44.067797<br />belirtiler:  94.52482<br />destek: dusuk","csorun:   50.847458<br />belirtiler:  95.62255<br />destek: dusuk","csorun:   57.627119<br />belirtiler:  96.72028<br />destek: dusuk","csorun:   64.406780<br />belirtiler:  97.81801<br />destek: dusuk","csorun:   71.186441<br />belirtiler:  98.91574<br />destek: dusuk","csorun:   77.966102<br />belirtiler: 100.01347<br />destek: dusuk","csorun:   84.745763<br />belirtiler: 101.11120<br />destek: dusuk","csorun:   91.525424<br />belirtiler: 102.20893<br />destek: dusuk","csorun:   98.305085<br />belirtiler: 103.30666<br />destek: dusuk","csorun:  105.084746<br />belirtiler: 104.40439<br />destek: dusuk","csorun:  111.864407<br />belirtiler: 105.50212<br />destek: dusuk","csorun:  118.644068<br />belirtiler: 106.59985<br />destek: dusuk","csorun:  125.423729<br />belirtiler: 107.69758<br />destek: dusuk","csorun:  132.203390<br />belirtiler: 108.79531<br />destek: dusuk","csorun:  138.983051<br />belirtiler: 109.89304<br />destek: dusuk","csorun:  145.762712<br />belirtiler: 110.99076<br />destek: dusuk","csorun:  152.542373<br />belirtiler: 112.08849<br />destek: dusuk","csorun:  159.322034<br />belirtiler: 113.18622<br />destek: dusuk","csorun:  166.101695<br />belirtiler: 114.28395<br />destek: dusuk","csorun:  172.881356<br />belirtiler: 115.38168<br />destek: dusuk","csorun:  179.661017<br />belirtiler: 116.47941<br />destek: dusuk","csorun:  186.440678<br />belirtiler: 117.57714<br />destek: dusuk","csorun:  193.220339<br />belirtiler: 118.67487<br />destek: dusuk","csorun:  200.000000<br />belirtiler: 119.77260<br />destek: dusuk"],"type":"scatter","mode":"lines","line":{"width":1.8897637795275593,"color":"rgba(248,118,109,1)","dash":"solid"},"hoveron":"points","name":"dusuk","legendgroup":"dusuk","showlegend":true,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[-200,-193.22033898305085,-186.4406779661017,-179.66101694915255,-172.88135593220341,-166.10169491525426,-159.32203389830508,-152.54237288135593,-145.76271186440678,-138.98305084745763,-132.20338983050848,-125.42372881355932,-118.64406779661017,-111.86440677966102,-105.08474576271186,-98.305084745762713,-91.525423728813564,-84.745762711864415,-77.966101694915267,-71.186440677966118,-64.406779661016969,-57.627118644067792,-50.847457627118644,-44.067796610169495,-37.288135593220346,-30.508474576271198,-23.728813559322049,-16.9491525423729,-10.169491525423723,-3.3898305084745743,3.3898305084745743,10.169491525423723,16.949152542372872,23.72881355932202,30.508474576271169,37.288135593220318,44.067796610169466,50.847457627118644,57.627118644067764,64.406779661016913,71.186440677966061,77.966101694915267,84.745762711864415,91.525423728813564,98.305084745762713,105.08474576271186,111.86440677966101,118.64406779661016,125.42372881355931,132.20338983050846,138.9830508474576,145.76271186440675,152.5423728813559,159.32203389830505,166.1016949152542,172.88135593220335,179.66101694915255,186.4406779661017,193.22033898305085,200],"y":[72.396610497096916,72.979265718704909,73.561920940312902,74.144576161920881,74.727231383528874,75.309886605136867,75.892541826744861,76.475197048352854,77.057852269960847,77.640507491568826,78.223162713176819,78.805817934784812,79.388473156392806,79.971128378000799,80.553783599608778,81.136438821216771,81.719094042824764,82.301749264432758,82.884404486040751,83.46705970764873,84.049714929256723,84.632370150864716,85.215025372472709,85.797680594080703,86.380335815688682,86.962991037296675,87.545646258904668,88.128301480512661,88.710956702120654,89.293611923728648,89.876267145336627,90.45892236694462,91.041577588552613,91.624232810160606,92.206888031768599,92.789543253376578,93.372198474984572,93.954853696592565,94.537508918200558,95.120164139808537,95.70281936141653,96.285474583024524,96.868129804632517,97.45078502624051,98.033440247848503,98.616095469456496,99.198750691064475,99.781405912672469,100.36406113428046,100.94671635588846,101.52937157749645,102.11202679910443,102.69468202071242,103.27733724232041,103.85999246392841,104.44264768553639,105.02530290714439,105.60795812875237,106.19061335036037,106.77326857196836],"text":["csorun: -200.000000<br />belirtiler:  72.39661<br />destek: orta","csorun: -193.220339<br />belirtiler:  72.97927<br />destek: orta","csorun: -186.440678<br />belirtiler:  73.56192<br />destek: orta","csorun: -179.661017<br />belirtiler:  74.14458<br />destek: orta","csorun: -172.881356<br />belirtiler:  74.72723<br />destek: orta","csorun: -166.101695<br />belirtiler:  75.30989<br />destek: orta","csorun: -159.322034<br />belirtiler:  75.89254<br />destek: orta","csorun: -152.542373<br />belirtiler:  76.47520<br />destek: orta","csorun: -145.762712<br />belirtiler:  77.05785<br />destek: orta","csorun: -138.983051<br />belirtiler:  77.64051<br />destek: orta","csorun: -132.203390<br />belirtiler:  78.22316<br />destek: orta","csorun: -125.423729<br />belirtiler:  78.80582<br />destek: orta","csorun: -118.644068<br />belirtiler:  79.38847<br />destek: orta","csorun: -111.864407<br />belirtiler:  79.97113<br />destek: orta","csorun: -105.084746<br />belirtiler:  80.55378<br />destek: orta","csorun:  -98.305085<br />belirtiler:  81.13644<br />destek: orta","csorun:  -91.525424<br />belirtiler:  81.71909<br />destek: orta","csorun:  -84.745763<br />belirtiler:  82.30175<br />destek: orta","csorun:  -77.966102<br />belirtiler:  82.88440<br />destek: orta","csorun:  -71.186441<br />belirtiler:  83.46706<br />destek: orta","csorun:  -64.406780<br />belirtiler:  84.04971<br />destek: orta","csorun:  -57.627119<br />belirtiler:  84.63237<br />destek: orta","csorun:  -50.847458<br />belirtiler:  85.21503<br />destek: orta","csorun:  -44.067797<br />belirtiler:  85.79768<br />destek: orta","csorun:  -37.288136<br />belirtiler:  86.38034<br />destek: orta","csorun:  -30.508475<br />belirtiler:  86.96299<br />destek: orta","csorun:  -23.728814<br />belirtiler:  87.54565<br />destek: orta","csorun:  -16.949153<br />belirtiler:  88.12830<br />destek: orta","csorun:  -10.169492<br />belirtiler:  88.71096<br />destek: orta","csorun:   -3.389831<br />belirtiler:  89.29361<br />destek: orta","csorun:    3.389831<br />belirtiler:  89.87627<br />destek: orta","csorun:   10.169492<br />belirtiler:  90.45892<br />destek: orta","csorun:   16.949153<br />belirtiler:  91.04158<br />destek: orta","csorun:   23.728814<br />belirtiler:  91.62423<br />destek: orta","csorun:   30.508475<br />belirtiler:  92.20689<br />destek: orta","csorun:   37.288136<br />belirtiler:  92.78954<br />destek: orta","csorun:   44.067797<br />belirtiler:  93.37220<br />destek: orta","csorun:   50.847458<br />belirtiler:  93.95485<br />destek: orta","csorun:   57.627119<br />belirtiler:  94.53751<br />destek: orta","csorun:   64.406780<br />belirtiler:  95.12016<br />destek: orta","csorun:   71.186441<br />belirtiler:  95.70282<br />destek: orta","csorun:   77.966102<br />belirtiler:  96.28547<br />destek: orta","csorun:   84.745763<br />belirtiler:  96.86813<br />destek: orta","csorun:   91.525424<br />belirtiler:  97.45079<br />destek: orta","csorun:   98.305085<br />belirtiler:  98.03344<br />destek: orta","csorun:  105.084746<br />belirtiler:  98.61610<br />destek: orta","csorun:  111.864407<br />belirtiler:  99.19875<br />destek: orta","csorun:  118.644068<br />belirtiler:  99.78141<br />destek: orta","csorun:  125.423729<br />belirtiler: 100.36406<br />destek: orta","csorun:  132.203390<br />belirtiler: 100.94672<br />destek: orta","csorun:  138.983051<br />belirtiler: 101.52937<br />destek: orta","csorun:  145.762712<br />belirtiler: 102.11203<br />destek: orta","csorun:  152.542373<br />belirtiler: 102.69468<br />destek: orta","csorun:  159.322034<br />belirtiler: 103.27734<br />destek: orta","csorun:  166.101695<br />belirtiler: 103.85999<br />destek: orta","csorun:  172.881356<br />belirtiler: 104.44265<br />destek: orta","csorun:  179.661017<br />belirtiler: 105.02530<br />destek: orta","csorun:  186.440678<br />belirtiler: 105.60796<br />destek: orta","csorun:  193.220339<br />belirtiler: 106.19061<br />destek: orta","csorun:  200.000000<br />belirtiler: 106.77327<br />destek: orta"],"type":"scatter","mode":"lines","line":{"width":1.8897637795275593,"color":"rgba(0,186,56,1)","dash":"solid"},"hoveron":"points","name":"orta","legendgroup":"orta","showlegend":true,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[-200,-193.22033898305085,-186.4406779661017,-179.66101694915255,-172.88135593220341,-166.10169491525426,-159.32203389830508,-152.54237288135593,-145.76271186440678,-138.98305084745763,-132.20338983050848,-125.42372881355932,-118.64406779661017,-111.86440677966102,-105.08474576271186,-98.305084745762713,-91.525423728813564,-84.745762711864415,-77.966101694915267,-71.186440677966118,-64.406779661016969,-57.627118644067792,-50.847457627118644,-44.067796610169495,-37.288135593220346,-30.508474576271198,-23.728813559322049,-16.9491525423729,-10.169491525423723,-3.3898305084745743,3.3898305084745743,10.169491525423723,16.949152542372872,23.72881355932202,30.508474576271169,37.288135593220318,44.067796610169466,50.847457627118644,57.627118644067764,64.406779661016913,71.186440677966061,77.966101694915267,84.745762711864415,91.525423728813564,98.305084745762713,105.08474576271186,111.86440677966101,118.64406779661016,125.42372881355931,132.20338983050846,138.9830508474576,145.76271186440675,152.5423728813559,159.32203389830505,166.1016949152542,172.88135593220335,179.66101694915255,186.4406779661017,193.22033898305085,200],"y":[89.786669400908707,89.854250170008072,89.921830939107451,89.989411708206816,90.056992477306196,90.124573246405575,90.19215401550494,90.259734784604319,90.327315553703698,90.394896322803064,90.462477091902443,90.530057861001822,90.597638630101187,90.665219399200566,90.732800168299931,90.800380937399311,90.86796170649869,90.935542475598069,91.003123244697449,91.070704013796799,91.138284782896179,91.205865551995558,91.273446321094937,91.341027090194316,91.408607859293681,91.476188628393047,91.543769397492426,91.611350166591805,91.678930935691184,91.746511704790564,91.814092473889914,91.881673242989294,91.949254012088673,92.016834781188052,92.084415550287432,92.151996319386797,92.219577088486176,92.287157857585541,92.35473862668492,92.422319395784285,92.489900164883665,92.55748093398303,92.625061703082409,92.692642472181788,92.760223241281167,92.827804010380547,92.895384779479912,92.962965548579291,93.030546317678656,93.098127086778035,93.165707855877415,93.23328862497678,93.300869394076159,93.368450163175538,93.436030932274903,93.503611701374268,93.571192470473662,93.638773239573027,93.706354008672406,93.773934777771771],"text":["csorun: -200.000000<br />belirtiler:  89.78667<br />destek: yuksek","csorun: -193.220339<br />belirtiler:  89.85425<br />destek: yuksek","csorun: -186.440678<br />belirtiler:  89.92183<br />destek: yuksek","csorun: -179.661017<br />belirtiler:  89.98941<br />destek: yuksek","csorun: -172.881356<br />belirtiler:  90.05699<br />destek: yuksek","csorun: -166.101695<br />belirtiler:  90.12457<br />destek: yuksek","csorun: -159.322034<br />belirtiler:  90.19215<br />destek: yuksek","csorun: -152.542373<br />belirtiler:  90.25973<br />destek: yuksek","csorun: -145.762712<br />belirtiler:  90.32732<br />destek: yuksek","csorun: -138.983051<br />belirtiler:  90.39490<br />destek: yuksek","csorun: -132.203390<br />belirtiler:  90.46248<br />destek: yuksek","csorun: -125.423729<br />belirtiler:  90.53006<br />destek: yuksek","csorun: -118.644068<br />belirtiler:  90.59764<br />destek: yuksek","csorun: -111.864407<br />belirtiler:  90.66522<br />destek: yuksek","csorun: -105.084746<br />belirtiler:  90.73280<br />destek: yuksek","csorun:  -98.305085<br />belirtiler:  90.80038<br />destek: yuksek","csorun:  -91.525424<br />belirtiler:  90.86796<br />destek: yuksek","csorun:  -84.745763<br />belirtiler:  90.93554<br />destek: yuksek","csorun:  -77.966102<br />belirtiler:  91.00312<br />destek: yuksek","csorun:  -71.186441<br />belirtiler:  91.07070<br />destek: yuksek","csorun:  -64.406780<br />belirtiler:  91.13828<br />destek: yuksek","csorun:  -57.627119<br />belirtiler:  91.20587<br />destek: yuksek","csorun:  -50.847458<br />belirtiler:  91.27345<br />destek: yuksek","csorun:  -44.067797<br />belirtiler:  91.34103<br />destek: yuksek","csorun:  -37.288136<br />belirtiler:  91.40861<br />destek: yuksek","csorun:  -30.508475<br />belirtiler:  91.47619<br />destek: yuksek","csorun:  -23.728814<br />belirtiler:  91.54377<br />destek: yuksek","csorun:  -16.949153<br />belirtiler:  91.61135<br />destek: yuksek","csorun:  -10.169492<br />belirtiler:  91.67893<br />destek: yuksek","csorun:   -3.389831<br />belirtiler:  91.74651<br />destek: yuksek","csorun:    3.389831<br />belirtiler:  91.81409<br />destek: yuksek","csorun:   10.169492<br />belirtiler:  91.88167<br />destek: yuksek","csorun:   16.949153<br />belirtiler:  91.94925<br />destek: yuksek","csorun:   23.728814<br />belirtiler:  92.01683<br />destek: yuksek","csorun:   30.508475<br />belirtiler:  92.08442<br />destek: yuksek","csorun:   37.288136<br />belirtiler:  92.15200<br />destek: yuksek","csorun:   44.067797<br />belirtiler:  92.21958<br />destek: yuksek","csorun:   50.847458<br />belirtiler:  92.28716<br />destek: yuksek","csorun:   57.627119<br />belirtiler:  92.35474<br />destek: yuksek","csorun:   64.406780<br />belirtiler:  92.42232<br />destek: yuksek","csorun:   71.186441<br />belirtiler:  92.48990<br />destek: yuksek","csorun:   77.966102<br />belirtiler:  92.55748<br />destek: yuksek","csorun:   84.745763<br />belirtiler:  92.62506<br />destek: yuksek","csorun:   91.525424<br />belirtiler:  92.69264<br />destek: yuksek","csorun:   98.305085<br />belirtiler:  92.76022<br />destek: yuksek","csorun:  105.084746<br />belirtiler:  92.82780<br />destek: yuksek","csorun:  111.864407<br />belirtiler:  92.89538<br />destek: yuksek","csorun:  118.644068<br />belirtiler:  92.96297<br />destek: yuksek","csorun:  125.423729<br />belirtiler:  93.03055<br />destek: yuksek","csorun:  132.203390<br />belirtiler:  93.09813<br />destek: yuksek","csorun:  138.983051<br />belirtiler:  93.16571<br />destek: yuksek","csorun:  145.762712<br />belirtiler:  93.23329<br />destek: yuksek","csorun:  152.542373<br />belirtiler:  93.30087<br />destek: yuksek","csorun:  159.322034<br />belirtiler:  93.36845<br />destek: yuksek","csorun:  166.101695<br />belirtiler:  93.43603<br />destek: yuksek","csorun:  172.881356<br />belirtiler:  93.50361<br />destek: yuksek","csorun:  179.661017<br />belirtiler:  93.57119<br />destek: yuksek","csorun:  186.440678<br />belirtiler:  93.63877<br />destek: yuksek","csorun:  193.220339<br />belirtiler:  93.70635<br />destek: yuksek","csorun:  200.000000<br />belirtiler:  93.77393<br />destek: yuksek"],"type":"scatter","mode":"lines","line":{"width":1.8897637795275593,"color":"rgba(97,156,255,1)","dash":"solid"},"hoveron":"points","name":"yuksek","legendgroup":"yuksek","showlegend":true,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null}],"layout":{"margin":{"t":26.228310502283104,"r":7.3059360730593621,"b":40.182648401826491,"l":43.105022831050235},"plot_bgcolor":"rgba(255,255,255,1)","paper_bgcolor":"rgba(255,255,255,1)","font":{"color":"rgba(0,0,0,1)","family":"","size":14.611872146118724},"xaxis":{"domain":[0,1],"automargin":true,"type":"linear","autorange":false,"range":[-220,220],"tickmode":"array","ticktext":["-200","-100","0","100","200"],"tickvals":[-200,-100.00000000000001,0,100,200],"categoryorder":"array","categoryarray":["-200","-100","0","100","200"],"nticks":null,"ticks":"outside","tickcolor":"rgba(51,51,51,1)","ticklen":3.6529680365296811,"tickwidth":0.66417600664176002,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":11.68949771689498},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"gridcolor":"rgba(235,235,235,1)","gridwidth":0.66417600664176002,"zeroline":false,"anchor":"y","title":{"text":"csorun","font":{"color":"rgba(0,0,0,1)","family":"","size":14.611872146118724}},"hoverformat":".2f"},"yaxis":{"domain":[0,1],"automargin":true,"type":"linear","autorange":false,"range":[51.768249054641139,123.01090490480894],"tickmode":"array","ticktext":["60","80","100","120"],"tickvals":[60,80,100,120],"categoryorder":"array","categoryarray":["60","80","100","120"],"nticks":null,"ticks":"outside","tickcolor":"rgba(51,51,51,1)","ticklen":3.6529680365296811,"tickwidth":0.66417600664176002,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":11.68949771689498},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"gridcolor":"rgba(235,235,235,1)","gridwidth":0.66417600664176002,"zeroline":false,"anchor":"x","title":{"text":"belirtiler","font":{"color":"rgba(0,0,0,1)","family":"","size":14.611872146118724}},"hoverformat":".2f"},"shapes":[{"type":"rect","fillcolor":"transparent","line":{"color":"rgba(51,51,51,1)","width":0.66417600664176002,"linetype":"solid"},"yref":"paper","xref":"paper","x0":0,"x1":1,"y0":0,"y1":1}],"showlegend":true,"legend":{"bgcolor":"rgba(255,255,255,1)","bordercolor":"transparent","borderwidth":1.8897637795275593,"font":{"color":"rgba(0,0,0,1)","family":"","size":11.68949771689498},"title":{"text":"destek","font":{"color":"rgba(0,0,0,1)","family":"","size":14.611872146118724}}},"hovermode":"closest","barmode":"relative"},"config":{"doubleClick":"reset","modeBarButtonsToAdd":["hoverclosest","hovercompare"],"showSendToCloud":false},"source":"A","attrs":{"49b021635e95":{"x":{},"y":{},"colour":{},"type":"scatter"}},"cur_data":"49b021635e95","visdat":{"49b021635e95":["function (y) ","x"]},"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.20000000000000001,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot","plotly_sunburstclick"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script>
```


require(stats); require(graphics)
pairs(LifeCycleSavings, panel = panel.smooth,
      main = "LifeCycleSavings data")
fm1 <- lm(sr ~ pop15 + pop75 + dpi + ddpi, data = LifeCycleSavings)
summary(fm1)


sr_3 <- lm(sr ~ pop75 + dpi + ddpi, data = LifeCycleSavings)
summary(sr_3)$residuals
pop15_3 <- lm(pop15 ~ pop75 + dpi + ddpi, data = LifeCycleSavings)
summary(pop15_3)$residuals
model_last <- lm(summary(sr_3)$residuals ~ summary(pop15_3)$residuals)
round(model_last$coefficients,3)


